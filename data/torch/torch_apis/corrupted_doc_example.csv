API,Example,Bug
"
 torch. as_tensor ( data ,  dtype ,  device )   → ¶",">>> a=numpy.array([1,2,3])
>>> t=torch.as_tensor(a)
>>> t
tensor([ 1,  2,  3])
>>> t[0]=-1
>>> a
array([-1,  2,  3])>>> a=numpy.array([1,2,3])
>>> t=torch.as_tensor(a,device=torch.device('cuda'))
>>> t
tensor([ 1,  2,  3])
>>> t[0]=-1
>>> a
array([1,  2,  3])
","  File ""example.py"", line 7
    array([-1,  2,  3])a=numpy.array([1,2,3])
                       ^
SyntaxError: invalid syntax
"
"
 torch. set_default_tensor_type ( t ) [source] ¶",">>> torch.tensor([1.2,3]).dtype
>>> torch.set_default_tensor_type(torch.DoubleTensor)
","Traceback (most recent call last):
  File ""/home/nimashiri/.local/lib/python3.8/site-packages/torch/decorate_func.py"", line 13, in json_serialize
    json.dumps(v)
  File ""/usr/lib/python3.8/json/__init__.py"", line 231, in dumps
    return _default_encoder.encode(obj)
  File ""/usr/lib/python3.8/json/encoder.py"", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File ""/usr/lib/python3.8/json/encoder.py"", line 257, in iterencode
    return _iterencode(o, 0)
  File ""/usr/lib/python3.8/json/encoder.py"", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type tensortype is not JSON serializable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/nimashiri/.local/lib/python3.8/site-packages/torch/decorate_func.py"", line 56, in get_var_shape
    return list(s)  # convert torch.Size to list
TypeError: 'getset_descriptor' object is not iterable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    torch.set_default_tensor_type(torch.DoubleTensor)
  File ""/home/nimashiri/.local/lib/python3.8/site-packages/torch/decorate_func.py"", line 102, in wrapper
    param_dict = build_param_dict(*args, **kwargs)
  File ""/home/nimashiri/.local/lib/python3.8/site-packages/torch/decorate_func.py"", line 42, in build_param_dict
    param_dict['parameter:%d' % ind] = json_serialize(arg)
  File ""/home/nimashiri/.local/lib/python3.8/site-packages/torch/decorate_func.py"", line 17, in json_serialize
    return get_var_signature(
  File ""/home/nimashiri/.local/lib/python3.8/site-packages/torch/decorate_func.py"", line 88, in get_var_signature
    s['shape'] = get_var_shape(var)
  File ""/home/nimashiri/.local/lib/python3.8/site-packages/torch/decorate_func.py"", line 58, in get_var_shape
    print(e.message)
AttributeError: 'TypeError' object has no attribute 'message'
"
"
 torch. randint ( low=0 ,  high ,  size ,  \* ,  generator=None ,  out=None ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False )   → ¶",">>> torch.randint(3,5,(3,))
>>> torch.randint(10,(2,2))
>>> torch.randint(3,10,(2,2))","  File ""example.py"", line 3
    tensor([4, 3, 4])torch.randint(10,(2,2))
                     ^
SyntaxError: invalid syntax
"
"
 torch. tensor ( data ,  * ,  dtype ,  device ,  requires_grad ,  pin_memory )   → ¶",">>> torch.tensor([[0.1,1.2],[2.2,3.1],[4.9,5.2]])
>>> torch.tensor([0,1])# Type inference on data
>>> torch.tensor([[0.11111,0.222222,0.3333333]], dtype=torch.float64, device=torch.device('cuda:0'))
>>> torch.tensor(3.14159)
","  File ""example.py"", line 3
    [ 4.9000,  5.2000]])torch.tensor([0,1])# Type inference on data
    ^
IndentationError: unexpected indent
"
"
 torch. sparse_coo_tensor ( indices ,  values ,  size ,  * ,  dtype ,  device ,  requires_grad )   → ¶",">>> i=torch.tensor([[0,1,1],[2,0,2]])
>>> v=torch.tensor([3,4,5],dtype=torch.float32)
>>> torch.sparse_coo_tensor(i,v,[2,4])
>>> torch.sparse_coo_tensor(i,v)# Shape inference
tensor(indices=tensor([[0, 1, 1],
                       [2, 0, 2]]),
       values=tensor([3., 4., 5.]),
       Size=(2, 3), nnz=3, layout=torch.sparse_coo)>>> torch.sparse_coo_tensor(i,v,[2,4],
... dtype=torch.float64,
... device=torch.device('cuda:0'))
tensor(indices=tensor([[0, 1, 1],
                       [2, 0, 2]]),
       values=tensor([3., 4., 5.]),
       device='cuda:0', size=(2, 4), nnz=3, dtype=torch.float64,
       layout=torch.sparse_coo)# Create an empty sparse tensor with the following invariants:
#   1. sparse_dim + dense_dim = len(SparseTensor.shape)
#   2. SparseTensor._indices().shape = (sparse_dim, nnz)
#   3. SparseTensor._values().shape = (nnz, SparseTensor.shape[sparse_dim:])
#
# For instance, to create an empty sparse tensor with nnz = 0, dense_dim = 0 and
# sparse_dim = 1 (hence indices is a 2D tensor of shape = (1, 0))
>>> S=torch.sparse_coo_tensor(torch.empty([1,0]),[],[1])
tensor(indices=tensor([], size=(1, 0)),
       values=tensor([], size=(0,)),
       size=(1,), nnz=0, layout=torch.sparse_coo)# and to create an empty sparse tensor with nnz = 0, dense_dim = 1 and
# sparse_dim = 1
>>> S=torch.sparse_coo_tensor(torch.empty([1,0]),torch.empty([0,2]),[1,2])
tensor(indices=tensor([], size=(1, 0)),
       values=tensor([], size=(0, 2)),
       size=(1, 2), nnz=0, layout=torch.sparse_coo)
","  File ""example.py"", line 3
    v=torch.tensor([3,4,5],dtype=torch.float32)
     ^
SyntaxError: invalid syntax
"
"
 torch. asarray ( obj ,  * ,  dtype ,  device ,  copy ,  requires_grad )   → ¶",">>> a=torch.tensor([1,2,3])
>>> # Shares memory with tensor 'a'
>>> b=torch.asarray(a)
>>> a.data_ptr()==b.data_ptr()
True
>>> # Forces memory copy
>>> c=torch.asarray(a,copy=True)
>>> a.data_ptr()==c.data_ptr()
False>>> a=torch.tensor([1,2,3],requires_grad=True).float()
>>> b=a+2
>>> b
tensor([1., 2., 3.], grad_fn=<AddBackward0>)
>>> # Shares memory with tensor 'b', with no grad
>>> c=torch.asarray(b)
>>> c
tensor([1., 2., 3.])
>>> # Shares memory with tensor 'b', retaining autograd history
>>> d=torch.asarray(b,requires_grad=True)
>>> d
tensor([1., 2., 3.], grad_fn=<AddBackward0>)>>> array=numpy.array([1,2,3])
>>> # Shares memory with array 'array'
>>> t1=torch.asarray(array)
>>> array.__array_interface__['data'][0]==t1.data_ptr()
True
>>> # Copies memory due to dtype mismatch
>>> t2=torch.asarray(array,dtype=torch.float32)
>>> array.__array_interface__['data'][0]==t1.data_ptr()
False
","  File ""example.py"", line 18
    tensor([1., 2., 3.], grad_fn=<AddBackward0>)array=numpy.array([1,2,3])
                                 ^
SyntaxError: invalid syntax
"
"
 torch. as_tensor ( data ,  dtype ,  device )   → ¶",">>> a=numpy.array([1,2,3])
>>> t=torch.as_tensor(a)
>>> t
tensor([ 1,  2,  3])
>>> t[0]=-1
>>> a
array([-1,  2,  3])>>> a=numpy.array([1,2,3])
>>> t=torch.as_tensor(a,device=torch.device('cuda'))
>>> t
tensor([ 1,  2,  3])
>>> t[0]=-1
>>> a
array([1,  2,  3])
","  File ""example.py"", line 7
    array([-1,  2,  3])a=numpy.array([1,2,3])
                       ^
SyntaxError: invalid syntax
"
"
 torch. from_numpy ( ndarray )   → ¶",">>> a=numpy.array([1,2,3])
>>> t=torch.from_numpy(a)
>>> t
tensor([ 1,  2,  3])
>>> t[0]=-1
>>> a
array([-1,  2,  3])
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    a=numpy.array([1,2,3])
NameError: name 'numpy' is not defined
"
"
 torch. frombuffer ( buffer ,  * ,  dtype ,  count ,  offset ,  requires_grad )   → ¶",">>> importarray
>>> a=array.array('i',[1,2,3])
>>> t=torch.frombuffer(a,dtype=torch.int32)
>>> t
tensor([ 1,  2,  3])
>>> t[0]=-1
>>> a
array([-1,  2,  3])>>> # Interprets the signed char bytes as 32-bit integers.
>>> # Each 4 signed char elements will be interpreted as
>>> # 1 signed 32-bit integer.
>>> importarray
>>> a=array.array('b',[-1,0,0,0])
>>> torch.frombuffer(a,dtype=torch.int32)
tensor([255], dtype=torch.int32)
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    importarray
NameError: name 'importarray' is not defined
"
"
 torch. zeros ( *size ,  * ,  out=None ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False )   → ¶",">>> torch.zeros(2,3)
tensor([[ 0.,  0.,  0.],
        [ 0.,  0.,  0.]])>>> torch.zeros(5)
tensor([ 0.,  0.,  0.,  0.,  0.])
","  File ""example.py"", line 3
    [ 0.,  0.,  0.]])torch.zeros(5)
    ^
IndentationError: unexpected indent
"
"
 torch. ones ( *size ,  * ,  out=None ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False )   → ¶",">>> torch.ones(2,3)
tensor([[ 1.,  1.,  1.],
        [ 1.,  1.,  1.]])>>> torch.ones(5)
tensor([ 1.,  1.,  1.,  1.,  1.])
","  File ""example.py"", line 3
    [ 1.,  1.,  1.]])torch.ones(5)
    ^
IndentationError: unexpected indent
"
"
 torch. range ( start=0 ,  end ,  step=1 ,  * ,  out=None ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False )   → ¶",">>> torch.range(1,4)
tensor([ 1.,  2.,  3.,  4.])
>>> torch.range(1,4,0.5)
tensor([ 1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  3.5000,  4.0000])
","/home/nimashiri/.local/lib/python3.8/site-packages/torch/decorate_func.py:99: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  outputs = func(*args, **kwargs)
"
"
 torch. polar ( abs ,  angle ,  * ,  out )   → ¶",">>> importnumpyasnp
>>> abs=torch.tensor([1,2],dtype=torch.float64)
>>> angle=torch.tensor([np.pi/2,5*np.pi/4],dtype=torch.float64)
>>> z=torch.polar(abs,angle)
>>> z
tensor([(0.0000+1.0000j), (-1.4142-1.4142j)], dtype=torch.complex128)
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    importnumpyasnp
NameError: name 'importnumpyasnp' is not defined
"
"
 torch. argwhere ( input )   → ¶",">>> t=torch.tensor([1,0,1])
>>> torch.argwhere(t)
tensor([[0],
        [2]])
>>> t=torch.tensor([[1,0,1],[0,1,1]])
>>> torch.argwhere(t)
tensor([[0, 0],
        [0, 2],
        [1, 1],
        [1, 2]])
","Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    torch.argwhere(t)
AttributeError: module 'torch' has no attribute 'argwhere'
"
"
 torch. conj ( input )   → ¶",">>> x=torch.tensor([-1+1j,-2+2j,3-3j])
>>> x.is_conj()
False
>>> y=torch.conj(x)
>>> y.is_conj()
True
","Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    x.is_conj()
AttributeError: 'Tensor' object has no attribute 'is_conj'
"
"
 Tensor. index_add_ ( dim ,  index ,  source ,  * ,  alpha )   → ¶",">>> x=torch.ones(5,3)
>>> t=torch.tensor([[1,2,3],[4,5,6],[7,8,9]],dtype=torch.float)
>>> index=torch.tensor([0,4,2])
>>> x.index_add_(0,index,t)
tensor([[  2.,   3.,   4.],
        [  1.,   1.,   1.],
        [  8.,   9.,  10.],
        [  1.,   1.,   1.],
        [  5.,   6.,   7.]])
>>> x.index_add_(0,index,t,alpha=-1)
tensor([[  1.,   1.,   1.],
        [  1.,   1.,   1.],
        [  1.,   1.,   1.],
        [  1.,   1.,   1.],
        [  1.,   1.,   1.]])
","Traceback (most recent call last):
  File ""example.py"", line 6, in <module>
    x.index_add_(0,index,t,alpha=-1)
  File ""/home/nimashiri/.local/lib/python3.8/site-packages/torch/decorate_func.py"", line 99, in wrapper
    outputs = func(*args, **kwargs)
TypeError: index_add_() got an unexpected keyword argument 'alpha'
"
"
 Tensor. index_reduce_ ( dim ,  index ,  source ,  reduce ,  * ,  include_self )   → ¶",">>> x=torch.empty(5,3).fill_(2)
>>> t=torch.tensor([[1,2,3],[4,5,6],[7,8,9],[10,11,12]],dtype=torch.float)
>>> index=torch.tensor([0,4,2,0])
>>> x.index_reduce_(0,index,t,'prod')
tensor([[20., 44., 72.],
        [ 2.,  2.,  2.],
        [14., 16., 18.],
        [ 2.,  2.,  2.],
        [ 8., 10., 12.]])
>>> x=torch.empty(5,3).fill_(2)
>>> x.index_reduce_(0,index,t,'prod',include_self=False)
tensor([[10., 22., 36.],
        [ 2.,  2.,  2.],
        [ 7.,  8.,  9.],
        [ 2.,  2.,  2.],
        [ 4.,  5.,  6.]])
","Traceback (most recent call last):
  File ""example.py"", line 5, in <module>
    x.index_reduce_(0,index,t,'prod')
AttributeError: 'Tensor' object has no attribute 'index_reduce_'
"
"
 torch. nonzero ( input ,  * ,  out ,  as_tuple )   → ¶",">>> torch.nonzero(torch.tensor([1,1,1,0,1]))
tensor([[ 0],
        [ 1],
        [ 2],
        [ 4]])
>>> torch.nonzero(torch.tensor([[0.6,0.0,0.0,0.0],
... [0.0,0.4,0.0,0.0],
... [0.0,0.0,1.2,0.0],
... [0.0,0.0,0.0,-0.4]]))
tensor([[ 0,  0],
        [ 1,  1],
        [ 2,  2],
        [ 3,  3]])
>>> torch.nonzero(torch.tensor([1,1,1,0,1]),as_tuple=True)
(tensor([0, 1, 2, 4]),)
>>> torch.nonzero(torch.tensor([[0.6,0.0,0.0,0.0],
... [0.0,0.4,0.0,0.0],
... [0.0,0.0,1.2,0.0],
... [0.0,0.0,0.0,-0.4]]),as_tuple=True)
(tensor([0, 1, 2, 3]), tensor([0, 1, 2, 3]))
>>> torch.nonzero(torch.tensor(5),as_tuple=True)
(tensor([0]),)
","  File ""example.py"", line 5
    torch.nonzero(torch.tensor([[0.6,0.0,0.0,0.0],
    ^
SyntaxError: invalid syntax
"
"
 Tensor. scatter_ ( dim ,  index ,  src ,  reduce )   → ¶",">>> src=torch.arange(1,11).reshape((2,5))
>>> src
tensor([[ 1,  2,  3,  4,  5],
        [ 6,  7,  8,  9, 10]])
>>> index=torch.tensor([[0,1,2,0]])
>>> torch.zeros(3,5,dtype=src.dtype).scatter_(0,index,src)
tensor([[1, 0, 0, 4, 0],
        [0, 2, 0, 0, 0],
        [0, 0, 3, 0, 0]])
>>> index=torch.tensor([[0,1,2],[0,1,4]])
>>> torch.zeros(3,5,dtype=src.dtype).scatter_(1,index,src)
tensor([[1, 2, 3, 0, 0],
        [6, 7, 0, 0, 8],
        [0, 0, 0, 0, 0]])>>> torch.full((2,4),2.).scatter_(1,torch.tensor([[2],[3]]),
... 1.23,reduce='multiply')
tensor([[2.0000, 2.0000, 2.4600, 2.0000],
        [2.0000, 2.0000, 2.0000, 2.4600]])
>>> torch.full((2,4),2.).scatter_(1,torch.tensor([[2],[3]]),
... 1.23,reduce='add')
tensor([[2.0000, 2.0000, 3.2300, 2.0000],
        [2.0000, 2.0000, 2.0000, 3.2300]])
","  File ""example.py"", line 8
    [0, 0, 0, 0, 0]])torch.full((2,4),2.).scatter_(1,torch.tensor([[2],[3]]),
    ^
IndentationError: unexpected indent
"
"
 torch. select_scatter ( input ,  src ,  dim ,  index )   → ¶",">>> a=torch.zeros(2,2)
>>> b=torch.ones(2)
>>> a.select_scatter(b,0,0)
tensor([[1., 1.],
        [0., 0.]])
","Traceback (most recent call last):
  File ""example.py"", line 4, in <module>
    a.select_scatter(b,0,0)
AttributeError: 'Tensor' object has no attribute 'select_scatter'
"
"
 torch. slice_scatter ( input ,  src ,  dim ,  start ,  end ,  step )   → ¶",">>> a=torch.zeros(8,8)
>>> b=torch.ones(8)
>>> a.slice_scatter(b,start=6)
tensor([[0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0.],
        [1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1.]])>>> b=torch.ones(2)
>>> a.slice_scatter(b,dim=1,start=2,end=6,step=2)
tensor([[0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.]])
","  File ""example.py"", line 5
    [1., 1., 1., 1., 1., 1., 1., 1.]])b=torch.ones(2)
    ^
IndentationError: unexpected indent
"
"
 Tensor. scatter_reduce_ ( dim ,  index ,  src ,  reduce ,  * ,  include_self )   → ¶",">>> src=torch.tensor([1.,2.,3.,4.,5.,6.])
>>> index=torch.tensor([0,1,0,1,2,1])
>>> input=torch.tensor([1.,2.,3.,4.])
>>> input.scatter_reduce(0,index,src,reduce=""sum"")
tensor([5., 14., 8., 4.])
>>> input.scatter_reduce(0,index,src,reduce=""sum"",include_self=False)
tensor([4., 12., 5., 4.])
>>> input2=torch.tensor([5.,4.,3.,2.])
>>> input2.scatter_reduce(0,index,src,reduce=""amax"")
tensor([5., 6., 5., 2.])
>>> input2.scatter_reduce(0,index,src,reduce=""amax"",include_self=False)
tensor([3., 6., 5., 2.])
","Traceback (most recent call last):
  File ""example.py"", line 5, in <module>
    input.scatter_reduce(0,index,src,reduce=""sum"")
AttributeError: 'Tensor' object has no attribute 'scatter_reduce'
"
"
 torch. take ( input ,  index )   → ¶",">>> src=torch.tensor([[4,3,5],
... [6,7,8]])
>>> torch.take(src,torch.tensor([0,2,5]))
tensor([ 4,  5,  8])
","  File ""example.py"", line 4
    
                                         ^
SyntaxError: unexpected EOF while parsing
"
"
 torch. take_along_dim ( input ,  indices ,  dim ,  * ,  out )   → ¶",">>> t=torch.tensor([[10,30,20],[60,40,50]])
>>> max_idx=torch.argmax(t)
>>> torch.take_along_dim(t,max_idx)
tensor([60])
>>> sorted_idx=torch.argsort(t,dim=1)
>>> torch.take_along_dim(t,sorted_idx,dim=1)
tensor([[10, 20, 30],
        [40, 50, 60]])
","Traceback (most recent call last):
  File ""example.py"", line 4, in <module>
    torch.take_along_dim(t,max_idx)
AttributeError: module 'torch' has no attribute 'take_along_dim'
"
"
 torch. tensor_split ( input ,  indices_or_sections ,  dim )   → ¶",">>> x=torch.arange(8)
>>> torch.tensor_split(x,3)
(tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7]))>>> x=torch.arange(7)
>>> torch.tensor_split(x,3)
(tensor([0, 1, 2]), tensor([3, 4]), tensor([5, 6]))
>>> torch.tensor_split(x,(1,6))
(tensor([0]), tensor([1, 2, 3, 4, 5]), tensor([6]))>>> x=torch.arange(14).reshape(2,7)
>>> x
tensor([[ 0,  1,  2,  3,  4,  5,  6],
        [ 7,  8,  9, 10, 11, 12, 13]])
>>> torch.tensor_split(x,3,dim=1)
(tensor([[0, 1, 2],
        [7, 8, 9]]),
 tensor([[ 3,  4],
        [10, 11]]),
 tensor([[ 5,  6],
        [12, 13]]))
>>> torch.tensor_split(x,(1,6),dim=1)
(tensor([[0],
        [7]]),
 tensor([[ 1,  2,  3,  4,  5],
        [ 8,  9, 10, 11, 12]]),
 tensor([[ 6],
        [13]]))
","  File ""example.py"", line 4
    (tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7]))x=torch.arange(7)
                                                          ^
SyntaxError: invalid syntax
"
"
 torch. bernoulli ( input ,  * ,  generator ,  out )   → ¶",">>> a=torch.empty(3,3).uniform_(0,1)# generate a uniform random matrix with range [0, 1]
>>> a
tensor([[ 0.1737,  0.0950,  0.3609],
        [ 0.7148,  0.0289,  0.2676],
        [ 0.9456,  0.8937,  0.7202]])
>>> torch.bernoulli(a)
tensor([[ 1.,  0.,  0.],
        [ 0.,  0.,  0.],
        [ 1.,  1.,  1.]])>>> a=torch.ones(3,3)# probability of drawing ""1"" is 1
>>> torch.bernoulli(a)
tensor([[ 1.,  1.,  1.],
        [ 1.,  1.,  1.],
        [ 1.,  1.,  1.]])
>>> a=torch.zeros(3,3)# probability of drawing ""1"" is 0
>>> torch.bernoulli(a)
tensor([[ 0.,  0.,  0.],
        [ 0.,  0.,  0.],
        [ 0.,  0.,  0.]])
","  File ""example.py"", line 5
    [ 1.,  1.,  1.]])a=torch.ones(3,3)# probability of drawing ""1"" is 1
    ^
IndentationError: unexpected indent
"
"
 torch. clamp ( input ,  min ,  max ,  * ,  out )   → ¶",">>> a=torch.randn(4)
>>> a
tensor([-1.7120,  0.1734, -0.0478, -0.0922])
>>> torch.clamp(a,min=-0.5,max=0.5)
tensor([-0.5000,  0.1734, -0.0478, -0.0922])>>> min=torch.linspace(-1,1,steps=4)
>>> torch.clamp(a,min=min)
tensor([-1.0000,  0.1734,  0.3333,  1.0000])
","  File ""example.py"", line 5
    tensor([-0.5000,  0.1734, -0.0478, -0.0922])min=torch.linspace(-1,1,steps=4)
                                                ^
SyntaxError: invalid syntax
"
"
 torch. conj_physical ( input ,  * ,  out )   → ¶",">>> torch.conj_physical(torch.tensor([-1+1j,-2+2j,3-3j]))
tensor([-1 - 1j, -2 - 2j, 3 + 3j])
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    torch.conj_physical(torch.tensor([-1+1j,-2+2j,3-3j]))
AttributeError: module 'torch' has no attribute 'conj_physical'
"
"
 torch. exp ( input ,  * ,  out )   → ¶",">>> torch.exp(torch.tensor([0,math.log(2.)]))
tensor([ 1.,  2.])
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    torch.exp(torch.tensor([0,math.log(2.)]))
NameError: name 'math' is not defined
"
"
 torch. fake_quantize_per_channel_affine ( input ,  scale ,  zero_point ,  quant_min ,  quant_max )   → ¶",">>> x=torch.randn(2,2,2)
>>> x
tensor([[[-0.2525, -0.0466],
         [ 0.3491, -0.2168]],        [[-0.5906,  1.6258],
         [ 0.6444, -0.0542]]])
>>> scales=(torch.randn(2)+1)*0.05
>>> scales
tensor([0.0475, 0.0486])
>>> zero_points=torch.zeros(2).to(torch.int32)
>>> zero_points
tensor([0, 0])
>>> torch.fake_quantize_per_channel_affine(x,scales,zero_points,1,0,255)
tensor([[[0.0000, 0.0000],
         [0.3405, 0.0000]],        [[0.0000, 1.6134],
        [0.6323, 0.0000]]])
","Traceback (most recent call last):
  File ""example.py"", line 8, in <module>
    torch.fake_quantize_per_channel_affine(x,scales,zero_points,1,0,255)
  File ""/home/nimashiri/.local/lib/python3.8/site-packages/torch/decorate_func.py"", line 99, in wrapper
    outputs = func(*args, **kwargs)
RuntimeError: Zero-point must be Long, found Int
"
"
 torch. float_power ( input ,  exponent ,  * ,  out )   → ¶",">>> a=torch.randint(10,(4,))
>>> a
tensor([6, 4, 7, 1])
>>> torch.float_power(a,2)
tensor([36., 16., 49.,  1.], dtype=torch.float64)>>> a=torch.arange(1,5)
>>> a
tensor([ 1,  2,  3,  4])
>>> exp=torch.tensor([2,-3,4,-5])
>>> exp
tensor([ 2, -3,  4, -5])
>>> torch.float_power(a,exp)
tensor([1.0000e+00, 1.2500e-01, 8.1000e+01, 9.7656e-04], dtype=torch.float64)
","  File ""example.py"", line 5
    tensor([36., 16., 49.,  1.], dtype=torch.float64)a=torch.arange(1,5)
                                                     ^
SyntaxError: invalid syntax
"
"
 torch. frexp ( input ,  * ,  out=None) ,  Tensor ) ¶",">>> x=torch.arange(9.)
>>> mantissa,exponent=torch.frexp(x)
>>> mantissa
tensor([0.0000, 0.5000, 0.5000, 0.7500, 0.5000, 0.6250, 0.7500, 0.8750, 0.5000])
>>> exponent
tensor([0, 1, 2, 2, 3, 3, 3, 3, 4], dtype=torch.int32)
>>> torch.ldexp(mantissa,exponent)
tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])
","Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    mantissa,exponent=torch.frexp(x)
AttributeError: module 'torch' has no attribute 'frexp'
"
"
 torch. log10 ( input ,  * ,  out )   → ¶",">>> a=torch.rand(5)
>>> a
tensor([ 0.5224,  0.9354,  0.7257,  0.1301,  0.2251])>>> torch.log10(a)
tensor([-0.2820, -0.0290, -0.1392, -0.8857, -0.6476])
","  File ""example.py"", line 4
    tensor([ 0.5224,  0.9354,  0.7257,  0.1301,  0.2251])torch.log10(a)
                                                         ^
SyntaxError: invalid syntax
"
"
 torch. log2 ( input ,  * ,  out )   → ¶",">>> a=torch.rand(5)
>>> a
tensor([ 0.8419,  0.8003,  0.9971,  0.5287,  0.0490])>>> torch.log2(a)
tensor([-0.2483, -0.3213, -0.0042, -0.9196, -4.3504])
","  File ""example.py"", line 4
    tensor([ 0.8419,  0.8003,  0.9971,  0.5287,  0.0490])torch.log2(a)
                                                         ^
SyntaxError: invalid syntax
"
"
 torch. positive ( input )   → ¶",">>> t=torch.randn(5)
>>> t
tensor([ 0.0090, -0.2262, -0.0682, -0.2866,  0.3940])
>>> torch.positive(t)
tensor([ 0.0090, -0.2262, -0.0682, -0.2866,  0.3940])
","Traceback (most recent call last):
  File ""example.py"", line 4, in <module>
    torch.positive(t)
AttributeError: module 'torch' has no attribute 'positive'
"
"
 torch. pow ( input ,  exponent ,  * ,  out )   → ¶",">>> a=torch.randn(4)
>>> a
tensor([ 0.4331,  1.2475,  0.6834, -0.2791])
>>> torch.pow(a,2)
tensor([ 0.1875,  1.5561,  0.4670,  0.0779])
>>> exp=torch.arange(1.,5.)>>> a=torch.arange(1.,5.)
>>> a
tensor([ 1.,  2.,  3.,  4.])
>>> exp
tensor([ 1.,  2.,  3.,  4.])
>>> torch.pow(a,exp)
tensor([   1.,    4.,   27.,  256.])
","  File ""example.py"", line 5
    exp=torch.arange(1.,5.)a=torch.arange(1.,5.)
                           ^
SyntaxError: invalid syntax
"
"
 torch. round ( input ,  * ,  decimals ,  out )   → ¶",">>> torch.round(torch.tensor((4.7,-2.3,9.1,-7.7)))
tensor([ 5.,  -2.,  9., -8.])>>> # Values equidistant from two integers are rounded towards the
>>> #   the nearest even value (zero is treated as even)
>>> torch.round(torch.tensor([-0.5,0.5,1.5,2.5]))
tensor([-0., 0., 2., 2.])>>> # A positive decimals argument rounds to the to that decimal place
>>> torch.round(torch.tensor([0.1234567]),decimals=3)
tensor([0.1230])>>> # A negative decimals argument rounds to the left of the decimal
>>> torch.round(torch.tensor([1200.1234567]),decimals=-3)
tensor([1000.])
","Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    tensor([ 5.,  -2.,  9., -8.])# Values equidistant from two integers are rounded towards the
NameError: name 'tensor' is not defined
"
"
 torch. aminmax ( input ,  * ,  dim=None ,  keepdim=False ,  out=None) ,  Tensor ) ¶",">>> torch.aminmax(torch.tensor([1,-3,5]))
torch.return_types.aminmax(
min=tensor(-3),
max=tensor(5))>>> # aminmax propagates NaNs
>>> torch.aminmax(torch.tensor([1,-3,5,torch.nan]))
torch.return_types.aminmax(
min=tensor(nan),
max=tensor(nan))>>> t=torch.arange(10).view(2,5)
>>> t
tensor([[0, 1, 2, 3, 4],
        [5, 6, 7, 8, 9]])
>>> t.aminmax(dim=0,keepdim=True)
torch.return_types.aminmax(
min=tensor([[0, 1, 2, 3, 4]]),
max=tensor([[5, 6, 7, 8, 9]]))
","  File ""example.py"", line 3
    max=tensor(5))# aminmax propagates NaNs
                 ^
SyntaxError: unmatched ')'
"
"
 torch. nanmean ( input ,  dim ,  keepdim ,  * ,  dtype ,  out )   → ¶",">>> x=torch.tensor([[torch.nan,1,2],[1,2,3]])
>>> x.mean()
tensor(nan)
>>> x.nanmean()
tensor(1.8000)
>>> x.mean(dim=0)
tensor([   nan, 1.5000, 2.5000])
>>> x.nanmean(dim=0)
tensor([1.0000, 1.5000, 2.5000])# If all elements in the reduced dimensions are NaN then the result is NaN
>>> torch.tensor([torch.nan]).nanmean()
tensor(nan)
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    x=torch.tensor([[torch.nan,1,2],[1,2,3]])
AttributeError: module 'torch' has no attribute 'nan'
"
"
 torch. norm ( input ,  p ,  dim ,  keepdim ,  out ,  dtype ) [source] ¶",">>> importtorch
>>> a=torch.arange(9,dtype=torch.float)-4
>>> b=a.reshape((3,3))
>>> torch.norm(a)
tensor(7.7460)
>>> torch.norm(b)
tensor(7.7460)
>>> torch.norm(a,float('inf'))
tensor(4.)
>>> torch.norm(b,float('inf'))
tensor(4.)
>>> c=torch.tensor([[1,2,3],[-1,1,4]],dtype=torch.float)
>>> torch.norm(c,dim=0)
tensor([1.4142, 2.2361, 5.0000])
>>> torch.norm(c,dim=1)
tensor([3.7417, 4.2426])
>>> torch.norm(c,p=1,dim=1)
tensor([6., 6.])
>>> d=torch.arange(8,dtype=torch.float).reshape(2,2,2)
>>> torch.norm(d,dim=(1,2))
tensor([ 3.7417, 11.2250])
>>> torch.norm(d[0,:,:]),torch.norm(d[1,:,:])
(tensor(3.7417), tensor(11.2250))
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    importtorch
NameError: name 'importtorch' is not defined
"
"
 torch. quantile ( input ,  q ,  dim ,  keepdim ,  * ,  interpolation ,  out )   → ¶",">>> a=torch.randn(2,3)
>>> a
tensor([[ 0.0795, -1.2117,  0.9765],
        [ 1.1707,  0.6706,  0.4884]])
>>> q=torch.tensor([0.25,0.5,0.75])
>>> torch.quantile(a,q,dim=1,keepdim=True)
tensor([[[-0.5661],
        [ 0.5795]],        [[ 0.0795],
        [ 0.6706]],        [[ 0.5280],
        [ 0.9206]]])
>>> torch.quantile(a,q,dim=1,keepdim=True).shape
torch.Size([3, 2, 1])
>>> a=torch.arange(4.)
>>> a
tensor([0., 1., 2., 3.])
>>> torch.quantile(a,0.6,interpolation='linear')
tensor(1.8000)
>>> torch.quantile(a,0.6,interpolation='lower')
tensor(1.)
>>> torch.quantile(a,0.6,interpolation='higher')
tensor(2.)
>>> torch.quantile(a,0.6,interpolation='midpoint')
tensor(1.5000)
>>> torch.quantile(a,0.6,interpolation='nearest')
tensor(2.)
>>> torch.quantile(a,0.4,interpolation='nearest')
tensor(1.)
","Traceback (most recent call last):
  File ""example.py"", line 9, in <module>
    torch.quantile(a,0.6,interpolation='linear')
  File ""/home/nimashiri/.local/lib/python3.8/site-packages/torch/decorate_func.py"", line 99, in wrapper
    outputs = func(*args, **kwargs)
TypeError: quantile() received an invalid combination of arguments - got (Tensor, float, interpolation=str), but expected one of:
 * (Tensor input, Tensor q, int dim, bool keepdim, *, Tensor out)
 * (Tensor input, float q, int dim, bool keepdim, *, Tensor out)

"
"
 torch. unique ( input ,  sorted ,  return_inverse ,  return_counts ,  dim )   → ¶",">>> output=torch.unique(torch.tensor([1,3,2,3],dtype=torch.long))
>>> output
tensor([1, 2, 3])>>> output,inverse_indices=torch.unique(
... torch.tensor([1,3,2,3],dtype=torch.long),sorted=True,return_inverse=True)
>>> output
tensor([1, 2, 3])
>>> inverse_indices
tensor([0, 2, 1, 2])>>> output,inverse_indices=torch.unique(
... torch.tensor([[1,3],[2,3]],dtype=torch.long),sorted=True,return_inverse=True)
>>> output
tensor([1, 2, 3])
>>> inverse_indices
tensor([[0, 2],
        [1, 2]])
","  File ""example.py"", line 4
    tensor([1, 2, 3])output,inverse_indices=torch.unique(
                     ^
SyntaxError: invalid syntax
"
"
 torch. unique_consecutive ( * ,  ** ) ¶",">>> x=torch.tensor([1,1,2,2,3,1,1,2])
>>> output=torch.unique_consecutive(x)
>>> output
tensor([1, 2, 3, 1, 2])>>> output,inverse_indices=torch.unique_consecutive(x,return_inverse=True)
>>> output
tensor([1, 2, 3, 1, 2])
>>> inverse_indices
tensor([0, 0, 1, 1, 2, 3, 3, 4])>>> output,counts=torch.unique_consecutive(x,return_counts=True)
>>> output
tensor([1, 2, 3, 1, 2])
>>> counts
tensor([2, 2, 1, 2, 1])
","  File ""example.py"", line 5
    tensor([1, 2, 3, 1, 2])output,inverse_indices=torch.unique_consecutive(x,return_inverse=True)
                           ^
SyntaxError: invalid syntax
"
"
 torch. argsort ( input ,  dim ,  descending ,  stable )   → ¶",">>> a=torch.randn(4,4)
>>> a
tensor([[ 0.0785,  1.5267, -0.8521,  0.4065],
        [ 0.1598,  0.0788, -0.0745, -1.2700],
        [ 1.2208,  1.0722, -0.7064,  1.2564],
        [ 0.0669, -0.2318, -0.8229, -0.9280]])>>> torch.argsort(a,dim=1)
tensor([[2, 0, 3, 1],
        [3, 2, 1, 0],
        [2, 1, 0, 3],
        [3, 2, 1, 0]])
","  File ""example.py"", line 4
    [ 0.0669, -0.2318, -0.8229, -0.9280]])torch.argsort(a,dim=1)
    ^
IndentationError: unexpected indent
"
"
 torch. kthvalue ( input ,  k ,  dim ,  keepdim ,  * ,  out ) ¶",">>> x=torch.arange(1.,6.)
>>> x
tensor([ 1.,  2.,  3.,  4.,  5.])
>>> torch.kthvalue(x,4)
torch.return_types.kthvalue(values=tensor(4.), indices=tensor(3))>>> x=torch.arange(1.,7.).resize_(2,3)
>>> x
tensor([[ 1.,  2.,  3.],
        [ 4.,  5.,  6.]])
>>> torch.kthvalue(x,2,0,True)
torch.return_types.kthvalue(values=tensor([[4., 5., 6.]]), indices=tensor([[1, 1, 1]]))
","  File ""example.py"", line 5
    torch.return_types.kthvalue(values=tensor(4.), indices=tensor(3))x=torch.arange(1.,7.).resize_(2,3)
                                                                     ^
SyntaxError: invalid syntax
"
"
 torch. sort ( input ,  dim ,  descending ,  stable ,  * ,  out ) ¶",">>> x=torch.randn(3,4)
>>> sorted,indices=torch.sort(x)
>>> sorted
tensor([[-0.2162,  0.0608,  0.6719,  2.3332],
        [-0.5793,  0.0061,  0.6058,  0.9497],
        [-0.5071,  0.3343,  0.9553,  1.0960]])
>>> indices
tensor([[ 1,  0,  2,  3],
        [ 3,  1,  0,  2],
        [ 0,  3,  1,  2]])>>> sorted,indices=torch.sort(x,0)
>>> sorted
tensor([[-0.5071, -0.2162,  0.6719, -0.5793],
        [ 0.0608,  0.0061,  0.9497,  0.3343],
        [ 0.6058,  0.9553,  1.0960,  2.3332]])
>>> indices
tensor([[ 2,  0,  0,  1],
        [ 0,  1,  1,  2],
        [ 1,  2,  2,  0]])
>>> x=torch.tensor([0,1]*9)
>>> x.sort()
torch.return_types.sort(
    values=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]),
    indices=tensor([ 2, 16,  4,  6, 14,  8,  0, 10, 12,  9, 17, 15, 13, 11,  7,  5,  3,  1]))
>>> x.sort(stable=True)
torch.return_types.sort(
    values=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]),
    indices=tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16,  1,  3,  5,  7,  9, 11, 13, 15, 17]))
","  File ""example.py"", line 6
    [ 0,  3,  1,  2]])sorted,indices=torch.sort(x,0)
    ^
IndentationError: unexpected indent
"
"
 torch. bincount ( input ,  weights ,  minlength )   → ¶",">>> input=torch.randint(0,8,(5,),dtype=torch.int64)
>>> weights=torch.linspace(0,1,steps=5)
>>> input,weights
(tensor([4, 3, 6, 3, 4]),
 tensor([ 0.0000,  0.2500,  0.5000,  0.7500,  1.0000])>>> torch.bincount(input)
tensor([0, 0, 0, 2, 2, 0, 1])>>> input.bincount(weights)
tensor([0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.5000])
","  File ""example.py"", line 5
    tensor([ 0.0000,  0.2500,  0.5000,  0.7500,  1.0000])torch.bincount(input)
    ^
IndentationError: unexpected indent
"
"
 torch. block_diag ( * ) [source] ¶",">>> importtorch
>>> A=torch.tensor([[0,1],[1,0]])
>>> B=torch.tensor([[3,4,5],[6,7,8]])
>>> C=torch.tensor(7)
>>> D=torch.tensor([1,2,3])
>>> E=torch.tensor([[4],[5],[6]])
>>> torch.block_diag(A,B,C,D,E)
tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 3, 4, 5, 0, 0, 0, 0, 0],
        [0, 0, 6, 7, 8, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 7, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 2, 3, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 4],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 6]])
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    importtorch
NameError: name 'importtorch' is not defined
"
"
 torch. cartesian_prod ( * ) [source] ¶",">>> importitertools
>>> a=[1,2,3]
>>> b=[4,5]
>>> list(itertools.product(a,b))
[(1, 4), (1, 5), (2, 4), (2, 5), (3, 4), (3, 5)]
>>> tensor_a=torch.tensor(a)
>>> tensor_b=torch.tensor(b)
>>> torch.cartesian_prod(tensor_a,tensor_b)
tensor([[1, 4],
        [1, 5],
        [2, 4],
        [2, 5],
        [3, 4],
        [3, 5]])
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    importitertools
NameError: name 'importitertools' is not defined
"
"
 torch. combinations ( input ,  r ,  with_replacement )   → ¶",">>> a=[1,2,3]
>>> list(itertools.combinations(a,r=2))
[(1, 2), (1, 3), (2, 3)]
>>> list(itertools.combinations(a,r=3))
[(1, 2, 3)]
>>> list(itertools.combinations_with_replacement(a,r=2))
[(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)]
>>> tensor_a=torch.tensor(a)
>>> torch.combinations(tensor_a)
tensor([[1, 2],
        [1, 3],
        [2, 3]])
>>> torch.combinations(tensor_a,r=3)
tensor([[1, 2, 3]])
>>> torch.combinations(tensor_a,with_replacement=True)
tensor([[1, 1],
        [1, 2],
        [1, 3],
        [2, 2],
        [2, 3],
        [3, 3]])
","Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    list(itertools.combinations(a,r=2))
NameError: name 'itertools' is not defined
"
"
 torch. corrcoef ( input )   → ¶",">>> x=torch.tensor([[0,1,2],[2,1,0]])
>>> torch.corrcoef(x)
tensor([[ 1., -1.],
        [-1.,  1.]])
>>> x=torch.randn(2,4)
>>> x
tensor([[-0.2678, -0.0908, -0.3766,  0.2780],
        [-0.5812,  0.1535,  0.2387,  0.2350]])
>>> torch.corrcoef(x)
tensor([[1.0000, 0.3582],
        [0.3582, 1.0000]])
>>> torch.corrcoef(x[0])
tensor(1.)
","Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    torch.corrcoef(x)
AttributeError: module 'torch' has no attribute 'corrcoef'
"
"
 torch. cumprod ( input ,  dim ,  * ,  dtype ,  out )   → ¶",">>> a=torch.randn(10)
>>> a
tensor([ 0.6001,  0.2069, -0.1919,  0.9792,  0.6727,  1.0062,  0.4126,
        -0.2129, -0.4206,  0.1968])
>>> torch.cumprod(a,dim=0)
tensor([ 0.6001,  0.1241, -0.0238, -0.0233, -0.0157, -0.0158, -0.0065,
         0.0014, -0.0006, -0.0001])>>> a[5]=0.0
>>> torch.cumprod(a,dim=0)
tensor([ 0.6001,  0.1241, -0.0238, -0.0233, -0.0157, -0.0000, -0.0000,
         0.0000, -0.0000, -0.0000])
","  File ""example.py"", line 5
    0.0014, -0.0006, -0.0001])a[5]=0.0
    ^
IndentationError: unexpected indent
"
"
 torch. diag_embed ( input ,  offset ,  dim1 ,  dim2 )   → ¶",">>> a=torch.randn(2,3)
>>> torch.diag_embed(a)
tensor([[[ 1.5410,  0.0000,  0.0000],
         [ 0.0000, -0.2934,  0.0000],
         [ 0.0000,  0.0000, -2.1788]],        [[ 0.5684,  0.0000,  0.0000],
         [ 0.0000, -1.0845,  0.0000],
         [ 0.0000,  0.0000, -1.3986]]])>>> torch.diag_embed(a,offset=1,dim1=0,dim2=2)
tensor([[[ 0.0000,  1.5410,  0.0000,  0.0000],
         [ 0.0000,  0.5684,  0.0000,  0.0000]],        [[ 0.0000,  0.0000, -0.2934,  0.0000],
         [ 0.0000,  0.0000, -1.0845,  0.0000]],        [[ 0.0000,  0.0000,  0.0000, -2.1788],
         [ 0.0000,  0.0000,  0.0000, -1.3986]],        [[ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]])
","  File ""example.py"", line 4
    [ 0.0000,  0.0000, -1.3986]]])torch.diag_embed(a,offset=1,dim1=0,dim2=2)
    ^
IndentationError: unexpected indent
"
"
 torch. flatten ( input ,  start_dim ,  end_dim )   → ¶",">>> t=torch.tensor([[[1,2],
... [3,4]],
... [[5,6],
... [7,8]]])
>>> torch.flatten(t)
tensor([1, 2, 3, 4, 5, 6, 7, 8])
>>> torch.flatten(t,start_dim=1)
tensor([[1, 2, 3, 4],
        [5, 6, 7, 8]])
","  File ""example.py"", line 4
    torch.flatten(t,start_dim=1)
    ^
SyntaxError: invalid syntax
"
"
 torch. rot90 ( input ,  k ,  dims )   → ¶",">>> x=torch.arange(4).view(2,2)
>>> x
tensor([[0, 1],
        [2, 3]])
>>> torch.rot90(x,1,[0,1])
tensor([[1, 3],
        [0, 2]])>>> x=torch.arange(8).view(2,2,2)
>>> x
tensor([[[0, 1],
         [2, 3]],        [[4, 5],
         [6, 7]]])
>>> torch.rot90(x,1,[1,2])
tensor([[[1, 3],
         [0, 2]],        [[5, 7],
         [4, 6]]])
","  File ""example.py"", line 5
    [0, 2]])x=torch.arange(8).view(2,2,2)
    ^
IndentationError: unexpected indent
"
"
 torch. histogram ( input ,  bins ,  * ,  range ,  weight ,  density ,  out ) ¶",">>> torch.histogram(torch.tensor([1.,2,1]),bins=4,range=(0.,3.),weight=torch.tensor([1.,2.,4.]))
(tensor([ 0.,  5.,  2.,  0.]), tensor([0., 0.75, 1.5, 2.25, 3.]))
>>> torch.histogram(torch.tensor([1.,2,1]),bins=4,range=(0.,3.),weight=torch.tensor([1.,2.,4.]),density=True)
(tensor([ 0.,  0.9524,  0.3810,  0.]), tensor([0., 0.75, 1.5, 2.25, 3.]))
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    torch.histogram(torch.tensor([1.,2,1]),bins=4,range=(0.,3.),weight=torch.tensor([1.,2.,4.]))
AttributeError: module 'torch' has no attribute 'histogram'
"
"
 torch. meshgrid ( * ,  indexing ) [source] ¶",">>> x=torch.tensor([1,2,3])
>>> y=torch.tensor([4,5,6])Observe the element-wise pairings across the grid, (1, 4),
(1, 5), ..., (3, 6). This is the same thing as the
cartesian product.
>>> grid_x,grid_y=torch.meshgrid(x,y,indexing='ij')
>>> grid_x
tensor([[1, 1, 1],
        [2, 2, 2],
        [3, 3, 3]])
>>> grid_y
tensor([[4, 5, 6],
        [4, 5, 6],
        [4, 5, 6]])This correspondence can be seen when these grids are
stacked properly.
>>> torch.equal(torch.cat(tuple(torch.dstack([grid_x,grid_y]))),
... torch.cartesian_prod(x,y))
True`torch.meshgrid` is commonly used to produce a grid for
plotting.
>>> importmatplotlib.pyplotasplt
>>> xs=torch.linspace(-5,5,steps=100)
>>> ys=torch.linspace(-5,5,steps=100)
>>> x,y=torch.meshgrid(xs,ys,indexing='xy')
>>> z=torch.sin(torch.sqrt(x*x+y*y))
>>> ax=plt.axes(projection='3d')
>>> ax.plot_surface(x.numpy(),y.numpy(),z.numpy())
>>> plt.show()
","  File ""example.py"", line 3
    y=torch.tensor([4,5,6])Observe the element-wise pairings across the grid, (1, 4),
                           ^
SyntaxError: invalid syntax
"
"
 torch. ravel ( input )   → ¶",">>> t=torch.tensor([[[1,2],
... [3,4]],
... [[5,6],
... [7,8]]])
>>> torch.ravel(t)
tensor([1, 2, 3, 4, 5, 6, 7, 8])
","  File ""example.py"", line 4
    
                  ^
SyntaxError: unexpected EOF while parsing
"
"
 torch. repeat_interleave ( input ,  repeats ,  dim ,  * ,  output_size )   → ¶",">>> x=torch.tensor([1,2,3])
>>> x.repeat_interleave(2)
tensor([1, 1, 2, 2, 3, 3])
>>> y=torch.tensor([[1,2],[3,4]])
>>> torch.repeat_interleave(y,2)
tensor([1, 1, 2, 2, 3, 3, 4, 4])
>>> torch.repeat_interleave(y,3,dim=1)
tensor([[1, 1, 1, 2, 2, 2],
        [3, 3, 3, 4, 4, 4]])
>>> torch.repeat_interleave(y,torch.tensor([1,2]),dim=0)
tensor([[1, 2],
        [3, 4],
        [3, 4]])
>>> torch.repeat_interleave(y,torch.tensor([1,2]),dim=0,output_size=3)
tensor([[1, 2],
        [3, 4],
        [3, 4]])
","Traceback (most recent call last):
  File ""example.py"", line 8, in <module>
    torch.repeat_interleave(y,torch.tensor([1,2]),dim=0,output_size=3)
  File ""/home/nimashiri/.local/lib/python3.8/site-packages/torch/decorate_func.py"", line 99, in wrapper
    outputs = func(*args, **kwargs)
TypeError: repeat_interleave() received an invalid combination of arguments - got (Tensor, Tensor, output_size=int, dim=int), but expected one of:
 * (Tensor input, Tensor repeats, int dim)
 * (Tensor input, int repeats, int dim)
 * (Tensor repeats)

"
"
 torch. searchsorted ( sorted_sequence ,  values ,  * ,  out_int32 ,  right ,  side ,  out ,  sorter )   → ¶",">>> sorted_sequence=torch.tensor([[1,3,5,7,9],[2,4,6,8,10]])
>>> sorted_sequence
tensor([[ 1,  3,  5,  7,  9],
        [ 2,  4,  6,  8, 10]])
>>> values=torch.tensor([[3,6,9],[3,6,9]])
>>> values
tensor([[3, 6, 9],
        [3, 6, 9]])
>>> torch.searchsorted(sorted_sequence,values)
tensor([[1, 3, 4],
        [1, 2, 4]])
>>> torch.searchsorted(sorted_sequence,values,side='right')
tensor([[2, 3, 5],
        [1, 3, 4]])>>> sorted_sequence_1d=torch.tensor([1,3,5,7,9])
>>> sorted_sequence_1d
tensor([1, 3, 5, 7, 9])
>>> torch.searchsorted(sorted_sequence_1d,values)
tensor([[1, 3, 4],
        [1, 3, 4]])
","  File ""example.py"", line 8
    [1, 3, 4]])sorted_sequence_1d=torch.tensor([1,3,5,7,9])
    ^
IndentationError: unexpected indent
"
"
 torch. tril ( input ,  diagonal ,  * ,  out )   → ¶",">>> a=torch.randn(3,3)
>>> a
tensor([[-1.0813, -0.8619,  0.7105],
        [ 0.0935,  0.1380,  2.2112],
        [-0.3409, -0.9828,  0.0289]])
>>> torch.tril(a)
tensor([[-1.0813,  0.0000,  0.0000],
        [ 0.0935,  0.1380,  0.0000],
        [-0.3409, -0.9828,  0.0289]])>>> b=torch.randn(4,6)
>>> b
tensor([[ 1.2219,  0.5653, -0.2521, -0.2345,  1.2544,  0.3461],
        [ 0.4785, -0.4477,  0.6049,  0.6368,  0.8775,  0.7145],
        [ 1.1502,  3.2716, -1.1243, -0.5413,  0.3615,  0.6864],
        [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024,  0.0978]])
>>> torch.tril(b,diagonal=1)
tensor([[ 1.2219,  0.5653,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.4785, -0.4477,  0.6049,  0.0000,  0.0000,  0.0000],
        [ 1.1502,  3.2716, -1.1243, -0.5413,  0.0000,  0.0000],
        [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024,  0.0000]])
>>> torch.tril(b,diagonal=-1)
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.4785,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 1.1502,  3.2716,  0.0000,  0.0000,  0.0000,  0.0000],
        [-0.0614, -0.7344, -1.3164,  0.0000,  0.0000,  0.0000]])
","  File ""example.py"", line 5
    [-0.3409, -0.9828,  0.0289]])b=torch.randn(4,6)
    ^
IndentationError: unexpected indent
"
"
 torch. tril_indices ( row ,  col ,  offset ,  * ,  dtype ,  device ,  layout )   → ¶",">>> a=torch.tril_indices(3,3)
>>> a
tensor([[0, 1, 1, 2, 2, 2],
        [0, 0, 1, 0, 1, 2]])>>> a=torch.tril_indices(4,3,-1)
>>> a
tensor([[1, 2, 2, 3, 3, 3],
        [0, 0, 1, 0, 1, 2]])>>> a=torch.tril_indices(4,3,1)
>>> a
tensor([[0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],
        [0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2]])
","  File ""example.py"", line 4
    [0, 0, 1, 0, 1, 2]])a=torch.tril_indices(4,3,-1)
    ^
IndentationError: unexpected indent
"
"
 torch. triu ( input ,  diagonal ,  * ,  out )   → ¶",">>> a=torch.randn(3,3)
>>> a
tensor([[ 0.2309,  0.5207,  2.0049],
        [ 0.2072, -1.0680,  0.6602],
        [ 0.3480, -0.5211, -0.4573]])
>>> torch.triu(a)
tensor([[ 0.2309,  0.5207,  2.0049],
        [ 0.0000, -1.0680,  0.6602],
        [ 0.0000,  0.0000, -0.4573]])
>>> torch.triu(a,diagonal=1)
tensor([[ 0.0000,  0.5207,  2.0049],
        [ 0.0000,  0.0000,  0.6602],
        [ 0.0000,  0.0000,  0.0000]])
>>> torch.triu(a,diagonal=-1)
tensor([[ 0.2309,  0.5207,  2.0049],
        [ 0.2072, -1.0680,  0.6602],
        [ 0.0000, -0.5211, -0.4573]])>>> b=torch.randn(4,6)
>>> b
tensor([[ 0.5876, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],
        [-0.2447,  0.9556, -1.2919,  1.3378, -0.1768, -1.0857],
        [ 0.4333,  0.3146,  0.6576, -1.0432,  0.9348, -0.4410],
        [-0.9888,  1.0679, -1.3337, -1.6556,  0.4798,  0.2830]])
>>> torch.triu(b,diagonal=1)
tensor([[ 0.0000, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],
        [ 0.0000,  0.0000, -1.2919,  1.3378, -0.1768, -1.0857],
        [ 0.0000,  0.0000,  0.0000, -1.0432,  0.9348, -0.4410],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4798,  0.2830]])
>>> torch.triu(b,diagonal=-1)
tensor([[ 0.5876, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],
        [-0.2447,  0.9556, -1.2919,  1.3378, -0.1768, -1.0857],
        [ 0.0000,  0.3146,  0.6576, -1.0432,  0.9348, -0.4410],
        [ 0.0000,  0.0000, -1.3337, -1.6556,  0.4798,  0.2830]])
","  File ""example.py"", line 7
    [ 0.0000, -0.5211, -0.4573]])b=torch.randn(4,6)
    ^
IndentationError: unexpected indent
"
"
 torch. triu_indices ( row ,  col ,  offset ,  * ,  dtype ,  device ,  layout )   → ¶",">>> a=torch.triu_indices(3,3)
>>> a
tensor([[0, 0, 0, 1, 1, 2],
        [0, 1, 2, 1, 2, 2]])>>> a=torch.triu_indices(4,3,-1)
>>> a
tensor([[0, 0, 0, 1, 1, 1, 2, 2, 3],
        [0, 1, 2, 0, 1, 2, 1, 2, 2]])>>> a=torch.triu_indices(4,3,1)
>>> a
tensor([[0, 0, 1],
        [1, 2, 2]])
","  File ""example.py"", line 4
    [0, 1, 2, 1, 2, 2]])a=torch.triu_indices(4,3,-1)
    ^
IndentationError: unexpected indent
"
"
 torch. resolve_conj ( input )   → ¶",">>> x=torch.tensor([-1+1j,-2+2j,3-3j])
>>> y=x.conj()
>>> y.is_conj()
True
>>> z=y.resolve_conj()
>>> z
tensor([-1 - 1j, -2 - 2j, 3 + 3j])
>>> z.is_conj()
False
","Traceback (most recent call last):
  File ""example.py"", line 4, in <module>
    y.is_conj()
AttributeError: 'Tensor' object has no attribute 'is_conj'
"
"
 torch. resolve_neg ( input )   → ¶",">>> x=torch.tensor([-1+1j,-2+2j,3-3j])
>>> y=x.conj()
>>> z=y.imag
>>> z.is_neg()
True
>>> out=y.resolve_neg()
>>> out
tensor([-1, -2, -3])
>>> out.is_neg()
False
","Traceback (most recent call last):
  File ""example.py"", line 5, in <module>
    z.is_neg()
AttributeError: 'Tensor' object has no attribute 'is_neg'
"
"
 torch. cholesky ( input ,  upper ,  * ,  out )   → ¶",">>> a=torch.randn(3,3)
>>> a=a@a.mT+1e-3# make symmetric positive-definite
>>> l=torch.cholesky(a)
>>> a
tensor([[ 2.4112, -0.7486,  1.4551],
        [-0.7486,  1.3544,  0.1294],
        [ 1.4551,  0.1294,  1.6724]])
>>> l
tensor([[ 1.5528,  0.0000,  0.0000],
        [-0.4821,  1.0592,  0.0000],
        [ 0.9371,  0.5487,  0.7023]])
>>> l@l.mT
tensor([[ 2.4112, -0.7486,  1.4551],
        [-0.7486,  1.3544,  0.1294],
        [ 1.4551,  0.1294,  1.6724]])
>>> a=torch.randn(3,2,2)# Example for batched input
>>> a=a@a.mT+1e-03# make symmetric positive-definite
>>> l=torch.cholesky(a)
>>> z=l@l.mT
>>> torch.dist(z,a)
tensor(2.3842e-07)
","Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    a=a@a.mT+1e-3# make symmetric positive-definite
AttributeError: 'Tensor' object has no attribute 'mT'
"
"
 torch. cholesky_inverse ( input ,  upper ,  * ,  out )   → ¶",">>> a=torch.randn(3,3)
>>> a=torch.mm(a,a.t())+1e-05*torch.eye(3)# make symmetric positive definite
>>> u=torch.linalg.cholesky(a)
>>> a
tensor([[  0.9935,  -0.6353,   1.5806],
        [ -0.6353,   0.8769,  -1.7183],
        [  1.5806,  -1.7183,  10.6618]])
>>> torch.cholesky_inverse(u)
tensor([[ 1.9314,  1.2251, -0.0889],
        [ 1.2251,  2.4439,  0.2122],
        [-0.0889,  0.2122,  0.1412]])
>>> a.inverse()
tensor([[ 1.9314,  1.2251, -0.0889],
        [ 1.2251,  2.4439,  0.2122],
        [-0.0889,  0.2122,  0.1412]])
>>> a=torch.randn(3,2,2)# Example for batched input
>>> a=a@a.mT+1e-03# make symmetric positive-definite
>>> l=torch.linalg.cholesky(a)
>>> z=l@l.mT
>>> torch.dist(z,a)
tensor(3.5894e-07)
","Traceback (most recent call last):
  File ""example.py"", line 9, in <module>
    a=a@a.mT+1e-03# make symmetric positive-definite
AttributeError: 'Tensor' object has no attribute 'mT'
"
"
 torch. inner ( input ,  other ,  * ,  out )   → ¶","# Dot product
>>>torch.inner(torch.tensor([1,2,3]),torch.tensor([0,2,1]))
tensor(7)# Multidimensional input tensors
>>>a=torch.randn(2,3)
>>>a
tensor([[0.8173,1.0874,1.1784],[0.3279,0.1234,2.7894]])
>>>b=torch.randn(2,4,3)
>>>b
tensor([[[-0.4682,-0.7159,0.1506],[0.4034,-0.3657,1.0387],[0.9892,-0.6684,0.1774],[0.9482,1.3261,0.3917]],[[0.4537,0.7493,1.1724],[0.2291,0.5749,-0.2267],[-0.7920,0.3607,-0.3701],[1.3666,-0.5850,-1.7242]]])
>>>torch.inner(a,b)
tensor([[[-0.9837,1.1560,0.2907,2.6785],[2.5671,0.5452,-0.6912,-1.5509]],[[0.1782,2.9843,0.7366,1.5672],[3.5115,-0.4864,-1.2476,-4.4337]]])# Scalar input
>>>torch.inner(a,torch.tensor(2))
tensor([[1.6347,2.1748,2.3567],[0.6558,0.2469,5.5787]])
","  File ""example.py"", line 2
    >>>torch.inner(torch.tensor([1,2,3]),torch.tensor([0,2,1]))
    ^
SyntaxError: invalid syntax
"
"
 torch. lu ( * ,  ** ) ¶",">>> A=torch.randn(2,3,3)
>>> A_LU,pivots=torch.lu(A)
>>> A_LU
tensor([[[ 1.3506,  2.5558, -0.0816],
         [ 0.1684,  1.1551,  0.1940],
         [ 0.1193,  0.6189, -0.5497]],        [[ 0.4526,  1.2526, -0.3285],
         [-0.7988,  0.7175, -0.9701],
         [ 0.2634, -0.9255, -0.3459]]])
>>> pivots
tensor([[ 3,  3,  3],
        [ 3,  3,  3]], dtype=torch.int32)
>>> A_LU,pivots,info=torch.lu(A,get_infos=True)
>>> ifinfo.nonzero().size(0)==0:
... print('LU factorization succeeded for all samples!')
LU factorization succeeded for all samples!
","  File ""example.py"", line 7
    ifinfo.nonzero().size(0)==0:
                               ^
SyntaxError: invalid syntax
"
"
 torch. lu_solve ( b ,  LU_data ,  LU_pivots ,  * ,  out )   → ¶",">>> A=torch.randn(2,3,3)
>>> b=torch.randn(2,3,1)
>>> LU,pivots=torch.linalg.lu_factor(A)
>>> x=torch.lu_solve(b,LU,pivots)
>>> torch.dist(A@x,b)
tensor(1.00000e-07 *
       2.8312)
","Traceback (most recent call last):
  File ""example.py"", line 4, in <module>
    LU,pivots=torch.linalg.lu_factor(A)
AttributeError: module 'torch.linalg' has no attribute 'lu_factor'
"
"
 torch.linalg. matrix_exp ( A )   → ¶",">>> A=torch.empty(2,2,2)
>>> A[0,:,:]=torch.eye(2,2)
>>> A[1,:,:]=2*torch.eye(2,2)
>>> A
tensor([[[1., 0.],
         [0., 1.]],        [[2., 0.],
         [0., 2.]]])
>>> torch.linalg.matrix_exp(A)
tensor([[[2.7183, 0.0000],
         [0.0000, 2.7183]],         [[7.3891, 0.0000],
          [0.0000, 7.3891]]])>>> importmath
>>> A=torch.tensor([[0,math.pi/3],[-math.pi/3,0]])# A is skew-symmetric
>>> torch.linalg.matrix_exp(A)# matrix_exp(A) = [[cos(pi/3), sin(pi/3)], [-sin(pi/3), cos(pi/3)]]
tensor([[ 0.5000,  0.8660],
        [-0.8660,  0.5000]])
","  File ""example.py"", line 7
    [0.0000, 7.3891]]])importmath
    ^
IndentationError: unexpected indent
"
"
 torch. qr ( input ,  some ,  * ,  out ) ¶",">>> a=torch.tensor([[12.,-51,4],[6,167,-68],[-4,24,-41]])
>>> q,r=torch.qr(a)
>>> q
tensor([[-0.8571,  0.3943,  0.3314],
        [-0.4286, -0.9029, -0.0343],
        [ 0.2857, -0.1714,  0.9429]])
>>> r
tensor([[ -14.0000,  -21.0000,   14.0000],
        [   0.0000, -175.0000,   70.0000],
        [   0.0000,    0.0000,  -35.0000]])
>>> torch.mm(q,r).round()
tensor([[  12.,  -51.,    4.],
        [   6.,  167.,  -68.],
        [  -4.,   24.,  -41.]])
>>> torch.mm(q.t(),q).round()
tensor([[ 1.,  0.,  0.],
        [ 0.,  1., -0.],
        [ 0., -0.,  1.]])
>>> a=torch.randn(3,4,5)
>>> q,r=torch.qr(a,some=False)
>>> torch.allclose(torch.matmul(q,r),a)
True
>>> torch.allclose(torch.matmul(q.mT,q),torch.eye(5))
True
","Traceback (most recent call last):
  File ""example.py"", line 11, in <module>
    torch.allclose(torch.matmul(q.mT,q),torch.eye(5))
AttributeError: 'Tensor' object has no attribute 'mT'
"
"
 torch. svd ( input ,  some ,  compute_uv ,  * ,  out ) ¶",">>> a=torch.randn(5,3)
>>> a
tensor([[ 0.2364, -0.7752,  0.6372],
        [ 1.7201,  0.7394, -0.0504],
        [-0.3371, -1.0584,  0.5296],
        [ 0.3550, -0.4022,  1.5569],
        [ 0.2445, -0.0158,  1.1414]])
>>> u,s,v=torch.svd(a)
>>> u
tensor([[ 0.4027,  0.0287,  0.5434],
        [-0.1946,  0.8833,  0.3679],
        [ 0.4296, -0.2890,  0.5261],
        [ 0.6604,  0.2717, -0.2618],
        [ 0.4234,  0.2481, -0.4733]])
>>> s
tensor([2.3289, 2.0315, 0.7806])
>>> v
tensor([[-0.0199,  0.8766,  0.4809],
        [-0.5080,  0.4054, -0.7600],
        [ 0.8611,  0.2594, -0.4373]])
>>> torch.dist(a,torch.mm(torch.mm(u,torch.diag(s)),v.t()))
tensor(8.6531e-07)
>>> a_big=torch.randn(7,5,3)
>>> u,s,v=torch.svd(a_big)
>>> torch.dist(a_big,torch.matmul(torch.matmul(u,torch.diag_embed(s)),v.mT))
tensor(2.6503e-06)
","Traceback (most recent call last):
  File ""example.py"", line 11, in <module>
    torch.dist(a_big,torch.matmul(torch.matmul(u,torch.diag_embed(s)),v.mT))
AttributeError: 'Tensor' object has no attribute 'mT'
"
"
 torch. use_deterministic_algorithms ( mode ,  * ,  warn_only ) [source] ¶",">>> torch.use_deterministic_algorithms(True)# Forward mode nondeterministic error
>>> torch.randn(10,device='cuda').kthvalue(0)
...
RuntimeError: kthvalue CUDA does not have a deterministic implementation...# Backward mode nondeterministic error
>>> torch.nn.AvgPool3d(1)(torch.randn(3,4,5,6,requires_grad=True).cuda()).sum().backward()
...
RuntimeError: avg_pool3d_backward_cuda does not have a deterministic implementation...
","[W Context.cpp:70] Warning: torch.use_deterministic_algorithms is in beta, and its design and functionality may change in the future. (function operator())
Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    torch.randn(10,device='cuda').kthvalue(0)
RuntimeError: kthvalue CUDA does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True)'. You can turn off determinism just for this operation if that's acceptable for your application. You can also file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation.
"
"
 class torch.nn. MaxUnpool1d ( kernel_size ,  stride ,  padding ) [source] ¶",">>> pool=nn.MaxPool1d(2,stride=2,return_indices=True)
>>> unpool=nn.MaxUnpool1d(2,stride=2)
>>> input=torch.tensor([[[1.,2,3,4,5,6,7,8]]])
>>> output,indices=pool(input)
>>> unpool(output,indices)
tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])>>> # Example showcasing the use of output_size
>>> input=torch.tensor([[[1.,2,3,4,5,6,7,8,9]]])
>>> output,indices=pool(input)
>>> unpool(output,indices,output_size=input.size())
tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.,  0.]]])>>> unpool(output,indices)
tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])
","  File ""example.py"", line 11
    tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.,  0.]]])unpool(output,indices)
                                                            ^
SyntaxError: invalid syntax
"
"
 class torch.nn. MaxUnpool2d ( kernel_size ,  stride ,  padding ) [source] ¶",">>> pool=nn.MaxPool2d(2,stride=2,return_indices=True)
>>> unpool=nn.MaxUnpool2d(2,stride=2)
>>> input=torch.tensor([[[[1.,2.,3.,4.],
                            [ 5.,  6.,  7.,  8.],
                            [ 9., 10., 11., 12.],
                            [13., 14., 15., 16.]]]])
>>> output,indices=pool(input)
>>> unpool(output,indices)
tensor([[[[  0.,   0.,   0.,   0.],
          [  0.,   6.,   0.,   8.],
          [  0.,   0.,   0.,   0.],
          [  0.,  14.,   0.,  16.]]]])
>>> # Now using output_size to resolve an ambiguous size for the inverse
>>> input=torch.torch.tensor([[[[1.,2.,3.,4.,5.],
                                  [ 6.,  7.,  8., 9., 10.],
                                  [11., 12., 13., 14., 15.],
                                  [16., 17., 18., 19., 20.]]]])
>>> output,indices=pool(input)
>>> # This call will not work without specifying output_size
>>> unpool(output,indices,output_size=input.size())
tensor([[[[ 0.,  0.,  0.,  0.,  0.],
          [ 0.,  7.,  0.,  9.,  0.],
          [ 0.,  0.,  0.,  0.,  0.],
          [ 0., 17.,  0., 19.,  0.]]]])
","  File ""example.py"", line 5
    output,indices=pool(input)
                  ^
SyntaxError: invalid syntax
"
"
 class torch.nn. MaxUnpool3d ( kernel_size ,  stride ,  padding ) [source] ¶",">>> # pool of square window of size=3, stride=2
>>> pool=nn.MaxPool3d(3,stride=2,return_indices=True)
>>> unpool=nn.MaxUnpool3d(3,stride=2)
>>> output,indices=pool(torch.randn(20,16,51,33,15))
>>> unpooled_output=unpool(output,indices)
>>> unpooled_output.size()
torch.Size([20, 16, 51, 33, 15])
","Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    pool=nn.MaxPool3d(3,stride=2,return_indices=True)
NameError: name 'nn' is not defined
"
"
 class torch.nn. DataParallel ( module ,  device_ids ,  output_device ,  dim ) [source] ¶",">>> net=torch.nn.DataParallel(model,device_ids=[0,1,2])
>>> output=net(input_var)# input_var can be on any device, including CPU
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    net=torch.nn.DataParallel(model,device_ids=[0,1,2])
NameError: name 'model' is not defined
"
"
 class torch.nn.parallel. DistributedDataParallel ( module ,  device_ids ,  output_device ,  dim ,  broadcast_buffers ,  process_group ,  bucket_cap_mb ,  find_unused_parameters ,  check_reduction ,  gradient_as_bucket_view ,  static_graph ) [source] ¶",">>> torch.distributed.init_process_group(backend='nccl',world_size=4,init_method='...')
>>> net=torch.nn.parallel.DistributedDataParallel(model)
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    torch.distributed.init_process_group(backend='nccl',world_size=4,init_method='...')
  File ""/home/nimashiri/.local/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py"", line 497, in init_process_group
    rendezvous_iterator = rendezvous(
  File ""/home/nimashiri/.local/lib/python3.8/site-packages/torch/distributed/rendezvous.py"", line 82, in rendezvous
    raise RuntimeError(""No rendezvous handler for {}://"".format(result.scheme))
RuntimeError: No rendezvous handler for ://
"
"
 torch.nn.utils. weight_norm ( module ,  name ,  dim ) [source] ¶",">>> m=weight_norm(nn.Linear(20,40),name='weight')
>>> m
Linear(in_features=20, out_features=40, bias=True)
>>> m.weight_g.size()
torch.Size([40, 1])
>>> m.weight_v.size()
torch.Size([40, 20])
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    m=weight_norm(nn.Linear(20,40),name='weight')
NameError: name 'weight_norm' is not defined
"
"
 torch.nn.utils. spectral_norm ( module ,  name ,  n_power_iterations ,  eps ,  dim ) [source] ¶",">>> m=spectral_norm(nn.Linear(20,40))
>>> m
Linear(in_features=20, out_features=40, bias=True)
>>> m.weight_u.size()
torch.Size([40])
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    m=spectral_norm(nn.Linear(20,40))
NameError: name 'spectral_norm' is not defined
"
"
 torch.nn.utils. skip_init ( module_cls ,  * ,  ** ) [source] ¶",">>> importtorch
>>> m=torch.nn.utils.skip_init(torch.nn.Linear,5,1)
>>> m.weight
Parameter containing:
tensor([[0.0000e+00, 1.5846e+29, 7.8307e+00, 2.5250e-29, 1.1210e-44]],
       requires_grad=True)
>>> m2=torch.nn.utils.skip_init(torch.nn.Linear,in_features=6,out_features=1)
>>> m2.weight
Parameter containing:
tensor([[-1.4677e+24,  4.5915e-41,  1.4013e-45,  0.0000e+00, -1.4677e+24,
          4.5915e-41]], requires_grad=True)
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    importtorch
NameError: name 'importtorch' is not defined
"
"
 torch.nn.utils.parametrizations. orthogonal ( module ,  name ,  orthogonal_map ,  * ,  use_trivialization ) [source] ¶",">>> orth_linear=orthogonal(nn.Linear(20,40))
>>> orth_linear
ParametrizedLinear(
in_features=20, out_features=40, bias=True
(parametrizations): ModuleDict(
    (weight): ParametrizationList(
    (0): _Orthogonal()
    )
)
)
>>> Q=orth_linear.weight
>>> torch.dist(Q.T@Q,torch.eye(20))
tensor(4.9332e-07)
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    orth_linear=orthogonal(nn.Linear(20,40))
NameError: name 'orthogonal' is not defined
"
"
 torch.nn.utils.parametrizations. spectral_norm ( module ,  name ,  n_power_iterations ,  eps ,  dim ) [source] ¶",">>> snm=spectral_norm(nn.Linear(20,40))
>>> snm
ParametrizedLinear(
  in_features=20, out_features=40, bias=True
  (parametrizations): ModuleDict(
    (weight): ParametrizationList(
      (0): _SpectralNorm()
    )
  )
)
>>> torch.linalg.matrix_norm(snm.weight,2)
tensor(1.0081, grad_fn=<AmaxBackward0>)
","Traceback (most recent call last):
  File ""example.py"", line 2, in <module>
    snm=spectral_norm(nn.Linear(20,40))
NameError: name 'spectral_norm' is not defined
"
"
 torch.nn.functional. cosine_similarity ( x1 ,  x2 ,  dim ,  eps )   → ¶",">>> input1=torch.randn(100,128)
>>> input2=torch.randn(100,128)
>>> output=F.cosine_similarity(input1,input2)
>>> print(output)
","Traceback (most recent call last):
  File ""example.py"", line 4, in <module>
    output=F.cosine_similarity(input1,input2)
NameError: name 'F' is not defined
"
"
 torch.nn.functional. ctc_loss ( log_probs ,  targets ,  input_lengths ,  target_lengths ,  blank ,  reduction ,  zero_infinity ) [source] ¶",">>> log_probs=torch.randn(50,16,20).log_softmax(2).detach().requires_grad_()
>>> targets=torch.randint(1,20,(16,30),dtype=torch.long)
>>> input_lengths=torch.full((16,),50,dtype=torch.long)
>>> target_lengths=torch.randint(10,30,(16,),dtype=torch.long)
>>> loss=F.ctc_loss(log_probs,targets,input_lengths,target_lengths)
>>> loss.backward()
","Traceback (most recent call last):
  File ""example.py"", line 6, in <module>
    loss=F.ctc_loss(log_probs,targets,input_lengths,target_lengths)
NameError: name 'F' is not defined
"
"
 torch.nn.functional. nll_loss ( input ,  target ,  weight ,  size_average ,  ignore_index ,  reduce ,  reduction ) [source] ¶",">>> # input is of size N x C = 3 x 5
>>> input=torch.randn(3,5,requires_grad=True)
>>> # each element in target has to have 0 <= value < C
>>> target=torch.tensor([1,0,4])
>>> output=F.nll_loss(F.log_softmax(input,dim=1),target)
>>> output.backward()
","Traceback (most recent call last):
  File ""example.py"", line 6, in <module>
    output=F.nll_loss(F.log_softmax(input,dim=1),target)
NameError: name 'F' is not defined
"
"
 Tensor. requires_grad_ ( requires_grad )   → ¶",">>> # Let's say we want to preprocess some saved weights and use
>>> # the result as new weights.
>>> saved_weights=[0.1,0.2,0.3,0.25]
>>> loaded_weights=torch.tensor(saved_weights)
>>> weights=preprocess(loaded_weights)# some function
>>> weights
tensor([-0.5503,  0.4926, -2.1158, -0.8303])>>> # Now, start to record operations done to weights
>>> weights.requires_grad_()
>>> out=weights.pow(2).sum()
>>> out.backward()
>>> weights.grad
tensor([-1.1007,  0.9853, -4.2316, -1.6606])
","Traceback (most recent call last):
  File ""example.py"", line 6, in <module>
    weights=preprocess(loaded_weights)# some function
NameError: name 'preprocess' is not defined
"
"
 Tensor. to ( * ,  ** )   → ¶",">>> tensor=torch.randn(2,2)# Initially dtype=float32, device=cpu
>>> tensor.to(torch.float64)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], dtype=torch.float64)>>> cuda0=torch.device('cuda:0')
>>> tensor.to(cuda0)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], device='cuda:0')>>> tensor.to(cuda0,dtype=torch.float64)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')>>> other=torch.randn((),dtype=torch.float64,device=cuda0)
>>> tensor.to(other,non_blocking=True)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')
","  File ""example.py"", line 4
    [ 0.3310, -0.0584]], dtype=torch.float64)cuda0=torch.device('cuda:0')
    ^
IndentationError: unexpected indent
"
"
 Tensor. put_ ( index ,  source ,  accumulate )   → ¶",">>> src=torch.tensor([[4,3,5],
... [6,7,8]])
>>> src.put_(torch.tensor([1,3]),torch.tensor([9,10]))
tensor([[  4,   9,   5],
        [ 10,   7,   8]])
","  File ""example.py"", line 4
    
                                                      ^
SyntaxError: unexpected EOF while parsing
"
"
 Tensor. register_hook ( hook ) [source] ¶",">>> v=torch.tensor([0.,0.,0.],requires_grad=True)
>>> h=v.register_hook(lambdagrad:grad*2)# double the gradient
>>> v.backward(torch.tensor([1.,2.,3.]))
>>> v.grad 2
 4
 6
[torch.FloatTensor of size (3,)]>>> h.remove()# removes the hook
","  File ""example.py"", line 3
    h=v.register_hook(lambdagrad:grad*2)# double the gradient
                                ^
SyntaxError: invalid syntax
"
"
 Tensor. sparse_mask ( mask )   → ¶",">>> nse=5
>>> dims=(5,5,2,2)
>>> I=torch.cat([torch.randint(0,dims[0],size=(nse,)),
... torch.randint(0,dims[1],size=(nse,))],0).reshape(2,nse)
>>> V=torch.randn(nse,dims[2],dims[3])
>>> S=torch.sparse_coo_tensor(I,V,dims).coalesce()
>>> D=torch.randn(dims)
>>> D.sparse_mask(S)
tensor(indices=tensor([[0, 0, 0, 2],
                       [0, 1, 4, 3]]),
       values=tensor([[[ 1.6550,  0.2397],
                       [-0.1611, -0.0779]],                      [[ 0.2326, -1.0558],
                       [ 1.4711,  1.9678]],                      [[-0.5138, -0.0411],
                       [ 1.9417,  0.5158]],                      [[ 0.0793,  0.0036],
                       [-0.2569, -0.1055]]]),
       size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)
","  File ""example.py"", line 5
    V=torch.randn(nse,dims[2],dims[3])
     ^
SyntaxError: invalid syntax
"
"
 Tensor. to_dense ( )   → ¶",">>> s=torch.sparse_coo_tensor(
... torch.tensor([[1,1],
... [0,2]]),
... torch.tensor([9,10]),
... size=(3,3))
>>> s.to_dense()
tensor([[ 0,  0,  0],
        [ 9,  0, 10],
        [ 0,  0,  0]])
","  File ""example.py"", line 4
    
                ^
SyntaxError: unexpected EOF while parsing
"
"
 Tensor. to_sparse_csr ( )   → ¶",">>> dense=torch.randn(5,5)
>>> sparse=dense.to_sparse_csr()
>>> sparse._nnz()
25
","Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    sparse=dense.to_sparse_csr()
AttributeError: 'Tensor' object has no attribute 'to_sparse_csr'
"
"
 Tensor. to_sparse_csc ( )   → ¶",">>> dense=torch.randn(5,5)
>>> sparse=dense.to_sparse_csc()
>>> sparse._nnz()
25
","Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    sparse=dense.to_sparse_csc()
AttributeError: 'Tensor' object has no attribute 'to_sparse_csc'
"
"
 Tensor. to_sparse_bsr ( blocksize )   → ¶",">>> dense=torch.randn(10,10)
>>> sparse=dense.to_sparse_csr()
>>> sparse_bsr=sparse.to_sparse_bsr((5,5))
>>> sparse_bsr.col_indices()
tensor([0, 1, 0, 1])
","Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    sparse=dense.to_sparse_csr()
AttributeError: 'Tensor' object has no attribute 'to_sparse_csr'
"
"
 Tensor. to_sparse_bsc ( blocksize )   → ¶",">>> dense=torch.randn(10,10)
>>> sparse=dense.to_sparse_csr()
>>> sparse_bsc=sparse.to_sparse_bsc((5,5))
>>> sparse_bsc.row_indices()
tensor([0, 1, 0, 1])
","Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    sparse=dense.to_sparse_csr()
AttributeError: 'Tensor' object has no attribute 'to_sparse_csr'
"
"
 Tensor. view ( * )   → ¶",">>> x=torch.randn(4,4)
>>> x.size()
torch.Size([4, 4])
>>> y=x.view(16)
>>> y.size()
torch.Size([16])
>>> z=x.view(-1,8)# the size -1 is inferred from other dimensions
>>> z.size()
torch.Size([2, 8])>>> a=torch.randn(1,2,3,4)
>>> a.size()
torch.Size([1, 2, 3, 4])
>>> b=a.transpose(1,2)# Swaps 2nd and 3rd dimension
>>> b.size()
torch.Size([1, 3, 2, 4])
>>> c=a.view(1,3,2,4)# Does not change tensor layout in memory
>>> c.size()
torch.Size([1, 3, 2, 4])
>>> torch.equal(b,c)
False
","  File ""example.py"", line 8
    torch.Size([2, 8])a=torch.randn(1,2,3,4)
                      ^
SyntaxError: invalid syntax
"
"
 class torch.autograd.forward_ad. dual_level [source] ¶",">>> x=torch.tensor([1])
>>> x_t=torch.tensor([1])
>>> withdual_level():
... inp=make_dual(x,x_t)
... # Do computations with inp
... out=your_fn(inp)
... _,grad=unpack_dual(out)
>>> gradisNone
False
>>> # After exiting the level, the grad is deleted
>>> _,grad_after=unpack_dual(out)
>>> gradisNone
True
","  File ""example.py"", line 4
    withdual_level():
                    ^
SyntaxError: invalid syntax
"
"
 torch.autograd.forward_ad. make_dual ( tensor ,  tangent ,  * ,  level ) [source] ¶",">>> withdual_level():
... inp=make_dual(x,v)
... out=f(inp)
... y,jvp=unpack_dual(out)
","  File ""example.py"", line 2
    withdual_level():
                    ^
SyntaxError: invalid syntax
"
"
 torch.autograd.forward_ad. unpack_dual ( tensor ,  * ,  level ) [source] ¶",">>> withdual_level():
... inp=make_dual(x,x_t)
... out=f(inp)
... y,jvp=unpack_dual(out)
... jvp=unpack_dual(out).tangent
","  File ""example.py"", line 2
    withdual_level():
                    ^
SyntaxError: invalid syntax
"
"
 torch.linalg. vander ( x ,  N )   → ¶",">>> x=torch.tensor([1,2,3,5])
>>> linalg.vander(x)
tensor([[  1,   1,   1,   1],
        [  1,   2,   4,   8],
        [  1,   3,   9,  27],
        [  1,   5,  25, 125]])
>>> linalg.vander(x,N=3)
tensor([[ 1,  1,  1],
        [ 1,  2,  4],
        [ 1,  3,  9],
        [ 1,  5, 25]])
","Traceback (most recent call last):
  File ""example.py"", line 3, in <module>
    linalg.vander(x)
NameError: name 'linalg' is not defined
"
"
 torch.sparse. sum ( input ,  dim ,  dtype ) [source] ¶",">>> nnz=3
>>> dims=[5,5,2,3]
>>> I=torch.cat([torch.randint(0,dims[0],size=(nnz,)),
                   torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)
>>> V=torch.randn(nnz,dims[2],dims[3])
>>> size=torch.Size(dims)
>>> S=torch.sparse_coo_tensor(I,V,size)
>>> S
tensor(indices=tensor([[2, 0, 3],
                       [2, 4, 1]]),
       values=tensor([[[-0.6438, -1.6467,  1.4004],
                       [ 0.3411,  0.0918, -0.2312]],                      [[ 0.5348,  0.0634, -2.0494],
                       [-0.7125, -1.0646,  2.1844]],                      [[ 0.1276,  0.1874, -0.6334],
                       [-1.9682, -0.5340,  0.7483]]]),
       size=(5, 5, 2, 3), nnz=3, layout=torch.sparse_coo)# when sum over only part of sparse_dims, return a sparse tensor
>>> torch.sparse.sum(S,[1,3])
tensor(indices=tensor([[0, 2, 3]]),
       values=tensor([[-1.4512,  0.4073],
                      [-0.8901,  0.2017],
                      [-0.3183, -1.7539]]),
       size=(5, 2), nnz=3, layout=torch.sparse_coo)# when sum over all sparse dim, return a dense tensor
# with summed dims squeezed
>>> torch.sparse.sum(S,[0,1,3])
tensor([-2.6596, -1.1450])
","  File ""example.py"", line 5
    V=torch.randn(nnz,dims[2],dims[3])
     ^
SyntaxError: invalid syntax
"
