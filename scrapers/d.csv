Raw_API,Full_API,Description
tf.debugging.Assert,"tf.debugging.Assert(
    condition, data, summarize=None, name=None
)
",Asserts that the given condition is true.View aliases
tf.CriticalSection,"tf.CriticalSection(
    name=None, shared_name=None, critical_section_def=None, import_scope=None
)
",Critical section.View aliases
tf.DeviceSpec,"tf.DeviceSpec(
    job=None, replica=None, task=None, device_type=None, device_index=None
)
",Represents a (possibly partial) specification for a TensorFlow device.
tf.GradientTape,"tf.GradientTape(
    persistent=False, watch_accessed_variables=True
)
",Record operations for automatic differentiation.View aliases
tf.IndexedSlices,"tf.IndexedSlices(
    values, indices, dense_shape=None
)
",A sparse representation of a set of tensor slices at given indices.View aliases
tf.IndexedSlicesSpec,"tf.IndexedSlicesSpec(
    shape=None,
    dtype=tf.dtypes.float32,
    indices_dtype=tf.dtypes.int64,
    dense_shape_dtype=None,
    indices_shape=None
)
","Type specification for a tf.IndexedSlices.Inherits From: TypeSpec, TraceTypeView aliases"
tf.Module,"tf.Module(
    name=None
)
",Base neural network module class.View aliases
tf.Operation,"tf.Operation(
    node_def,
    g,
    inputs=None,
    output_types=None,
    control_inputs=None,
    input_types=None,
    original_op=None,
    op_def=None
)
",Represents a graph node that performs computation on tensors.View aliases
tf.OptionalSpec,"tf.OptionalSpec(
    element_spec
)
","Type specification for tf.experimental.Optional.Inherits From: TypeSpec, TraceTypeView aliases"
tf.ragged.constant,"tf.ragged.constant([[0], [1, 2]]).shape","Represents a ragged tensor.View aliasesUsed in the notebooksA RaggedTensor is a tensor with one or more ragged dimensions, which aredimensions whose slices may have different lengths.  For example, the inner(column) dimension of rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []] is ragged,since the column slices (rt[0, :], ..., rt[4, :]) have different lengths.Dimensions whose slices all have the same length are called uniformdimensions.  The outermost dimension of a RaggedTensor is always uniform,since it consists of a single slice (and so there is no possibility fordiffering slice lengths).The total number of dimensions in a RaggedTensor is called its rank,and the number of ragged dimensions in a RaggedTensor is called itsragged-rank.  A RaggedTensor's ragged-rank is fixed at graph creationtime: it can't depend on the runtime values of Tensors, and can't varydynamically for different session runs.Note that the __init__ constructor is private. Please use one of thefollowing methods to construct a RaggedTensor:tf.RaggedTensor.from_row_lengthstf.RaggedTensor.from_value_rowidstf.RaggedTensor.from_row_splitstf.RaggedTensor.from_row_startstf.RaggedTensor.from_row_limitstf.RaggedTensor.from_nested_row_splitstf.RaggedTensor.from_nested_row_lengthstf.RaggedTensor.from_nested_value_rowidsPotentially Ragged TensorsMany ops support both Tensors and RaggedTensors(see tf.ragged for afull listing). The term ""potentially ragged tensor"" may be used to refer to atensor that might be either a Tensor or a RaggedTensor.  The ragged-rankof a Tensor is zero.Documenting RaggedTensor ShapesWhen documenting the shape of a RaggedTensor, ragged dimensions can beindicated by enclosing them in parentheses.  For example, the shape ofa 3-D RaggedTensor that stores the fixed-size word embedding for eachword in a sentence, for each sentence in a batch, could be written as[num_sentences, (num_words), embedding_size].  The parentheses around(num_words) indicate that dimension is ragged, and that the lengthof each element list in that dimension may vary for each item.Component TensorsInternally, a RaggedTensor consists of a concatenated list of values thatare partitioned into variable-length rows.  In particular, each RaggedTensorconsists of:A A Example:print(tf.RaggedTensor.from_row_splits(      values=[3, 1, 4, 1, 5, 9, 2, 6],      row_splits=[0, 4, 4, 7, 8, 8]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>Alternative Row-Partitioning SchemesIn addition to row_splits, ragged tensors provide support for five otherrow-partitioning schemes:row_lengthsvalue_rowidsrow_startsrow_limitsuniform_row_lengthExample: The following ragged tensors are equivalent, and all represent thenested list [[3, 1, 4, 1], [], [5, 9, 2], [6], []].values = [3, 1, 4, 1, 5, 9, 2, 6]RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_value_rowids(    values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5)<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_uniform_row_length(values, uniform_row_length=2)<tf.RaggedTensor [[3, 1], [4, 1], [5, 9], [2, 6]]>Multiple Ragged DimensionsRaggedTensors with multiple ragged dimensions can be defined by usinga nested RaggedTensor for the values tensor.  Each nested RaggedTensoradds a single ragged dimension.inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above    values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8])outer_rt = RaggedTensor.from_row_splits(    values=inner_rt, row_splits=[0, 3, 3, 5])print(outer_rt.to_list())[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]print(outer_rt.ragged_rank)2The factory function RaggedTensor.from_nested_row_splits may be used toconstruct a RaggedTensor with multiple ragged dimensions directly, byproviding a list of row_splits tensors:RaggedTensor.from_nested_row_splits(    flat_values=[3, 1, 4, 1, 5, 9, 2, 6],    nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list()[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]Uniform Inner DimensionsRaggedTensors with uniform inner dimensions can be definedby using a multidimensional Tensor for values.rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3], tf.int32),                                  row_splits=[0, 2, 5])print(rt.to_list())[[[1, 1, 1], [1, 1, 1]], [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]print(rt.shape)(2, None, 3)Uniform Outer DimensionsRaggedTensors with uniform outer dimensions can be defined by usingone or more RaggedTensor with a uniform_row_length row-partitioningtensor.  For example, a RaggedTensor with shape [2, 2, None] can beconstructed with this method from a RaggedTensor values with shape[4, None]:values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])print(values.shape)(4, None)rt6 = tf.RaggedTensor.from_uniform_row_length(values, 2)print(rt6)<tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>print(rt6.shape)(2, 2, None)Note that rt6 only contains one ragged dimension (the innermostdimension). In contrast, if from_row_splits is used to construct a similarRaggedTensor, then that RaggedTensor will have two ragged dimensions:rt7 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])print(rt7.shape)(2, None, None)Uniform and ragged outer dimensions may be interleaved, meaning that atensor with any combination of ragged and uniform dimensions may be created.For example, a RaggedTensor t4 with shape [3, None, 4, 8, None, 2] couldbe constructed as follows:t0 = tf.zeros([1000, 2])                           # Shape:         [1000, 2]t1 = RaggedTensor.from_row_lengths(t0, [...])      #           [160, None, 2]t2 = RaggedTensor.from_uniform_row_length(t1, 8)   #         [20, 8, None, 2]t3 = RaggedTensor.from_uniform_row_length(t2, 4)   #       [5, 4, 8, None, 2]t4 = RaggedTensor.from_row_lengths(t3, [...])      # [3, None, 4, 8, None, 2]Concretely, if rt.values is a Tensor, then rt.flat_values isrt.values; otherwise, rt.flat_values is rt.values.flat_values.Conceptually, flat_values is the tensor formed by flattening theoutermost dimension and all of the ragged dimensions into a singledimension.rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:](where nvals is the number of items in the flattened dimensions).Example:rt = tf.ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])print(rt.flat_values)tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)rt.nested_row_splits is a tuple containing the row_splits tensors forall ragged dimensions in rt, ordered from outermost to innermost.  Inparticular, rt.nested_row_splits = (rt.row_splits,) + value_splits where:* `value_splits = ()` if `rt.values` is a `Tensor`.* `value_splits = rt.values.nested_row_splits` otherwise.Example:rt = tf.ragged.constant(    [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])for i, splits in enumerate(rt.nested_row_splits):  print('Splits for dimension %d: %s' % (i+1, splits.numpy()))Splits for dimension 1: [0 3]Splits for dimension 2: [0 3 3 5]Splits for dimension 3: [0 4 4 7 8 8]values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])values.ragged_rank1rt = tf.RaggedTensor.from_uniform_row_length(values, 2)rt.ragged_rank2rt.row_splits specifies where the values for each row begin and end inrt.values.  In particular, the values for row rt[i] are stored inthe slice rt.values[rt.row_splits[i]:rt.row_splits[i+1]].Example:rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])print(rt.row_splits)  # indices of row splits in rt.valuestf.Tensor([0 4 4 7 8 8], shape=(6,), dtype=int64)"
tf.ragged.constant,"tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shape","Represents a ragged tensor.View aliasesUsed in the notebooksA RaggedTensor is a tensor with one or more ragged dimensions, which aredimensions whose slices may have different lengths.  For example, the inner(column) dimension of rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []] is ragged,since the column slices (rt[0, :], ..., rt[4, :]) have different lengths.Dimensions whose slices all have the same length are called uniformdimensions.  The outermost dimension of a RaggedTensor is always uniform,since it consists of a single slice (and so there is no possibility fordiffering slice lengths).The total number of dimensions in a RaggedTensor is called its rank,and the number of ragged dimensions in a RaggedTensor is called itsragged-rank.  A RaggedTensor's ragged-rank is fixed at graph creationtime: it can't depend on the runtime values of Tensors, and can't varydynamically for different session runs.Note that the __init__ constructor is private. Please use one of thefollowing methods to construct a RaggedTensor:tf.RaggedTensor.from_row_lengthstf.RaggedTensor.from_value_rowidstf.RaggedTensor.from_row_splitstf.RaggedTensor.from_row_startstf.RaggedTensor.from_row_limitstf.RaggedTensor.from_nested_row_splitstf.RaggedTensor.from_nested_row_lengthstf.RaggedTensor.from_nested_value_rowidsPotentially Ragged TensorsMany ops support both Tensors and RaggedTensors(see tf.ragged for afull listing). The term ""potentially ragged tensor"" may be used to refer to atensor that might be either a Tensor or a RaggedTensor.  The ragged-rankof a Tensor is zero.Documenting RaggedTensor ShapesWhen documenting the shape of a RaggedTensor, ragged dimensions can beindicated by enclosing them in parentheses.  For example, the shape ofa 3-D RaggedTensor that stores the fixed-size word embedding for eachword in a sentence, for each sentence in a batch, could be written as[num_sentences, (num_words), embedding_size].  The parentheses around(num_words) indicate that dimension is ragged, and that the lengthof each element list in that dimension may vary for each item.Component TensorsInternally, a RaggedTensor consists of a concatenated list of values thatare partitioned into variable-length rows.  In particular, each RaggedTensorconsists of:A A Example:print(tf.RaggedTensor.from_row_splits(      values=[3, 1, 4, 1, 5, 9, 2, 6],      row_splits=[0, 4, 4, 7, 8, 8]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>Alternative Row-Partitioning SchemesIn addition to row_splits, ragged tensors provide support for five otherrow-partitioning schemes:row_lengthsvalue_rowidsrow_startsrow_limitsuniform_row_lengthExample: The following ragged tensors are equivalent, and all represent thenested list [[3, 1, 4, 1], [], [5, 9, 2], [6], []].values = [3, 1, 4, 1, 5, 9, 2, 6]RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_value_rowids(    values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5)<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_uniform_row_length(values, uniform_row_length=2)<tf.RaggedTensor [[3, 1], [4, 1], [5, 9], [2, 6]]>Multiple Ragged DimensionsRaggedTensors with multiple ragged dimensions can be defined by usinga nested RaggedTensor for the values tensor.  Each nested RaggedTensoradds a single ragged dimension.inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above    values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8])outer_rt = RaggedTensor.from_row_splits(    values=inner_rt, row_splits=[0, 3, 3, 5])print(outer_rt.to_list())[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]print(outer_rt.ragged_rank)2The factory function RaggedTensor.from_nested_row_splits may be used toconstruct a RaggedTensor with multiple ragged dimensions directly, byproviding a list of row_splits tensors:RaggedTensor.from_nested_row_splits(    flat_values=[3, 1, 4, 1, 5, 9, 2, 6],    nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list()[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]Uniform Inner DimensionsRaggedTensors with uniform inner dimensions can be definedby using a multidimensional Tensor for values.rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3], tf.int32),                                  row_splits=[0, 2, 5])print(rt.to_list())[[[1, 1, 1], [1, 1, 1]], [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]print(rt.shape)(2, None, 3)Uniform Outer DimensionsRaggedTensors with uniform outer dimensions can be defined by usingone or more RaggedTensor with a uniform_row_length row-partitioningtensor.  For example, a RaggedTensor with shape [2, 2, None] can beconstructed with this method from a RaggedTensor values with shape[4, None]:values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])print(values.shape)(4, None)rt6 = tf.RaggedTensor.from_uniform_row_length(values, 2)print(rt6)<tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>print(rt6.shape)(2, 2, None)Note that rt6 only contains one ragged dimension (the innermostdimension). In contrast, if from_row_splits is used to construct a similarRaggedTensor, then that RaggedTensor will have two ragged dimensions:rt7 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])print(rt7.shape)(2, None, None)Uniform and ragged outer dimensions may be interleaved, meaning that atensor with any combination of ragged and uniform dimensions may be created.For example, a RaggedTensor t4 with shape [3, None, 4, 8, None, 2] couldbe constructed as follows:t0 = tf.zeros([1000, 2])                           # Shape:         [1000, 2]t1 = RaggedTensor.from_row_lengths(t0, [...])      #           [160, None, 2]t2 = RaggedTensor.from_uniform_row_length(t1, 8)   #         [20, 8, None, 2]t3 = RaggedTensor.from_uniform_row_length(t2, 4)   #       [5, 4, 8, None, 2]t4 = RaggedTensor.from_row_lengths(t3, [...])      # [3, None, 4, 8, None, 2]Concretely, if rt.values is a Tensor, then rt.flat_values isrt.values; otherwise, rt.flat_values is rt.values.flat_values.Conceptually, flat_values is the tensor formed by flattening theoutermost dimension and all of the ragged dimensions into a singledimension.rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:](where nvals is the number of items in the flattened dimensions).Example:rt = tf.ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])print(rt.flat_values)tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)rt.nested_row_splits is a tuple containing the row_splits tensors forall ragged dimensions in rt, ordered from outermost to innermost.  Inparticular, rt.nested_row_splits = (rt.row_splits,) + value_splits where:* `value_splits = ()` if `rt.values` is a `Tensor`.* `value_splits = rt.values.nested_row_splits` otherwise.Example:rt = tf.ragged.constant(    [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])for i, splits in enumerate(rt.nested_row_splits):  print('Splits for dimension %d: %s' % (i+1, splits.numpy()))Splits for dimension 1: [0 3]Splits for dimension 2: [0 3 3 5]Splits for dimension 3: [0 4 4 7 8 8]values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])values.ragged_rank1rt = tf.RaggedTensor.from_uniform_row_length(values, 2)rt.ragged_rank2rt.row_splits specifies where the values for each row begin and end inrt.values.  In particular, the values for row rt[i] are stored inthe slice rt.values[rt.row_splits[i]:rt.row_splits[i+1]].Example:rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])print(rt.row_splits)  # indices of row splits in rt.valuestf.Tensor([0 4 4 7 8 8], shape=(6,), dtype=int64)tf.ragged.constant([[0], [1, 2]]).shapeTensorShape([2, None])"
tf.ragged.constant,tf.ragged.constant(,"Represents a ragged tensor.View aliasesUsed in the notebooksA RaggedTensor is a tensor with one or more ragged dimensions, which aredimensions whose slices may have different lengths.  For example, the inner(column) dimension of rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []] is ragged,since the column slices (rt[0, :], ..., rt[4, :]) have different lengths.Dimensions whose slices all have the same length are called uniformdimensions.  The outermost dimension of a RaggedTensor is always uniform,since it consists of a single slice (and so there is no possibility fordiffering slice lengths).The total number of dimensions in a RaggedTensor is called its rank,and the number of ragged dimensions in a RaggedTensor is called itsragged-rank.  A RaggedTensor's ragged-rank is fixed at graph creationtime: it can't depend on the runtime values of Tensors, and can't varydynamically for different session runs.Note that the __init__ constructor is private. Please use one of thefollowing methods to construct a RaggedTensor:tf.RaggedTensor.from_row_lengthstf.RaggedTensor.from_value_rowidstf.RaggedTensor.from_row_splitstf.RaggedTensor.from_row_startstf.RaggedTensor.from_row_limitstf.RaggedTensor.from_nested_row_splitstf.RaggedTensor.from_nested_row_lengthstf.RaggedTensor.from_nested_value_rowidsPotentially Ragged TensorsMany ops support both Tensors and RaggedTensors(see tf.ragged for afull listing). The term ""potentially ragged tensor"" may be used to refer to atensor that might be either a Tensor or a RaggedTensor.  The ragged-rankof a Tensor is zero.Documenting RaggedTensor ShapesWhen documenting the shape of a RaggedTensor, ragged dimensions can beindicated by enclosing them in parentheses.  For example, the shape ofa 3-D RaggedTensor that stores the fixed-size word embedding for eachword in a sentence, for each sentence in a batch, could be written as[num_sentences, (num_words), embedding_size].  The parentheses around(num_words) indicate that dimension is ragged, and that the lengthof each element list in that dimension may vary for each item.Component TensorsInternally, a RaggedTensor consists of a concatenated list of values thatare partitioned into variable-length rows.  In particular, each RaggedTensorconsists of:A A Example:print(tf.RaggedTensor.from_row_splits(      values=[3, 1, 4, 1, 5, 9, 2, 6],      row_splits=[0, 4, 4, 7, 8, 8]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>Alternative Row-Partitioning SchemesIn addition to row_splits, ragged tensors provide support for five otherrow-partitioning schemes:row_lengthsvalue_rowidsrow_startsrow_limitsuniform_row_lengthExample: The following ragged tensors are equivalent, and all represent thenested list [[3, 1, 4, 1], [], [5, 9, 2], [6], []].values = [3, 1, 4, 1, 5, 9, 2, 6]RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_value_rowids(    values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5)<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_uniform_row_length(values, uniform_row_length=2)<tf.RaggedTensor [[3, 1], [4, 1], [5, 9], [2, 6]]>Multiple Ragged DimensionsRaggedTensors with multiple ragged dimensions can be defined by usinga nested RaggedTensor for the values tensor.  Each nested RaggedTensoradds a single ragged dimension.inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above    values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8])outer_rt = RaggedTensor.from_row_splits(    values=inner_rt, row_splits=[0, 3, 3, 5])print(outer_rt.to_list())[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]print(outer_rt.ragged_rank)2The factory function RaggedTensor.from_nested_row_splits may be used toconstruct a RaggedTensor with multiple ragged dimensions directly, byproviding a list of row_splits tensors:RaggedTensor.from_nested_row_splits(    flat_values=[3, 1, 4, 1, 5, 9, 2, 6],    nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list()[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]Uniform Inner DimensionsRaggedTensors with uniform inner dimensions can be definedby using a multidimensional Tensor for values.rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3], tf.int32),                                  row_splits=[0, 2, 5])print(rt.to_list())[[[1, 1, 1], [1, 1, 1]], [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]print(rt.shape)(2, None, 3)Uniform Outer DimensionsRaggedTensors with uniform outer dimensions can be defined by usingone or more RaggedTensor with a uniform_row_length row-partitioningtensor.  For example, a RaggedTensor with shape [2, 2, None] can beconstructed with this method from a RaggedTensor values with shape[4, None]:values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])print(values.shape)(4, None)rt6 = tf.RaggedTensor.from_uniform_row_length(values, 2)print(rt6)<tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>print(rt6.shape)(2, 2, None)Note that rt6 only contains one ragged dimension (the innermostdimension). In contrast, if from_row_splits is used to construct a similarRaggedTensor, then that RaggedTensor will have two ragged dimensions:rt7 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])print(rt7.shape)(2, None, None)Uniform and ragged outer dimensions may be interleaved, meaning that atensor with any combination of ragged and uniform dimensions may be created.For example, a RaggedTensor t4 with shape [3, None, 4, 8, None, 2] couldbe constructed as follows:t0 = tf.zeros([1000, 2])                           # Shape:         [1000, 2]t1 = RaggedTensor.from_row_lengths(t0, [...])      #           [160, None, 2]t2 = RaggedTensor.from_uniform_row_length(t1, 8)   #         [20, 8, None, 2]t3 = RaggedTensor.from_uniform_row_length(t2, 4)   #       [5, 4, 8, None, 2]t4 = RaggedTensor.from_row_lengths(t3, [...])      # [3, None, 4, 8, None, 2]Concretely, if rt.values is a Tensor, then rt.flat_values isrt.values; otherwise, rt.flat_values is rt.values.flat_values.Conceptually, flat_values is the tensor formed by flattening theoutermost dimension and all of the ragged dimensions into a singledimension.rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:](where nvals is the number of items in the flattened dimensions).Example:rt = tf.ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])print(rt.flat_values)tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)rt.nested_row_splits is a tuple containing the row_splits tensors forall ragged dimensions in rt, ordered from outermost to innermost.  Inparticular, rt.nested_row_splits = (rt.row_splits,) + value_splits where:* `value_splits = ()` if `rt.values` is a `Tensor`.* `value_splits = rt.values.nested_row_splits` otherwise.Example:rt = tf.ragged.constant(    [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])for i, splits in enumerate(rt.nested_row_splits):  print('Splits for dimension %d: %s' % (i+1, splits.numpy()))Splits for dimension 1: [0 3]Splits for dimension 2: [0 3 3 5]Splits for dimension 3: [0 4 4 7 8 8]values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])values.ragged_rank1rt = tf.RaggedTensor.from_uniform_row_length(values, 2)rt.ragged_rank2rt.row_splits specifies where the values for each row begin and end inrt.values.  In particular, the values for row rt[i] are stored inthe slice rt.values[rt.row_splits[i]:rt.row_splits[i+1]].Example:rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])print(rt.row_splits)  # indices of row splits in rt.valuestf.Tensor([0 4 4 7 8 8], shape=(6,), dtype=int64)tf.ragged.constant([[0], [1, 2]]).shapeTensorShape([2, None])tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shapeTensorShape([2, None, 2])rt1 = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])print(rt1.uniform_row_length)  # rows are ragged.Nonert2 = tf.RaggedTensor.from_uniform_row_length(    values=rt1, uniform_row_length=2)print(rt2)<tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>print(rt2.uniform_row_length)  # rows are not ragged (all have size 2).tf.Tensor(2, shape=(), dtype=int64)A RaggedTensor's rows are only considered to be uniform (i.e. non-ragged)if it can be determined statically (at graph construction time) that therows all have the same length.rt.values is a potentially ragged tensor formed by flattening the twooutermost dimensions of rt into a single dimension.rt.values.shape = [nvals] + rt.shape[2:] (where nvals is thenumber of items in the outer two dimensions of rt).rt.ragged_rank = self.ragged_rank - 1Example:rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])print(rt.values)tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)Methodsbounding_shapeView sourcebounding_shape(    axis=None, name=None, out_type=None)Returns the tight bounding box shape for this RaggedTensor.Example:rt = tf.ragged.constant([[1, 2, 3, 4], [5], [], [6, 7, 8, 9], [10]])rt.bounding_shape().numpy()array([5, 4])consumersView sourceconsumers()from_nested_row_lengthsView source@classmethodfrom_nested_row_lengths(    flat_values, nested_row_lengths, name=None, validate=True)Creates a RaggedTensor from a nested list of row_lengths tensors.Equivalent to:result = flat_valuesfor row_lengths in reversed(nested_row_lengths):  result = from_row_lengths(result, row_lengths)from_nested_row_splitsView source@classmethodfrom_nested_row_splits(    flat_values, nested_row_splits, name=None, validate=True)Creates a RaggedTensor from a nested list of row_splits tensors.Equivalent to:result = flat_valuesfor row_splits in reversed(nested_row_splits):  result = from_row_splits(result, row_splits)from_nested_value_rowidsView source@classmethodfrom_nested_value_rowids(    flat_values,    nested_value_rowids,    nested_nrows=None,    name=None,    validate=True)Creates a RaggedTensor from a nested list of value_rowids tensors.Equivalent to:result = flat_valuesfor (rowids, nrows) in reversed(zip(nested_value_rowids, nested_nrows)):  result = from_value_rowids(result, rowids, nrows)from_row_lengthsView source@classmethodfrom_row_lengths(    values, row_lengths, name=None, validate=True)Creates a RaggedTensor with rows partitioned by row_lengths.The returned RaggedTensor corresponds with the python list defined by:result = [[values.pop(0) for i in range(length)]          for length in row_lengths]Example:print(tf.RaggedTensor.from_row_lengths(    values=[3, 1, 4, 1, 5, 9, 2, 6],    row_lengths=[4, 0, 3, 1, 0]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>from_row_limitsView source@classmethodfrom_row_limits(    values, row_limits, name=None, validate=True)Creates a RaggedTensor with rows partitioned by row_limits.Equivalent to: from_row_splits(values, concat([0, row_limits])).Example:print(tf.RaggedTensor.from_row_limits(    values=[3, 1, 4, 1, 5, 9, 2, 6],    row_limits=[4, 4, 7, 8, 8]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>from_row_splitsView source@classmethodfrom_row_splits(    values, row_splits, name=None, validate=True)Creates a RaggedTensor with rows partitioned by row_splits.The returned RaggedTensor corresponds with the python list defined by:result = [values[row_splits[i]:row_splits[i + 1]]          for i in range(len(row_splits) - 1)]Example:print(tf.RaggedTensor.from_row_splits(    values=[3, 1, 4, 1, 5, 9, 2, 6],    row_splits=[0, 4, 4, 7, 8, 8]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>from_row_startsView source@classmethodfrom_row_starts(    values, row_starts, name=None, validate=True)Creates a RaggedTensor with rows partitioned by row_starts.Equivalent to: from_row_splits(values, concat([row_starts, nvals])).Example:print(tf.RaggedTensor.from_row_starts(    values=[3, 1, 4, 1, 5, 9, 2, 6],    row_starts=[0, 4, 4, 7, 8]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>from_sparseView source@classmethodfrom_sparse(    st_input,    name=None,    row_splits_dtype=Converts a 2D tf.sparse.SparseTensor to a RaggedTensor.Each row of the output RaggedTensor will contain the explicit valuesfrom the same row in st_input.  st_input must be ragged-right.  If notit is not ragged-right, then an error will be generated.Example:indices = [[0, 0], [0, 1], [0, 2], [1, 0], [3, 0]]st = tf.sparse.SparseTensor(indices=indices,                            values=[1, 2, 3, 4, 5],                            dense_shape=[4, 3])tf.RaggedTensor.from_sparse(st).to_list()[[1, 2, 3], [4], [], [5]]Currently, only two-dimensional SparseTensors are supported.from_tensorView source@classmethodfrom_tensor(    tensor,    lengths=None,    padding=None,    ragged_rank=1,    name=None,    row_splits_dtype=Converts a tf.Tensor into a RaggedTensor.The set of absent/default values may be specified using a vector of lengthsor a padding value (but not both).  If lengths is specified, then theoutput tensor will satisfy output[row] = tensor[row][:lengths[row]]. If'lengths' is a list of lists or tuple of lists, those lists will be usedas nested row lengths. If padding is specified, then any row suffixconsisting entirely of padding will be excluded from the returnedRaggedTensor.  If neither lengths nor padding is specified, then thereturned RaggedTensor will have no absent/default values.Examples:dt = tf.constant([[5, 7, 0], [0, 3, 0], [6, 0, 0]])tf.RaggedTensor.from_tensor(dt)<tf.RaggedTensor [[5, 7, 0], [0, 3, 0], [6, 0, 0]]>tf.RaggedTensor.from_tensor(dt, lengths=[1, 0, 3])<tf.RaggedTensor [[5], [], [6, 0, 0]]>tf.RaggedTensor.from_tensor(dt, padding=0)<tf.RaggedTensor [[5, 7], [0, 3], [6]]>dt = tf.constant([[[5, 0], [7, 0], [0, 0]],                  [[0, 0], [3, 0], [0, 0]],                  [[6, 0], [0, 0], [0, 0]]])tf.RaggedTensor.from_tensor(dt, lengths=([2, 0, 3], [1, 1, 2, 0, 1]))<tf.RaggedTensor [[[5], [7]], [], [[6, 0], [], [0]]]>from_uniform_row_lengthView source@classmethodfrom_uniform_row_length(    values, uniform_row_length, nrows=None, validate=True, name=None)Creates a RaggedTensor with rows partitioned by uniform_row_length.This method can be used to create RaggedTensors with multiple uniformouter dimensions.  For example, a RaggedTensor with shape [2, 2, None]can be constructed with this method from a RaggedTensor values with shape[4, None]:values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])print(values.shape)(4, None)rt1 = tf.RaggedTensor.from_uniform_row_length(values, 2)print(rt1)<tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>print(rt1.shape)(2, 2, None)Note that rt1 only contains one ragged dimension (the innermostdimension). In contrast, if from_row_splits is used to construct a similarRaggedTensor, then that RaggedTensor will have two ragged dimensions:rt2 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])print(rt2.shape)(2, None, None)result = [[values.pop(0) for i in range(uniform_row_length)]          for _ in range(nrows)]result.rank = values.rank + 1.result.ragged_rank = values.ragged_rank + 1.from_value_rowidsView source@classmethodfrom_value_rowids(    values, value_rowids, nrows=None, name=None, validate=True)Creates a RaggedTensor with rows partitioned by value_rowids.The returned RaggedTensor corresponds with the python list defined by:result = [[values[i] for i in range(len(values)) if value_rowids[i] == row]          for row in range(nrows)]Example:print(tf.RaggedTensor.from_value_rowids(    values=[3, 1, 4, 1, 5, 9, 2, 6],    value_rowids=[0, 0, 0, 0, 2, 2, 2, 3],    nrows=5))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>get_shapeView sourceget_shape()The statically known shape of this ragged tensor.Alias for shape property.Examples:tf.ragged.constant([[0], [1, 2]]).get_shape()TensorShape([2, None])"
tf.RaggedTensorSpec,"tf.RaggedTensorSpec(
    shape=None,
    dtype=tf.dtypes.float32,
    ragged_rank=None,
    row_splits_dtype=tf.dtypes.int64,
    flat_values_spec=None
)
","Type specification for a tf.RaggedTensor.Inherits From: TypeSpec, TraceTypeView aliases"
tf.RegisterGradient,"tf.RegisterGradient(
    op_type
)
",A decorator for registering the gradient function for an op type.View aliases
tf.sparse.SparseTensor,"tf.sparse.SparseTensor(
    indices, values, dense_shape
)
",Represents a sparse tensor.View aliases
tf.SparseTensorSpec,"tf.SparseTensorSpec(
    shape=None,
    dtype=tf.dtypes.float32
)
","Type specification for a tf.sparse.SparseTensor.Inherits From: TypeSpec, TraceTypeView aliases"
tf.Tensor,"tf.Tensor(
    op, value_index, dtype
)
",A tf.Tensor represents a multidimensional array of elements.View aliases
tf.TensorArray,"tf.TensorArray(
    dtype,
    size=None,
    dynamic_size=None,
    clear_after_read=None,
    tensor_array_name=None,
    handle=None,
    flow=None,
    infer_shape=True,
    element_shape=None,
    colocate_with_first_write_call=True,
    name=None
)
","Class wrapping dynamic-sized, per-time-step, write-once Tensor arrays.View aliases"
tf.TensorArraySpec,"tf.TensorArraySpec(
    element_shape=None,
    dtype=tf.dtypes.float32,
    dynamic_size=False,
    infer_shape=True
)
","Type specification for a tf.TensorArray.Inherits From: TypeSpec, TraceTypeView aliases"
tf.TensorShape,"tf.TensorShape(
    dims
)
",Represents the shape of a Tensor.Inherits From: TraceTypeView aliases
tf.TensorSpec,"tf.TensorSpec(
    shape,
    dtype=tf.dtypes.float32,
    name=None
)
","Describes a tf.Tensor.Inherits From: TypeSpec, TraceTypeView aliases"
tf.Variable,"tf.Variable(
    initial_value=None,
    trainable=None,
    validate_shape=True,
    caching_device=None,
    name=None,
    variable_def=None,
    dtype=None,
    import_scope=None,
    constraint=None,
    synchronization=tf.VariableSynchronization.AUTO,
    aggregation=tf.compat.v1.VariableAggregation.NONE,
    shape=None
)
",See the variable guide.
tf.Variable.SaveSliceInfo,"tf.Variable.SaveSliceInfo(
    full_name=None,
    full_shape=None,
    var_offset=None,
    var_shape=None,
    save_slice_info_def=None,
    import_scope=None
)
",Information on how to save this Variable as a slice.View aliases
tf.math.abs,"tf.math.abs(
    x, name=None
)
",Computes the absolute value of a tensor.View aliases
tf.math.acos,"tf.math.acos(
    x, name=None
)
",Computes acos of x element-wise.View aliases
tf.math.acosh,"tf.math.acosh(
    x, name=None
)
",Computes inverse hyperbolic cosine of x element-wise.View aliases
tf.math.add,"tf.math.add(
    x, y, name=None
)
",Returns x + y element-wise.View aliases
tf.math.add_n,"tf.math.add_n(
    inputs, name=None
)
",Adds all input tensors element-wise.View aliases
tf.approx_top_k,"tf.approx_top_k(
    input,
    k,
    reduction_dimension=-1,
    recall_target=0.95,
    is_max_k=True,
    reduction_input_size_override=-1,
    aggregate_to_topk=True,
    name=None
)
",Returns min/max k values and their indices of the input operand in an approximate manner.View aliases
tf.math.argmax,"tf.math.argmax(
    input,
    axis=None,
    output_type=tf.dtypes.int64,
    name=None
)
",Returns the index with the largest value across axes of a tensor.View aliases
tf.math.argmin,"tf.math.argmin(
    input,
    axis=None,
    output_type=tf.dtypes.int64,
    name=None
)
",Returns the index with the smallest value across axes of a tensor.View aliases
tf.argsort,"tf.argsort(
    values, axis=-1, direction='ASCENDING', stable=False, name=None
)
",Returns the indices of a tensor that give its sorted order along an axis.View aliases
tf.dtypes.as_dtype,"tf.dtypes.as_dtype(
    type_value
)
",Converts the given type_value to a DType.View aliases
tf.strings.as_string,"tf.strings.as_string(
    input,
    precision=-1,
    scientific=False,
    shortest=False,
    width=-1,
    fill='',
    name=None
)
",Converts each entry in the given tensor to strings.View aliases
tf.math.asin,"tf.math.asin(
    x, name=None
)
",Computes the trignometric inverse sine of x element-wise.View aliases
tf.math.asinh,"tf.math.asinh(
    x, name=None
)
",Computes inverse hyperbolic sine of x element-wise.View aliases
tf.debugging.assert_equal,"tf.debugging.assert_equal(
    x, y, message=None, summarize=None, name=None
)
",Assert the condition x == y holds element-wise.View aliases
tf.debugging.assert_greater,"tf.debugging.assert_greater(
    x, y, message=None, summarize=None, name=None
)
",Assert the condition x > y holds element-wise.View aliases
tf.debugging.assert_less,"tf.debugging.assert_less(
    x, y, message=None, summarize=None, name=None
)
",Assert the condition x < y holds element-wise.View aliases
tf.debugging.assert_rank,"tf.debugging.assert_rank(
    x, rank, message=None, name=None
)
",Assert that x has rank equal to rank.View aliases
tf.math.atan,"tf.math.atan(
    x, name=None
)
",Computes the trignometric inverse tangent of x element-wise.View aliases
tf.math.atan2,"tf.math.atan2(
    y, x, name=None
)
","Computes arctangent of y/x element-wise, respecting signs of the arguments.View aliases"
tf.math.atanh,"tf.math.atanh(
    x, name=None
)
",Computes inverse hyperbolic tangent of x element-wise.View aliases
tf.audio.decode_wav,"tf.audio.decode_wav(
    contents, desired_channels=-1, desired_samples=-1, name=None
)
",Decode a 16-bit PCM WAV file to a float tensor.View aliases
tf.audio.encode_wav,"tf.audio.encode_wav(
    audio, sample_rate, name=None
)
",Encode audio data using the WAV file format.View aliases
tf.autodiff.ForwardAccumulator,"tf.autodiff.ForwardAccumulator(
    primals, tangents
)
","Computes Jacobian-vector products (""JVP""s) using forward-mode autodiff."
tf.GradientTape,"tf.GradientTape(
    persistent=False, watch_accessed_variables=True
)
",Record operations for automatic differentiation.View aliases
tf.autograph.experimental.do_not_convert,"tf.autograph.experimental.do_not_convert(
    func=None
)
",Decorator that suppresses the conversion of a function.View aliases
tf.autograph.experimental.set_loop_options,"tf.autograph.experimental.set_loop_options(
    parallel_iterations=UNSPECIFIED,
    swap_memory=UNSPECIFIED,
    maximum_iterations=UNSPECIFIED,
    shape_invariants=UNSPECIFIED
)
",Specifies additional arguments to be passed to the enclosing while_loop.View aliases
tf.autograph.set_verbosity,"tf.autograph.set_verbosity(
    level, alsologtostdout=False
)
",Sets the AutoGraph verbosity level.View aliases
tf.autograph.to_code,"tf.autograph.to_code(
    entity, recursive=True, experimental_optional_features=None
)
","Returns the source code generated by AutoGraph, as a string."
tf.autograph.to_graph,"tf.autograph.to_graph(
    entity, recursive=True, experimental_optional_features=None
)
",Converts a Python entity into a TensorFlow graph.
tf.autograph.trace,"tf.autograph.trace(
    *args
)
",Traces argument information at compilation time.View aliases
tf.batch_to_space,"tf.batch_to_space(
    input, block_shape, crops, name=None
)
",BatchToSpace for N-D tensors of type T.
tf.bitcast,"tf.bitcast(
    input, type, name=None
)
",Bitcasts a tensor from one type to another without copying data.View aliases
tf.bitwise.bitwise_and,"tf.bitwise.bitwise_and(
    x, y, name=None
)
",Elementwise computes the bitwise AND of x and y.View aliases
tf.bitwise.bitwise_or,"tf.bitwise.bitwise_or(
    x, y, name=None
)
",Elementwise computes the bitwise OR of x and y.View aliases
tf.bitwise.bitwise_xor,"tf.bitwise.bitwise_xor(
    x, y, name=None
)
",Elementwise computes the bitwise XOR of x and y.View aliases
tf.bitwise.invert,"tf.bitwise.invert(
    x, name=None
)
","Invert (flip) each bit of supported types; for example, type uint8 value 01010101 becomes 10101010.View aliases"
tf.bitwise.left_shift,"tf.bitwise.left_shift(
    x, y, name=None
)
",Elementwise computes the bitwise left-shift of x and y.View aliases
tf.bitwise.right_shift,"tf.bitwise.right_shift(
    x, y, name=None
)
",Elementwise computes the bitwise right-shift of x and y.View aliases
tf.boolean_mask,"tf.boolean_mask(
    tensor, mask, axis=None, name='boolean_mask'
)
",Apply boolean mask to tensor.
tf.broadcast_dynamic_shape,"tf.broadcast_dynamic_shape(
    shape_x, shape_y
)
",Computes the shape of a broadcast given symbolic shapes.View aliases
tf.broadcast_static_shape,"tf.broadcast_static_shape(
    shape_x, shape_y
)
",Computes the shape of a broadcast given known shapes.View aliases
tf.broadcast_to,"tf.broadcast_to(
    input, shape, name=None
)
",Broadcast an array for a compatible shape.View aliases
tf.case,"tf.case(
    pred_fn_pairs,
    default=None,
    exclusive=False,
    strict=False,
    name='case'
)
",Create a case operation.
tf.cast,"tf.cast(
    x, dtype, name=None
)
",Casts a tensor to a new type.View aliases
tf.clip_by_global_norm,"tf.clip_by_global_norm(
    t_list, clip_norm, use_norm=None, name=None
)
",Clips values of multiple tensors by the ratio of the sum of their norms.View aliases
tf.clip_by_norm,"tf.clip_by_norm(
    t, clip_norm, axes=None, name=None
)
",Clips tensor values to a maximum L2-norm.View aliases
tf.clip_by_value,"tf.clip_by_value(
    t, clip_value_min, clip_value_max, name=None
)
",Clips tensor values to a specified min and max.View aliases
tf.compat.as_bytes,"tf.compat.as_bytes(
    bytes_or_text, encoding='utf-8'
)
","Converts bytearray, bytes, or unicode python input types to bytes.View aliases"
tf.compat.as_str,"tf.compat.as_str(
    bytes_or_text, encoding='utf-8'
)
",View aliases
tf.compat.as_str_any,"tf.compat.as_str_any(
    value
)
",Converts input to str type.View aliases
tf.compat.as_text,"tf.compat.as_text(
    bytes_or_text, encoding='utf-8'
)
",Converts any string-like python input types to unicode.View aliases
tf.compat.dimension_at_index,"tf.compat.dimension_at_index(
    shape, index
)
",Compatibility utility required to allow for both V1 and V2 behavior in TF.View aliases
tf.compat.dimension_value,"tf.compat.dimension_value(
    dimension
)
",Compatibility utility required to allow for both V1 and V2 behavior in TF.View aliases
tf.compat.forward_compatible,"tf.compat.forward_compatible(
    year, month, day
)
",Return true if the forward compatibility window has expired.View aliases
tf.compat.path_to_str,"tf.compat.path_to_str(
    path
)
",Converts input which is a PathLike object to str type.View aliases
tf.dtypes.complex,"tf.dtypes.complex(
    real, imag, name=None
)
",Converts two real numbers to a complex number.View aliases
tf.concat,"tf.concat(
    values, axis, name='concat'
)
",Concatenates tensors along one dimension.View aliases
tf.cond,"tf.cond(
    pred, true_fn=None, false_fn=None, name=None
)
",Return true_fn() if the predicate pred is true else false_fn().
tf.config.LogicalDevice,"tf.config.LogicalDevice(
    name, device_type
)
",Abstraction for a logical device initialized by the runtime.View aliases
tf.config.LogicalDeviceConfiguration,"tf.config.LogicalDeviceConfiguration(
    memory_limit=None,
    experimental_priority=None,
    experimental_device_ordinal=0
)
",Configuration class for a logical devices.View aliases
tf.config.PhysicalDevice,"tf.config.PhysicalDevice(
    name, device_type
)
",Abstraction for a locally visible physical device.View aliases
tf.config.LogicalDeviceConfiguration,"tf.config.LogicalDeviceConfiguration(
    memory_limit=None,
    experimental_priority=None,
    experimental_device_ordinal=0
)
",Configuration class for a logical devices.View aliases
tf.config.experimental.enable_tensor_float_32_execution,"tf.config.experimental.enable_tensor_float_32_execution(
    enabled
)
",Enable or disable the use of TensorFloat-32 on supported hardware.View aliases
tf.config.experimental.get_device_details,"tf.config.experimental.get_device_details(
    device
)
",Returns details about a physical devices.View aliases
tf.config.experimental.get_memory_growth,"tf.config.experimental.get_memory_growth(
    device
)
",Get if memory growth is enabled for a PhysicalDevice.View aliases
tf.config.experimental.get_memory_info,"tf.config.experimental.get_memory_info(
    device
)
","Get memory info for the chosen device, as a dict.View aliases"
tf.config.experimental.get_memory_usage,"tf.config.experimental.get_memory_usage(
    device
)
","Get the current memory usage, in bytes, for the chosen device. (deprecated)View aliases"
tf.config.get_logical_device_configuration,"tf.config.get_logical_device_configuration(
    device
)
",Get the virtual device configuration for a tf.config.PhysicalDevice.View aliases
tf.config.get_visible_devices,"tf.config.get_visible_devices(
    device_type=None
)
",Get the list of visible physical devices.View aliases
tf.config.list_logical_devices,"tf.config.list_logical_devices(
    device_type=None
)
",Return a list of logical devices created by runtime.View aliases
tf.config.list_physical_devices,"tf.config.list_physical_devices(
    device_type=None
)
",Return a list of physical devices visible to the host runtime.View aliases
tf.config.experimental.reset_memory_stats,"tf.config.experimental.reset_memory_stats(
    device
)
",Resets the tracked memory stats for the chosen device.View aliases
tf.config.experimental.set_device_policy,"tf.config.experimental.set_device_policy(
    device_policy
)
",Sets the current thread device policy.View aliases
tf.config.experimental.set_memory_growth,"tf.config.experimental.set_memory_growth(
    device, enable
)
",Set if memory growth should be enabled for a PhysicalDevice.View aliases
tf.config.experimental.set_synchronous_execution,"tf.config.experimental.set_synchronous_execution(
    enable
)
",Specifies whether operations are executed synchronously or asynchronously.View aliases
tf.config.set_logical_device_configuration,"tf.config.set_logical_device_configuration(
    device, logical_devices
)
",Set the logical device configuration for a tf.config.PhysicalDevice.View aliases
tf.config.set_visible_devices,"tf.config.set_visible_devices(
    devices, device_type=None
)
",Set the list of visible devices.View aliases
tf.config.experimental_connect_to_cluster,"tf.config.experimental_connect_to_cluster(
    cluster_spec_or_resolver,
    job_name='localhost',
    task_index=0,
    protocol=None,
    make_master_device_default=True,
    cluster_device_filters=None
)
",Connects to the given cluster.View aliases
tf.config.experimental_connect_to_host,"tf.config.experimental_connect_to_host(
    remote_host=None, job_name='worker'
)
",Connects to a single machine to enable remote execution on it.View aliases
tf.config.experimental_run_functions_eagerly,"tf.config.experimental_run_functions_eagerly(
    run_eagerly
)
",Enables / disables eager execution of tf.functions. (deprecated)View aliases
tf.config.get_logical_device_configuration,"tf.config.get_logical_device_configuration(
    device
)
",Get the virtual device configuration for a tf.config.PhysicalDevice.View aliases
tf.config.get_visible_devices,"tf.config.get_visible_devices(
    device_type=None
)
",Get the list of visible physical devices.View aliases
tf.config.list_logical_devices,"tf.config.list_logical_devices(
    device_type=None
)
",Return a list of logical devices created by runtime.View aliases
tf.config.list_physical_devices,"tf.config.list_physical_devices(
    device_type=None
)
",Return a list of physical devices visible to the host runtime.View aliases
tf.config.optimizer.get_jit,"tf.config.optimizer.get_jit() -> str
",Returns JIT compilation configuration for code inside tf.function.View aliases
tf.config.optimizer.set_experimental_options,"tf.config.optimizer.set_experimental_options(
    options
)
",Set experimental optimizer options.View aliases
tf.config.optimizer.set_jit,"tf.config.optimizer.set_jit(
    enabled: Union[bool, str]
)
",Configure JIT compilation. (deprecated argument values)View aliases
tf.config.run_functions_eagerly,"tf.config.run_functions_eagerly(
    run_eagerly
)
",Enables / disables eager execution of tf.functions.View aliases
tf.config.set_logical_device_configuration,"tf.config.set_logical_device_configuration(
    device, logical_devices
)
",Set the logical device configuration for a tf.config.PhysicalDevice.View aliases
tf.config.set_soft_device_placement,"tf.config.set_soft_device_placement(
    enabled
)
",Enable or disable soft device placement.View aliases
tf.config.set_visible_devices,"tf.config.set_visible_devices(
    devices, device_type=None
)
",Set the list of visible devices.View aliases
tf.config.threading.set_inter_op_parallelism_threads,"tf.config.threading.set_inter_op_parallelism_threads(
    num_threads
)
",Set number of threads used for parallelism between independent operations.View aliases
tf.config.threading.set_intra_op_parallelism_threads,"tf.config.threading.set_intra_op_parallelism_threads(
    num_threads
)
",Set number of threads used within an individual op for parallelism.View aliases
tf.constant,"tf.constant(
    value, dtype=None, shape=None, name='Const'
)
",Creates a constant tensor from a tensor-like object.
tf.constant_initializer,"tf.constant_initializer(
    value=0
)
",Initializer that generates tensors with constant values.
tf.control_dependencies,"tf.control_dependencies(
    control_inputs
)
",Wrapper for Graph.control_dependencies() using the default graph.View aliases
tf.convert_to_tensor,"tf.convert_to_tensor(
    value, dtype=None, dtype_hint=None, name=None
)
",Converts the given value to a Tensor.
tf.math.cos,"tf.math.cos(
    x, name=None
)
",Computes cos of x element-wise.View aliases
tf.math.cosh,"tf.math.cosh(
    x, name=None
)
",Computes hyperbolic cosine of x element-wise.View aliases
tf.math.cumsum,"tf.math.cumsum(
    x, axis=0, exclusive=False, reverse=False, name=None
)
",Compute the cumulative sum of the tensor x along axis.View aliases
tf.custom_gradient,"tf.custom_gradient(
    f=None
)
",Decorator to define a function with a custom gradient.View aliases
tf.data.Dataset,"tf.data.Dataset(
    variant_tensor
)
",Represents a potentially large set of elements.
tf.data.DatasetSpec,"tf.data.DatasetSpec(
    element_spec, dataset_shape=()
)
","Type specification for tf.data.Dataset.Inherits From: TypeSpec, TraceTypeView aliases"
tf.data.FixedLengthRecordDataset,"tf.data.FixedLengthRecordDataset(
    filenames,
    record_bytes,
    header_bytes=None,
    footer_bytes=None,
    buffer_size=None,
    compression_type=None,
    num_parallel_reads=None,
    name=None
)
",A Dataset of fixed-length records from one or more binary files.Inherits From: Dataset
tf.data.IteratorSpec,"tf.data.IteratorSpec(
    element_spec
)
","Type specification for tf.data.Iterator.Inherits From: TypeSpec, TraceType"
tf.data.TFRecordDataset,"tf.data.TFRecordDataset(
    filenames,
    compression_type=None,
    buffer_size=None,
    num_parallel_reads=None,
    name=None
)
",A Dataset comprising records from one or more TFRecord files.Inherits From: Dataset
tf.data.TextLineDataset,"tf.data.TextLineDataset(
    filenames,
    compression_type=None,
    buffer_size=None,
    num_parallel_reads=None,
    name=None
)
",Creates a Dataset comprising lines from one or more text files.Inherits From: Dataset
tf.data.experimental.CheckpointInputPipelineHook,"tf.data.experimental.CheckpointInputPipelineHook(
    estimator, external_state_policy=None
)
",Checkpoints input pipeline state every N steps or seconds.Inherits From: SessionRunHookView aliases
tf.data.experimental.Counter,"tf.data.experimental.Counter(
    start=0,
    step=1,
    dtype=tf.dtypes.int64
)
",Creates a Dataset that counts from start in steps of size step.
tf.data.experimental.CsvDataset,"tf.data.experimental.CsvDataset(
    filenames,
    record_defaults,
    compression_type=None,
    buffer_size=None,
    header=False,
    field_delim=',',
    use_quote_delim=True,
    na_value='',
    select_cols=None,
    exclude_cols=None
)
",A Dataset comprising lines from one or more CSV files.Inherits From: Dataset
tf.data.experimental.DatasetInitializer,"tf.data.experimental.DatasetInitializer(
    dataset
)
",Creates a table initializer from a tf.data.Dataset.View aliases
tf.data.experimental.RandomDataset,"tf.data.experimental.RandomDataset(
    seed=None, name=None
)
",A Dataset of pseudorandom values. (deprecated)Inherits From: Dataset
tf.data.experimental.Reducer,"tf.data.experimental.Reducer(
    init_func, reduce_func, finalize_func
)
",A reducer is used for reducing a set of elements.View aliases
tf.data.experimental.SqlDataset,"tf.data.experimental.SqlDataset(
    driver_name, data_source_name, query, output_types
)
",A Dataset consisting of the results from a SQL query.Inherits From: Dataset
tf.data.experimental.TFRecordWriter,"tf.data.experimental.TFRecordWriter(
    filename, compression_type=None
)
",Writes a dataset to a TFRecord file. (deprecated)View aliases
tf.data.experimental.assert_cardinality,"tf.data.experimental.assert_cardinality(
    expected_cardinality
)
",Asserts the cardinality of the input dataset.View aliases
tf.data.experimental.bucket_by_sequence_length,"tf.data.experimental.bucket_by_sequence_length(
    element_length_func,
    bucket_boundaries,
    bucket_batch_sizes,
    padded_shapes=None,
    padding_values=None,
    pad_to_bucket_boundary=False,
    no_padding=False,
    drop_remainder=False
)
",A transformation that buckets elements in a Dataset by length. (deprecated)View aliases
tf.data.experimental.cardinality,"tf.data.experimental.cardinality(
    dataset
)
","Returns the cardinality of dataset, if known.View aliases"
tf.data.experimental.choose_from_datasets,"tf.data.experimental.choose_from_datasets(
    datasets, choice_dataset, stop_on_empty_dataset=False
)
",Creates a dataset that deterministically chooses elements from datasets. (deprecated)
tf.data.experimental.copy_to_device,"tf.data.experimental.copy_to_device(
    target_device, source_device='/cpu:0'
)
",A transformation that copies dataset elements to the given target_device.View aliases
tf.data.experimental.dense_to_ragged_batch,"tf.data.experimental.dense_to_ragged_batch(
    batch_size,
    drop_remainder=False,
    row_splits_dtype=tf.dtypes.int64
)
",A transformation that batches ragged elements into tf.RaggedTensors.View aliases
tf.data.experimental.dense_to_sparse_batch,"tf.data.experimental.dense_to_sparse_batch(
    batch_size, row_shape
)
",A transformation that batches ragged elements into tf.sparse.SparseTensors.View aliases
tf.data.experimental.enumerate_dataset,"tf.data.experimental.enumerate_dataset(
    start=0
)
",A transformation that enumerates the elements of a dataset. (deprecated)View aliases
tf.data.experimental.from_list,"tf.data.experimental.from_list(
    elements, name=None
)
",Creates a Dataset comprising the given list of elements.View aliases
tf.data.experimental.from_variant,"tf.data.experimental.from_variant(
    variant, structure
)
",Constructs a dataset from the given variant and (nested) structure.View aliases
tf.data.experimental.get_next_as_optional,"tf.data.experimental.get_next_as_optional(
    iterator
)
",Returns a tf.experimental.Optional with the next element of the iterator. (deprecated)View aliases
tf.data.experimental.get_single_element,"tf.data.experimental.get_single_element(
    dataset
)
",Returns the single element of the dataset as a nested structure of tensors. (deprecated)View aliases
tf.data.experimental.get_structure,"tf.data.experimental.get_structure(
    dataset_or_iterator
)
",Returns the type signature for elements of the input dataset / iterator.View aliases
tf.data.experimental.group_by_reducer,"tf.data.experimental.group_by_reducer(
    key_func, reducer
)
",A transformation that groups elements and performs a reduction.View aliases
tf.data.experimental.group_by_window,"tf.data.experimental.group_by_window(
    key_func, reduce_func, window_size=None, window_size_func=None
)
",A transformation that groups windows of elements by key and reduces them. (deprecated)View aliases
tf.data.experimental.ignore_errors,"tf.data.experimental.ignore_errors(
    log_warning=False
)
",Creates a Dataset from another Dataset and silently ignores any errors.View aliases
tf.data.experimental.index_table_from_dataset,"tf.data.experimental.index_table_from_dataset(
    dataset=None,
    num_oov_buckets=0,
    vocab_size=None,
    default_value=-1,
    hasher_spec=lookup_ops.FastHashSpec,
    key_dtype=tf.dtypes.string,
    name=None
)
",Returns an index lookup table based on the given dataset.View aliases
tf.data.experimental.load,"tf.data.experimental.load(
    path, element_spec=None, compression=None, reader_func=None
)
",Loads a previously saved dataset. (deprecated)
tf.data.experimental.make_batched_features_dataset,"tf.data.experimental.make_batched_features_dataset(
    file_pattern,
    batch_size,
    features,
    reader=None,
    label_key=None,
    reader_args=None,
    num_epochs=None,
    shuffle=True,
    shuffle_buffer_size=10000,
    shuffle_seed=None,
    prefetch_buffer_size=None,
    reader_num_threads=None,
    parser_num_threads=None,
    sloppy_ordering=False,
    drop_final_batch=False
)
",Returns a Dataset of feature dictionaries from Example protos.
tf.data.experimental.make_csv_dataset,"tf.data.experimental.make_csv_dataset(
    file_pattern,
    batch_size,
    column_names=None,
    column_defaults=None,
    label_name=None,
    select_columns=None,
    field_delim=',',
    use_quote_delim=True,
    na_value='',
    header=True,
    num_epochs=None,
    shuffle=True,
    shuffle_buffer_size=10000,
    shuffle_seed=None,
    prefetch_buffer_size=None,
    num_parallel_reads=None,
    sloppy=False,
    num_rows_for_inference=100,
    compression_type=None,
    ignore_errors=False
)
",Reads CSV files into a dataset.
tf.data.experimental.make_saveable_from_iterator,"tf.data.experimental.make_saveable_from_iterator(
    iterator, external_state_policy=None
)
",Returns a SaveableObject for saving/restoring iterator state using Saver. (deprecated)View aliases
tf.data.experimental.map_and_batch,"tf.data.experimental.map_and_batch(
    map_func,
    batch_size,
    num_parallel_batches=None,
    drop_remainder=False,
    num_parallel_calls=None
)
",Fused implementation of map and batch. (deprecated)View aliases
tf.data.experimental.parallel_interleave,"tf.data.experimental.parallel_interleave(
    map_func,
    cycle_length,
    block_length=1,
    sloppy=False,
    buffer_output_elements=None,
    prefetch_input_elements=None
)
",A parallel version of the Dataset.interleave() transformation. (deprecated)View aliases
tf.data.experimental.parse_example_dataset,"tf.data.experimental.parse_example_dataset(
    features, num_parallel_calls=1, deterministic=None
)
",A transformation that parses Example protos into a dict of tensors.View aliases
tf.data.experimental.prefetch_to_device,"tf.data.experimental.prefetch_to_device(
    device, buffer_size=None
)
",A transformation that prefetches dataset values to the given device.View aliases
tf.data.experimental.rejection_resample,"tf.data.experimental.rejection_resample(
    class_func, target_dist, initial_dist=None, seed=None
)
",A transformation that resamples a dataset to achieve a target distribution. (deprecated)View aliases
tf.data.experimental.sample_from_datasets,"tf.data.experimental.sample_from_datasets(
    datasets, weights=None, seed=None, stop_on_empty_dataset=False
)
",Samples elements at random from the datasets in datasets. (deprecated)
tf.data.experimental.save,"tf.data.experimental.save(
    dataset, path, compression=None, shard_func=None, checkpoint_args=None
)
",Saves the content of the given dataset. (deprecated)
tf.data.experimental.scan,"tf.data.experimental.scan(
    initial_state, scan_func
)
",A transformation that scans a function across an input dataset. (deprecated)View aliases
tf.data.experimental.service.CrossTrainerCache,"tf.data.experimental.service.CrossTrainerCache(
    trainer_id
)
",Options related to the tf.data service cross trainer cache.View aliases
tf.data.experimental.service.DispatchServer,"tf.data.experimental.service.DispatchServer(
    config=None, start=True
)
",An in-process tf.data service dispatch server.
tf.data.experimental.service.DispatcherConfig,"tf.data.experimental.service.DispatcherConfig(
    port=0,
    protocol=None,
    work_dir=None,
    fault_tolerant_mode=False,
    worker_addresses=None,
    job_gc_check_interval_ms=None,
    job_gc_timeout_ms=None
)
",Configuration class for tf.data service dispatchers.View aliases
tf.data.experimental.service.WorkerConfig,"tf.data.experimental.service.WorkerConfig(
    dispatcher_address,
    worker_address=None,
    port=0,
    protocol=None,
    heartbeat_interval_ms=None,
    dispatcher_timeout_ms=None
)
",Configuration class for tf.data service dispatchers.View aliases
tf.data.experimental.service.WorkerServer,"tf.data.experimental.service.WorkerServer(
    config, start=True
)
",An in-process tf.data service worker server.
tf.data.experimental.service.distribute,"tf.data.experimental.service.distribute(
    processing_mode,
    service,
    job_name=None,
    consumer_index=None,
    num_consumers=None,
    max_outstanding_requests=None,
    data_transfer_protocol=None,
    compression='AUTO',
    cross_trainer_cache=None,
    target_workers='AUTO'
)
",A transformation that moves dataset processing to the tf.data service.View aliases
tf.data.experimental.service.from_dataset_id,"tf.data.experimental.service.from_dataset_id(
    processing_mode,
    service,
    dataset_id,
    element_spec=None,
    job_name=None,
    consumer_index=None,
    num_consumers=None,
    max_outstanding_requests=None,
    data_transfer_protocol=None,
    cross_trainer_cache=None,
    target_workers='AUTO'
)
",Creates a dataset which reads data from the tf.data service.View aliases
tf.data.experimental.service.register_dataset,"tf.data.experimental.service.register_dataset(
    service, dataset, compression='AUTO', dataset_id=None
)
",Registers a dataset with the tf.data service.View aliases
tf.data.experimental.shuffle_and_repeat,"tf.data.experimental.shuffle_and_repeat(
    buffer_size, count=None, seed=None
)
","Shuffles and repeats a Dataset, reshuffling with each repetition. (deprecated)View aliases"
tf.data.experimental.snapshot,"tf.data.experimental.snapshot(
    path, compression='AUTO', reader_func=None, shard_func=None
)
",API to persist the output of the input dataset. (deprecated)View aliases
tf.data.experimental.table_from_dataset,"tf.data.experimental.table_from_dataset(
    dataset=None,
    num_oov_buckets=0,
    vocab_size=None,
    default_value=None,
    hasher_spec=lookup_ops.FastHashSpec,
    key_dtype=tf.dtypes.string,
    name=None
)
",Returns a lookup table based on the given dataset.View aliases
tf.data.experimental.take_while,"tf.data.experimental.take_while(
    predicate
)
",A transformation that stops dataset iteration based on a predicate. (deprecated)View aliases
tf.data.experimental.to_variant,"tf.data.experimental.to_variant(
    dataset
)
",Returns a variant representing the given dataset.View aliases
tf.debugging.Assert,"tf.debugging.Assert(
    condition, data, summarize=None, name=None
)
",Asserts that the given condition is true.View aliases
tf.debugging.assert_all_finite,"tf.debugging.assert_all_finite(
    x, message, name=None
)
",Assert that the tensor does not contain any NaN's or Inf's.
tf.debugging.assert_equal,"tf.debugging.assert_equal(
    x, y, message=None, summarize=None, name=None
)
",Assert the condition x == y holds element-wise.View aliases
tf.debugging.assert_greater,"tf.debugging.assert_greater(
    x, y, message=None, summarize=None, name=None
)
",Assert the condition x > y holds element-wise.View aliases
tf.debugging.assert_greater_equal,"tf.debugging.assert_greater_equal(
    x, y, message=None, summarize=None, name=None
)
",Assert the condition x >= y holds element-wise.
tf.debugging.assert_integer,"tf.debugging.assert_integer(
    x, message=None, name=None
)
",Assert that x is of integer dtype.
tf.debugging.assert_less,"tf.debugging.assert_less(
    x, y, message=None, summarize=None, name=None
)
",Assert the condition x < y holds element-wise.View aliases
tf.debugging.assert_less_equal,"tf.debugging.assert_less_equal(
    x, y, message=None, summarize=None, name=None
)
",Assert the condition x <= y holds element-wise.
tf.debugging.assert_near,"tf.debugging.assert_near(
    x, y, rtol=None, atol=None, message=None, summarize=None, name=None
)
",Assert the condition x and y are close element-wise.
tf.debugging.assert_negative,"tf.debugging.assert_negative(
    x, message=None, summarize=None, name=None
)
",Assert the condition x < 0 holds element-wise.
tf.debugging.assert_non_negative,"tf.debugging.assert_non_negative(
    x, message=None, summarize=None, name=None
)
",Assert the condition x >= 0 holds element-wise.
tf.debugging.assert_non_positive,"tf.debugging.assert_non_positive(
    x, message=None, summarize=None, name=None
)
",Assert the condition x <= 0 holds element-wise.
tf.debugging.assert_none_equal,"tf.debugging.assert_none_equal(
    x, y, summarize=None, message=None, name=None
)
",Assert the condition x != y holds for all elements.
tf.debugging.assert_positive,"tf.debugging.assert_positive(
    x, message=None, summarize=None, name=None
)
",Assert the condition x > 0 holds element-wise.
tf.debugging.assert_proper_iterable,"tf.debugging.assert_proper_iterable(
    values
)
","Static assert that values is a ""proper"" iterable.View aliases"
tf.debugging.assert_rank,"tf.debugging.assert_rank(
    x, rank, message=None, name=None
)
",Assert that x has rank equal to rank.View aliases
tf.debugging.assert_rank_at_least,"tf.debugging.assert_rank_at_least(
    x, rank, message=None, name=None
)
",Assert that x has rank of at least rank.
tf.debugging.assert_rank_in,"tf.debugging.assert_rank_in(
    x, ranks, message=None, name=None
)
",Assert that x has a rank in ranks.
tf.debugging.assert_same_float_dtype,"tf.debugging.assert_same_float_dtype(
    tensors=None, dtype=None
)
",Validate and return float type based on tensors and dtype.View aliases
tf.debugging.assert_scalar,"tf.debugging.assert_scalar(
    tensor, message=None, name=None
)
",Asserts that the given tensor is a scalar.
tf.debugging.assert_shapes,"tf.debugging.assert_shapes(
    shapes, data=None, summarize=None, message=None, name=None
)
",Assert tensor shapes and dimension size relationships between tensors.
tf.debugging.assert_shapes,tf.debugging.assert_shapes([,"Assert tensor shapes and dimension size relationships between tensors.tf.debugging.assert_shapes(    shapes, data=None, summarize=None, message=None, name=None)This Op checks that a collection of tensors shape relationshipssatisfies given constraints.Example:n = 10q = 3d = 7x = tf.zeros([n,q])y = tf.ones([n,d])param = tf.Variable([1.0, 2.0, 3.0])scalar = 1.0tf.debugging.assert_shapes([ (x, ('N', 'Q')), (y, ('N', 'D')), (param, ('Q',)), (scalar, ()),])"
tf.debugging.assert_type,"tf.debugging.assert_type(
    tensor, tf_type, message=None, name=None
)
",Asserts that the given Tensor is of the specified type.
tf.debugging.check_numerics,"tf.debugging.check_numerics(
    tensor, message, name=None
)
",Checks a tensor for NaN and Inf values.View aliases
tf.debugging.enable_check_numerics,"tf.debugging.enable_check_numerics(
    stack_height_limit=30, path_length_limit=50
)
",Enable tensor numerics checking in an eager/graph unified fashion.View aliases
tf.debugging.experimental.enable_dump_debug_info,"tf.debugging.experimental.enable_dump_debug_info(
    dump_root,
    tensor_debug_mode=DEFAULT_TENSOR_DEBUG_MODE,
    circular_buffer_size=1000,
    op_regex=None,
    tensor_dtypes=None
)
",Enable dumping debugging information from a TensorFlow program.View aliases
tf.debugging.is_numeric_tensor,"tf.debugging.is_numeric_tensor(
    tensor
)
",Returns True if the elements of tensor are numbers.View aliases
tf.debugging.set_log_device_placement,"tf.debugging.set_log_device_placement(
    enabled
)
",Turns logging for device placement decisions on or off.View aliases
tf.device,"tf.device(
    device_name
)
",Specifies the device for ops created/executed in this context.
tf.distribute.HierarchicalCopyAllReduce,"tf.distribute.HierarchicalCopyAllReduce(
    num_packs=1
)
",Hierarchical copy all-reduce implementation of CrossDeviceOps.Inherits From: CrossDeviceOpsView aliases
tf.distribute.InputContext,"tf.distribute.InputContext(
    num_input_pipelines=1, input_pipeline_id=0, num_replicas_in_sync=1
)
",A class wrapping information needed by an input function.View aliases
tf.distribute.InputOptions,"tf.distribute.InputOptions(
    experimental_fetch_to_device=None,
    experimental_replication_mode=tf.distribute.InputReplicationMode.PER_WORKER,
    experimental_place_dataset_on_device=False,
    experimental_per_replica_buffer_size=1
)
",Run options for experimental_distribute_dataset(s_from_function).
tf.distribute.MirroredStrategy,"tf.distribute.MirroredStrategy(
    devices=None, cross_device_ops=None
)
",Synchronous training across multiple replicas on one machine.Inherits From: Strategy
tf.distribute.MultiWorkerMirroredStrategy,"tf.distribute.MultiWorkerMirroredStrategy(
    cluster_resolver=None, communication_options=None
)
",A distribution strategy for synchronous training on multiple workers.Inherits From: Strategy
tf.distribute.NcclAllReduce,"tf.distribute.NcclAllReduce(
    num_packs=1
)
",NCCL all-reduce implementation of CrossDeviceOps.Inherits From: CrossDeviceOpsView aliases
tf.distribute.OneDeviceStrategy,"tf.distribute.OneDeviceStrategy(
    device
)
",A distribution strategy for running on a single device.Inherits From: Strategy
tf.distribute.experimental.ParameterServerStrategy,"tf.distribute.experimental.ParameterServerStrategy(
    cluster_resolver, variable_partitioner=None
)
",An multi-worker tf.distribute strategy with parameter servers.Inherits From: StrategyView aliases
tf.distribute.ReductionToOneDevice,"tf.distribute.ReductionToOneDevice(
    reduce_to_device=None, accumulation_fn=None
)
",A CrossDeviceOps implementation that copies values to one device to reduce.Inherits From: CrossDeviceOpsView aliases
tf.distribute.ReplicaContext,"tf.distribute.ReplicaContext(
    strategy, replica_id_in_sync_group
)
",A class with a collection of APIs that can be called in a replica context.
tf.distribute.RunOptions,"tf.distribute.RunOptions(
    experimental_enable_dynamic_batch_size=True,
    experimental_bucketizing_dynamic_shape=False,
    experimental_xla_options=None
)
",Run options for strategy.run.View aliases
tf.distribute.Server,"tf.distribute.Server(
    server_or_cluster_def,
    job_name=None,
    task_index=None,
    protocol=None,
    config=None,
    start=True
)
","An in-process TensorFlow server, for use in distributed training.View aliases"
tf.distribute.Strategy,"tf.distribute.Strategy(
    extended
)
",A state & compute distribution policy on a list of devices.
tf.distribute.StrategyExtended,"tf.distribute.StrategyExtended(
    container_strategy
)
",Additional APIs for algorithms that need to be distribution-aware.
tf.distribute.TPUStrategy,"tf.distribute.TPUStrategy(
    tpu_cluster_resolver=None,
    experimental_device_assignment=None,
    experimental_spmd_xla_partitioning=False
)
",Synchronous training on TPUs and TPU Pods.Inherits From: Strategy
tf.distribute.cluster_resolver.GCEClusterResolver,"tf.distribute.cluster_resolver.GCEClusterResolver(
    project,
    zone,
    instance_group,
    port,
    task_type='worker',
    task_id=0,
    rpc_layer='grpc',
    credentials='default',
    service=None
)
",ClusterResolver for Google Compute Engine.Inherits From: ClusterResolverView aliases
tf.distribute.cluster_resolver.KubernetesClusterResolver,"tf.distribute.cluster_resolver.KubernetesClusterResolver(
    job_to_label_mapping=None,
    tf_server_port=8470,
    rpc_layer='grpc',
    override_client=None
)
",ClusterResolver for Kubernetes.Inherits From: ClusterResolverView aliases
tf.distribute.cluster_resolver.SimpleClusterResolver,"tf.distribute.cluster_resolver.SimpleClusterResolver(
    cluster_spec,
    master='',
    task_type=None,
    task_id=None,
    environment='',
    num_accelerators=None,
    rpc_layer=None
)
",Simple implementation of ClusterResolver that accepts all attributes.Inherits From: ClusterResolverView aliases
tf.distribute.cluster_resolver.SlurmClusterResolver,"tf.distribute.cluster_resolver.SlurmClusterResolver(
    jobs=None,
    port_base=8888,
    gpus_per_node=None,
    gpus_per_task=None,
    tasks_per_node=None,
    auto_set_gpu=True,
    rpc_layer='grpc'
)
",ClusterResolver for system with Slurm workload manager.Inherits From: ClusterResolverView aliases
tf.distribute.cluster_resolver.TFConfigClusterResolver,"tf.distribute.cluster_resolver.TFConfigClusterResolver(
    task_type=None, task_id=None, rpc_layer=None, environment=None
)
",Implementation of a ClusterResolver which reads the TF_CONFIG EnvVar.Inherits From: ClusterResolverView aliases
tf.distribute.cluster_resolver.TPUClusterResolver,"tf.distribute.cluster_resolver.TPUClusterResolver(
    tpu=None,
    zone=None,
    project=None,
    job_name='worker',
    coordinator_name=None,
    coordinator_address=None,
    credentials='default',
    service=None,
    discovery_url=None
)
",Cluster Resolver for Google Cloud TPUs.Inherits From: ClusterResolverView aliases
tf.distribute.cluster_resolver.UnionResolver,"tf.distribute.cluster_resolver.UnionResolver(
    *args, **kwargs
)
",Performs a union on underlying ClusterResolvers.Inherits From: ClusterResolverView aliases
tf.distribute.experimental.coordinator.ClusterCoordinator,"tf.distribute.experimental.coordinator.ClusterCoordinator(
    strategy
)
",An object to schedule and coordinate remote function execution.View aliases
tf.distribute.experimental.coordinator.PerWorkerValues,"tf.distribute.experimental.coordinator.PerWorkerValues(
    values
)
","A container that holds a list of values, one value per worker.View aliases"
tf.distribute.experimental.CentralStorageStrategy,"tf.distribute.experimental.CentralStorageStrategy(
    compute_devices=None, parameter_device=None
)
",A one-machine strategy that puts all variables on a single device.Inherits From: Strategy
tf.distribute.experimental.CollectiveHints,"tf.distribute.experimental.CollectiveHints(
    bytes_per_pack=0, timeout_seconds=None
)
",Hints for collective operations like AllReduce.View aliases
tf.distribute.experimental.CommunicationOptions,"tf.distribute.experimental.CommunicationOptions(
    bytes_per_pack=0,
    timeout_seconds=None,
    implementation=tf.distribute.experimental.CollectiveCommunication.AUTO
)
",Options for cross device communications like All-reduce.View aliases
tf.distribute.experimental.MultiWorkerMirroredStrategy,"tf.distribute.experimental.MultiWorkerMirroredStrategy(
    communication=tf.distribute.experimental.CollectiveCommunication.AUTO,
    cluster_resolver=None
)
","A distribution strategy for synchronous training on multiple workers.Inherits From: MultiWorkerMirroredStrategy, Strategy"
tf.distribute.experimental.ParameterServerStrategy,"tf.distribute.experimental.ParameterServerStrategy(
    cluster_resolver, variable_partitioner=None
)
",An multi-worker tf.distribute strategy with parameter servers.Inherits From: StrategyView aliases
tf.distribute.experimental.PreemptionCheckpointHandler,"tf.distribute.experimental.PreemptionCheckpointHandler(
    cluster_resolver,
    checkpoint_or_checkpoint_manager,
    checkpoint_dir=None,
    termination_config=None
)
",Preemption and error handler for synchronous training.
tf.distribute.experimental.TPUStrategy,"tf.distribute.experimental.TPUStrategy(
    tpu_cluster_resolver=None, device_assignment=None
)
",Synchronous training on TPUs and TPU Pods.Inherits From: Strategy
tf.distribute.experimental.TerminationConfig,"tf.distribute.experimental.TerminationConfig(
    termination_watcher_fn=None, exit_fn=None, grace_period=None
)
",Customization of PreemptionCheckpointHandler for various platforms.
tf.distribute.experimental.ValueContext,"tf.distribute.experimental.ValueContext(
    replica_id_in_sync_group=0, num_replicas_in_sync=1
)
",A class wrapping information needed by a distribute function.
tf.distribute.experimental.coordinator.ClusterCoordinator,"tf.distribute.experimental.coordinator.ClusterCoordinator(
    strategy
)
",An object to schedule and coordinate remote function execution.View aliases
tf.distribute.experimental.coordinator.PerWorkerValues,"tf.distribute.experimental.coordinator.PerWorkerValues(
    values
)
","A container that holds a list of values, one value per worker.View aliases"
tf.distribute.experimental.partitioners.FixedShardsPartitioner,"tf.distribute.experimental.partitioners.FixedShardsPartitioner(
    num_shards
)
",Partitioner that allocates a fixed number of shards.Inherits From: Partitioner
tf.distribute.experimental.partitioners.MaxSizePartitioner,"tf.distribute.experimental.partitioners.MaxSizePartitioner(
    max_shard_bytes, max_shards=None, bytes_per_string=16
)
",Partitioner that keeps shards below max_shard_bytes.Inherits From: Partitioner
tf.distribute.experimental.partitioners.MinSizePartitioner,"tf.distribute.experimental.partitioners.MinSizePartitioner(
    min_shard_bytes=(256 << 10), max_shards=1, bytes_per_string=16
)
",Partitioner that allocates a minimum size per shard.Inherits From: Partitioner
tf.distribute.experimental_set_strategy,"tf.distribute.experimental_set_strategy(
    strategy
)
",Set a tf.distribute.Strategy as current without with strategy.scope().View aliases
tf.math.divide,"tf.math.divide(
    x, y, name=None
)
",Computes Python style division of x by y.View aliases
tf.dtypes.as_dtype,"tf.dtypes.as_dtype(
    type_value
)
",Converts the given type_value to a DType.View aliases
tf.cast,"tf.cast(
    x, dtype, name=None
)
",Casts a tensor to a new type.View aliases
tf.dtypes.complex,"tf.dtypes.complex(
    real, imag, name=None
)
",Converts two real numbers to a complex number.View aliases
tf.dtypes.saturate_cast,"tf.dtypes.saturate_cast(
    value, dtype, name=None
)
",Performs a safe saturating cast of value to dtype.View aliases
tf.dynamic_partition,"tf.dynamic_partition(
    data, partitions, num_partitions, name=None
)
",Partitions data into num_partitions tensors using indices from partitions.View aliases
tf.dynamic_stitch,"tf.dynamic_stitch(
    indices, data, name=None
)
",Interleave the values from the data tensors into a single tensor.View aliases
tf.edit_distance,"tf.edit_distance(
    hypothesis, truth, normalize=True, name='edit_distance'
)
",Computes the Levenshtein distance between sequences.View aliases
tf.linalg.eig,"tf.linalg.eig(
    tensor, name=None
)
",Computes the eigen decomposition of a batch of matrices.View aliases
tf.linalg.eigvals,"tf.linalg.eigvals(
    tensor, name=None
)
",Computes the eigenvalues of one or more matrices.View aliases
tf.einsum,"tf.einsum(
    equation, *inputs, **kwargs
)
",Tensor contraction over specified indices and outer product.View aliases
tf.ensure_shape,"tf.ensure_shape(
    x, shape, name=None
)
",Updates the shape of a tensor and checks at runtime that the shape holds.View aliases
tf.math.equal,"tf.math.equal(
    x, y, name=None
)
",Returns the truth value of (x == y) element-wise.View aliases
tf.errors.AbortedError,"tf.errors.AbortedError(
    node_def, op, message, *args
)
","The operation was aborted, typically due to a concurrent action.Inherits From: OpErrorView aliases"
tf.errors.AlreadyExistsError,"tf.errors.AlreadyExistsError(
    node_def, op, message, *args
)
",Raised when an entity that we attempted to create already exists.Inherits From: OpErrorView aliases
tf.errors.CancelledError,"tf.errors.CancelledError(
    node_def, op, message, *args
)
",Raised when an operation or step is cancelled.Inherits From: OpErrorView aliases
tf.errors.DataLossError,"tf.errors.DataLossError(
    node_def, op, message, *args
)
",Raised when unrecoverable data loss or corruption is encountered.Inherits From: OpErrorView aliases
tf.errors.DeadlineExceededError,"tf.errors.DeadlineExceededError(
    node_def, op, message, *args
)
",Raised when a deadline expires before an operation could complete.Inherits From: OpErrorView aliases
tf.errors.FailedPreconditionError,"tf.errors.FailedPreconditionError(
    node_def, op, message, *args
)
",Operation was rejected because the system is not in a state to execute it.Inherits From: OpErrorView aliases
tf.errors.InternalError,"tf.errors.InternalError(
    node_def, op, message, *args
)
",Raised when the system experiences an internal error.Inherits From: OpErrorView aliases
tf.errors.InvalidArgumentError,"tf.errors.InvalidArgumentError(
    node_def, op, message, *args
)
",Raised when an operation receives an invalid argument.Inherits From: OpErrorView aliases
tf.errors.NotFoundError,"tf.errors.NotFoundError(
    node_def, op, message, *args
)
","Raised when a requested entity (e.g., a file or directory) was not found.Inherits From: OpErrorView aliases"
tf.errors.OpError,"tf.errors.OpError(
    node_def, op, message, error_code, *args
)
",The base class for TensorFlow exceptions.View aliases
tf.errors.OperatorNotAllowedInGraphError,"tf.errors.OperatorNotAllowedInGraphError(
    *args, **kwargs
)
",An error is raised for unsupported operator in Graph execution.
tf.errors.OutOfRangeError,"tf.errors.OutOfRangeError(
    node_def, op, message, *args
)
",Raised when an operation iterates past the valid input range.Inherits From: OpErrorView aliases
tf.errors.PermissionDeniedError,"tf.errors.PermissionDeniedError(
    node_def, op, message, *args
)
",Raised when the caller does not have permission to run an operation.Inherits From: OpErrorView aliases
tf.errors.ResourceExhaustedError,"tf.errors.ResourceExhaustedError(
    node_def, op, message, *args
)
",Some resource has been exhausted.Inherits From: OpErrorView aliases
tf.errors.UnauthenticatedError,"tf.errors.UnauthenticatedError(
    node_def, op, message, *args
)
",The request does not have valid authentication credentials.Inherits From: OpErrorView aliases
tf.errors.UnavailableError,"tf.errors.UnavailableError(
    node_def, op, message, *args
)
",Raised when the runtime is currently unavailable.Inherits From: OpErrorView aliases
tf.errors.UnimplementedError,"tf.errors.UnimplementedError(
    node_def, op, message, *args
)
",Raised when an operation has not been implemented.Inherits From: OpErrorView aliases
tf.errors.UnknownError,"tf.errors.UnknownError(
    node_def, op, message, *args
)
",Unknown error.Inherits From: OpErrorView aliases
tf.estimator.BaselineClassifier,"tf.estimator.BaselineClassifier(
    model_dir=None,
    n_classes=2,
    weight_column=None,
    label_vocabulary=None,
    optimizer='Ftrl',
    config=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE
)
","A classifier that can establish a simple baseline.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator, Estimator"
tf.estimator.BaselineEstimator,"tf.estimator.BaselineEstimator(
    head, model_dir=None, optimizer='Ftrl', config=None
)
","An estimator that can establish a simple baseline.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator, Estimator"
tf.estimator.BaselineRegressor,"tf.estimator.BaselineRegressor(
    model_dir=None,
    label_dimension=1,
    weight_column=None,
    optimizer='Ftrl',
    config=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE
)
","A regressor that can establish a simple baseline.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator, Estimator"
tf.estimator.BestExporter,"tf.estimator.BestExporter(
    name='best_exporter',
    serving_input_receiver_fn=None,
    event_file_pattern='eval/*.tfevents.*',
    compare_fn=_loss_smaller,
    assets_extra=None,
    as_text=False,
    exports_to_keep=5
)
",This class exports the serving graph and checkpoints of the best models.Inherits From: ExporterView aliases
tf.estimator.BinaryClassHead,"tf.estimator.BinaryClassHead(
    weight_column=None,
    thresholds=None,
    label_vocabulary=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    loss_fn=None,
    name=None
)
",Creates a Head for single label binary classification.Inherits From: HeadView aliases
tf.estimator.CheckpointSaverHook,"tf.estimator.CheckpointSaverHook(
    checkpoint_dir,
    save_secs=None,
    save_steps=None,
    saver=None,
    checkpoint_basename='model.ckpt',
    scaffold=None,
    listeners=None,
    save_graph_def=True
)
",Saves checkpoints every N steps or seconds.Inherits From: SessionRunHookView aliases
tf.estimator.DNNClassifier,"tf.estimator.DNNClassifier(
    hidden_units,
    feature_columns,
    model_dir=None,
    n_classes=2,
    weight_column=None,
    label_vocabulary=None,
    optimizer='Adagrad',
    activation_fn=tf.nn.relu,
    dropout=None,
    config=None,
    warm_start_from=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    batch_norm=False
)
","A classifier for TensorFlow DNN models.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator, Estimator"
tf.estimator.DNNEstimator,"tf.estimator.DNNEstimator(
    head,
    hidden_units,
    feature_columns,
    model_dir=None,
    optimizer='Adagrad',
    activation_fn=tf.nn.relu,
    dropout=None,
    config=None,
    warm_start_from=None,
    batch_norm=False
)
","An estimator for TensorFlow DNN models with user-specified head.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator, Estimator"
tf.estimator.DNNLinearCombinedClassifier,"tf.estimator.DNNLinearCombinedClassifier(
    model_dir=None,
    linear_feature_columns=None,
    linear_optimizer='Ftrl',
    dnn_feature_columns=None,
    dnn_optimizer='Adagrad',
    dnn_hidden_units=None,
    dnn_activation_fn=tf.nn.relu,
    dnn_dropout=None,
    n_classes=2,
    weight_column=None,
    label_vocabulary=None,
    config=None,
    warm_start_from=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    batch_norm=False,
    linear_sparse_combiner='sum'
)
","An estimator for TensorFlow Linear and DNN joined classification models.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator, Estimator"
tf.estimator.DNNLinearCombinedEstimator,"tf.estimator.DNNLinearCombinedEstimator(
    head,
    model_dir=None,
    linear_feature_columns=None,
    linear_optimizer='Ftrl',
    dnn_feature_columns=None,
    dnn_optimizer='Adagrad',
    dnn_hidden_units=None,
    dnn_activation_fn=tf.nn.relu,
    dnn_dropout=None,
    config=None,
    batch_norm=False,
    linear_sparse_combiner='sum'
)
","An estimator for TensorFlow Linear and DNN joined models with custom head.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator, Estimator"
tf.estimator.DNNLinearCombinedRegressor,"tf.estimator.DNNLinearCombinedRegressor(
    model_dir=None,
    linear_feature_columns=None,
    linear_optimizer='Ftrl',
    dnn_feature_columns=None,
    dnn_optimizer='Adagrad',
    dnn_hidden_units=None,
    dnn_activation_fn=tf.nn.relu,
    dnn_dropout=None,
    label_dimension=1,
    weight_column=None,
    config=None,
    warm_start_from=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    batch_norm=False,
    linear_sparse_combiner='sum'
)
","An estimator for TensorFlow Linear and DNN joined models for regression.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator, Estimator"
tf.estimator.DNNRegressor,"tf.estimator.DNNRegressor(
    hidden_units,
    feature_columns,
    model_dir=None,
    label_dimension=1,
    weight_column=None,
    optimizer='Adagrad',
    activation_fn=tf.nn.relu,
    dropout=None,
    config=None,
    warm_start_from=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    batch_norm=False
)
","A regressor for TensorFlow DNN models.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator, Estimator"
tf.estimator.Estimator,"tf.estimator.Estimator(
    model_fn, model_dir=None, config=None, params=None, warm_start_from=None
)
",Estimator class to train and evaluate TensorFlow models.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.estimator.EstimatorSpec,"tf.estimator.EstimatorSpec(
    mode,
    predictions=None,
    loss=None,
    train_op=None,
    eval_metric_ops=None,
    export_outputs=None,
    training_chief_hooks=None,
    training_hooks=None,
    scaffold=None,
    evaluation_hooks=None,
    prediction_hooks=None
)
",Ops and objects returned from a model_fn and passed to an Estimator.View aliases
tf.estimator.EvalSpec,"tf.estimator.EvalSpec(
    input_fn,
    steps=100,
    name=None,
    hooks=None,
    exporters=None,
    start_delay_secs=120,
    throttle_secs=600
)
","Configuration for the ""eval"" part for the train_and_evaluate call.View aliases"
tf.estimator.FeedFnHook,"tf.estimator.FeedFnHook(
    feed_fn
)
",Runs feed_fn and sets the feed_dict accordingly.Inherits From: SessionRunHookView aliases
tf.estimator.FinalExporter,"tf.estimator.FinalExporter(
    name, serving_input_receiver_fn, assets_extra=None, as_text=False
)
",This class exports the serving graph and checkpoints at the end.Inherits From: ExporterView aliases
tf.estimator.FinalOpsHook,"tf.estimator.FinalOpsHook(
    final_ops, final_ops_feed_dict=None
)
",A hook which evaluates Tensors at the end of a session.Inherits From: SessionRunHookView aliases
tf.estimator.GlobalStepWaiterHook,"tf.estimator.GlobalStepWaiterHook(
    wait_until_step
)
",Delays execution until global step reaches wait_until_step.Inherits From: SessionRunHookView aliases
tf.estimator.LatestExporter,"tf.estimator.LatestExporter(
    name,
    serving_input_receiver_fn,
    assets_extra=None,
    as_text=False,
    exports_to_keep=5
)
",This class regularly exports the serving graph and checkpoints.Inherits From: ExporterView aliases
tf.estimator.LinearClassifier,"tf.estimator.LinearClassifier(
    feature_columns,
    model_dir=None,
    n_classes=2,
    weight_column=None,
    label_vocabulary=None,
    optimizer='Ftrl',
    config=None,
    warm_start_from=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    sparse_combiner='sum'
)
","Linear classifier model.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator, Estimator"
tf.estimator.LinearEstimator,"tf.estimator.LinearEstimator(
    head,
    feature_columns,
    model_dir=None,
    optimizer='Ftrl',
    config=None,
    sparse_combiner='sum',
    warm_start_from=None
)
","An estimator for TensorFlow linear models with user-specified head.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator, Estimator"
tf.estimator.LinearRegressor,"tf.estimator.LinearRegressor(
    feature_columns,
    model_dir=None,
    label_dimension=1,
    weight_column=None,
    optimizer='Ftrl',
    config=None,
    warm_start_from=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    sparse_combiner='sum'
)
","An estimator for TensorFlow Linear regression problems.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator, Estimator"
tf.estimator.LoggingTensorHook,"tf.estimator.LoggingTensorHook(
    tensors, every_n_iter=None, every_n_secs=None, at_end=False, formatter=None
)
","Prints the given tensors every N local steps, every N seconds, or at end.Inherits From: SessionRunHookView aliases"
tf.estimator.LogisticRegressionHead,"tf.estimator.LogisticRegressionHead(
    weight_column=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    name=None
)
","Creates a Head for logistic regression.Inherits From: RegressionHead, HeadView aliases"
tf.estimator.MultiClassHead,"tf.estimator.MultiClassHead(
    n_classes,
    weight_column=None,
    label_vocabulary=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    loss_fn=None,
    name=None
)
",Creates a Head for multi class classification.Inherits From: HeadView aliases
tf.estimator.MultiHead,"tf.estimator.MultiHead(
    heads, head_weights=None
)
",Creates a Head for multi-objective learning.Inherits From: HeadView aliases
tf.estimator.MultiLabelHead,"tf.estimator.MultiLabelHead(
    n_classes,
    weight_column=None,
    thresholds=None,
    label_vocabulary=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    loss_fn=None,
    classes_for_class_based_metrics=None,
    name=None
)
",Creates a Head for multi-label classification.Inherits From: HeadView aliases
tf.estimator.NanLossDuringTrainingError,"tf.estimator.NanLossDuringTrainingError(
    *args, **kwargs
)
",Unspecified run-time error.View aliases
tf.estimator.NanTensorHook,"tf.estimator.NanTensorHook(
    loss_tensor, fail_on_nan_loss=True
)
",Monitors the loss tensor and stops training if loss is NaN.Inherits From: SessionRunHookView aliases
tf.estimator.PoissonRegressionHead,"tf.estimator.PoissonRegressionHead(
    label_dimension=1,
    weight_column=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    compute_full_loss=True,
    name=None
)
","Creates a Head for poisson regression using tf.nn.log_poisson_loss.Inherits From: RegressionHead, HeadView aliases"
tf.estimator.ProfilerHook,"tf.estimator.ProfilerHook(
    save_steps=None,
    save_secs=None,
    output_dir='',
    show_dataflow=True,
    show_memory=False
)
",Captures CPU/GPU profiling information every N steps or seconds.Inherits From: SessionRunHookView aliases
tf.estimator.RegressionHead,"tf.estimator.RegressionHead(
    label_dimension=1,
    weight_column=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    loss_fn=None,
    inverse_link_fn=None,
    name=None
)
",Creates a Head for regression using the mean_squared_error loss.Inherits From: HeadView aliases
tf.estimator.RunConfig,"tf.estimator.RunConfig(
    model_dir=None,
    tf_random_seed=None,
    save_summary_steps=100,
    save_checkpoints_steps=_USE_DEFAULT,
    save_checkpoints_secs=_USE_DEFAULT,
    session_config=None,
    keep_checkpoint_max=5,
    keep_checkpoint_every_n_hours=10000,
    log_step_count_steps=100,
    train_distribute=None,
    device_fn=None,
    protocol=None,
    eval_distribute=None,
    experimental_distribute=None,
    experimental_max_worker_delay_secs=None,
    session_creation_timeout_secs=7200,
    checkpoint_save_graph_def=True
)
",This class specifies the configurations for an Estimator run.View aliases
tf.estimator.SecondOrStepTimer,"tf.estimator.SecondOrStepTimer(
    every_secs=None, every_steps=None
)
",Timer that triggers at most once every N seconds or once every N steps.View aliases
tf.estimator.SessionRunArgs,"tf.estimator.SessionRunArgs(
    fetches, feed_dict=None, options=None
)
",Represents arguments to be added to a Session.run() call.View aliases
tf.estimator.SessionRunContext,"tf.estimator.SessionRunContext(
    original_args, session
)
",Provides information about the session.run() call being made.View aliases
tf.estimator.SessionRunValues,"tf.estimator.SessionRunValues(
    results, options, run_metadata
)
",Contains the results of Session.run().View aliases
tf.estimator.StepCounterHook,"tf.estimator.StepCounterHook(
    every_n_steps=100, every_n_secs=None, output_dir=None, summary_writer=None
)
",Hook that counts steps per second.Inherits From: SessionRunHookView aliases
tf.estimator.StopAtStepHook,"tf.estimator.StopAtStepHook(
    num_steps=None, last_step=None
)
",Hook that requests stop at a specified step.Inherits From: SessionRunHookView aliases
tf.estimator.SummarySaverHook,"tf.estimator.SummarySaverHook(
    save_steps=None,
    save_secs=None,
    output_dir=None,
    summary_writer=None,
    scaffold=None,
    summary_op=None
)
",Saves summaries every N steps.Inherits From: SessionRunHookView aliases
tf.estimator.TrainSpec,"tf.estimator.TrainSpec(
    input_fn, max_steps=None, hooks=None, saving_listeners=None
)
","Configuration for the ""train"" part for the train_and_evaluate call.View aliases"
tf.estimator.VocabInfo,"tf.estimator.VocabInfo(
    new_vocab,
    new_vocab_size,
    num_oov_buckets,
    old_vocab,
    old_vocab_size=-1,
    backup_initializer=None,
    axis=0
)
",Vocabulary information for warm-starting.View aliases
tf.estimator.WarmStartSettings,"tf.estimator.WarmStartSettings(
    ckpt_to_initialize_from,
    vars_to_warm_start='.*',
    var_name_to_vocab_info=None,
    var_name_to_prev_var_name=None
)
",Settings for warm-starting in tf.estimator.Estimators.View aliases
tf.estimator.add_metrics,"tf.estimator.add_metrics(
    estimator, metric_fn
)
",Creates a new tf.estimator.Estimator which has given metrics.View aliases
tf.estimator.classifier_parse_example_spec,"tf.estimator.classifier_parse_example_spec(
    feature_columns,
    label_key,
    label_dtype=tf.dtypes.int64,
    label_default=None,
    weight_column=None
)
",Generates parsing spec for tf.parse_example to be used with classifiers.
tf.estimator.experimental.InMemoryEvaluatorHook,"tf.estimator.experimental.InMemoryEvaluatorHook(
    estimator, input_fn, steps=None, hooks=None, name=None, every_n_iter=100
)
",Hook to run evaluation in training without a checkpoint.Inherits From: SessionRunHookView aliases
tf.estimator.experimental.LinearSDCA,"tf.estimator.experimental.LinearSDCA(
    example_id_column,
    num_loss_partitions=1,
    num_table_shards=None,
    symmetric_l1_regularization=0.0,
    symmetric_l2_regularization=1.0,
    adaptive=False
)
",Stochastic Dual Coordinate Ascent helper for linear estimators.View aliases
tf.estimator.experimental.RNNClassifier,"tf.estimator.experimental.RNNClassifier(
    sequence_feature_columns,
    context_feature_columns=None,
    units=None,
    cell_type=USE_DEFAULT,
    rnn_cell_fn=None,
    return_sequences=False,
    model_dir=None,
    n_classes=2,
    weight_column=None,
    label_vocabulary=None,
    optimizer='Adagrad',
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    sequence_mask='sequence_mask',
    config=None
)
","A classifier for TensorFlow RNN models.Warning: Estimators are not recommended for new code.  Estimators runInherits From: RNNEstimator, Estimator"
tf.estimator.experimental.RNNEstimator,"tf.estimator.experimental.RNNEstimator(
    head,
    sequence_feature_columns,
    context_feature_columns=None,
    units=None,
    cell_type=USE_DEFAULT,
    rnn_cell_fn=None,
    return_sequences=False,
    model_dir=None,
    optimizer='Adagrad',
    config=None
)
",An Estimator for TensorFlow RNN models with user-specified head.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.estimator.experimental.build_raw_supervised_input_receiver_fn,"tf.estimator.experimental.build_raw_supervised_input_receiver_fn(
    features, labels, default_batch_size=None
)
",Build a supervised_input_receiver_fn for raw features and labels.View aliases
tf.estimator.experimental.call_logit_fn,"tf.estimator.experimental.call_logit_fn(
    logit_fn, features, mode, params, config
)
",Calls logit_fn (experimental).View aliases
tf.estimator.experimental.make_early_stopping_hook,"tf.estimator.experimental.make_early_stopping_hook(
    estimator, should_stop_fn, run_every_secs=60, run_every_steps=None
)
",Creates early-stopping hook.View aliases
tf.estimator.experimental.make_stop_at_checkpoint_step_hook,"tf.estimator.experimental.make_stop_at_checkpoint_step_hook(
    estimator, last_step, wait_after_file_check_secs=30
)
",Creates a proper StopAtCheckpointStepHook based on chief status.View aliases
tf.estimator.experimental.stop_if_higher_hook,"tf.estimator.experimental.stop_if_higher_hook(
    estimator,
    metric_name,
    threshold,
    eval_dir=None,
    min_steps=0,
    run_every_secs=60,
    run_every_steps=None
)
",Creates hook to stop if the given metric is higher than the threshold.View aliases
tf.estimator.experimental.stop_if_lower_hook,"tf.estimator.experimental.stop_if_lower_hook(
    estimator,
    metric_name,
    threshold,
    eval_dir=None,
    min_steps=0,
    run_every_secs=60,
    run_every_steps=None
)
",Creates hook to stop if the given metric is lower than the threshold.View aliases
tf.estimator.experimental.stop_if_no_decrease_hook,"tf.estimator.experimental.stop_if_no_decrease_hook(
    estimator,
    metric_name,
    max_steps_without_decrease,
    eval_dir=None,
    min_steps=0,
    run_every_secs=60,
    run_every_steps=None
)
",Creates hook to stop if metric does not decrease within given max steps.View aliases
tf.estimator.experimental.stop_if_no_increase_hook,"tf.estimator.experimental.stop_if_no_increase_hook(
    estimator,
    metric_name,
    max_steps_without_increase,
    eval_dir=None,
    min_steps=0,
    run_every_secs=60,
    run_every_steps=None
)
",Creates hook to stop if metric does not increase within given max steps.View aliases
tf.estimator.export.ClassificationOutput,"tf.estimator.export.ClassificationOutput(
    scores=None, classes=None
)
",Represents the output of a classification head.Inherits From: ExportOutputView aliases
tf.estimator.export.EvalOutput,"tf.estimator.export.EvalOutput(
    loss=None, predictions=None, metrics=None
)
",Represents the output of a supervised eval process.Inherits From: ExportOutputView aliases
tf.estimator.export.PredictOutput,"tf.estimator.export.PredictOutput(
    outputs
)
",Represents the output of a generic prediction head.Inherits From: ExportOutputView aliases
tf.estimator.export.RegressionOutput,"tf.estimator.export.RegressionOutput(
    value
)
",Represents the output of a regression head.Inherits From: ExportOutputView aliases
tf.estimator.export.ServingInputReceiver,"tf.estimator.export.ServingInputReceiver(
    features, receiver_tensors, receiver_tensors_alternatives=None
)
",A return type for a serving_input_receiver_fn.View aliases
tf.estimator.export.TensorServingInputReceiver,"tf.estimator.export.TensorServingInputReceiver(
    features, receiver_tensors, receiver_tensors_alternatives=None
)
",A return type for a serving_input_receiver_fn.View aliases
tf.estimator.export.build_parsing_serving_input_receiver_fn,"tf.estimator.export.build_parsing_serving_input_receiver_fn(
    feature_spec, default_batch_size=None
)
",Build a serving_input_receiver_fn expecting fed tf.Examples.View aliases
tf.estimator.export.build_raw_serving_input_receiver_fn,"tf.estimator.export.build_raw_serving_input_receiver_fn(
    features, default_batch_size=None
)
",Build a serving_input_receiver_fn expecting feature Tensors.View aliases
tf.estimator.regressor_parse_example_spec,"tf.estimator.regressor_parse_example_spec(
    feature_columns,
    label_key,
    label_dtype=tf.dtypes.float32,
    label_default=None,
    label_dimension=1,
    weight_column=None
)
",Generates parsing spec for tf.parse_example to be used with regressors.
tf.estimator.train_and_evaluate,"tf.estimator.train_and_evaluate(
    estimator, train_spec, eval_spec
)
",Train and evaluate the estimator.View aliases
tf.math.exp,"tf.math.exp(
    x, name=None
)
",Computes exponential of x element-wise.  \(y = e^x\).View aliases
tf.expand_dims,"tf.expand_dims(
    input, axis, name=None
)
",Returns a tensor with a length 1 axis inserted at index axis.
tf.experimental.BatchableExtensionType,"tf.experimental.BatchableExtensionType(
    *args, **kwargs
)
",An ExtensionType that can be batched and unbatched.Inherits From: ExtensionTypeView aliases
tf.experimental.DynamicRaggedShape,"tf.experimental.DynamicRaggedShape(
    row_partitions: Sequence[tf.experimental.RowPartition],
    inner_shape: tf.types.experimental.TensorLike,
    dtype: Optional[tf.dtypes.DType] = None,
    validate: bool = False,
    static_inner_shape: ... = None
)
","The shape of a ragged or dense tensor.Inherits From: BatchableExtensionType, ExtensionTypeView aliases"
tf.experimental.DynamicRaggedShape.Spec,"tf.experimental.DynamicRaggedShape.Spec(
    row_partitions: Tuple[RowPartitionSpec, ...],
    static_inner_shape: tf.TensorShape,
    dtype: tf.dtypes.DType
)
","A Spec for DynamicRaggedShape: similar to a static shape.Inherits From: TypeSpec, TraceTypeView aliases"
tf.experimental.ExtensionType,"tf.experimental.ExtensionType(
    *args, **kwargs
)
",Base class for TensorFlow ExtensionType classes.View aliases
tf.experimental.RowPartition,"tf.experimental.RowPartition(
    row_splits,
    row_lengths=None,
    value_rowids=None,
    nrows=None,
    uniform_row_length=None,
    nvals=None,
    internal=False
)
","Partitioning of a sequence of values into contiguous subsequences (""rows"").View aliases"
tf.experimental.dispatch_for_api,"tf.experimental.dispatch_for_api(
    api, *signatures
)
",Decorator that overrides the default implementation for a TensorFlow API.View aliases
tf.experimental.dispatch_for_binary_elementwise_apis,"tf.experimental.dispatch_for_binary_elementwise_apis(
    x_type, y_type
)
",Decorator to override default implementation for binary elementwise APIs.View aliases
tf.experimental.dispatch_for_binary_elementwise_assert_apis,"tf.experimental.dispatch_for_binary_elementwise_assert_apis(
    x_type, y_type
)
",Decorator to override default implementation for binary elementwise assert APIs.View aliases
tf.experimental.dispatch_for_unary_elementwise_apis,"tf.experimental.dispatch_for_unary_elementwise_apis(
    x_type
)
",Decorator to override default implementation for unary elementwise APIs.View aliases
tf.experimental.dlpack.from_dlpack,"tf.experimental.dlpack.from_dlpack(
    dlcapsule
)
",Returns the Tensorflow eager tensor.
tf.experimental.dlpack.to_dlpack,"tf.experimental.dlpack.to_dlpack(
    tf_tensor
)
",Returns the dlpack capsule representing the tensor.
tf.experimental.dtensor.DTensorCheckpoint,"tf.experimental.dtensor.DTensorCheckpoint(
    mesh: tf.experimental.dtensor.Mesh,
    root=None,
    **kwargs
)
","Manages saving/restoring trackable values to disk, for DTensor.Inherits From: Checkpoint"
tf.experimental.dtensor.DVariable,"tf.experimental.dtensor.DVariable(
    initial_value, *args, dtype=None, **kwargs
)
","A replacement for tf.Variable which follows initial value placement.Inherits From: Variable, Variable"
tf.Variable.SaveSliceInfo,"tf.Variable.SaveSliceInfo(
    full_name=None,
    full_shape=None,
    var_offset=None,
    var_shape=None,
    save_slice_info_def=None,
    import_scope=None
)
",Information on how to save this Variable as a slice.View aliases
tf.experimental.dtensor.Layout,"tf.experimental.dtensor.Layout(
    sharding_specs: List[str],
    mesh: tf.experimental.dtensor.Mesh
)
",Represents the layout information of a DTensor.
tf.experimental.dtensor.Mesh,"tf.experimental.dtensor.Mesh(
    dim_names: List[str],
    global_device_ids: np.ndarray,
    local_device_ids: List[int],
    local_devices: List[tf.compat.v1.DeviceSpec],
    mesh_name: str = '',
    global_devices: Optional[List[tf_device.DeviceSpec]] = None
)
",Represents a Mesh configuration over a certain list of Mesh Dimensions.
tf.experimental.dtensor.barrier,"tf.experimental.dtensor.barrier(
    mesh: tf.experimental.dtensor.Mesh,
    barrier_name: Optional[str] = None
)
",Runs a barrier on the mesh.
tf.experimental.dtensor.call_with_layout,"tf.experimental.dtensor.call_with_layout(
    fn: Callable[..., Any],
    layout: Optional[tf.experimental.dtensor.Layout],
    *args,
    **kwargs
) -> Any
",Calls a function in the DTensor device scope if layout is not None.
tf.experimental.dtensor.check_layout,"tf.experimental.dtensor.check_layout(
    tensor: tf.Tensor,
    layout: tf.experimental.dtensor.Layout
) -> None
",Asserts that the layout of the DTensor is layout.
tf.experimental.dtensor.client_id,"tf.experimental.dtensor.client_id() -> int
",Returns this client's ID.
tf.experimental.dtensor.copy_to_mesh,"tf.experimental.dtensor.copy_to_mesh(
    tensor: Any,
    layout: tf.experimental.dtensor.Layout,
    source_layout: Optional[tf.experimental.dtensor.Layout] = None
) -> tf.Tensor
",Copies a tf.Tensor onto the DTensor device with the given layout.
tf.experimental.dtensor.create_distributed_mesh,"tf.experimental.dtensor.create_distributed_mesh(
    mesh_dims: List[Tuple[str, int]],
    mesh_name: str = '',
    num_global_devices: Optional[int] = None,
    num_clients: Optional[int] = None,
    client_id: Optional[int] = None,
    device_type: str = 'CPU'
) -> tf.experimental.dtensor.Mesh
",Creates a single- or multi-client mesh.
tf.experimental.dtensor.create_mesh,"tf.experimental.dtensor.create_mesh(
    mesh_dims: Optional[List[Tuple[str, int]]] = None,
    mesh_name: str = '',
    devices: Optional[List[str]] = None,
    device_type: Optional[str] = None
) -> tf.experimental.dtensor.Mesh
",Creates a single-client mesh.
tf.experimental.dtensor.device_name,"tf.experimental.dtensor.device_name() -> str
",Returns the singleton DTensor device's name.
tf.experimental.dtensor.enable_save_as_bf16,"tf.experimental.dtensor.enable_save_as_bf16(
    variables: List[tf.Variable]
)
",Allows float32 DVariables to be checkpointed and restored as bfloat16.
tf.experimental.dtensor.fetch_layout,"tf.experimental.dtensor.fetch_layout(
    tensor: tf.Tensor
) -> tf.experimental.dtensor.Layout
",Fetches the layout of a DTensor.
tf.experimental.dtensor.full_job_name,"tf.experimental.dtensor.full_job_name(
    task_id: Optional[int] = None
) -> str
",Returns the fully qualified TF job name for this or another task.
tf.experimental.dtensor.heartbeat_enabled,"tf.experimental.dtensor.heartbeat_enabled() -> bool
",Returns true if DTensor heartbeat service is enabled.
tf.experimental.dtensor.initialize_multi_client,"tf.experimental.dtensor.initialize_multi_client(
    enable_coordination_service: Optional[bool] = False
) -> None
",Initializes Multi Client DTensor.
tf.experimental.dtensor.initialize_tpu_system,"tf.experimental.dtensor.initialize_tpu_system(
    enable_coordination_service=False
)
",Initialize the TPU devices.
tf.experimental.dtensor.job_name,"tf.experimental.dtensor.job_name() -> str
",Returns the job name used by all clients in this DTensor cluster.
tf.experimental.dtensor.jobs,"tf.experimental.dtensor.jobs() -> List[str]
",Returns a list of job names of all clients in this DTensor cluster.
tf.experimental.dtensor.local_devices,"tf.experimental.dtensor.local_devices(
    device_type: str, for_client_id: Optional[int] = None
) -> List[tf.compat.v1.DeviceSpec]
",Returns a list of device specs of device_type attached to this client.
tf.experimental.dtensor.name_based_restore,"tf.experimental.dtensor.name_based_restore(
    mesh: tf.experimental.dtensor.Mesh,
    checkpoint_prefix: str,
    name_tensor_dict: Dict[str, Union[ops.Tensor, tf_variables.Variable]]
)
",Restores from checkpoint_prefix to name based DTensors.
tf.experimental.dtensor.name_based_save,"tf.experimental.dtensor.name_based_save(
    mesh: tf.experimental.dtensor.Mesh,
    checkpoint_prefix: Union[str, tf.Tensor],
    name_tensor_dict: Dict[str, Union[ops.Tensor, tf_variables.Variable]]
)
",Saves name based Tensor into a Checkpoint.
tf.experimental.dtensor.num_clients,"tf.experimental.dtensor.num_clients() -> int
",Returns the number of clients in this DTensor cluster.
tf.experimental.dtensor.num_global_devices,"tf.experimental.dtensor.num_global_devices(
    device_type: str
) -> int
",Returns the number of devices of device_type in this DTensor cluster.
tf.experimental.dtensor.num_local_devices,"tf.experimental.dtensor.num_local_devices(
    device_type: str
) -> int
",Returns the number of devices of device_type attached to this client.
tf.experimental.dtensor.pack,"tf.experimental.dtensor.pack(
    tensors: Sequence[Any],
    layout: tf.experimental.dtensor.Layout
) -> Any
",Packs tf.Tensor components into a DTensor.
tf.experimental.dtensor.relayout,"tf.experimental.dtensor.relayout(
    tensor: tf.Tensor,
    layout: tf.experimental.dtensor.Layout
) -> tf.Tensor
",Changes the layout of tensor.
tf.experimental.dtensor.sharded_save,"tf.experimental.dtensor.sharded_save(
    mesh: tf.experimental.dtensor.Mesh,
    file_prefix: Union[str, tf.Tensor],
    tensor_names: Union[List[str], tf.Tensor],
    shape_and_slices: Union[List[str], tf.Tensor],
    tensors: List[Union[ops.Tensor, tf_variables.Variable]]
)
","Saves given named tensor slices in a sharded, multi-client safe fashion."
tf.experimental.dtensor.unpack,"tf.experimental.dtensor.unpack(
    tensor: Any
) -> Sequence[Any]
",Unpacks a DTensor into tf.Tensor components.
tf.experimental.numpy.abs,"tf.experimental.numpy.abs(
    x
)
",TensorFlow variant of NumPy's abs.
tf.experimental.numpy.absolute,"tf.experimental.numpy.absolute(
    x
)
",TensorFlow variant of NumPy's absolute.
tf.experimental.numpy.add,"tf.experimental.numpy.add(
    x1, x2
)
",TensorFlow variant of NumPy's add.
tf.experimental.numpy.all,"tf.experimental.numpy.all(
    a, axis=None, keepdims=None
)
",TensorFlow variant of NumPy's all.
tf.experimental.numpy.allclose,"tf.experimental.numpy.allclose(
    a, b, rtol=1e-05, atol=1e-08, equal_nan=False
)
",TensorFlow variant of NumPy's allclose.
tf.experimental.numpy.amax,"tf.experimental.numpy.amax(
    a, axis=None, out=None, keepdims=None
)
",TensorFlow variant of NumPy's amax.
tf.experimental.numpy.amin,"tf.experimental.numpy.amin(
    a, axis=None, out=None, keepdims=None
)
",TensorFlow variant of NumPy's amin.
tf.experimental.numpy.angle,"tf.experimental.numpy.angle(
    z, deg=False
)
",TensorFlow variant of NumPy's angle.
tf.experimental.numpy.any,"tf.experimental.numpy.any(
    a, axis=None, keepdims=None
)
",TensorFlow variant of NumPy's any.
tf.experimental.numpy.append,"tf.experimental.numpy.append(
    arr, values, axis=None
)
",TensorFlow variant of NumPy's append.
tf.experimental.numpy.arange,"tf.experimental.numpy.arange(
    start, stop=None, step=1, dtype=None
)
",TensorFlow variant of NumPy's arange.
tf.experimental.numpy.arccos,"tf.experimental.numpy.arccos(
    x
)
",TensorFlow variant of NumPy's arccos.
tf.experimental.numpy.arccosh,"tf.experimental.numpy.arccosh(
    x
)
",TensorFlow variant of NumPy's arccosh.
tf.experimental.numpy.arcsin,"tf.experimental.numpy.arcsin(
    x
)
",TensorFlow variant of NumPy's arcsin.
tf.experimental.numpy.arcsinh,"tf.experimental.numpy.arcsinh(
    x
)
",TensorFlow variant of NumPy's arcsinh.
tf.experimental.numpy.arctan,"tf.experimental.numpy.arctan(
    x
)
",TensorFlow variant of NumPy's arctan.
tf.experimental.numpy.arctan2,"tf.experimental.numpy.arctan2(
    x1, x2
)
",TensorFlow variant of NumPy's arctan2.
tf.experimental.numpy.arctanh,"tf.experimental.numpy.arctanh(
    x
)
",TensorFlow variant of NumPy's arctanh.
tf.experimental.numpy.argmax,"tf.experimental.numpy.argmax(
    a, axis=None
)
",TensorFlow variant of NumPy's argmax.
tf.experimental.numpy.argmin,"tf.experimental.numpy.argmin(
    a, axis=None
)
",TensorFlow variant of NumPy's argmin.
tf.experimental.numpy.argsort,"tf.experimental.numpy.argsort(
    a, axis=-1, kind='quicksort', order=None
)
",TensorFlow variant of NumPy's argsort.
tf.experimental.numpy.around,"tf.experimental.numpy.around(
    a, decimals=0
)
",TensorFlow variant of NumPy's around.
tf.experimental.numpy.array,"tf.experimental.numpy.array(
    val, dtype=None, copy=True, ndmin=0
)
",TensorFlow variant of NumPy's array.
tf.experimental.numpy.array_equal,"tf.experimental.numpy.array_equal(
    a1, a2
)
",TensorFlow variant of NumPy's array_equal.
tf.experimental.numpy.asanyarray,"tf.experimental.numpy.asanyarray(
    a, dtype=None
)
",TensorFlow variant of NumPy's asanyarray.
tf.experimental.numpy.asarray,"tf.experimental.numpy.asarray(
    a, dtype=None
)
",TensorFlow variant of NumPy's asarray.
tf.experimental.numpy.ascontiguousarray,"tf.experimental.numpy.ascontiguousarray(
    a, dtype=None
)
",TensorFlow variant of NumPy's ascontiguousarray.
tf.experimental.numpy.atleast_1d,"tf.experimental.numpy.atleast_1d(
    *arys
)
",TensorFlow variant of NumPy's atleast_1d.
tf.experimental.numpy.atleast_2d,"tf.experimental.numpy.atleast_2d(
    *arys
)
",TensorFlow variant of NumPy's atleast_2d.
tf.experimental.numpy.atleast_3d,"tf.experimental.numpy.atleast_3d(
    *arys
)
",TensorFlow variant of NumPy's atleast_3d.
tf.experimental.numpy.average,"tf.experimental.numpy.average(
    a, axis=None, weights=None, returned=False
)
",TensorFlow variant of NumPy's average.
tf.experimental.numpy.bitwise_and,"tf.experimental.numpy.bitwise_and(
    x1, x2
)
",TensorFlow variant of NumPy's bitwise_and.
tf.experimental.numpy.bitwise_not,"tf.experimental.numpy.bitwise_not(
    x
)
",TensorFlow variant of NumPy's bitwise_not.
tf.experimental.numpy.bitwise_or,"tf.experimental.numpy.bitwise_or(
    x1, x2
)
",TensorFlow variant of NumPy's bitwise_or.
tf.experimental.numpy.bitwise_xor,"tf.experimental.numpy.bitwise_xor(
    x1, x2
)
",TensorFlow variant of NumPy's bitwise_xor.
tf.experimental.numpy.bool_,"tf.experimental.numpy.bool_(
    *args, **kwargs
)
","Boolean type (True or False), stored as a byte."
tf.experimental.numpy.broadcast_arrays,"tf.experimental.numpy.broadcast_arrays(
    *args, **kwargs
)
",TensorFlow variant of NumPy's broadcast_arrays.
tf.experimental.numpy.broadcast_to,"tf.experimental.numpy.broadcast_to(
    array, shape
)
",TensorFlow variant of NumPy's broadcast_to.
tf.experimental.numpy.cbrt,"tf.experimental.numpy.cbrt(
    x
)
",TensorFlow variant of NumPy's cbrt.
tf.experimental.numpy.ceil,"tf.experimental.numpy.ceil(
    x
)
",TensorFlow variant of NumPy's ceil.
tf.experimental.numpy.clip,"tf.experimental.numpy.clip(
    a, a_min, a_max
)
",TensorFlow variant of NumPy's clip.
tf.experimental.numpy.complex128,"tf.experimental.numpy.complex128(
    *args, **kwargs
)
",Complex number type composed of two double-precision floating-pointInherits From: inexactView aliases
tf.experimental.numpy.complex64,"tf.experimental.numpy.complex64(
    *args, **kwargs
)
",Complex number type composed of two single-precision floating-pointInherits From: inexact
tf.experimental.numpy.complex128,"tf.experimental.numpy.complex128(
    *args, **kwargs
)
",Complex number type composed of two double-precision floating-pointInherits From: inexactView aliases
tf.experimental.numpy.compress,"tf.experimental.numpy.compress(
    condition, a, axis=None
)
",TensorFlow variant of NumPy's compress.
tf.experimental.numpy.concatenate,"tf.experimental.numpy.concatenate(
    arys, axis=0
)
",TensorFlow variant of NumPy's concatenate.
tf.experimental.numpy.conj,"tf.experimental.numpy.conj(
    x
)
",TensorFlow variant of NumPy's conj.
tf.experimental.numpy.conjugate,"tf.experimental.numpy.conjugate(
    x
)
",TensorFlow variant of NumPy's conjugate.
tf.experimental.numpy.copy,"tf.experimental.numpy.copy(
    a
)
",TensorFlow variant of NumPy's copy.
tf.experimental.numpy.cos,"tf.experimental.numpy.cos(
    x
)
",TensorFlow variant of NumPy's cos.
tf.experimental.numpy.cosh,"tf.experimental.numpy.cosh(
    x
)
",TensorFlow variant of NumPy's cosh.
tf.experimental.numpy.count_nonzero,"tf.experimental.numpy.count_nonzero(
    a, axis=None
)
",TensorFlow variant of NumPy's count_nonzero.
tf.experimental.numpy.cross,"tf.experimental.numpy.cross(
    a, b, axisa=-1, axisb=-1, axisc=-1, axis=None
)
",TensorFlow variant of NumPy's cross.
tf.experimental.numpy.cumprod,"tf.experimental.numpy.cumprod(
    a, axis=None, dtype=None
)
",TensorFlow variant of NumPy's cumprod.
tf.experimental.numpy.cumsum,"tf.experimental.numpy.cumsum(
    a, axis=None, dtype=None
)
",TensorFlow variant of NumPy's cumsum.
tf.experimental.numpy.deg2rad,"tf.experimental.numpy.deg2rad(
    x
)
",TensorFlow variant of NumPy's deg2rad.
tf.experimental.numpy.diag,"tf.experimental.numpy.diag(
    v, k=0
)
",TensorFlow variant of NumPy's diag.
tf.experimental.numpy.diag_indices,"tf.experimental.numpy.diag_indices(
    n, ndim=2
)
",TensorFlow variant of NumPy's diag_indices.
tf.experimental.numpy.diagflat,"tf.experimental.numpy.diagflat(
    v, k=0
)
",TensorFlow variant of NumPy's diagflat.
tf.experimental.numpy.diagonal,"tf.experimental.numpy.diagonal(
    a, offset=0, axis1=0, axis2=1
)
",TensorFlow variant of NumPy's diagonal.
tf.experimental.numpy.diff,"tf.experimental.numpy.diff(
    a, n=1, axis=-1
)
",TensorFlow variant of NumPy's diff.
tf.experimental.numpy.divide,"tf.experimental.numpy.divide(
    x1, x2
)
",TensorFlow variant of NumPy's divide.
tf.experimental.numpy.divmod,"tf.experimental.numpy.divmod(
    x1, x2
)
",TensorFlow variant of NumPy's divmod.
tf.experimental.numpy.dot,"tf.experimental.numpy.dot(
    a, b
)
",TensorFlow variant of NumPy's dot.
tf.experimental.numpy.dsplit,"tf.experimental.numpy.dsplit(
    ary, indices_or_sections
)
",TensorFlow variant of NumPy's dsplit.
tf.experimental.numpy.dstack,"tf.experimental.numpy.dstack(
    tup
)
",TensorFlow variant of NumPy's dstack.
tf.experimental.numpy.einsum,"tf.experimental.numpy.einsum(
    subscripts, *operands, **kwargs
)
",TensorFlow variant of NumPy's einsum.
tf.experimental.numpy.empty,"tf.experimental.numpy.empty(
    shape, dtype=float
)
",TensorFlow variant of NumPy's empty.
tf.experimental.numpy.empty_like,"tf.experimental.numpy.empty_like(
    a, dtype=None
)
",TensorFlow variant of NumPy's empty_like.
tf.experimental.numpy.equal,"tf.experimental.numpy.equal(
    x1, x2
)
",TensorFlow variant of NumPy's equal.
tf.experimental.numpy.exp,"tf.experimental.numpy.exp(
    x
)
",TensorFlow variant of NumPy's exp.
tf.experimental.numpy.exp2,"tf.experimental.numpy.exp2(
    x
)
",TensorFlow variant of NumPy's exp2.
tf.experimental.numpy.expand_dims,"tf.experimental.numpy.expand_dims(
    a, axis
)
",TensorFlow variant of NumPy's expand_dims.
tf.experimental.numpy.experimental_enable_numpy_behavior,"tf.experimental.numpy.experimental_enable_numpy_behavior(
    prefer_float32=False
)
",Enable NumPy behavior on Tensors.
tf.experimental.numpy.expm1,"tf.experimental.numpy.expm1(
    x
)
",TensorFlow variant of NumPy's expm1.
tf.experimental.numpy.eye,"tf.experimental.numpy.eye(
    N, M=None, k=0, dtype=float
)
",TensorFlow variant of NumPy's eye.
tf.experimental.numpy.fabs,"tf.experimental.numpy.fabs(
    x
)
",TensorFlow variant of NumPy's fabs.
tf.experimental.numpy.finfo,"tf.experimental.numpy.finfo(
    dtype
)
",TensorFlow variant of NumPy's finfo.
tf.experimental.numpy.fix,"tf.experimental.numpy.fix(
    x
)
",TensorFlow variant of NumPy's fix.
tf.experimental.numpy.flip,"tf.experimental.numpy.flip(
    m, axis=None
)
",TensorFlow variant of NumPy's flip.
tf.experimental.numpy.fliplr,"tf.experimental.numpy.fliplr(
    m
)
",TensorFlow variant of NumPy's fliplr.
tf.experimental.numpy.flipud,"tf.experimental.numpy.flipud(
    m
)
",TensorFlow variant of NumPy's flipud.
tf.experimental.numpy.float16,"tf.experimental.numpy.float16(
    *args, **kwargs
)
",Half-precision floating-point number type.Inherits From: inexact
tf.experimental.numpy.float32,"tf.experimental.numpy.float32(
    *args, **kwargs
)
","Single-precision floating-point number type, compatible with C float.Inherits From: inexact"
tf.experimental.numpy.float64,"tf.experimental.numpy.float64(
    *args, **kwargs
)
","Double-precision floating-point number type, compatible with Python floatInherits From: inexactView aliases"
tf.experimental.numpy.float64,"tf.experimental.numpy.float64(
    *args, **kwargs
)
","Double-precision floating-point number type, compatible with Python floatInherits From: inexactView aliases"
tf.experimental.numpy.float_power,"tf.experimental.numpy.float_power(
    x1, x2
)
",TensorFlow variant of NumPy's float_power.
tf.experimental.numpy.floor,"tf.experimental.numpy.floor(
    x
)
",TensorFlow variant of NumPy's floor.
tf.experimental.numpy.floor_divide,"tf.experimental.numpy.floor_divide(
    x1, x2
)
",TensorFlow variant of NumPy's floor_divide.
tf.experimental.numpy.full,"tf.experimental.numpy.full(
    shape, fill_value, dtype=None
)
",TensorFlow variant of NumPy's full.
tf.experimental.numpy.full_like,"tf.experimental.numpy.full_like(
    a, fill_value, dtype=None, order='K', subok=True, shape=None
)
",TensorFlow variant of NumPy's full_like.
tf.experimental.numpy.gcd,"tf.experimental.numpy.gcd(
    x1, x2
)
",TensorFlow variant of NumPy's gcd.
tf.experimental.numpy.geomspace,"tf.experimental.numpy.geomspace(
    start, stop, num=50, endpoint=True, dtype=None, axis=0
)
",TensorFlow variant of NumPy's geomspace.
tf.experimental.numpy.greater,"tf.experimental.numpy.greater(
    x1, x2
)
",TensorFlow variant of NumPy's greater.
tf.experimental.numpy.greater_equal,"tf.experimental.numpy.greater_equal(
    x1, x2
)
",TensorFlow variant of NumPy's greater_equal.
tf.experimental.numpy.heaviside,"tf.experimental.numpy.heaviside(
    x1, x2
)
",TensorFlow variant of NumPy's heaviside.
tf.experimental.numpy.hsplit,"tf.experimental.numpy.hsplit(
    ary, indices_or_sections
)
",TensorFlow variant of NumPy's hsplit.
tf.experimental.numpy.hstack,"tf.experimental.numpy.hstack(
    tup
)
",TensorFlow variant of NumPy's hstack.
tf.experimental.numpy.hypot,"tf.experimental.numpy.hypot(
    x1, x2
)
",TensorFlow variant of NumPy's hypot.
tf.experimental.numpy.identity,"tf.experimental.numpy.identity(
    n, dtype=float
)
",TensorFlow variant of NumPy's identity.
tf.experimental.numpy.iinfo,"tf.experimental.numpy.iinfo(
    int_type
)
",iinfo(type)
tf.experimental.numpy.imag,"tf.experimental.numpy.imag(
    val
)
",TensorFlow variant of NumPy's imag.
tf.experimental.numpy.inner,"tf.experimental.numpy.inner(
    a, b
)
",TensorFlow variant of NumPy's inner.
tf.experimental.numpy.int16,"tf.experimental.numpy.int16(
    *args, **kwargs
)
","Signed integer type, compatible with C short."
tf.experimental.numpy.int32,"tf.experimental.numpy.int32(
    *args, **kwargs
)
","Signed integer type, compatible with C int."
tf.experimental.numpy.int64,"tf.experimental.numpy.int64(
    *args, **kwargs
)
","Signed integer type, compatible with Python int and C long.View aliases"
tf.experimental.numpy.int8,"tf.experimental.numpy.int8(
    *args, **kwargs
)
","Signed integer type, compatible with C char."
tf.experimental.numpy.int64,"tf.experimental.numpy.int64(
    *args, **kwargs
)
","Signed integer type, compatible with Python int and C long.View aliases"
tf.experimental.numpy.isclose,"tf.experimental.numpy.isclose(
    a, b, rtol=1e-05, atol=1e-08, equal_nan=False
)
",TensorFlow variant of NumPy's isclose.
tf.experimental.numpy.iscomplex,"tf.experimental.numpy.iscomplex(
    x
)
",TensorFlow variant of NumPy's iscomplex.
tf.experimental.numpy.iscomplexobj,"tf.experimental.numpy.iscomplexobj(
    x
)
",TensorFlow variant of NumPy's iscomplexobj.
tf.experimental.numpy.isfinite,"tf.experimental.numpy.isfinite(
    x
)
",TensorFlow variant of NumPy's isfinite.
tf.experimental.numpy.isinf,"tf.experimental.numpy.isinf(
    x
)
",TensorFlow variant of NumPy's isinf.
tf.experimental.numpy.isnan,"tf.experimental.numpy.isnan(
    x
)
",TensorFlow variant of NumPy's isnan.
tf.experimental.numpy.isneginf,"tf.experimental.numpy.isneginf(
    x
)
",TensorFlow variant of NumPy's isneginf.
tf.experimental.numpy.isposinf,"tf.experimental.numpy.isposinf(
    x
)
",TensorFlow variant of NumPy's isposinf.
tf.experimental.numpy.isreal,"tf.experimental.numpy.isreal(
    x
)
",TensorFlow variant of NumPy's isreal.
tf.experimental.numpy.isrealobj,"tf.experimental.numpy.isrealobj(
    x
)
",TensorFlow variant of NumPy's isrealobj.
tf.experimental.numpy.isscalar,"tf.experimental.numpy.isscalar(
    num
)
",TensorFlow variant of NumPy's isscalar.
tf.experimental.numpy.issubdtype,"tf.experimental.numpy.issubdtype(
    arg1, arg2
)
",Returns True if first argument is a typecode lower/equal in type hierarchy.
tf.experimental.numpy.ix_,"tf.experimental.numpy.ix_(
    *args
)
",TensorFlow variant of NumPy's ix_.
tf.experimental.numpy.kron,"tf.experimental.numpy.kron(
    a, b
)
",TensorFlow variant of NumPy's kron.
tf.experimental.numpy.lcm,"tf.experimental.numpy.lcm(
    x1, x2
)
",TensorFlow variant of NumPy's lcm.
tf.experimental.numpy.less,"tf.experimental.numpy.less(
    x1, x2
)
",TensorFlow variant of NumPy's less.
tf.experimental.numpy.less_equal,"tf.experimental.numpy.less_equal(
    x1, x2
)
",TensorFlow variant of NumPy's less_equal.
tf.experimental.numpy.linspace,"tf.experimental.numpy.linspace(
    start, stop, num=50, endpoint=True, retstep=False, dtype=float, axis=0
)
",TensorFlow variant of NumPy's linspace.
tf.experimental.numpy.log,"tf.experimental.numpy.log(
    x
)
",TensorFlow variant of NumPy's log.
tf.experimental.numpy.log10,"tf.experimental.numpy.log10(
    x
)
",TensorFlow variant of NumPy's log10.
tf.experimental.numpy.log1p,"tf.experimental.numpy.log1p(
    x
)
",TensorFlow variant of NumPy's log1p.
tf.experimental.numpy.log2,"tf.experimental.numpy.log2(
    x
)
",TensorFlow variant of NumPy's log2.
tf.experimental.numpy.logaddexp,"tf.experimental.numpy.logaddexp(
    x1, x2
)
",TensorFlow variant of NumPy's logaddexp.
tf.experimental.numpy.logaddexp2,"tf.experimental.numpy.logaddexp2(
    x1, x2
)
",TensorFlow variant of NumPy's logaddexp2.
tf.experimental.numpy.logical_and,"tf.experimental.numpy.logical_and(
    x1, x2
)
",TensorFlow variant of NumPy's logical_and.
tf.experimental.numpy.logical_not,"tf.experimental.numpy.logical_not(
    x
)
",TensorFlow variant of NumPy's logical_not.
tf.experimental.numpy.logical_or,"tf.experimental.numpy.logical_or(
    x1, x2
)
",TensorFlow variant of NumPy's logical_or.
tf.experimental.numpy.logical_xor,"tf.experimental.numpy.logical_xor(
    x1, x2
)
",TensorFlow variant of NumPy's logical_xor.
tf.experimental.numpy.logspace,"tf.experimental.numpy.logspace(
    start, stop, num=50, endpoint=True, base=10.0, dtype=None, axis=0
)
",TensorFlow variant of NumPy's logspace.
tf.experimental.numpy.matmul,"tf.experimental.numpy.matmul(
    x1, x2
)
",TensorFlow variant of NumPy's matmul.
tf.experimental.numpy.max,"tf.experimental.numpy.max(
    a, axis=None, keepdims=None
)
",TensorFlow variant of NumPy's max.
tf.experimental.numpy.maximum,"tf.experimental.numpy.maximum(
    x1, x2
)
",TensorFlow variant of NumPy's maximum.
tf.experimental.numpy.mean,"tf.experimental.numpy.mean(
    a, axis=None, dtype=None, out=None, keepdims=None
)
",TensorFlow variant of NumPy's mean.
tf.experimental.numpy.meshgrid,"tf.experimental.numpy.meshgrid(
    *xi, **kwargs
)
",TensorFlow variant of NumPy's meshgrid.
tf.experimental.numpy.min,"tf.experimental.numpy.min(
    a, axis=None, keepdims=None
)
",TensorFlow variant of NumPy's min.
tf.experimental.numpy.minimum,"tf.experimental.numpy.minimum(
    x1, x2
)
",TensorFlow variant of NumPy's minimum.
tf.experimental.numpy.mod,"tf.experimental.numpy.mod(
    x1, x2
)
",TensorFlow variant of NumPy's mod.
tf.experimental.numpy.moveaxis,"tf.experimental.numpy.moveaxis(
    a, source, destination
)
",TensorFlow variant of NumPy's moveaxis.
tf.experimental.numpy.multiply,"tf.experimental.numpy.multiply(
    x1, x2
)
",TensorFlow variant of NumPy's multiply.
tf.experimental.numpy.nanmean,"tf.experimental.numpy.nanmean(
    a, axis=None, dtype=None, keepdims=None
)
",TensorFlow variant of NumPy's nanmean.
tf.experimental.numpy.nanprod,"tf.experimental.numpy.nanprod(
    a, axis=None, dtype=None, keepdims=False
)
",TensorFlow variant of NumPy's nanprod.
tf.experimental.numpy.nansum,"tf.experimental.numpy.nansum(
    a, axis=None, dtype=None, keepdims=False
)
",TensorFlow variant of NumPy's nansum.
tf.Tensor,"tf.Tensor(
    op, value_index, dtype
)
",A tf.Tensor represents a multidimensional array of elements.View aliases
tf.experimental.numpy.ndim,"tf.experimental.numpy.ndim(
    a
)
",TensorFlow variant of NumPy's ndim.
tf.experimental.numpy.negative,"tf.experimental.numpy.negative(
    x
)
",TensorFlow variant of NumPy's negative.
tf.experimental.numpy.nextafter,"tf.experimental.numpy.nextafter(
    x1, x2
)
",TensorFlow variant of NumPy's nextafter.
tf.experimental.numpy.nonzero,"tf.experimental.numpy.nonzero(
    a
)
",TensorFlow variant of NumPy's nonzero.
tf.experimental.numpy.not_equal,"tf.experimental.numpy.not_equal(
    x1, x2
)
",TensorFlow variant of NumPy's not_equal.
tf.experimental.numpy.object_,"tf.experimental.numpy.object_(
    *args, **kwargs
)
",Any Python object.
tf.experimental.numpy.ones,"tf.experimental.numpy.ones(
    shape, dtype=float
)
",TensorFlow variant of NumPy's ones.
tf.experimental.numpy.ones_like,"tf.experimental.numpy.ones_like(
    a, dtype=None
)
",TensorFlow variant of NumPy's ones_like.
tf.experimental.numpy.outer,"tf.experimental.numpy.outer(
    a, b
)
",TensorFlow variant of NumPy's outer.
tf.experimental.numpy.pad,"tf.experimental.numpy.pad(
    array, pad_width, mode, **kwargs
)
",TensorFlow variant of NumPy's pad.
tf.experimental.numpy.polyval,"tf.experimental.numpy.polyval(
    p, x
)
",TensorFlow variant of NumPy's polyval.
tf.experimental.numpy.positive,"tf.experimental.numpy.positive(
    x
)
",TensorFlow variant of NumPy's positive.
tf.experimental.numpy.power,"tf.experimental.numpy.power(
    x1, x2
)
",TensorFlow variant of NumPy's power.
tf.experimental.numpy.prod,"tf.experimental.numpy.prod(
    a, axis=None, dtype=None, keepdims=None
)
",TensorFlow variant of NumPy's prod.
tf.experimental.numpy.promote_types,"tf.experimental.numpy.promote_types(
    type1, type2
)
",TensorFlow variant of NumPy's promote_types.
tf.experimental.numpy.ptp,"tf.experimental.numpy.ptp(
    a, axis=None, keepdims=None
)
",TensorFlow variant of NumPy's ptp.
tf.experimental.numpy.rad2deg,"tf.experimental.numpy.rad2deg(
    x
)
",TensorFlow variant of NumPy's rad2deg.
tf.experimental.numpy.random.poisson,"tf.experimental.numpy.random.poisson(
    lam=1.0, size=None
)
",TensorFlow variant of NumPy's random.poisson.
tf.experimental.numpy.random.rand,"tf.experimental.numpy.random.rand(
    *size
)
",TensorFlow variant of NumPy's random.rand.
tf.experimental.numpy.random.randint,"tf.experimental.numpy.random.randint(
    low,
    high=None,
    size=None,
    dtype=tf.experimental.numpy.int64
)
",TensorFlow variant of NumPy's random.randint.
tf.experimental.numpy.random.randn,"tf.experimental.numpy.random.randn(
    *args
)
",TensorFlow variant of NumPy's random.randn.
tf.experimental.numpy.random.random,"tf.experimental.numpy.random.random(
    size=None
)
",TensorFlow variant of NumPy's random.random.
tf.experimental.numpy.random.seed,"tf.experimental.numpy.random.seed(
    s
)
",TensorFlow variant of NumPy's random.seed.
tf.experimental.numpy.random.standard_normal,"tf.experimental.numpy.random.standard_normal(
    size=None
)
",TensorFlow variant of NumPy's random.standard_normal.
tf.experimental.numpy.random.uniform,"tf.experimental.numpy.random.uniform(
    low=0.0, high=1.0, size=None
)
",TensorFlow variant of NumPy's random.uniform.
tf.experimental.numpy.ravel,"tf.experimental.numpy.ravel(
    a
)
",TensorFlow variant of NumPy's ravel.
tf.experimental.numpy.real,"tf.experimental.numpy.real(
    val
)
",TensorFlow variant of NumPy's real.
tf.experimental.numpy.reciprocal,"tf.experimental.numpy.reciprocal(
    x
)
",TensorFlow variant of NumPy's reciprocal.
tf.experimental.numpy.remainder,"tf.experimental.numpy.remainder(
    x1, x2
)
",TensorFlow variant of NumPy's remainder.
tf.experimental.numpy.repeat,"tf.experimental.numpy.repeat(
    a, repeats, axis=None
)
",TensorFlow variant of NumPy's repeat.
tf.experimental.numpy.reshape,"tf.experimental.numpy.reshape(
    a, newshape, order='C'
)
",TensorFlow variant of NumPy's reshape.
tf.experimental.numpy.result_type,"tf.experimental.numpy.result_type(
    *arrays_and_dtypes
)
",TensorFlow variant of NumPy's result_type.
tf.experimental.numpy.roll,"tf.experimental.numpy.roll(
    a, shift, axis=None
)
",TensorFlow variant of NumPy's roll.
tf.experimental.numpy.rot90,"tf.experimental.numpy.rot90(
    m, k=1, axes=(0, 1)
)
",TensorFlow variant of NumPy's rot90.
tf.experimental.numpy.round,"tf.experimental.numpy.round(
    a, decimals=0
)
",TensorFlow variant of NumPy's round.
tf.experimental.numpy.select,"tf.experimental.numpy.select(
    condlist, choicelist, default=0
)
",TensorFlow variant of NumPy's select.
tf.experimental.numpy.shape,"tf.experimental.numpy.shape(
    a
)
",TensorFlow variant of NumPy's shape.
tf.experimental.numpy.sign,"tf.experimental.numpy.sign(
    x, out=None, where=None, **kwargs
)
",TensorFlow variant of NumPy's sign.
tf.experimental.numpy.signbit,"tf.experimental.numpy.signbit(
    x
)
",TensorFlow variant of NumPy's signbit.
tf.experimental.numpy.sin,"tf.experimental.numpy.sin(
    x
)
",TensorFlow variant of NumPy's sin.
tf.experimental.numpy.sinc,"tf.experimental.numpy.sinc(
    x
)
",TensorFlow variant of NumPy's sinc.
tf.experimental.numpy.sinh,"tf.experimental.numpy.sinh(
    x
)
",TensorFlow variant of NumPy's sinh.
tf.experimental.numpy.size,"tf.experimental.numpy.size(
    x, axis=None
)
",TensorFlow variant of NumPy's size.
tf.experimental.numpy.sort,"tf.experimental.numpy.sort(
    a, axis=-1, kind='quicksort', order=None
)
",TensorFlow variant of NumPy's sort.
tf.experimental.numpy.split,"tf.experimental.numpy.split(
    ary, indices_or_sections, axis=0
)
",TensorFlow variant of NumPy's split.
tf.experimental.numpy.sqrt,"tf.experimental.numpy.sqrt(
    x
)
",TensorFlow variant of NumPy's sqrt.
tf.experimental.numpy.square,"tf.experimental.numpy.square(
    x
)
",TensorFlow variant of NumPy's square.
tf.experimental.numpy.squeeze,"tf.experimental.numpy.squeeze(
    a, axis=None
)
",TensorFlow variant of NumPy's squeeze.
tf.experimental.numpy.stack,"tf.experimental.numpy.stack(
    arrays, axis=0
)
",TensorFlow variant of NumPy's stack.
tf.experimental.numpy.std,"tf.experimental.numpy.std(
    a, axis=None, keepdims=None
)
",TensorFlow variant of NumPy's std.
tf.experimental.numpy.string_,"tf.experimental.numpy.string_(
    *args, **kwargs
)
",A byte string.
tf.experimental.numpy.subtract,"tf.experimental.numpy.subtract(
    x1, x2
)
",TensorFlow variant of NumPy's subtract.
tf.experimental.numpy.sum,"tf.experimental.numpy.sum(
    a, axis=None, dtype=None, keepdims=None
)
",TensorFlow variant of NumPy's sum.
tf.experimental.numpy.swapaxes,"tf.experimental.numpy.swapaxes(
    a, axis1, axis2
)
",TensorFlow variant of NumPy's swapaxes.
tf.experimental.numpy.take,"tf.experimental.numpy.take(
    a, indices, axis=None, out=None, mode='clip'
)
",TensorFlow variant of NumPy's take.
tf.experimental.numpy.take_along_axis,"tf.experimental.numpy.take_along_axis(
    arr, indices, axis
)
",TensorFlow variant of NumPy's take_along_axis.
tf.experimental.numpy.tan,"tf.experimental.numpy.tan(
    x
)
",TensorFlow variant of NumPy's tan.
tf.experimental.numpy.tanh,"tf.experimental.numpy.tanh(
    x
)
",TensorFlow variant of NumPy's tanh.
tf.experimental.numpy.tensordot,"tf.experimental.numpy.tensordot(
    a, b, axes=2
)
",TensorFlow variant of NumPy's tensordot.
tf.experimental.numpy.tile,"tf.experimental.numpy.tile(
    a, reps
)
",TensorFlow variant of NumPy's tile.
tf.experimental.numpy.trace,"tf.experimental.numpy.trace(
    a, offset=0, axis1=0, axis2=1, dtype=None
)
",TensorFlow variant of NumPy's trace.
tf.experimental.numpy.transpose,"tf.experimental.numpy.transpose(
    a, axes=None
)
",TensorFlow variant of NumPy's transpose.
tf.experimental.numpy.tri,"tf.experimental.numpy.tri(
    N, M=None, k=0, dtype=None
)
",TensorFlow variant of NumPy's tri.
tf.experimental.numpy.tril,"tf.experimental.numpy.tril(
    m, k=0
)
",TensorFlow variant of NumPy's tril.
tf.experimental.numpy.triu,"tf.experimental.numpy.triu(
    m, k=0
)
",TensorFlow variant of NumPy's triu.
tf.experimental.numpy.true_divide,"tf.experimental.numpy.true_divide(
    x1, x2
)
",TensorFlow variant of NumPy's true_divide.
tf.experimental.numpy.uint16,"tf.experimental.numpy.uint16(
    *args, **kwargs
)
","Unsigned integer type, compatible with C unsigned short."
tf.experimental.numpy.uint32,"tf.experimental.numpy.uint32(
    *args, **kwargs
)
","Unsigned integer type, compatible with C unsigned int."
tf.experimental.numpy.uint64,"tf.experimental.numpy.uint64(
    *args, **kwargs
)
","Unsigned integer type, compatible with C unsigned long."
tf.experimental.numpy.uint8,"tf.experimental.numpy.uint8(
    *args, **kwargs
)
","Unsigned integer type, compatible with C unsigned char."
tf.experimental.numpy.unicode_,"tf.experimental.numpy.unicode_(
    *args, **kwargs
)
",A unicode string.
tf.experimental.numpy.vander,"tf.experimental.numpy.vander(
    x, N=None, increasing=False
)
",TensorFlow variant of NumPy's vander.
tf.experimental.numpy.var,"tf.experimental.numpy.var(
    a, axis=None, dtype=None, out=None, ddof=0, keepdims=None
)
",TensorFlow variant of NumPy's var.
tf.experimental.numpy.vdot,"tf.experimental.numpy.vdot(
    a, b
)
",TensorFlow variant of NumPy's vdot.
tf.experimental.numpy.vsplit,"tf.experimental.numpy.vsplit(
    ary, indices_or_sections
)
",TensorFlow variant of NumPy's vsplit.
tf.experimental.numpy.vstack,"tf.experimental.numpy.vstack(
    tup
)
",TensorFlow variant of NumPy's vstack.
tf.experimental.numpy.where,"tf.experimental.numpy.where(
    condition, x=None, y=None
)
",TensorFlow variant of NumPy's where.
tf.experimental.numpy.zeros,"tf.experimental.numpy.zeros(
    shape, dtype=float
)
",TensorFlow variant of NumPy's zeros.
tf.experimental.numpy.zeros_like,"tf.experimental.numpy.zeros_like(
    a, dtype=None
)
",TensorFlow variant of NumPy's zeros_like.
tf.experimental.register_filesystem_plugin,"tf.experimental.register_filesystem_plugin(
    plugin_location
)
",Loads a TensorFlow FileSystem plugin.View aliases
tf.experimental.tensorrt.ConversionParams,"tf.experimental.tensorrt.ConversionParams(
    max_workspace_size_bytes=DEFAULT_TRT_MAX_WORKSPACE_SIZE_BYTES,
    precision_mode=TrtPrecisionMode.FP32,
    minimum_segment_size=3,
    maximum_cached_engines=1,
    use_calibration=True,
    allow_build_at_runtime=True
)
",Parameters that are used for TF-TRT conversion.
tf.experimental.tensorrt.Converter,"tf.experimental.tensorrt.Converter(
    input_saved_model_dir=None,
    input_saved_model_tags=None,
    input_saved_model_signature_key=None,
    use_dynamic_shape=None,
    dynamic_shape_profile_strategy=None,
    max_workspace_size_bytes=DEFAULT_TRT_MAX_WORKSPACE_SIZE_BYTES,
    precision_mode=TrtPrecisionMode.FP32,
    minimum_segment_size=3,
    maximum_cached_engines=1,
    use_calibration=True,
    allow_build_at_runtime=True,
    conversion_params=None
)
",An offline converter for TF-TRT transformation for TF 2.0 SavedModels.
tf.experimental.unregister_dispatch_for,"tf.experimental.unregister_dispatch_for(
    dispatch_target
)
",Unregisters a function that was registered with @dispatch_for_*.View aliases
tf.extract_volume_patches,"tf.extract_volume_patches(
    input, ksizes, strides, padding, name=None
)
","Extract patches from input and put them in the ""depth"" output dimension. 3D extension of extract_image_patches.View aliases"
tf.eye,"tf.eye(
    num_rows,
    num_columns=None,
    batch_shape=None,
    dtype=tf.dtypes.float32,
    name=None
)
","Construct an identity matrix, or a batch of matrices.View aliases"
tf.feature_column.bucketized_column,"tf.feature_column.bucketized_column(
    source_column, boundaries
)
",Represents discretized dense input bucketed by boundaries.View aliases
tf.feature_column.categorical_column_with_hash_bucket,"tf.feature_column.categorical_column_with_hash_bucket(
    key,
    hash_bucket_size,
    dtype=tf.dtypes.string
)
",Represents sparse feature where ids are set by hashing.View aliases
tf.feature_column.categorical_column_with_identity,"tf.feature_column.categorical_column_with_identity(
    key, num_buckets, default_value=None
)
",A CategoricalColumn that returns identity values.View aliases
tf.feature_column.categorical_column_with_vocabulary_file,"tf.feature_column.categorical_column_with_vocabulary_file(
    key,
    vocabulary_file,
    vocabulary_size=None,
    dtype=tf.dtypes.string,
    default_value=None,
    num_oov_buckets=0,
    file_format=None
)
",A CategoricalColumn with a vocabulary file.
tf.feature_column.categorical_column_with_vocabulary_list,"tf.feature_column.categorical_column_with_vocabulary_list(
    key, vocabulary_list, dtype=None, default_value=-1, num_oov_buckets=0
)
",A CategoricalColumn with in-memory vocabulary.View aliases
tf.feature_column.crossed_column,"tf.feature_column.crossed_column(
    keys, hash_bucket_size, hash_key=None
)
",Returns a column for performing crosses of categorical features.View aliases
tf.feature_column.embedding_column,"tf.feature_column.embedding_column(
    categorical_column,
    dimension,
    combiner='mean',
    initializer=None,
    ckpt_to_load_from=None,
    tensor_name_in_ckpt=None,
    max_norm=None,
    trainable=True,
    use_safe_embedding_lookup=True
)
","DenseColumn that converts from sparse, categorical input.View aliases"
tf.feature_column.indicator_column,"tf.feature_column.indicator_column(
    categorical_column
)
",Represents multi-hot representation of given categorical column.View aliases
tf.feature_column.make_parse_example_spec,"tf.feature_column.make_parse_example_spec(
    feature_columns
)
",Creates parsing spec dictionary from input feature_columns.
tf.feature_column.numeric_column,"tf.feature_column.numeric_column(
    key,
    shape=(1,),
    default_value=None,
    dtype=tf.dtypes.float32,
    normalizer_fn=None
)
",Represents real valued or numerical features.View aliases
tf.feature_column.sequence_categorical_column_with_hash_bucket,"tf.feature_column.sequence_categorical_column_with_hash_bucket(
    key,
    hash_bucket_size,
    dtype=tf.dtypes.string
)
",A sequence of categorical terms where ids are set by hashing.View aliases
tf.feature_column.sequence_categorical_column_with_identity,"tf.feature_column.sequence_categorical_column_with_identity(
    key, num_buckets, default_value=None
)
",Returns a feature column that represents sequences of integers.View aliases
tf.feature_column.sequence_categorical_column_with_vocabulary_file,"tf.feature_column.sequence_categorical_column_with_vocabulary_file(
    key,
    vocabulary_file,
    vocabulary_size=None,
    num_oov_buckets=0,
    default_value=None,
    dtype=tf.dtypes.string
)
",A sequence of categorical terms where ids use a vocabulary file.View aliases
tf.feature_column.sequence_categorical_column_with_vocabulary_list,"tf.feature_column.sequence_categorical_column_with_vocabulary_list(
    key, vocabulary_list, dtype=None, default_value=-1, num_oov_buckets=0
)
",A sequence of categorical terms where ids use an in-memory list.View aliases
tf.feature_column.sequence_numeric_column,"tf.feature_column.sequence_numeric_column(
    key,
    shape=(1,),
    default_value=0.0,
    dtype=tf.dtypes.float32,
    normalizer_fn=None
)
",Returns a feature column that represents sequences of numeric data.View aliases
tf.feature_column.shared_embeddings,"tf.feature_column.shared_embeddings(
    categorical_columns,
    dimension,
    combiner='mean',
    initializer=None,
    shared_embedding_collection_name=None,
    ckpt_to_load_from=None,
    tensor_name_in_ckpt=None,
    max_norm=None,
    trainable=True,
    use_safe_embedding_lookup=True
)
","List of dense columns that convert from sparse, categorical input."
tf.feature_column.weighted_categorical_column,"tf.feature_column.weighted_categorical_column(
    categorical_column,
    weight_feature_key,
    dtype=tf.dtypes.float32
)
",Applies weight values to a CategoricalColumn.View aliases
tf.fill,"tf.fill(
    dims, value, name=None
)
",Creates a tensor filled with a scalar value.View aliases
tf.fingerprint,"tf.fingerprint(
    data, method='farmhash64', name=None
)
",Generates fingerprint values.View aliases
tf.math.floor,"tf.math.floor(
    x, name=None
)
",Returns element-wise largest integer not greater than x.View aliases
tf.foldl,"tf.foldl(
    fn,
    elems,
    initializer=None,
    parallel_iterations=10,
    back_prop=True,
    swap_memory=False,
    name=None
)
",foldl on the list of tensors unpacked from elems on dimension 0. (deprecated argument values)
tf.foldr,"tf.foldr(
    fn,
    elems,
    initializer=None,
    parallel_iterations=10,
    back_prop=True,
    swap_memory=False,
    name=None
)
",foldr on the list of tensors unpacked from elems on dimension 0. (deprecated argument values)
tf.function,"tf.function(
    func=None,
    input_signature=None,
    autograph=True,
    jit_compile=None,
    reduce_retracing=False,
    experimental_implements=None,
    experimental_autograph_options=None,
    experimental_relax_shapes=None,
    experimental_compile=None,
    experimental_follow_type_hints=None
) -> tf.types.experimental.GenericFunction
",Compiles a function into a callable TensorFlow graph. (deprecated arguments) (deprecated arguments)View aliases
tf.gather,"tf.gather(
    params, indices, validate_indices=None, axis=None, batch_dims=0, name=None
)
",Gather slices from params axis axis according to indices. (deprecated arguments)
tf.gather_nd,"tf.gather_nd(
    params, indices, batch_dims=0, name=None
)
",Gather slices from params into a Tensor with shape specified by indices.
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)tf.gather_nd(    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0'],        [b'a1', b'b1']],       [[b'a0', b'b0'],        [b'c1', b'd1']]], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)tf.gather_nd(    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0'],        [b'a1', b'b1']],       [[b'a0', b'b0'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'b0', b'b1'],       [b'd0', b'c1']], dtype=object)Examples with batched 'params' and 'indices':"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)tf.gather_nd(    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0'],        [b'a1', b'b1']],       [[b'a0', b'b0'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'b0', b'b1'],       [b'd0', b'c1']], dtype=object)Examples with batched 'params' and 'indices':tf.gather_nd(    batch_dims = 1,    indices = [[1],               [0]],    params = [[['a0', 'b0'],               ['c0', 'd0']],              [['a1', 'b1'],               ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.tf.gather_nd(    params, indices, batch_dims=0, name=None)Used in the notebooksindices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)tf.gather_nd(    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0'],        [b'a1', b'b1']],       [[b'a0', b'b0'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'b0', b'b1'],       [b'd0', b'c1']], dtype=object)Examples with batched 'params' and 'indices':tf.gather_nd(    batch_dims = 1,    indices = [[1],               [0]],    params = [[['a0', 'b0'],               ['c0', 'd0']],              [['a1', 'b1'],               ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    batch_dims = 1,    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0']],       [[b'a1', b'b1']]], dtype=object)"
tf.get_static_value,"tf.get_static_value(
    tensor, partial=False
)
","Returns the constant value of the given tensor, if efficiently calculable.View aliases"
tf.grad_pass_through,"tf.grad_pass_through(
    f
)
",Creates a grad-pass-through op with the forward behavior provided in f.View aliases
tf.gradients,"tf.gradients(
    ys,
    xs,
    grad_ys=None,
    name='gradients',
    gate_gradients=False,
    aggregation_method=None,
    stop_gradients=None,
    unconnected_gradients=tf.UnconnectedGradients.NONE
)
",Constructs symbolic derivatives of sum of ys w.r.t. x in xs.
tf.graph_util.import_graph_def,"tf.graph_util.import_graph_def(
    graph_def,
    input_map=None,
    return_elements=None,
    name=None,
    op_dict=None,
    producer_op_list=None
)
",Imports the graph from graph_def into the current default Graph. (deprecated arguments)View aliases
tf.math.greater,"tf.math.greater(
    x, y, name=None
)
",Returns the truth value of (x > y) element-wise.View aliases
tf.math.greater_equal,"tf.math.greater_equal(
    x, y, name=None
)
",Returns the truth value of (x >= y) element-wise.View aliases
tf.group,"tf.group(
    *inputs, **kwargs
)
",Create an op that groups multiple operations.View aliases
tf.guarantee_const,"tf.guarantee_const(
    input, name=None
)
",Promise to the TF runtime that the input tensor is a constant. (deprecated)View aliases
tf.hessians,"tf.hessians(
    ys,
    xs,
    gate_gradients=False,
    aggregation_method=None,
    name='hessians'
)
",Constructs the Hessian of sum of ys with respect to x in xs.
tf.histogram_fixed_width,"tf.histogram_fixed_width(
    values,
    value_range,
    nbins=100,
    dtype=tf.dtypes.int32,
    name=None
)
",Return histogram of values.View aliases
tf.histogram_fixed_width_bins,"tf.histogram_fixed_width_bins(
    values,
    value_range,
    nbins=100,
    dtype=tf.dtypes.int32,
    name=None
)
",Bins the given values for use in a histogram.View aliases
tf.identity,"tf.identity(
    input, name=None
)
",Return a Tensor with the same shape and contents as input.View aliases
tf.identity_n,"tf.identity_n(
    input, name=None
)
",Returns a list of tensors with the same shapes and contents as the inputView aliases
tf.image.adjust_brightness,"tf.image.adjust_brightness(
    image, delta
)
",Adjust the brightness of RGB or Grayscale images.View aliases
tf.image.adjust_contrast,"tf.image.adjust_contrast(
    images, contrast_factor
)
",Adjust contrast of RGB or grayscale images.View aliases
tf.image.adjust_gamma,"tf.image.adjust_gamma(
    image, gamma=1, gain=1
)
",Performs Gamma Correction.View aliases
tf.image.adjust_hue,"tf.image.adjust_hue(
    image, delta, name=None
)
",Adjust hue of RGB images.View aliases
tf.image.adjust_jpeg_quality,"tf.image.adjust_jpeg_quality(
    image, jpeg_quality, name=None
)
",Adjust jpeg encoding quality of an image.View aliases
tf.image.adjust_saturation,"tf.image.adjust_saturation(
    image, saturation_factor, name=None
)
",Adjust saturation of RGB images.View aliases
tf.image.central_crop,"tf.image.central_crop(
    image, central_fraction
)
",Crop the central region of the image(s).View aliases
tf.image.combined_non_max_suppression,"tf.image.combined_non_max_suppression(
    boxes,
    scores,
    max_output_size_per_class,
    max_total_size,
    iou_threshold=0.5,
    score_threshold=float('-inf'),
    pad_per_class=False,
    clip_boxes=True,
    name=None
)
",Greedily selects a subset of bounding boxes in descending order of score.View aliases
tf.image.convert_image_dtype,"tf.image.convert_image_dtype(
    image, dtype, saturate=False, name=None
)
","Convert image to dtype, scaling its values if needed.View aliases"
tf.image.crop_and_resize,"tf.image.crop_and_resize(
    image,
    boxes,
    box_indices,
    crop_size,
    method='bilinear',
    extrapolation_value=0.0,
    name=None
)
",Extracts crops from the input image tensor and resizes them.
tf.image.crop_to_bounding_box,"tf.image.crop_to_bounding_box(
    image, offset_height, offset_width, target_height, target_width
)
",Crops an image to a specified bounding box.View aliases
tf.io.decode_and_crop_jpeg,"tf.io.decode_and_crop_jpeg(
    contents,
    crop_window,
    channels=0,
    ratio=1,
    fancy_upscaling=True,
    try_recover_truncated=False,
    acceptable_fraction=1,
    dct_method='',
    name=None
)
",Decode and Crop a JPEG-encoded image to a uint8 tensor.View aliases
tf.io.decode_bmp,"tf.io.decode_bmp(
    contents, channels=0, name=None
)
",Decode the first frame of a BMP-encoded image to a uint8 tensor.View aliases
tf.io.decode_gif,"tf.io.decode_gif(
    contents, name=None
)
",Decode the frame(s) of a GIF-encoded image to a uint8 tensor.View aliases
tf.io.decode_image,"tf.io.decode_image(
    contents,
    channels=None,
    dtype=tf.dtypes.uint8,
    name=None,
    expand_animations=True
)
","Function for decode_bmp, decode_gif, decode_jpeg, and decode_png.View aliases"
tf.io.decode_jpeg,"tf.io.decode_jpeg(
    contents,
    channels=0,
    ratio=1,
    fancy_upscaling=True,
    try_recover_truncated=False,
    acceptable_fraction=1,
    dct_method='',
    name=None
)
",Decode a JPEG-encoded image to a uint8 tensor.View aliases
tf.io.decode_png,"tf.io.decode_png(
    contents,
    channels=0,
    dtype=tf.dtypes.uint8,
    name=None
)
",Decode a PNG-encoded image to a uint8 or uint16 tensor.View aliases
tf.image.draw_bounding_boxes,"tf.image.draw_bounding_boxes(
    images, boxes, colors, name=None
)
",Draw bounding boxes on a batch of images.
tf.io.encode_jpeg,"tf.io.encode_jpeg(
    image,
    format='',
    quality=95,
    progressive=False,
    optimize_size=False,
    chroma_downsampling=True,
    density_unit='in',
    x_density=300,
    y_density=300,
    xmp_metadata='',
    name=None
)
",JPEG-encode an image.View aliases
tf.io.encode_png,"tf.io.encode_png(
    image, compression=-1, name=None
)
",PNG-encode an image.View aliases
tf.image.extract_glimpse,"tf.image.extract_glimpse(
    input,
    size,
    offsets,
    centered=True,
    normalized=True,
    noise='uniform',
    name=None
)
",Extracts a glimpse from the input tensor.
tf.io.extract_jpeg_shape,"tf.io.extract_jpeg_shape(
    contents,
    output_type=tf.dtypes.int32,
    name=None
)
",Extract the shape information of a JPEG-encoded image.View aliases
tf.image.extract_patches,"tf.image.extract_patches(
    images, sizes, strides, rates, padding, name=None
)
",Extract patches from images.View aliases
tf.image.flip_left_right,"tf.image.flip_left_right(
    image
)
",Flip an image horizontally (left to right).View aliases
tf.image.flip_up_down,"tf.image.flip_up_down(
    image
)
",Flip an image vertically (upside down).View aliases
tf.image.generate_bounding_box_proposals,"tf.image.generate_bounding_box_proposals(
    scores,
    bbox_deltas,
    image_info,
    anchors,
    nms_threshold=0.7,
    pre_nms_topn=6000,
    min_size=16,
    post_nms_topn=300,
    name=None
)
",Generate bounding box proposals from encoded bounding boxes.View aliases
tf.image.grayscale_to_rgb,"tf.image.grayscale_to_rgb(
    images, name=None
)
",Converts one or more images from Grayscale to RGB.View aliases
tf.image.hsv_to_rgb,"tf.image.hsv_to_rgb(
    images, name=None
)
",Convert one or more images from HSV to RGB.View aliases
tf.image.image_gradients,"tf.image.image_gradients(
    image
)
","Returns image gradients (dy, dx) for each color channel.View aliases"
tf.io.is_jpeg,"tf.io.is_jpeg(
    contents, name=None
)
",Convenience function to check if the 'contents' encodes a JPEG image.View aliases
tf.image.non_max_suppression,"tf.image.non_max_suppression(
    boxes,
    scores,
    max_output_size,
    iou_threshold=0.5,
    score_threshold=float('-inf'),
    name=None
)
",Greedily selects a subset of bounding boxes in descending order of score.View aliases
tf.image.non_max_suppression_overlaps,"tf.image.non_max_suppression_overlaps(
    overlaps,
    scores,
    max_output_size,
    overlap_threshold=0.5,
    score_threshold=float('-inf'),
    name=None
)
",Greedily selects a subset of bounding boxes in descending order of score.View aliases
tf.image.non_max_suppression_padded,"tf.image.non_max_suppression_padded(
    boxes,
    scores,
    max_output_size,
    iou_threshold=0.5,
    score_threshold=float('-inf'),
    pad_to_max_output_size=False,
    name=None,
    sorted_input=False,
    canonicalized_coordinates=False,
    tile_size=512
)
",Greedily selects a subset of bounding boxes in descending order of score.View aliases
tf.image.non_max_suppression_with_scores,"tf.image.non_max_suppression_with_scores(
    boxes,
    scores,
    max_output_size,
    iou_threshold=0.5,
    score_threshold=float('-inf'),
    soft_nms_sigma=0.0,
    name=None
)
",Greedily selects a subset of bounding boxes in descending order of score.View aliases
tf.image.pad_to_bounding_box,"tf.image.pad_to_bounding_box(
    image, offset_height, offset_width, target_height, target_width
)
",Pad image with zeros to the specified height and width.View aliases
tf.image.per_image_standardization,"tf.image.per_image_standardization(
    image
)
",Linearly scales each image in image to have mean 0 and variance 1.View aliases
tf.image.psnr,"tf.image.psnr(
    a, b, max_val, name=None
)
",Returns the Peak Signal-to-Noise Ratio between a and b.View aliases
tf.image.random_brightness,"tf.image.random_brightness(
    image, max_delta, seed=None
)
",Adjust the brightness of images by a random factor.View aliases
tf.image.random_contrast,"tf.image.random_contrast(
    image, lower, upper, seed=None
)
",Adjust the contrast of an image or images by a random factor.View aliases
tf.image.random_crop,"tf.image.random_crop(
    value, size, seed=None, name=None
)
",Randomly crops a tensor to a given size.View aliases
tf.image.random_flip_left_right,"tf.image.random_flip_left_right(
    image, seed=None
)
",Randomly flip an image horizontally (left to right).View aliases
tf.image.random_flip_up_down,"tf.image.random_flip_up_down(
    image, seed=None
)
",Randomly flips an image vertically (upside down).View aliases
tf.image.random_hue,"tf.image.random_hue(
    image, max_delta, seed=None
)
",Adjust the hue of RGB images by a random factor.View aliases
tf.image.random_jpeg_quality,"tf.image.random_jpeg_quality(
    image, min_jpeg_quality, max_jpeg_quality, seed=None
)
",Randomly changes jpeg encoding quality for inducing jpeg noise.View aliases
tf.image.random_saturation,"tf.image.random_saturation(
    image, lower, upper, seed=None
)
",Adjust the saturation of RGB images by a random factor.View aliases
tf.image.resize,"tf.image.resize(
    images,
    size,
    method=ResizeMethod.BILINEAR,
    preserve_aspect_ratio=False,
    antialias=False,
    name=None
)
",Resize images to size using the specified method.
tf.image.resize_with_crop_or_pad,"tf.image.resize_with_crop_or_pad(
    image, target_height, target_width
)
",Crops and/or pads an image to a target width and height.View aliases
tf.image.resize_with_pad,"tf.image.resize_with_pad(
    image,
    target_height,
    target_width,
    method=ResizeMethod.BILINEAR,
    antialias=False
)
",Resizes and pads an image to a target width and height.
tf.image.rgb_to_grayscale,"tf.image.rgb_to_grayscale(
    images, name=None
)
",Converts one or more images from RGB to Grayscale.View aliases
tf.image.rgb_to_hsv,"tf.image.rgb_to_hsv(
    images, name=None
)
",Converts one or more images from RGB to HSV.View aliases
tf.image.rgb_to_yiq,"tf.image.rgb_to_yiq(
    images
)
",Converts one or more images from RGB to YIQ.View aliases
tf.image.rgb_to_yuv,"tf.image.rgb_to_yuv(
    images
)
",Converts one or more images from RGB to YUV.View aliases
tf.image.rot90,"tf.image.rot90(
    image, k=1, name=None
)
",Rotate image(s) counter-clockwise by 90 degrees.View aliases
tf.image.sample_distorted_bounding_box,"tf.image.sample_distorted_bounding_box(
    image_size,
    bounding_boxes,
    seed=0,
    min_object_covered=0.1,
    aspect_ratio_range=None,
    area_range=None,
    max_attempts=None,
    use_image_if_no_bounding_boxes=None,
    name=None
)
",Generate a single randomly distorted bounding box for an image.
tf.image.sobel_edges,"tf.image.sobel_edges(
    image
)
",Returns a tensor holding Sobel edge maps.View aliases
tf.image.ssim,"tf.image.ssim(
    img1, img2, max_val, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03
)
",Computes SSIM index between img1 and img2.View aliases
tf.image.ssim_multiscale,"tf.image.ssim_multiscale(
    img1,
    img2,
    max_val,
    power_factors=_MSSSIM_WEIGHTS,
    filter_size=11,
    filter_sigma=1.5,
    k1=0.01,
    k2=0.03
)
",Computes the MS-SSIM between img1 and img2.View aliases
tf.image.stateless_random_brightness,"tf.image.stateless_random_brightness(
    image, max_delta, seed
)
",Adjust the brightness of images by a random factor deterministically.
tf.image.stateless_random_contrast,"tf.image.stateless_random_contrast(
    image, lower, upper, seed
)
",Adjust the contrast of images by a random factor deterministically.
tf.image.stateless_random_crop,"tf.image.stateless_random_crop(
    value, size, seed, name=None
)
",Randomly crops a tensor to a given size in a deterministic manner.
tf.image.stateless_random_flip_left_right,"tf.image.stateless_random_flip_left_right(
    image, seed
)
",Randomly flip an image horizontally (left to right) deterministically.
tf.image.stateless_random_flip_up_down,"tf.image.stateless_random_flip_up_down(
    image, seed
)
",Randomly flip an image vertically (upside down) deterministically.
tf.image.stateless_random_hue,"tf.image.stateless_random_hue(
    image, max_delta, seed
)
",Adjust the hue of RGB images by a random factor deterministically.
tf.image.stateless_random_jpeg_quality,"tf.image.stateless_random_jpeg_quality(
    image, min_jpeg_quality, max_jpeg_quality, seed
)
",Deterministically radomize jpeg encoding quality for inducing jpeg noise.
tf.image.stateless_random_saturation,"tf.image.stateless_random_saturation(
    image, lower, upper, seed=None
)
",Adjust the saturation of RGB images by a random factor deterministically.
tf.image.stateless_sample_distorted_bounding_box,"tf.image.stateless_sample_distorted_bounding_box(
    image_size,
    bounding_boxes,
    seed,
    min_object_covered=0.1,
    aspect_ratio_range=None,
    area_range=None,
    max_attempts=None,
    use_image_if_no_bounding_boxes=None,
    name=None
)
",Generate a randomly distorted bounding box for an image deterministically.
tf.image.total_variation,"tf.image.total_variation(
    images, name=None
)
",Calculate and return the total variation for one or more images.View aliases
tf.image.transpose,"tf.image.transpose(
    image, name=None
)
",Transpose image(s) by swapping the height and width dimension.View aliases
tf.image.yiq_to_rgb,"tf.image.yiq_to_rgb(
    images
)
",Converts one or more images from YIQ to RGB.View aliases
tf.image.yuv_to_rgb,"tf.image.yuv_to_rgb(
    images
)
",Converts one or more images from YUV to RGB.View aliases
tf.graph_util.import_graph_def,"tf.graph_util.import_graph_def(
    graph_def,
    input_map=None,
    return_elements=None,
    name=None,
    op_dict=None,
    producer_op_list=None
)
",Imports the graph from graph_def into the current default Graph. (deprecated arguments)View aliases
tf.keras.initializers.Constant,"tf.keras.initializers.Constant(
    value=0
)
",Initializer that generates tensors with constant values.Inherits From: InitializerView aliases
tf.keras.initializers.GlorotNormal,"tf.keras.initializers.GlorotNormal(
    seed=None
)
","The Glorot normal initializer, also called Xavier normal initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.GlorotUniform,"tf.keras.initializers.GlorotUniform(
    seed=None
)
","The Glorot uniform initializer, also called Xavier uniform initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.HeNormal,"tf.keras.initializers.HeNormal(
    seed=None
)
","He normal initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.HeUniform,"tf.keras.initializers.HeUniform(
    seed=None
)
","He uniform variance scaling initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.Identity,"tf.keras.initializers.Identity(
    gain=1.0
)
",Initializer that generates the identity matrix.Inherits From: InitializerView aliases
tf.keras.initializers.LecunNormal,"tf.keras.initializers.LecunNormal(
    seed=None
)
","Lecun normal initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.LecunUniform,"tf.keras.initializers.LecunUniform(
    seed=None
)
","Lecun uniform initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.Orthogonal,"tf.keras.initializers.Orthogonal(
    gain=1.0, seed=None
)
",Initializer that generates an orthogonal matrix.Inherits From: InitializerView aliases
tf.keras.initializers.RandomNormal,"tf.keras.initializers.RandomNormal(
    mean=0.0, stddev=0.05, seed=None
)
",Initializer that generates tensors with a normal distribution.Inherits From: InitializerView aliases
tf.keras.initializers.RandomUniform,"tf.keras.initializers.RandomUniform(
    minval=-0.05, maxval=0.05, seed=None
)
",Initializer that generates tensors with a uniform distribution.Inherits From: InitializerView aliases
tf.keras.initializers.TruncatedNormal,"tf.keras.initializers.TruncatedNormal(
    mean=0.0, stddev=0.05, seed=None
)
",Initializer that generates a truncated normal distribution.Inherits From: InitializerView aliases
tf.keras.initializers.VarianceScaling,"tf.keras.initializers.VarianceScaling(
    scale=1.0,
    mode='fan_in',
    distribution='truncated_normal',
    seed=None
)
",Initializer capable of adapting its scale to the shape of weights tensors.Inherits From: InitializerView aliases
tf.keras.initializers.Constant,"tf.keras.initializers.Constant(
    value=0
)
",Initializer that generates tensors with constant values.Inherits From: InitializerView aliases
tf.keras.initializers.deserialize,"tf.keras.initializers.deserialize(
    config, custom_objects=None
)
",Return an Initializer object from its config.View aliases
tf.keras.initializers.get,"tf.keras.initializers.get(
    identifier
)
",Retrieve a Keras initializer by the identifier.View aliases
tf.keras.initializers.GlorotNormal,"tf.keras.initializers.GlorotNormal(
    seed=None
)
","The Glorot normal initializer, also called Xavier normal initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.GlorotUniform,"tf.keras.initializers.GlorotUniform(
    seed=None
)
","The Glorot uniform initializer, also called Xavier uniform initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.HeNormal,"tf.keras.initializers.HeNormal(
    seed=None
)
","He normal initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.HeUniform,"tf.keras.initializers.HeUniform(
    seed=None
)
","He uniform variance scaling initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.Identity,"tf.keras.initializers.Identity(
    gain=1.0
)
",Initializer that generates the identity matrix.Inherits From: InitializerView aliases
tf.keras.initializers.LecunNormal,"tf.keras.initializers.LecunNormal(
    seed=None
)
","Lecun normal initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.LecunUniform,"tf.keras.initializers.LecunUniform(
    seed=None
)
","Lecun uniform initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.Orthogonal,"tf.keras.initializers.Orthogonal(
    gain=1.0, seed=None
)
",Initializer that generates an orthogonal matrix.Inherits From: InitializerView aliases
tf.keras.initializers.RandomNormal,"tf.keras.initializers.RandomNormal(
    mean=0.0, stddev=0.05, seed=None
)
",Initializer that generates tensors with a normal distribution.Inherits From: InitializerView aliases
tf.keras.initializers.RandomUniform,"tf.keras.initializers.RandomUniform(
    minval=-0.05, maxval=0.05, seed=None
)
",Initializer that generates tensors with a uniform distribution.Inherits From: InitializerView aliases
tf.keras.initializers.serialize,"tf.keras.initializers.serialize(
    initializer
)
",View aliases
tf.keras.initializers.TruncatedNormal,"tf.keras.initializers.TruncatedNormal(
    mean=0.0, stddev=0.05, seed=None
)
",Initializer that generates a truncated normal distribution.Inherits From: InitializerView aliases
tf.keras.initializers.VarianceScaling,"tf.keras.initializers.VarianceScaling(
    scale=1.0,
    mode='fan_in',
    distribution='truncated_normal',
    seed=None
)
",Initializer capable of adapting its scale to the shape of weights tensors.Inherits From: InitializerView aliases
tf.io.FixedLenFeature,"tf.io.FixedLenFeature(
    shape, dtype, default_value=None
)
",Configuration for parsing a fixed-length input feature.View aliases
tf.io.FixedLenSequenceFeature,"tf.io.FixedLenSequenceFeature(
    shape, dtype, allow_missing=False, default_value=None
)
",Configuration for parsing a variable-length input feature into a Tensor.View aliases
tf.io.RaggedFeature,"tf.io.RaggedFeature(
    dtype,
    value_key=None,
    partitions=(),
    row_splits_dtype=tf.dtypes.int32,
    validate=False
)
",Configuration for passing a RaggedTensor input feature.View aliases
tf.io.RaggedFeature.RowLengths,"tf.io.RaggedFeature.RowLengths(
    key
)
","RowLengths(key,)View aliases"
tf.io.RaggedFeature.RowLimits,"tf.io.RaggedFeature.RowLimits(
    key
)
","RowLimits(key,)View aliases"
tf.io.RaggedFeature.RowSplits,"tf.io.RaggedFeature.RowSplits(
    key
)
","RowSplits(key,)View aliases"
tf.io.RaggedFeature.RowStarts,"tf.io.RaggedFeature.RowStarts(
    key
)
","RowStarts(key,)View aliases"
tf.io.RaggedFeature.UniformRowLength,"tf.io.RaggedFeature.UniformRowLength(
    length
)
","UniformRowLength(length,)View aliases"
tf.io.RaggedFeature.ValueRowIds,"tf.io.RaggedFeature.ValueRowIds(
    key
)
","ValueRowIds(key,)View aliases"
tf.io.SparseFeature,"tf.io.SparseFeature(
    index_key, value_key, dtype, size, already_sorted=False
)
",Configuration for parsing a sparse input feature from an Example.View aliases
tf.io.TFRecordOptions,"tf.io.TFRecordOptions(
    compression_type=None,
    flush_mode=None,
    input_buffer_size=None,
    output_buffer_size=None,
    window_bits=None,
    compression_level=None,
    compression_method=None,
    mem_level=None,
    compression_strategy=None
)
",Options used for manipulating TFRecord files.View aliases
tf.io.TFRecordWriter,"tf.io.TFRecordWriter(
    path, options=None
)
",A class to write records to a TFRecords file.View aliases
tf.io.VarLenFeature,"tf.io.VarLenFeature(
    dtype
)
",Configuration for parsing a variable-length input feature.View aliases
tf.io.decode_and_crop_jpeg,"tf.io.decode_and_crop_jpeg(
    contents,
    crop_window,
    channels=0,
    ratio=1,
    fancy_upscaling=True,
    try_recover_truncated=False,
    acceptable_fraction=1,
    dct_method='',
    name=None
)
",Decode and Crop a JPEG-encoded image to a uint8 tensor.View aliases
tf.io.decode_base64,"tf.io.decode_base64(
    input, name=None
)
",Decode web-safe base64-encoded strings.View aliases
tf.io.decode_bmp,"tf.io.decode_bmp(
    contents, channels=0, name=None
)
",Decode the first frame of a BMP-encoded image to a uint8 tensor.View aliases
tf.io.decode_compressed,"tf.io.decode_compressed(
    bytes, compression_type='', name=None
)
",Decompress strings.View aliases
tf.io.decode_csv,"tf.io.decode_csv(
    records,
    record_defaults,
    field_delim=',',
    use_quote_delim=True,
    na_value='',
    select_cols=None,
    name=None
)
",Convert CSV records to tensors. Each column maps to one tensor.
tf.io.decode_gif,"tf.io.decode_gif(
    contents, name=None
)
",Decode the frame(s) of a GIF-encoded image to a uint8 tensor.View aliases
tf.io.decode_image,"tf.io.decode_image(
    contents,
    channels=None,
    dtype=tf.dtypes.uint8,
    name=None,
    expand_animations=True
)
","Function for decode_bmp, decode_gif, decode_jpeg, and decode_png.View aliases"
tf.io.decode_jpeg,"tf.io.decode_jpeg(
    contents,
    channels=0,
    ratio=1,
    fancy_upscaling=True,
    try_recover_truncated=False,
    acceptable_fraction=1,
    dct_method='',
    name=None
)
",Decode a JPEG-encoded image to a uint8 tensor.View aliases
tf.io.decode_json_example,"tf.io.decode_json_example(
    json_examples, name=None
)
",Convert JSON-encoded Example records to binary protocol buffer strings.View aliases
tf.io.decode_json_example,tf.io.decode_json_example([,"Convert JSON-encoded Example records to binary protocol buffer strings.View aliasestf.io.decode_json_example(    json_examples, name=None)Note: This is This op converts JSON-serialized tf.train.Example (maybe created withjson_format.MessageToJson, following thestandard JSON mapping)to a binary-serialized tf.train.Example (equivalent toExample.SerializeToString()) suitable for conversion to tensors withtf.io.parse_example.Here is a tf.train.Example proto:example = tf.train.Example(  features=tf.train.Features(      feature={          ""a"": tf.train.Feature(              int64_list=tf.train.Int64List(                  value=[1, 1, 3]))}))Here it is converted to JSON:from google.protobuf import json_formatexample_json = json_format.MessageToJson(example)print(example_json){  ""features"": {    ""feature"": {      ""a"": {        ""int64List"": {          ""value"": [            ""1"",            ""1"",            ""3""          ]        }      }    }  }}This op converts the above json string to a binary proto:example_binary = tf.io.decode_json_example(example_json)example_binary.numpy()b'\n\x0f\n\r\n\x01a\x12\x08\x1a\x06\x08\x01\x08\x01\x08\x03'The OP works on string tensors of andy shape:"
tf.io.parse_example,tf.io.parse_example(,"Convert JSON-encoded Example records to binary protocol buffer strings.View aliasestf.io.decode_json_example(    json_examples, name=None)Note: This is This op converts JSON-serialized tf.train.Example (maybe created withjson_format.MessageToJson, following thestandard JSON mapping)to a binary-serialized tf.train.Example (equivalent toExample.SerializeToString()) suitable for conversion to tensors withtf.io.parse_example.Here is a tf.train.Example proto:example = tf.train.Example(  features=tf.train.Features(      feature={          ""a"": tf.train.Feature(              int64_list=tf.train.Int64List(                  value=[1, 1, 3]))}))Here it is converted to JSON:from google.protobuf import json_formatexample_json = json_format.MessageToJson(example)print(example_json){  ""features"": {    ""feature"": {      ""a"": {        ""int64List"": {          ""value"": [            ""1"",            ""1"",            ""3""          ]        }      }    }  }}This op converts the above json string to a binary proto:example_binary = tf.io.decode_json_example(example_json)example_binary.numpy()b'\n\x0f\n\r\n\x01a\x12\x08\x1a\x06\x08\x01\x08\x01\x08\x03'The OP works on string tensors of andy shape:tf.io.decode_json_example([    [example_json, example_json],    [example_json, example_json]]).shape.as_list()[2, 2]This resulting binary-string is equivalent to Example.SerializeToString(),and can be converted to Tensors using tf.io.parse_example and relatedfunctions:"
tf.io.decode_png,"tf.io.decode_png(
    contents,
    channels=0,
    dtype=tf.dtypes.uint8,
    name=None
)
",Decode a PNG-encoded image to a uint8 or uint16 tensor.View aliases
tf.io.decode_proto,"tf.io.decode_proto(
    bytes,
    message_type,
    field_names,
    output_types,
    descriptor_source='local://',
    message_format='binary',
    sanitize=False,
    name=None
)
",The op extracts fields from a serialized protocol buffers message into tensors.View aliases
tf.io.decode_raw,"tf.io.decode_raw(
    input_bytes, out_type, little_endian=True, fixed_length=None, name=None
)
",Convert raw bytes from input tensor into numeric tensors.
tf.io.decode_raw,"tf.io.decode_raw(tf.constant([""1"",""2""]), tf.uint8).shape","Convert raw bytes from input tensor into numeric tensors.tf.io.decode_raw(    input_bytes, out_type, little_endian=True, fixed_length=None, name=None)Used in the notebooksEvery component of the input tensor is interpreted as a sequence of bytes.These bytes are then decoded as numbers in the format specified by out_type.tf.io.decode_raw(tf.constant(""1""), tf.uint8)<tf.Tensor: shape=(1,), dtype=uint8, numpy=array([49], dtype=uint8)>tf.io.decode_raw(tf.constant(""1,2""), tf.uint8)<tf.Tensor: shape=(3,), dtype=uint8, numpy=array([49, 44, 50], dtype=uint8)>Note that the rank of the output tensor is always one more than the input one:"
tf.io.deserialize_many_sparse,"tf.io.deserialize_many_sparse(
    serialized_sparse, dtype, rank=None, name=None
)
",Deserialize and concatenate SparseTensors from a serialized minibatch.View aliases
tf.io.encode_base64,"tf.io.encode_base64(
    input, pad=False, name=None
)
",Encode strings into web-safe base64 format.View aliases
tf.io.encode_jpeg,"tf.io.encode_jpeg(
    image,
    format='',
    quality=95,
    progressive=False,
    optimize_size=False,
    chroma_downsampling=True,
    density_unit='in',
    x_density=300,
    y_density=300,
    xmp_metadata='',
    name=None
)
",JPEG-encode an image.View aliases
tf.io.encode_png,"tf.io.encode_png(
    image, compression=-1, name=None
)
",PNG-encode an image.View aliases
tf.io.encode_proto,"tf.io.encode_proto(
    sizes,
    values,
    field_names,
    message_type,
    descriptor_source='local://',
    name=None
)
",The op serializes protobuf messages provided in the input tensors.View aliases
tf.io.extract_jpeg_shape,"tf.io.extract_jpeg_shape(
    contents,
    output_type=tf.dtypes.int32,
    name=None
)
",Extract the shape information of a JPEG-encoded image.View aliases
tf.io.gfile.GFile,"tf.io.gfile.GFile(
    name, mode='r'
)
",File I/O wrappers without thread locking.View aliases
tf.io.gfile.copy,"tf.io.gfile.copy(
    src, dst, overwrite=False
)
",Copies data from src to dst.View aliases
tf.io.gfile.exists,"tf.io.gfile.exists(
    path
)
",Determines whether a path exists or not.View aliases
tf.io.gfile.glob,"tf.io.gfile.glob(
    pattern
)
",Returns a list of files that match the given pattern(s).View aliases
tf.io.gfile.isdir,"tf.io.gfile.isdir(
    path
)
",Returns whether the path is a directory or not.View aliases
tf.io.gfile.join,"tf.io.gfile.join(
    path, *paths
)
",Join one or more path components intelligently.View aliases
tf.io.gfile.listdir,"tf.io.gfile.listdir(
    path
)
",Returns a list of entries contained within a directory.View aliases
tf.io.gfile.makedirs,"tf.io.gfile.makedirs(
    path
)
",Creates a directory and all parent/intermediate directories.View aliases
tf.io.gfile.mkdir,"tf.io.gfile.mkdir(
    path
)
",Creates a directory with the name given by path.View aliases
tf.io.gfile.remove,"tf.io.gfile.remove(
    path
)
",Deletes the path located at 'path'.View aliases
tf.io.gfile.rename,"tf.io.gfile.rename(
    src, dst, overwrite=False
)
",Rename or move a file / directory.View aliases
tf.io.gfile.rmtree,"tf.io.gfile.rmtree(
    path
)
",Deletes everything under path recursively.View aliases
tf.io.gfile.stat,"tf.io.gfile.stat(
    path
)
",Returns file statistics for a given path.View aliases
tf.io.gfile.walk,"tf.io.gfile.walk(
    top, topdown=True, onerror=None
)
",Recursive directory tree generator for directories.View aliases
tf.io.is_jpeg,"tf.io.is_jpeg(
    contents, name=None
)
",Convenience function to check if the 'contents' encodes a JPEG image.View aliases
tf.io.match_filenames_once,"tf.io.match_filenames_once(
    pattern, name=None
)
","Save the list of files matching pattern, so it is only computed once.View aliases"
tf.io.matching_files,"tf.io.matching_files(
    pattern, name=None
)
",Returns the set of files matching one or more glob patterns.View aliases
tf.io.parse_example,"tf.io.parse_example(
    serialized, features, example_names=None, name=None
)
",Parses Example protos into a dict of tensors.
tf.io.parse_sequence_example,"tf.io.parse_sequence_example(
    serialized,
    context_features=None,
    sequence_features=None,
    example_names=None,
    name=None
)
",Parses a batch of SequenceExample protos.View aliases
tf.io.parse_single_example,"tf.io.parse_single_example(
    serialized, features, example_names=None, name=None
)
",Parses a single Example proto.
tf.io.parse_single_sequence_example,"tf.io.parse_single_sequence_example(
    serialized,
    context_features=None,
    sequence_features=None,
    example_name=None,
    name=None
)
",Parses a single SequenceExample proto.View aliases
tf.io.parse_tensor,"tf.io.parse_tensor(
    serialized, out_type, name=None
)
",Transforms a serialized tensorflow.TensorProto proto into a Tensor.View aliases
tf.io.read_file,"tf.io.read_file(
    filename, name=None
)
",Reads the contents of file.View aliases
tf.io.serialize_many_sparse,"tf.io.serialize_many_sparse(
    sp_input,
    out_type=tf.dtypes.string,
    name=None
)
","Serialize N-minibatch SparseTensor into an [N, 3] Tensor."
tf.io.serialize_sparse,"tf.io.serialize_sparse(
    sp_input,
    out_type=tf.dtypes.string,
    name=None
)
",Serialize a SparseTensor into a 3-vector (1-D Tensor) object.
tf.io.serialize_tensor,"tf.io.serialize_tensor(
    tensor, name=None
)
",Transforms a Tensor into a serialized TensorProto proto.View aliases
tf.io.write_file,"tf.io.write_file(
    filename, contents, name=None
)
",Writes contents to the file at input filename.View aliases
tf.io.write_graph,"tf.io.write_graph(
    graph_or_graph_def, logdir, name, as_text=True
)
",Writes a graph proto to a file.View aliases
tf.is_tensor,"tf.is_tensor(
    x
)
",Checks whether x is a TF-native type that can be passed to many TF ops.View aliases
tf.keras.Input,"tf.keras.Input(
    shape=None,
    batch_size=None,
    name=None,
    dtype=None,
    sparse=None,
    tensor=None,
    ragged=None,
    type_spec=None,
    **kwargs
)
",Input() is used to instantiate a Keras tensor.View aliases
tf.keras.Model,"tf.keras.Model(
    *args, **kwargs
)
","Model groups layers into an object with training and inference features.Inherits From: Layer, ModuleView aliases"
tf.keras.Sequential,"tf.keras.Sequential(
    layers=None, name=None
)
","Sequential groups a linear stack of layers into a tf.keras.Model.Inherits From: Model, Layer, ModuleView aliases"
tf.keras.activations.deserialize,"tf.keras.activations.deserialize(
    name, custom_objects=None
)
",Returns activation function given a string identifier.View aliases
tf.keras.activations.elu,"tf.keras.activations.elu(
    x, alpha=1.0
)
",Exponential Linear Unit.View aliases
tf.keras.activations.exponential,"tf.keras.activations.exponential(
    x
)
",Exponential activation function.View aliases
tf.keras.activations.gelu,"tf.keras.activations.gelu(
    x, approximate=False
)
",Applies the Gaussian error linear unit (GELU) activation function.
tf.keras.activations.get,"tf.keras.activations.get(
    identifier
)
",Returns function.View aliases
tf.keras.activations.hard_sigmoid,"tf.keras.activations.hard_sigmoid(
    x
)
",Hard sigmoid activation function.View aliases
tf.keras.activations.linear,"tf.keras.activations.linear(
    x
)
",Linear activation function (pass-through).View aliases
tf.keras.activations.relu,"tf.keras.activations.relu(
    x, alpha=0.0, max_value=None, threshold=0.0
)
",Applies the rectified linear unit activation function.View aliases
tf.keras.activations.selu,"tf.keras.activations.selu(
    x
)
",Scaled Exponential Linear Unit (SELU).View aliases
tf.keras.activations.serialize,"tf.keras.activations.serialize(
    activation
)
",Returns the string identifier of an activation function.View aliases
tf.keras.activations.sigmoid,"tf.keras.activations.sigmoid(
    x
)
","Sigmoid activation function, sigmoid(x) = 1 / (1 + exp(-x)).View aliases"
tf.keras.activations.softmax,"tf.keras.activations.softmax(
    x, axis=-1
)
",Softmax converts a vector of values to a probability distribution.View aliases
tf.keras.activations.softplus,"tf.keras.activations.softplus(
    x
)
","Softplus activation function, softplus(x) = log(exp(x) + 1).View aliases"
tf.keras.activations.softsign,"tf.keras.activations.softsign(
    x
)
","Softsign activation function, softsign(x) = x / (abs(x) + 1).View aliases"
tf.keras.activations.swish,"tf.keras.activations.swish(
    x
)
","Swish activation function, swish(x) = x * sigmoid(x).View aliases"
tf.keras.activations.tanh,"tf.keras.activations.tanh(
    x
)
",Hyperbolic tangent activation function.View aliases
tf.keras.applications.convnext.ConvNeXtBase,"tf.keras.applications.convnext.ConvNeXtBase(
    model_name='convnext_base',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtBase architecture.View aliases
tf.keras.applications.convnext.ConvNeXtLarge,"tf.keras.applications.convnext.ConvNeXtLarge(
    model_name='convnext_large',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtLarge architecture.View aliases
tf.keras.applications.convnext.ConvNeXtSmall,"tf.keras.applications.convnext.ConvNeXtSmall(
    model_name='convnext_small',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtSmall architecture.View aliases
tf.keras.applications.convnext.ConvNeXtTiny,"tf.keras.applications.convnext.ConvNeXtTiny(
    model_name='convnext_tiny',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtTiny architecture.View aliases
tf.keras.applications.convnext.ConvNeXtXLarge,"tf.keras.applications.convnext.ConvNeXtXLarge(
    model_name='convnext_xlarge',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtXLarge architecture.View aliases
tf.keras.applications.densenet.DenseNet121,"tf.keras.applications.densenet.DenseNet121(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Densenet121 architecture.View aliases
tf.keras.applications.densenet.DenseNet169,"tf.keras.applications.densenet.DenseNet169(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Densenet169 architecture.View aliases
tf.keras.applications.densenet.DenseNet201,"tf.keras.applications.densenet.DenseNet201(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Densenet201 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB0,"tf.keras.applications.efficientnet.EfficientNetB0(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB0 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB1,"tf.keras.applications.efficientnet.EfficientNetB1(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB1 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB2,"tf.keras.applications.efficientnet.EfficientNetB2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB2 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB3,"tf.keras.applications.efficientnet.EfficientNetB3(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB3 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB4,"tf.keras.applications.efficientnet.EfficientNetB4(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB4 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB5,"tf.keras.applications.efficientnet.EfficientNetB5(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB5 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB6,"tf.keras.applications.efficientnet.EfficientNetB6(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB6 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB7,"tf.keras.applications.efficientnet.EfficientNetB7(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB7 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B0,"tf.keras.applications.efficientnet_v2.EfficientNetV2B0(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B0 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B1,"tf.keras.applications.efficientnet_v2.EfficientNetV2B1(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B1 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B2,"tf.keras.applications.efficientnet_v2.EfficientNetV2B2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B2 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B3,"tf.keras.applications.efficientnet_v2.EfficientNetV2B3(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B3 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2L,"tf.keras.applications.efficientnet_v2.EfficientNetV2L(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2L architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2M,"tf.keras.applications.efficientnet_v2.EfficientNetV2M(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2M architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2S,"tf.keras.applications.efficientnet_v2.EfficientNetV2S(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2S architecture.View aliases
tf.keras.applications.inception_resnet_v2.InceptionResNetV2,"tf.keras.applications.inception_resnet_v2.InceptionResNetV2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the Inception-ResNet v2 architecture.View aliases
tf.keras.applications.inception_v3.InceptionV3,"tf.keras.applications.inception_v3.InceptionV3(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Inception v3 architecture.View aliases
tf.keras.applications.mobilenet.MobileNet,"tf.keras.applications.mobilenet.MobileNet(
    input_shape=None,
    alpha=1.0,
    depth_multiplier=1,
    dropout=0.001,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the MobileNet architecture.View aliases
tf.keras.applications.mobilenet_v2.MobileNetV2,"tf.keras.applications.mobilenet_v2.MobileNetV2(
    input_shape=None,
    alpha=1.0,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the MobileNetV2 architecture.View aliases
tf.keras.applications.MobileNetV3Large,"tf.keras.applications.MobileNetV3Large(
    input_shape=None,
    alpha=1.0,
    minimalistic=False,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    classes=1000,
    pooling=None,
    dropout_rate=0.2,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the MobileNetV3Large architecture.View aliases
tf.keras.applications.MobileNetV3Small,"tf.keras.applications.MobileNetV3Small(
    input_shape=None,
    alpha=1.0,
    minimalistic=False,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    classes=1000,
    pooling=None,
    dropout_rate=0.2,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the MobileNetV3Small architecture.View aliases
tf.keras.applications.nasnet.NASNetLarge,"tf.keras.applications.nasnet.NASNetLarge(
    input_shape=None,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates a NASNet model in ImageNet mode.View aliases
tf.keras.applications.nasnet.NASNetMobile,"tf.keras.applications.nasnet.NASNetMobile(
    input_shape=None,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates a Mobile NASNet model in ImageNet mode.View aliases
tf.keras.applications.regnet.RegNetX002,"tf.keras.applications.regnet.RegNetX002(
    model_name='regnetx002',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX002 architecture.View aliases
tf.keras.applications.regnet.RegNetX004,"tf.keras.applications.regnet.RegNetX004(
    model_name='regnetx004',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX004 architecture.View aliases
tf.keras.applications.regnet.RegNetX006,"tf.keras.applications.regnet.RegNetX006(
    model_name='regnetx006',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX006 architecture.View aliases
tf.keras.applications.regnet.RegNetX008,"tf.keras.applications.regnet.RegNetX008(
    model_name='regnetx008',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX008 architecture.View aliases
tf.keras.applications.regnet.RegNetX016,"tf.keras.applications.regnet.RegNetX016(
    model_name='regnetx016',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX016 architecture.View aliases
tf.keras.applications.regnet.RegNetX032,"tf.keras.applications.regnet.RegNetX032(
    model_name='regnetx032',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX032 architecture.View aliases
tf.keras.applications.regnet.RegNetX040,"tf.keras.applications.regnet.RegNetX040(
    model_name='regnetx040',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX040 architecture.View aliases
tf.keras.applications.regnet.RegNetX064,"tf.keras.applications.regnet.RegNetX064(
    model_name='regnetx064',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX064 architecture.View aliases
tf.keras.applications.regnet.RegNetX080,"tf.keras.applications.regnet.RegNetX080(
    model_name='regnetx080',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX080 architecture.View aliases
tf.keras.applications.regnet.RegNetX120,"tf.keras.applications.regnet.RegNetX120(
    model_name='regnetx120',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX120 architecture.View aliases
tf.keras.applications.regnet.RegNetX160,"tf.keras.applications.regnet.RegNetX160(
    model_name='regnetx160',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX160 architecture.View aliases
tf.keras.applications.regnet.RegNetX320,"tf.keras.applications.regnet.RegNetX320(
    model_name='regnetx320',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX320 architecture.View aliases
tf.keras.applications.regnet.RegNetY002,"tf.keras.applications.regnet.RegNetY002(
    model_name='regnety002',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY002 architecture.View aliases
tf.keras.applications.regnet.RegNetY004,"tf.keras.applications.regnet.RegNetY004(
    model_name='regnety004',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY004 architecture.View aliases
tf.keras.applications.regnet.RegNetY006,"tf.keras.applications.regnet.RegNetY006(
    model_name='regnety006',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY006 architecture.View aliases
tf.keras.applications.regnet.RegNetY008,"tf.keras.applications.regnet.RegNetY008(
    model_name='regnety008',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY008 architecture.View aliases
tf.keras.applications.regnet.RegNetY016,"tf.keras.applications.regnet.RegNetY016(
    model_name='regnety016',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY016 architecture.View aliases
tf.keras.applications.regnet.RegNetY032,"tf.keras.applications.regnet.RegNetY032(
    model_name='regnety032',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY032 architecture.View aliases
tf.keras.applications.regnet.RegNetY040,"tf.keras.applications.regnet.RegNetY040(
    model_name='regnety040',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY040 architecture.View aliases
tf.keras.applications.regnet.RegNetY064,"tf.keras.applications.regnet.RegNetY064(
    model_name='regnety064',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY064 architecture.View aliases
tf.keras.applications.regnet.RegNetY080,"tf.keras.applications.regnet.RegNetY080(
    model_name='regnety080',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY080 architecture.View aliases
tf.keras.applications.regnet.RegNetY120,"tf.keras.applications.regnet.RegNetY120(
    model_name='regnety120',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY120 architecture.View aliases
tf.keras.applications.regnet.RegNetY160,"tf.keras.applications.regnet.RegNetY160(
    model_name='regnety160',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY160 architecture.View aliases
tf.keras.applications.regnet.RegNetY320,"tf.keras.applications.regnet.RegNetY320(
    model_name='regnety320',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY320 architecture.View aliases
tf.keras.applications.resnet.ResNet101,"tf.keras.applications.resnet.ResNet101(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet101 architecture.View aliases
tf.keras.applications.resnet_v2.ResNet101V2,"tf.keras.applications.resnet_v2.ResNet101V2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ResNet101V2 architecture.View aliases
tf.keras.applications.resnet.ResNet152,"tf.keras.applications.resnet.ResNet152(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet152 architecture.View aliases
tf.keras.applications.resnet_v2.ResNet152V2,"tf.keras.applications.resnet_v2.ResNet152V2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ResNet152V2 architecture.View aliases
tf.keras.applications.resnet50.ResNet50,"tf.keras.applications.resnet50.ResNet50(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet50 architecture.View aliases
tf.keras.applications.resnet_v2.ResNet50V2,"tf.keras.applications.resnet_v2.ResNet50V2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ResNet50V2 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS101,"tf.keras.applications.resnet_rs.ResNetRS101(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS101 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS152,"tf.keras.applications.resnet_rs.ResNetRS152(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS152 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS200,"tf.keras.applications.resnet_rs.ResNetRS200(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS200 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS270,"tf.keras.applications.resnet_rs.ResNetRS270(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS270 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS350,"tf.keras.applications.resnet_rs.ResNetRS350(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS350 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS420,"tf.keras.applications.resnet_rs.ResNetRS420(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS420 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS50,"tf.keras.applications.resnet_rs.ResNetRS50(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS50 architecture.View aliases
tf.keras.applications.vgg16.VGG16,"tf.keras.applications.vgg16.VGG16(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the VGG16 model.View aliases
tf.keras.applications.vgg19.VGG19,"tf.keras.applications.vgg19.VGG19(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the VGG19 architecture.View aliases
tf.keras.applications.xception.Xception,"tf.keras.applications.xception.Xception(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Xception architecture.View aliases
tf.keras.applications.convnext.ConvNeXtBase,"tf.keras.applications.convnext.ConvNeXtBase(
    model_name='convnext_base',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtBase architecture.View aliases
tf.keras.applications.convnext.ConvNeXtLarge,"tf.keras.applications.convnext.ConvNeXtLarge(
    model_name='convnext_large',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtLarge architecture.View aliases
tf.keras.applications.convnext.ConvNeXtSmall,"tf.keras.applications.convnext.ConvNeXtSmall(
    model_name='convnext_small',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtSmall architecture.View aliases
tf.keras.applications.convnext.ConvNeXtTiny,"tf.keras.applications.convnext.ConvNeXtTiny(
    model_name='convnext_tiny',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtTiny architecture.View aliases
tf.keras.applications.convnext.ConvNeXtXLarge,"tf.keras.applications.convnext.ConvNeXtXLarge(
    model_name='convnext_xlarge',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtXLarge architecture.View aliases
tf.keras.applications.convnext.decode_predictions,"tf.keras.applications.convnext.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.convnext.preprocess_input,"tf.keras.applications.convnext.preprocess_input(
    x, data_format=None
)
",A placeholder method for backward compatibility.View aliases
tf.keras.applications.densenet.DenseNet121,"tf.keras.applications.densenet.DenseNet121(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Densenet121 architecture.View aliases
tf.keras.applications.densenet.DenseNet169,"tf.keras.applications.densenet.DenseNet169(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Densenet169 architecture.View aliases
tf.keras.applications.densenet.DenseNet201,"tf.keras.applications.densenet.DenseNet201(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Densenet201 architecture.View aliases
tf.keras.applications.densenet.decode_predictions,"tf.keras.applications.densenet.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.densenet.preprocess_input,"tf.keras.applications.densenet.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.efficientnet.EfficientNetB0,"tf.keras.applications.efficientnet.EfficientNetB0(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB0 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB1,"tf.keras.applications.efficientnet.EfficientNetB1(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB1 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB2,"tf.keras.applications.efficientnet.EfficientNetB2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB2 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB3,"tf.keras.applications.efficientnet.EfficientNetB3(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB3 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB4,"tf.keras.applications.efficientnet.EfficientNetB4(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB4 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB5,"tf.keras.applications.efficientnet.EfficientNetB5(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB5 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB6,"tf.keras.applications.efficientnet.EfficientNetB6(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB6 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB7,"tf.keras.applications.efficientnet.EfficientNetB7(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB7 architecture.View aliases
tf.keras.applications.efficientnet.decode_predictions,"tf.keras.applications.efficientnet.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.efficientnet.preprocess_input,"tf.keras.applications.efficientnet.preprocess_input(
    x, data_format=None
)
",A placeholder method for backward compatibility.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B0,"tf.keras.applications.efficientnet_v2.EfficientNetV2B0(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B0 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B1,"tf.keras.applications.efficientnet_v2.EfficientNetV2B1(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B1 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B2,"tf.keras.applications.efficientnet_v2.EfficientNetV2B2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B2 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B3,"tf.keras.applications.efficientnet_v2.EfficientNetV2B3(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B3 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2L,"tf.keras.applications.efficientnet_v2.EfficientNetV2L(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2L architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2M,"tf.keras.applications.efficientnet_v2.EfficientNetV2M(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2M architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2S,"tf.keras.applications.efficientnet_v2.EfficientNetV2S(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2S architecture.View aliases
tf.keras.applications.efficientnet_v2.decode_predictions,"tf.keras.applications.efficientnet_v2.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.efficientnet_v2.preprocess_input,"tf.keras.applications.efficientnet_v2.preprocess_input(
    x, data_format=None
)
",A placeholder method for backward compatibility.View aliases
tf.keras.applications.imagenet_utils.decode_predictions,"tf.keras.applications.imagenet_utils.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.imagenet_utils.preprocess_input,"tf.keras.applications.imagenet_utils.preprocess_input(
    x, data_format=None, mode='caffe'
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.inception_resnet_v2.InceptionResNetV2,"tf.keras.applications.inception_resnet_v2.InceptionResNetV2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the Inception-ResNet v2 architecture.View aliases
tf.keras.applications.inception_resnet_v2.decode_predictions,"tf.keras.applications.inception_resnet_v2.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.inception_resnet_v2.preprocess_input,"tf.keras.applications.inception_resnet_v2.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.inception_v3.InceptionV3,"tf.keras.applications.inception_v3.InceptionV3(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Inception v3 architecture.View aliases
tf.keras.applications.inception_v3.decode_predictions,"tf.keras.applications.inception_v3.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.inception_v3.preprocess_input,"tf.keras.applications.inception_v3.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.mobilenet.MobileNet,"tf.keras.applications.mobilenet.MobileNet(
    input_shape=None,
    alpha=1.0,
    depth_multiplier=1,
    dropout=0.001,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the MobileNet architecture.View aliases
tf.keras.applications.mobilenet.decode_predictions,"tf.keras.applications.mobilenet.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.mobilenet.preprocess_input,"tf.keras.applications.mobilenet.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.mobilenet_v2.MobileNetV2,"tf.keras.applications.mobilenet_v2.MobileNetV2(
    input_shape=None,
    alpha=1.0,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the MobileNetV2 architecture.View aliases
tf.keras.applications.mobilenet_v2.decode_predictions,"tf.keras.applications.mobilenet_v2.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.mobilenet_v2.preprocess_input,"tf.keras.applications.mobilenet_v2.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.mobilenet_v3.decode_predictions,"tf.keras.applications.mobilenet_v3.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.mobilenet_v3.preprocess_input,"tf.keras.applications.mobilenet_v3.preprocess_input(
    x, data_format=None
)
",A placeholder method for backward compatibility.View aliases
tf.keras.applications.nasnet.NASNetLarge,"tf.keras.applications.nasnet.NASNetLarge(
    input_shape=None,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates a NASNet model in ImageNet mode.View aliases
tf.keras.applications.nasnet.NASNetMobile,"tf.keras.applications.nasnet.NASNetMobile(
    input_shape=None,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates a Mobile NASNet model in ImageNet mode.View aliases
tf.keras.applications.nasnet.decode_predictions,"tf.keras.applications.nasnet.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.nasnet.preprocess_input,"tf.keras.applications.nasnet.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.regnet.RegNetX002,"tf.keras.applications.regnet.RegNetX002(
    model_name='regnetx002',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX002 architecture.View aliases
tf.keras.applications.regnet.RegNetX004,"tf.keras.applications.regnet.RegNetX004(
    model_name='regnetx004',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX004 architecture.View aliases
tf.keras.applications.regnet.RegNetX006,"tf.keras.applications.regnet.RegNetX006(
    model_name='regnetx006',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX006 architecture.View aliases
tf.keras.applications.regnet.RegNetX008,"tf.keras.applications.regnet.RegNetX008(
    model_name='regnetx008',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX008 architecture.View aliases
tf.keras.applications.regnet.RegNetX016,"tf.keras.applications.regnet.RegNetX016(
    model_name='regnetx016',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX016 architecture.View aliases
tf.keras.applications.regnet.RegNetX032,"tf.keras.applications.regnet.RegNetX032(
    model_name='regnetx032',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX032 architecture.View aliases
tf.keras.applications.regnet.RegNetX040,"tf.keras.applications.regnet.RegNetX040(
    model_name='regnetx040',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX040 architecture.View aliases
tf.keras.applications.regnet.RegNetX064,"tf.keras.applications.regnet.RegNetX064(
    model_name='regnetx064',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX064 architecture.View aliases
tf.keras.applications.regnet.RegNetX080,"tf.keras.applications.regnet.RegNetX080(
    model_name='regnetx080',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX080 architecture.View aliases
tf.keras.applications.regnet.RegNetX120,"tf.keras.applications.regnet.RegNetX120(
    model_name='regnetx120',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX120 architecture.View aliases
tf.keras.applications.regnet.RegNetX160,"tf.keras.applications.regnet.RegNetX160(
    model_name='regnetx160',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX160 architecture.View aliases
tf.keras.applications.regnet.RegNetX320,"tf.keras.applications.regnet.RegNetX320(
    model_name='regnetx320',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX320 architecture.View aliases
tf.keras.applications.regnet.RegNetY002,"tf.keras.applications.regnet.RegNetY002(
    model_name='regnety002',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY002 architecture.View aliases
tf.keras.applications.regnet.RegNetY004,"tf.keras.applications.regnet.RegNetY004(
    model_name='regnety004',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY004 architecture.View aliases
tf.keras.applications.regnet.RegNetY006,"tf.keras.applications.regnet.RegNetY006(
    model_name='regnety006',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY006 architecture.View aliases
tf.keras.applications.regnet.RegNetY008,"tf.keras.applications.regnet.RegNetY008(
    model_name='regnety008',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY008 architecture.View aliases
tf.keras.applications.regnet.RegNetY016,"tf.keras.applications.regnet.RegNetY016(
    model_name='regnety016',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY016 architecture.View aliases
tf.keras.applications.regnet.RegNetY032,"tf.keras.applications.regnet.RegNetY032(
    model_name='regnety032',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY032 architecture.View aliases
tf.keras.applications.regnet.RegNetY040,"tf.keras.applications.regnet.RegNetY040(
    model_name='regnety040',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY040 architecture.View aliases
tf.keras.applications.regnet.RegNetY064,"tf.keras.applications.regnet.RegNetY064(
    model_name='regnety064',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY064 architecture.View aliases
tf.keras.applications.regnet.RegNetY080,"tf.keras.applications.regnet.RegNetY080(
    model_name='regnety080',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY080 architecture.View aliases
tf.keras.applications.regnet.RegNetY120,"tf.keras.applications.regnet.RegNetY120(
    model_name='regnety120',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY120 architecture.View aliases
tf.keras.applications.regnet.RegNetY160,"tf.keras.applications.regnet.RegNetY160(
    model_name='regnety160',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY160 architecture.View aliases
tf.keras.applications.regnet.RegNetY320,"tf.keras.applications.regnet.RegNetY320(
    model_name='regnety320',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY320 architecture.View aliases
tf.keras.applications.regnet.decode_predictions,"tf.keras.applications.regnet.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.regnet.preprocess_input,"tf.keras.applications.regnet.preprocess_input(
    x, data_format=None
)
",A placeholder method for backward compatibility.View aliases
tf.keras.applications.resnet.ResNet101,"tf.keras.applications.resnet.ResNet101(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet101 architecture.View aliases
tf.keras.applications.resnet.ResNet152,"tf.keras.applications.resnet.ResNet152(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet152 architecture.View aliases
tf.keras.applications.resnet50.ResNet50,"tf.keras.applications.resnet50.ResNet50(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet50 architecture.View aliases
tf.keras.applications.resnet50.decode_predictions,"tf.keras.applications.resnet50.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.resnet50.preprocess_input,"tf.keras.applications.resnet50.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.resnet50.ResNet50,"tf.keras.applications.resnet50.ResNet50(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet50 architecture.View aliases
tf.keras.applications.resnet50.decode_predictions,"tf.keras.applications.resnet50.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.resnet50.preprocess_input,"tf.keras.applications.resnet50.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.resnet_rs.ResNetRS101,"tf.keras.applications.resnet_rs.ResNetRS101(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS101 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS152,"tf.keras.applications.resnet_rs.ResNetRS152(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS152 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS200,"tf.keras.applications.resnet_rs.ResNetRS200(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS200 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS270,"tf.keras.applications.resnet_rs.ResNetRS270(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS270 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS350,"tf.keras.applications.resnet_rs.ResNetRS350(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS350 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS420,"tf.keras.applications.resnet_rs.ResNetRS420(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS420 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS50,"tf.keras.applications.resnet_rs.ResNetRS50(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS50 architecture.View aliases
tf.keras.applications.resnet_rs.decode_predictions,"tf.keras.applications.resnet_rs.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.resnet_rs.preprocess_input,"tf.keras.applications.resnet_rs.preprocess_input(
    x, data_format=None
)
",A placeholder method for backward compatibility.View aliases
tf.keras.applications.resnet_v2.ResNet101V2,"tf.keras.applications.resnet_v2.ResNet101V2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ResNet101V2 architecture.View aliases
tf.keras.applications.resnet_v2.ResNet152V2,"tf.keras.applications.resnet_v2.ResNet152V2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ResNet152V2 architecture.View aliases
tf.keras.applications.resnet_v2.ResNet50V2,"tf.keras.applications.resnet_v2.ResNet50V2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ResNet50V2 architecture.View aliases
tf.keras.applications.resnet_v2.decode_predictions,"tf.keras.applications.resnet_v2.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.resnet_v2.preprocess_input,"tf.keras.applications.resnet_v2.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.vgg16.VGG16,"tf.keras.applications.vgg16.VGG16(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the VGG16 model.View aliases
tf.keras.applications.vgg16.decode_predictions,"tf.keras.applications.vgg16.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.vgg16.preprocess_input,"tf.keras.applications.vgg16.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.vgg19.VGG19,"tf.keras.applications.vgg19.VGG19(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the VGG19 architecture.View aliases
tf.keras.applications.vgg19.decode_predictions,"tf.keras.applications.vgg19.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.vgg19.preprocess_input,"tf.keras.applications.vgg19.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.xception.Xception,"tf.keras.applications.xception.Xception(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Xception architecture.View aliases
tf.keras.applications.xception.decode_predictions,"tf.keras.applications.xception.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.xception.preprocess_input,"tf.keras.applications.xception.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.backend.get_uid,"tf.keras.backend.get_uid(
    prefix=''
)
",Associates a string prefix with an integer counter in a TensorFlow graph.View aliases
tf.keras.backend.is_keras_tensor,"tf.keras.backend.is_keras_tensor(
    x
)
",Returns whether x is a Keras tensor.View aliases
tf.keras.backend.rnn,"tf.keras.backend.rnn(
    step_function,
    inputs,
    initial_states,
    go_backwards=False,
    mask=None,
    constants=None,
    unroll=False,
    input_length=None,
    time_major=False,
    zero_output_for_mask=False,
    return_all_outputs=True
)
",Iterates over the time dimension of a tensor.View aliases
tf.keras.backend.set_epsilon,"tf.keras.backend.set_epsilon(
    value
)
",Sets the value of the fuzz factor used in numeric expressions.View aliases
tf.keras.backend.set_floatx,"tf.keras.backend.set_floatx(
    value
)
",Sets the default float type.View aliases
tf.keras.backend.set_image_data_format,"tf.keras.backend.set_image_data_format(
    data_format
)
",Sets the value of the image data format convention.View aliases
tf.keras.callbacks.BackupAndRestore,"tf.keras.callbacks.BackupAndRestore(
    backup_dir, save_freq='epoch', delete_checkpoint=True
)
",Callback to back up and restore the training state.Inherits From: Callback
tf.keras.callbacks.BaseLogger,"tf.keras.callbacks.BaseLogger(
    stateful_metrics=None
)
",Callback that accumulates epoch averages of metrics.Inherits From: CallbackView aliases
tf.keras.callbacks.CSVLogger,"tf.keras.callbacks.CSVLogger(
    filename, separator=',', append=False
)
",Callback that streams epoch results to a CSV file.Inherits From: CallbackView aliases
tf.keras.callbacks.CallbackList,"tf.keras.callbacks.CallbackList(
    callbacks=None, add_history=False, add_progbar=False, model=None, **params
)
",Container abstracting a list of callbacks.View aliases
tf.keras.callbacks.EarlyStopping,"tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    min_delta=0,
    patience=0,
    verbose=0,
    mode='auto',
    baseline=None,
    restore_best_weights=False
)
",Stop training when a monitored metric has stopped improving.Inherits From: CallbackView aliases
tf.keras.callbacks.LambdaCallback,"tf.keras.callbacks.LambdaCallback(
    on_epoch_begin=None,
    on_epoch_end=None,
    on_batch_begin=None,
    on_batch_end=None,
    on_train_begin=None,
    on_train_end=None,
    **kwargs
)
","Callback for creating simple, custom callbacks on-the-fly.Inherits From: CallbackView aliases"
tf.keras.callbacks.LearningRateScheduler,"tf.keras.callbacks.LearningRateScheduler(
    schedule, verbose=0
)
",Learning rate scheduler.Inherits From: CallbackView aliases
tf.keras.callbacks.ModelCheckpoint,"tf.keras.callbacks.ModelCheckpoint(
    filepath,
    monitor: str = 'val_loss',
    verbose: int = 0,
    save_best_only: bool = False,
    save_weights_only: bool = False,
    mode: str = 'auto',
    save_freq='epoch',
    options=None,
    initial_value_threshold=None,
    **kwargs
)
",Callback to save the Keras model or model weights at some frequency.Inherits From: CallbackView aliases
tf.keras.callbacks.ProgbarLogger,"tf.keras.callbacks.ProgbarLogger(
    count_mode: str = 'samples', stateful_metrics=None
)
",Callback that prints metrics to stdout.Inherits From: CallbackView aliases
tf.keras.callbacks.ReduceLROnPlateau,"tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.1,
    patience=10,
    verbose=0,
    mode='auto',
    min_delta=0.0001,
    cooldown=0,
    min_lr=0,
    **kwargs
)
",Reduce learning rate when a metric has stopped improving.Inherits From: CallbackView aliases
tf.keras.callbacks.RemoteMonitor,"tf.keras.callbacks.RemoteMonitor(
    root='http://localhost:9000',
    path='/publish/epoch/end/',
    field='data',
    headers=None,
    send_as_json=False
)
",Callback used to stream events to a server.Inherits From: CallbackView aliases
tf.keras.callbacks.TensorBoard,"tf.keras.callbacks.TensorBoard(
    log_dir='logs',
    histogram_freq=0,
    write_graph=True,
    write_images=False,
    write_steps_per_second=False,
    update_freq='epoch',
    profile_batch=0,
    embeddings_freq=0,
    embeddings_metadata=None,
    **kwargs
)
",Enable visualizations for TensorBoard.Inherits From: Callback
tf.keras.callbacks.experimental.BackupAndRestore,"tf.keras.callbacks.experimental.BackupAndRestore(
    *args, **kwargs
)
","Deprecated. Please use tf.keras.callbacks.BackupAndRestore instead.Inherits From: BackupAndRestore, Callback"
tf.keras.constraints.MaxNorm,"tf.keras.constraints.MaxNorm(
    max_value=2, axis=0
)
",MaxNorm weight constraint.Inherits From: ConstraintView aliases
tf.keras.constraints.MinMaxNorm,"tf.keras.constraints.MinMaxNorm(
    min_value=0.0, max_value=1.0, rate=1.0, axis=0
)
",MinMaxNorm weight constraint.Inherits From: ConstraintView aliases
tf.keras.constraints.UnitNorm,"tf.keras.constraints.UnitNorm(
    axis=0
)
",Constrains the weights incident to each hidden unit to have unit norm.Inherits From: ConstraintView aliases
tf.keras.constraints.deserialize,"tf.keras.constraints.deserialize(
    config, custom_objects=None
)
",View aliases
tf.keras.constraints.get,"tf.keras.constraints.get(
    identifier
)
",Retrieves a Keras constraint function.View aliases
tf.keras.constraints.MaxNorm,"tf.keras.constraints.MaxNorm(
    max_value=2, axis=0
)
",MaxNorm weight constraint.Inherits From: ConstraintView aliases
tf.keras.constraints.MinMaxNorm,"tf.keras.constraints.MinMaxNorm(
    min_value=0.0, max_value=1.0, rate=1.0, axis=0
)
",MinMaxNorm weight constraint.Inherits From: ConstraintView aliases
tf.keras.constraints.serialize,"tf.keras.constraints.serialize(
    constraint
)
",View aliases
tf.keras.constraints.UnitNorm,"tf.keras.constraints.UnitNorm(
    axis=0
)
",Constrains the weights incident to each hidden unit to have unit norm.Inherits From: ConstraintView aliases
tf.keras.datasets.boston_housing.load_data,"tf.keras.datasets.boston_housing.load_data(
    path='boston_housing.npz', test_split=0.2, seed=113
)
",Loads the Boston Housing dataset.View aliases
tf.keras.datasets.cifar100.load_data,"tf.keras.datasets.cifar100.load_data(
    label_mode='fine'
)
",Loads the CIFAR100 dataset.View aliases
tf.keras.datasets.imdb.get_word_index,"tf.keras.datasets.imdb.get_word_index(
    path='imdb_word_index.json'
)
",Retrieves a dict mapping words to their index in the IMDB dataset.View aliases
tf.keras.datasets.imdb.load_data,"tf.keras.datasets.imdb.load_data(
    path='imdb.npz',
    num_words=None,
    skip_top=0,
    maxlen=None,
    seed=113,
    start_char=1,
    oov_char=2,
    index_from=3,
    **kwargs
)
",Loads the IMDB dataset.View aliases
tf.keras.datasets.mnist.load_data,"tf.keras.datasets.mnist.load_data(
    path='mnist.npz'
)
",Loads the MNIST dataset.View aliases
tf.keras.datasets.reuters.get_word_index,"tf.keras.datasets.reuters.get_word_index(
    path='reuters_word_index.json'
)
",Retrieves a dict mapping words to their index in the Reuters dataset.View aliases
tf.keras.datasets.reuters.load_data,"tf.keras.datasets.reuters.load_data(
    path='reuters.npz',
    num_words=None,
    skip_top=0,
    maxlen=None,
    test_split=0.2,
    seed=113,
    start_char=1,
    oov_char=2,
    index_from=3,
    **kwargs
)
",Loads the Reuters newswire classification dataset.View aliases
tf.keras.dtensor.experimental.LayoutMap,"tf.keras.dtensor.experimental.LayoutMap(
    mesh=None
)
",A dict-like object that maps string to Layout instances.
tf.keras.dtensor.experimental.optimizers.Adadelta,"tf.keras.dtensor.experimental.optimizers.Adadelta(
    learning_rate=0.001,
    rho=0.95,
    epsilon=1e-07,
    gradients_clip_option=None,
    ema_option=None,
    name='Adadelta',
    mesh=None
)
","DTensor specific optimizers.Inherits From: Adadelta, Optimizer"
tf.keras.dtensor.experimental.optimizers.Adagrad,"tf.keras.dtensor.experimental.optimizers.Adagrad(
    learning_rate=0.001,
    initial_accumulator_value=0.1,
    epsilon=1e-07,
    gradients_clip_option=None,
    ema_option=None,
    name='Adagrad',
    mesh=None
)
","DTensor specific optimizers.Inherits From: Adagrad, Optimizer"
tf.keras.dtensor.experimental.optimizers.Adam,"tf.keras.dtensor.experimental.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    gradients_clip_option=None,
    ema_option=None,
    name='Adam',
    mesh=None
)
","DTensor specific optimizers.Inherits From: Adam, Optimizer"
tf.keras.dtensor.experimental.optimizers.AdamW,"tf.keras.dtensor.experimental.optimizers.AdamW(
    learning_rate=0.001,
    weight_decay=0.004,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    name='AdamW',
    mesh=None
)
","DTensor specific optimizers.Inherits From: AdamW, Optimizer"
tf.keras.dtensor.experimental.optimizers.RMSprop,"tf.keras.dtensor.experimental.optimizers.RMSprop(
    learning_rate=0.001,
    rho=0.9,
    momentum=0.0,
    epsilon=1e-07,
    centered=False,
    gradients_clip_option=None,
    ema_option=None,
    jit_compile=False,
    name='RMSprop',
    mesh=None
)
","DTensor specific optimizers.Inherits From: RMSprop, Optimizer"
tf.keras.dtensor.experimental.optimizers.SGD,"tf.keras.dtensor.experimental.optimizers.SGD(
    learning_rate=0.01,
    momentum=0.0,
    nesterov=False,
    amsgrad=False,
    gradients_clip_option=None,
    ema_option=None,
    jit_compile=False,
    name='SGD',
    mesh=None
)
","DTensor specific optimizers.Inherits From: SGD, Optimizer"
tf.keras.estimator.model_to_estimator,"tf.keras.estimator.model_to_estimator(
    keras_model=None,
    keras_model_path=None,
    custom_objects=None,
    model_dir=None,
    config=None,
    checkpoint_format='checkpoint',
    metric_names_map=None,
    export_outputs=None
)
",Constructs an Estimator instance from given keras model.
tf.keras.optimizers.schedules.CosineDecay,"tf.keras.optimizers.schedules.CosineDecay(
    initial_learning_rate, decay_steps, alpha=0.0, name=None
)
",A LearningRateSchedule that uses a cosine decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.CosineDecayRestarts,"tf.keras.optimizers.schedules.CosineDecayRestarts(
    initial_learning_rate,
    first_decay_steps,
    t_mul=2.0,
    m_mul=1.0,
    alpha=0.0,
    name=None
)
",A LearningRateSchedule that uses a cosine decay schedule with restarts.Inherits From: LearningRateScheduleView aliases
tf.keras.experimental.LinearModel,"tf.keras.experimental.LinearModel(
    units=1,
    activation=None,
    use_bias=True,
    kernel_initializer='zeros',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    **kwargs
)
","Linear Model for regression and classification problems.Inherits From: Model, Layer, ModuleView aliases"
tf.keras.experimental.SequenceFeatures,"tf.keras.experimental.SequenceFeatures(
    feature_columns, trainable=True, name=None, **kwargs
)
","A layer for sequence input.Inherits From: Layer, ModuleView aliases"
tf.keras.experimental.SidecarEvaluator,"tf.keras.experimental.SidecarEvaluator(
    *args, **kwargs
)
",Deprecated. Please use tf.keras.utils.SidecarEvaluator instead.Inherits From: SidecarEvaluator
tf.keras.experimental.WideDeepModel,"tf.keras.experimental.WideDeepModel(
    linear_model, dnn_model, activation=None, **kwargs
)
","Wide & Deep Model for regression and classification problems.Inherits From: Model, Layer, ModuleView aliases"
tf.keras.initializers.Constant,"tf.keras.initializers.Constant(
    value=0
)
",Initializer that generates tensors with constant values.Inherits From: InitializerView aliases
tf.keras.initializers.GlorotNormal,"tf.keras.initializers.GlorotNormal(
    seed=None
)
","The Glorot normal initializer, also called Xavier normal initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.GlorotUniform,"tf.keras.initializers.GlorotUniform(
    seed=None
)
","The Glorot uniform initializer, also called Xavier uniform initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.HeNormal,"tf.keras.initializers.HeNormal(
    seed=None
)
","He normal initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.HeUniform,"tf.keras.initializers.HeUniform(
    seed=None
)
","He uniform variance scaling initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.Identity,"tf.keras.initializers.Identity(
    gain=1.0
)
",Initializer that generates the identity matrix.Inherits From: InitializerView aliases
tf.keras.initializers.LecunNormal,"tf.keras.initializers.LecunNormal(
    seed=None
)
","Lecun normal initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.LecunUniform,"tf.keras.initializers.LecunUniform(
    seed=None
)
","Lecun uniform initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.Orthogonal,"tf.keras.initializers.Orthogonal(
    gain=1.0, seed=None
)
",Initializer that generates an orthogonal matrix.Inherits From: InitializerView aliases
tf.keras.initializers.RandomNormal,"tf.keras.initializers.RandomNormal(
    mean=0.0, stddev=0.05, seed=None
)
",Initializer that generates tensors with a normal distribution.Inherits From: InitializerView aliases
tf.keras.initializers.RandomUniform,"tf.keras.initializers.RandomUniform(
    minval=-0.05, maxval=0.05, seed=None
)
",Initializer that generates tensors with a uniform distribution.Inherits From: InitializerView aliases
tf.keras.initializers.TruncatedNormal,"tf.keras.initializers.TruncatedNormal(
    mean=0.0, stddev=0.05, seed=None
)
",Initializer that generates a truncated normal distribution.Inherits From: InitializerView aliases
tf.keras.initializers.VarianceScaling,"tf.keras.initializers.VarianceScaling(
    scale=1.0,
    mode='fan_in',
    distribution='truncated_normal',
    seed=None
)
",Initializer capable of adapting its scale to the shape of weights tensors.Inherits From: InitializerView aliases
tf.keras.initializers.Constant,"tf.keras.initializers.Constant(
    value=0
)
",Initializer that generates tensors with constant values.Inherits From: InitializerView aliases
tf.keras.initializers.deserialize,"tf.keras.initializers.deserialize(
    config, custom_objects=None
)
",Return an Initializer object from its config.View aliases
tf.keras.initializers.get,"tf.keras.initializers.get(
    identifier
)
",Retrieve a Keras initializer by the identifier.View aliases
tf.keras.initializers.GlorotNormal,"tf.keras.initializers.GlorotNormal(
    seed=None
)
","The Glorot normal initializer, also called Xavier normal initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.GlorotUniform,"tf.keras.initializers.GlorotUniform(
    seed=None
)
","The Glorot uniform initializer, also called Xavier uniform initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.HeNormal,"tf.keras.initializers.HeNormal(
    seed=None
)
","He normal initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.HeUniform,"tf.keras.initializers.HeUniform(
    seed=None
)
","He uniform variance scaling initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.Identity,"tf.keras.initializers.Identity(
    gain=1.0
)
",Initializer that generates the identity matrix.Inherits From: InitializerView aliases
tf.keras.initializers.LecunNormal,"tf.keras.initializers.LecunNormal(
    seed=None
)
","Lecun normal initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.LecunUniform,"tf.keras.initializers.LecunUniform(
    seed=None
)
","Lecun uniform initializer.Inherits From: VarianceScaling, InitializerView aliases"
tf.keras.initializers.Orthogonal,"tf.keras.initializers.Orthogonal(
    gain=1.0, seed=None
)
",Initializer that generates an orthogonal matrix.Inherits From: InitializerView aliases
tf.keras.initializers.RandomNormal,"tf.keras.initializers.RandomNormal(
    mean=0.0, stddev=0.05, seed=None
)
",Initializer that generates tensors with a normal distribution.Inherits From: InitializerView aliases
tf.keras.initializers.RandomUniform,"tf.keras.initializers.RandomUniform(
    minval=-0.05, maxval=0.05, seed=None
)
",Initializer that generates tensors with a uniform distribution.Inherits From: InitializerView aliases
tf.keras.initializers.serialize,"tf.keras.initializers.serialize(
    initializer
)
",View aliases
tf.keras.initializers.TruncatedNormal,"tf.keras.initializers.TruncatedNormal(
    mean=0.0, stddev=0.05, seed=None
)
",Initializer that generates a truncated normal distribution.Inherits From: InitializerView aliases
tf.keras.initializers.VarianceScaling,"tf.keras.initializers.VarianceScaling(
    scale=1.0,
    mode='fan_in',
    distribution='truncated_normal',
    seed=None
)
",Initializer capable of adapting its scale to the shape of weights tensors.Inherits From: InitializerView aliases
tf.keras.layers.AbstractRNNCell,"tf.keras.layers.AbstractRNNCell(
    trainable=True, name=None, dtype=None, dynamic=False, **kwargs
)
","Abstract object representing an RNN cell.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Activation,"tf.keras.layers.Activation(
    activation, **kwargs
)
","Applies an activation function to an output.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.ActivityRegularization,"tf.keras.layers.ActivityRegularization(
    l1=0.0, l2=0.0, **kwargs
)
","Layer that applies an update to the cost function based input activity.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Add,"tf.keras.layers.Add(
    **kwargs
)
","Layer that adds a list of inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AdditiveAttention,"tf.keras.layers.AdditiveAttention(
    use_scale=True, **kwargs
)
","Additive attention layer, a.k.a. Bahdanau-style attention.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AlphaDropout,"tf.keras.layers.AlphaDropout(
    rate, noise_shape=None, seed=None, **kwargs
)
","Applies Alpha Dropout to the input.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Attention,"tf.keras.layers.Attention(
    use_scale=False, score_mode='dot', **kwargs
)
","Dot-product attention layer, a.k.a. Luong-style attention.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Average,"tf.keras.layers.Average(
    **kwargs
)
","Layer that averages a list of inputs element-wise.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AveragePooling1D,"tf.keras.layers.AveragePooling1D(
    pool_size=2,
    strides=None,
    padding='valid',
    data_format='channels_last',
    **kwargs
)
","Average pooling for temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AveragePooling2D,"tf.keras.layers.AveragePooling2D(
    pool_size=(2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Average pooling operation for spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AveragePooling3D,"tf.keras.layers.AveragePooling3D(
    pool_size=(2, 2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Average pooling operation for 3D data (spatial or spatio-temporal).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AveragePooling1D,"tf.keras.layers.AveragePooling1D(
    pool_size=2,
    strides=None,
    padding='valid',
    data_format='channels_last',
    **kwargs
)
","Average pooling for temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AveragePooling2D,"tf.keras.layers.AveragePooling2D(
    pool_size=(2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Average pooling operation for spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AveragePooling3D,"tf.keras.layers.AveragePooling3D(
    pool_size=(2, 2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Average pooling operation for 3D data (spatial or spatio-temporal).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.BatchNormalization,"tf.keras.layers.BatchNormalization(
    axis=-1,
    momentum=0.99,
    epsilon=0.001,
    center=True,
    scale=True,
    beta_initializer='zeros',
    gamma_initializer='ones',
    moving_mean_initializer='zeros',
    moving_variance_initializer='ones',
    beta_regularizer=None,
    gamma_regularizer=None,
    beta_constraint=None,
    gamma_constraint=None,
    **kwargs
)
","Layer that normalizes its inputs.Inherits From: Layer, Module"
tf.keras.layers.Bidirectional,"tf.keras.layers.Bidirectional(
    layer,
    merge_mode='concat',
    weights=None,
    backward_layer=None,
    **kwargs
)
","Bidirectional wrapper for RNNs.Inherits From: Wrapper, Layer, ModuleView aliases"
tf.keras.layers.CategoryEncoding,"tf.keras.layers.CategoryEncoding(
    num_tokens=None, output_mode='multi_hot', sparse=False, **kwargs
)
","A preprocessing layer which encodes integer features.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.CenterCrop,"tf.keras.layers.CenterCrop(
    height, width, **kwargs
)
","A preprocessing layer which crops images.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Concatenate,"tf.keras.layers.Concatenate(
    axis=-1, **kwargs
)
","Layer that concatenates a list of inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv1D,"tf.keras.layers.Conv1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format='channels_last',
    dilation_rate=1,
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","1D convolution layer (e.g. temporal convolution).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv1DTranspose,"tf.keras.layers.Conv1DTranspose(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    output_padding=None,
    data_format=None,
    dilation_rate=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Transposed convolution layer (sometimes called Deconvolution).Inherits From: Conv1D, Layer, ModuleView aliases"
tf.keras.layers.Conv2D,"tf.keras.layers.Conv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1),
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","2D convolution layer (e.g. spatial convolution over images).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv2DTranspose,"tf.keras.layers.Conv2DTranspose(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    output_padding=None,
    data_format=None,
    dilation_rate=(1, 1),
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Transposed convolution layer (sometimes called Deconvolution).Inherits From: Conv2D, Layer, ModuleView aliases"
tf.keras.layers.Conv3D,"tf.keras.layers.Conv3D(
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1, 1),
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","3D convolution layer (e.g. spatial convolution over volumes).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv3DTranspose,"tf.keras.layers.Conv3DTranspose(
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    output_padding=None,
    data_format=None,
    dilation_rate=(1, 1, 1),
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Transposed convolution layer (sometimes called Deconvolution).Inherits From: Conv3D, Layer, ModuleView aliases"
tf.keras.layers.ConvLSTM1D,"tf.keras.layers.ConvLSTM1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format=None,
    dilation_rate=1,
    activation='tanh',
    recurrent_activation='hard_sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    unit_forget_bias=True,
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    dropout=0.0,
    recurrent_dropout=0.0,
    **kwargs
)
","1D Convolutional LSTM.Inherits From: RNN, Layer, ModuleView aliases"
tf.keras.layers.ConvLSTM2D,"tf.keras.layers.ConvLSTM2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1),
    activation='tanh',
    recurrent_activation='hard_sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    unit_forget_bias=True,
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    dropout=0.0,
    recurrent_dropout=0.0,
    **kwargs
)
","2D Convolutional LSTM.Inherits From: RNN, Layer, ModuleView aliases"
tf.keras.layers.ConvLSTM3D,"tf.keras.layers.ConvLSTM3D(
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1, 1),
    activation='tanh',
    recurrent_activation='hard_sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    unit_forget_bias=True,
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    dropout=0.0,
    recurrent_dropout=0.0,
    **kwargs
)
","3D Convolutional LSTM.Inherits From: RNN, Layer, ModuleView aliases"
tf.keras.layers.Conv1D,"tf.keras.layers.Conv1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format='channels_last',
    dilation_rate=1,
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","1D convolution layer (e.g. temporal convolution).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv1DTranspose,"tf.keras.layers.Conv1DTranspose(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    output_padding=None,
    data_format=None,
    dilation_rate=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Transposed convolution layer (sometimes called Deconvolution).Inherits From: Conv1D, Layer, ModuleView aliases"
tf.keras.layers.Conv2D,"tf.keras.layers.Conv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1),
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","2D convolution layer (e.g. spatial convolution over images).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv2DTranspose,"tf.keras.layers.Conv2DTranspose(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    output_padding=None,
    data_format=None,
    dilation_rate=(1, 1),
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Transposed convolution layer (sometimes called Deconvolution).Inherits From: Conv2D, Layer, ModuleView aliases"
tf.keras.layers.Conv3D,"tf.keras.layers.Conv3D(
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1, 1),
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","3D convolution layer (e.g. spatial convolution over volumes).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv3DTranspose,"tf.keras.layers.Conv3DTranspose(
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    output_padding=None,
    data_format=None,
    dilation_rate=(1, 1, 1),
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Transposed convolution layer (sometimes called Deconvolution).Inherits From: Conv3D, Layer, ModuleView aliases"
tf.keras.layers.Cropping1D,"tf.keras.layers.Cropping1D(
    cropping=(1, 1), **kwargs
)
","Cropping layer for 1D input (e.g. temporal sequence).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Cropping2D,"tf.keras.layers.Cropping2D(
    cropping=((0, 0), (0, 0)), data_format=None, **kwargs
)
","Cropping layer for 2D input (e.g. picture).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Cropping3D,"tf.keras.layers.Cropping3D(
    cropping=((1, 1), (1, 1), (1, 1)), data_format=None, **kwargs
)
","Cropping layer for 3D data (e.g. spatial or spatio-temporal).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Dense,"tf.keras.layers.Dense(
    units,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Just your regular densely-connected NN layer.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.DenseFeatures,"tf.keras.layers.DenseFeatures(
    feature_columns, trainable=True, name=None, **kwargs
)
","A layer that produces a dense Tensor based on given feature_columns.Inherits From: DenseFeatures, Layer, Module"
tf.keras.layers.DepthwiseConv1D,"tf.keras.layers.DepthwiseConv1D(
    kernel_size,
    strides=1,
    padding='valid',
    depth_multiplier=1,
    data_format=None,
    dilation_rate=1,
    activation=None,
    use_bias=True,
    depthwise_initializer='glorot_uniform',
    bias_initializer='zeros',
    depthwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Depthwise 1D convolution.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.DepthwiseConv2D,"tf.keras.layers.DepthwiseConv2D(
    kernel_size,
    strides=(1, 1),
    padding='valid',
    depth_multiplier=1,
    data_format=None,
    dilation_rate=(1, 1),
    activation=None,
    use_bias=True,
    depthwise_initializer='glorot_uniform',
    bias_initializer='zeros',
    depthwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Depthwise 2D convolution.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Discretization,"tf.keras.layers.Discretization(
    bin_boundaries=None,
    num_bins=None,
    epsilon=0.01,
    output_mode='int',
    sparse=False,
    **kwargs
)
","A preprocessing layer which buckets continuous features by ranges.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.Dot,"tf.keras.layers.Dot(
    axes, normalize=False, **kwargs
)
","Layer that computes a dot product between samples in two tensors.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Dropout,"tf.keras.layers.Dropout(
    rate, noise_shape=None, seed=None, **kwargs
)
","Applies Dropout to the input.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.ELU,"tf.keras.layers.ELU(
    alpha=1.0, **kwargs
)
","Exponential Linear Unit.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.EinsumDense,"tf.keras.layers.EinsumDense(
    equation,
    output_shape,
    activation=None,
    bias_axes=None,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","A layer that uses tf.einsum as the backing computation.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Embedding,"tf.keras.layers.Embedding(
    input_dim,
    output_dim,
    embeddings_initializer='uniform',
    embeddings_regularizer=None,
    activity_regularizer=None,
    embeddings_constraint=None,
    mask_zero=False,
    input_length=None,
    **kwargs
)
","Turns positive integers (indexes) into dense vectors of fixed size.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Flatten,"tf.keras.layers.Flatten(
    data_format=None, **kwargs
)
","Flattens the input. Does not affect the batch size.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GRU,"tf.keras.layers.GRU(
    units,
    activation='tanh',
    recurrent_activation='sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    dropout=0.0,
    recurrent_dropout=0.0,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    unroll=False,
    time_major=False,
    reset_after=True,
    **kwargs
)
","Gated Recurrent Unit - Cho et al. 2014.Inherits From: RNN, Layer, Module"
tf.keras.layers.GRUCell,"tf.keras.layers.GRUCell(
    units,
    activation='tanh',
    recurrent_activation='sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    dropout=0.0,
    recurrent_dropout=0.0,
    reset_after=True,
    **kwargs
)
","Cell class for the GRU layer.Inherits From: Layer, Module"
tf.keras.layers.GaussianDropout,"tf.keras.layers.GaussianDropout(
    rate, seed=None, **kwargs
)
","Apply multiplicative 1-centered Gaussian noise.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GaussianNoise,"tf.keras.layers.GaussianNoise(
    stddev, seed=None, **kwargs
)
","Apply additive zero-centered Gaussian noise.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalAveragePooling1D,"tf.keras.layers.GlobalAveragePooling1D(
    data_format='channels_last', **kwargs
)
","Global average pooling operation for temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalAveragePooling2D,"tf.keras.layers.GlobalAveragePooling2D(
    data_format=None, keepdims=False, **kwargs
)
","Global average pooling operation for spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalAveragePooling3D,"tf.keras.layers.GlobalAveragePooling3D(
    data_format=None, keepdims=False, **kwargs
)
","Global Average pooling operation for 3D data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalAveragePooling1D,"tf.keras.layers.GlobalAveragePooling1D(
    data_format='channels_last', **kwargs
)
","Global average pooling operation for temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalAveragePooling2D,"tf.keras.layers.GlobalAveragePooling2D(
    data_format=None, keepdims=False, **kwargs
)
","Global average pooling operation for spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalAveragePooling3D,"tf.keras.layers.GlobalAveragePooling3D(
    data_format=None, keepdims=False, **kwargs
)
","Global Average pooling operation for 3D data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalMaxPool1D,"tf.keras.layers.GlobalMaxPool1D(
    data_format='channels_last', keepdims=False, **kwargs
)
","Global max pooling operation for 1D temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalMaxPool2D,"tf.keras.layers.GlobalMaxPool2D(
    data_format=None, keepdims=False, **kwargs
)
","Global max pooling operation for spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalMaxPool3D,"tf.keras.layers.GlobalMaxPool3D(
    data_format=None, keepdims=False, **kwargs
)
","Global Max pooling operation for 3D data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalMaxPool1D,"tf.keras.layers.GlobalMaxPool1D(
    data_format='channels_last', keepdims=False, **kwargs
)
","Global max pooling operation for 1D temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalMaxPool2D,"tf.keras.layers.GlobalMaxPool2D(
    data_format=None, keepdims=False, **kwargs
)
","Global max pooling operation for spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalMaxPool3D,"tf.keras.layers.GlobalMaxPool3D(
    data_format=None, keepdims=False, **kwargs
)
","Global Max pooling operation for 3D data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Hashing,"tf.keras.layers.Hashing(
    num_bins,
    mask_value=None,
    salt=None,
    output_mode='int',
    sparse=False,
    **kwargs
)
","A preprocessing layer which hashes and bins categorical features.Inherits From: Layer, ModuleView aliases"
tf.keras.Input,"tf.keras.Input(
    shape=None,
    batch_size=None,
    name=None,
    dtype=None,
    sparse=None,
    tensor=None,
    ragged=None,
    type_spec=None,
    **kwargs
)
",Input() is used to instantiate a Keras tensor.View aliases
tf.keras.layers.InputLayer,"tf.keras.layers.InputLayer(
    input_shape=None,
    batch_size=None,
    dtype=None,
    input_tensor=None,
    sparse=None,
    name=None,
    ragged=None,
    type_spec=None,
    **kwargs
)
","Layer to be used as an entry point into a Network (a graph of layers).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.InputSpec,"tf.keras.layers.InputSpec(
    dtype=None,
    shape=None,
    ndim=None,
    max_ndim=None,
    min_ndim=None,
    axes=None,
    allow_last_axis_squeeze=False,
    name=None
)
","Specifies the rank, dtype and shape of every input to a layer.View aliases"
tf.keras.layers.IntegerLookup,"tf.keras.layers.IntegerLookup(
    max_tokens=None,
    num_oov_indices=1,
    mask_token=None,
    oov_token=-1,
    vocabulary=None,
    vocabulary_dtype='int64',
    idf_weights=None,
    invert=False,
    output_mode='int',
    sparse=False,
    pad_to_max_tokens=False,
    **kwargs
)
","A preprocessing layer which maps integer features to contiguous ranges.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.LSTM,"tf.keras.layers.LSTM(
    units,
    activation='tanh',
    recurrent_activation='sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    unit_forget_bias=True,
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    dropout=0.0,
    recurrent_dropout=0.0,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    time_major=False,
    unroll=False,
    **kwargs
)
","Long Short-Term Memory layer - Hochreiter 1997.Inherits From: RNN, Layer, Module"
tf.keras.layers.LSTMCell,"tf.keras.layers.LSTMCell(
    units,
    activation='tanh',
    recurrent_activation='sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    unit_forget_bias=True,
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    dropout=0.0,
    recurrent_dropout=0.0,
    **kwargs
)
","Cell class for the LSTM layer.Inherits From: Layer, Module"
tf.keras.layers.Lambda,"tf.keras.layers.Lambda(
    function, output_shape=None, mask=None, arguments=None, **kwargs
)
","Wraps arbitrary expressions as a Layer object.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Layer,"tf.keras.layers.Layer(
    trainable=True, name=None, dtype=None, dynamic=False, **kwargs
)
",This is the class from which all layers inherit.Inherits From: ModuleView aliases
tf.keras.layers.LayerNormalization,"tf.keras.layers.LayerNormalization(
    axis=-1,
    epsilon=0.001,
    center=True,
    scale=True,
    beta_initializer='zeros',
    gamma_initializer='ones',
    beta_regularizer=None,
    gamma_regularizer=None,
    beta_constraint=None,
    gamma_constraint=None,
    **kwargs
)
","Layer normalization layer (Ba et al., 2016).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.LeakyReLU,"tf.keras.layers.LeakyReLU(
    alpha=0.3, **kwargs
)
","Leaky version of a Rectified Linear Unit.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.LocallyConnected1D,"tf.keras.layers.LocallyConnected1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format=None,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    implementation=1,
    **kwargs
)
","Locally-connected layer for 1D inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.LocallyConnected2D,"tf.keras.layers.LocallyConnected2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format=None,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    implementation=1,
    **kwargs
)
","Locally-connected layer for 2D inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Masking,"tf.keras.layers.Masking(
    mask_value=0.0, **kwargs
)
","Masks a sequence by using a mask value to skip timesteps.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.MaxPool1D,"tf.keras.layers.MaxPool1D(
    pool_size=2,
    strides=None,
    padding='valid',
    data_format='channels_last',
    **kwargs
)
","Max pooling operation for 1D temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.MaxPool2D,"tf.keras.layers.MaxPool2D(
    pool_size=(2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Max pooling operation for 2D spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.MaxPool3D,"tf.keras.layers.MaxPool3D(
    pool_size=(2, 2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Max pooling operation for 3D data (spatial or spatio-temporal).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.MaxPool1D,"tf.keras.layers.MaxPool1D(
    pool_size=2,
    strides=None,
    padding='valid',
    data_format='channels_last',
    **kwargs
)
","Max pooling operation for 1D temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.MaxPool2D,"tf.keras.layers.MaxPool2D(
    pool_size=(2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Max pooling operation for 2D spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.MaxPool3D,"tf.keras.layers.MaxPool3D(
    pool_size=(2, 2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Max pooling operation for 3D data (spatial or spatio-temporal).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Maximum,"tf.keras.layers.Maximum(
    **kwargs
)
","Layer that computes the maximum (element-wise) a list of inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Maximum,"tf.keras.layers.Maximum()([np.arange(5).reshape(5, 1),","Layer that computes the maximum (element-wise) a list of inputs.Inherits From: Layer, ModuleView aliasestf.keras.layers.Maximum(    **kwargs)It takes as input a list of tensors, all of the same shape, and returnsa single tensor (also of the same shape)."
tf.keras.layers.Minimum,"tf.keras.layers.Minimum(
    **kwargs
)
","Layer that computes the minimum (element-wise) a list of inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Minimum,"tf.keras.layers.Minimum()([np.arange(5).reshape(5, 1),","Layer that computes the minimum (element-wise) a list of inputs.Inherits From: Layer, ModuleView aliasestf.keras.layers.Minimum(    **kwargs)It takes as input a list of tensors, all of the same shape, and returnsa single tensor (also of the same shape)."
tf.keras.layers.MultiHeadAttention,"tf.keras.layers.MultiHeadAttention(
    num_heads,
    key_dim,
    value_dim=None,
    dropout=0.0,
    use_bias=True,
    output_shape=None,
    attention_axes=None,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","MultiHeadAttention layer.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Multiply,"tf.keras.layers.Multiply(
    **kwargs
)
","Layer that multiplies (element-wise) a list of inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Multiply,"tf.keras.layers.Multiply()([np.arange(5).reshape(5, 1),","Layer that multiplies (element-wise) a list of inputs.Inherits From: Layer, ModuleView aliasestf.keras.layers.Multiply(    **kwargs)It takes as input a list of tensors, all of the same shape, and returnsa single tensor (also of the same shape)."
tf.keras.layers.Normalization,"tf.keras.layers.Normalization(
    axis=-1, mean=None, variance=None, invert=False, **kwargs
)
","A preprocessing layer which normalizes continuous features.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.PReLU,"tf.keras.layers.PReLU(
    alpha_initializer='zeros',
    alpha_regularizer=None,
    alpha_constraint=None,
    shared_axes=None,
    **kwargs
)
","Parametric Rectified Linear Unit.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Permute,"tf.keras.layers.Permute(
    dims, **kwargs
)
","Permutes the dimensions of the input according to a given pattern.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RNN,"tf.keras.layers.RNN(
    cell,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    unroll=False,
    time_major=False,
    **kwargs
)
","Base class for recurrent layers.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomBrightness,"tf.keras.layers.RandomBrightness(
    factor, value_range=(0, 255), seed=None, **kwargs
)
","A preprocessing layer which randomly adjusts brightness during training.Inherits From: Layer, Module"
tf.keras.layers.RandomContrast,"tf.keras.layers.RandomContrast(
    factor, seed=None, **kwargs
)
","A preprocessing layer which randomly adjusts contrast during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomCrop,"tf.keras.layers.RandomCrop(
    height, width, seed=None, **kwargs
)
","A preprocessing layer which randomly crops images during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomFlip,"tf.keras.layers.RandomFlip(
    mode=HORIZONTAL_AND_VERTICAL, seed=None, **kwargs
)
","A preprocessing layer which randomly flips images during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomHeight,"tf.keras.layers.RandomHeight(
    factor, interpolation='bilinear', seed=None, **kwargs
)
","A preprocessing layer which randomly varies image height during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomRotation,"tf.keras.layers.RandomRotation(
    factor,
    fill_mode='reflect',
    interpolation='bilinear',
    seed=None,
    fill_value=0.0,
    **kwargs
)
","A preprocessing layer which randomly rotates images during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomTranslation,"tf.keras.layers.RandomTranslation(
    height_factor,
    width_factor,
    fill_mode='reflect',
    interpolation='bilinear',
    seed=None,
    fill_value=0.0,
    **kwargs
)
","A preprocessing layer which randomly translates images during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomWidth,"tf.keras.layers.RandomWidth(
    factor, interpolation='bilinear', seed=None, **kwargs
)
","A preprocessing layer which randomly varies image width during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomZoom,"tf.keras.layers.RandomZoom(
    height_factor,
    width_factor=None,
    fill_mode='reflect',
    interpolation='bilinear',
    seed=None,
    fill_value=0.0,
    **kwargs
)
","A preprocessing layer which randomly zooms images during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.ReLU,"tf.keras.layers.ReLU(
    max_value=None, negative_slope=0.0, threshold=0.0, **kwargs
)
","Rectified Linear Unit activation function.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RepeatVector,"tf.keras.layers.RepeatVector(
    n, **kwargs
)
","Repeats the input n times.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Rescaling,"tf.keras.layers.Rescaling(
    scale, offset=0.0, **kwargs
)
","A preprocessing layer which rescales input values to a new range.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Reshape,"tf.keras.layers.Reshape(
    target_shape, **kwargs
)
","Layer that reshapes inputs into the given shape.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Resizing,"tf.keras.layers.Resizing(
    height,
    width,
    interpolation='bilinear',
    crop_to_aspect_ratio=False,
    **kwargs
)
","A preprocessing layer which resizes images.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.SeparableConv1D,"tf.keras.layers.SeparableConv1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format=None,
    dilation_rate=1,
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    depthwise_initializer='glorot_uniform',
    pointwise_initializer='glorot_uniform',
    bias_initializer='zeros',
    depthwise_regularizer=None,
    pointwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    pointwise_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Depthwise separable 1D convolution.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.SeparableConv2D,"tf.keras.layers.SeparableConv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1),
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    depthwise_initializer='glorot_uniform',
    pointwise_initializer='glorot_uniform',
    bias_initializer='zeros',
    depthwise_regularizer=None,
    pointwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    pointwise_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Depthwise separable 2D convolution.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.SeparableConv1D,"tf.keras.layers.SeparableConv1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format=None,
    dilation_rate=1,
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    depthwise_initializer='glorot_uniform',
    pointwise_initializer='glorot_uniform',
    bias_initializer='zeros',
    depthwise_regularizer=None,
    pointwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    pointwise_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Depthwise separable 1D convolution.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.SeparableConv2D,"tf.keras.layers.SeparableConv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1),
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    depthwise_initializer='glorot_uniform',
    pointwise_initializer='glorot_uniform',
    bias_initializer='zeros',
    depthwise_regularizer=None,
    pointwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    pointwise_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Depthwise separable 2D convolution.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.SimpleRNN,"tf.keras.layers.SimpleRNN(
    units,
    activation='tanh',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    dropout=0.0,
    recurrent_dropout=0.0,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    unroll=False,
    **kwargs
)
","Fully-connected RNN where the output is to be fed back to input.Inherits From: RNN, Layer, ModuleView aliases"
tf.keras.layers.SimpleRNNCell,"tf.keras.layers.SimpleRNNCell(
    units,
    activation='tanh',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    dropout=0.0,
    recurrent_dropout=0.0,
    **kwargs
)
","Cell class for SimpleRNN.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Softmax,"tf.keras.layers.Softmax(
    axis=-1, **kwargs
)
","Softmax activation function.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.SpatialDropout1D,"tf.keras.layers.SpatialDropout1D(
    rate, **kwargs
)
","Spatial 1D version of Dropout.Inherits From: Dropout, Layer, ModuleView aliases"
tf.keras.layers.SpatialDropout2D,"tf.keras.layers.SpatialDropout2D(
    rate, data_format=None, **kwargs
)
","Spatial 2D version of Dropout.Inherits From: Dropout, Layer, ModuleView aliases"
tf.keras.layers.SpatialDropout3D,"tf.keras.layers.SpatialDropout3D(
    rate, data_format=None, **kwargs
)
","Spatial 3D version of Dropout.Inherits From: Dropout, Layer, ModuleView aliases"
tf.keras.layers.StackedRNNCells,"tf.keras.layers.StackedRNNCells(
    cells, **kwargs
)
","Wrapper allowing a stack of RNN cells to behave as a single cell.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.StringLookup,"tf.keras.layers.StringLookup(
    max_tokens=None,
    num_oov_indices=1,
    mask_token=None,
    oov_token='[UNK]',
    vocabulary=None,
    idf_weights=None,
    encoding=None,
    invert=False,
    output_mode='int',
    sparse=False,
    pad_to_max_tokens=False,
    **kwargs
)
","A preprocessing layer which maps string features to integer indices.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.Subtract,"tf.keras.layers.Subtract(
    **kwargs
)
","Layer that subtracts two inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.TextVectorization,"tf.keras.layers.TextVectorization(
    max_tokens=None,
    standardize='lower_and_strip_punctuation',
    split='whitespace',
    ngrams=None,
    output_mode='int',
    output_sequence_length=None,
    pad_to_max_tokens=False,
    vocabulary=None,
    idf_weights=None,
    sparse=False,
    ragged=False,
    **kwargs
)
","A preprocessing layer which maps text features to integer sequences.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.ThresholdedReLU,"tf.keras.layers.ThresholdedReLU(
    theta=1.0, **kwargs
)
","Thresholded Rectified Linear Unit.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.TimeDistributed,"tf.keras.layers.TimeDistributed(
    layer, **kwargs
)
","This wrapper allows to apply a layer to every temporal slice of an input.Inherits From: Wrapper, Layer, ModuleView aliases"
tf.keras.layers.UnitNormalization,"tf.keras.layers.UnitNormalization(
    axis=-1, **kwargs
)
","Unit normalization layer.Inherits From: Layer, Module"
tf.keras.layers.UpSampling1D,"tf.keras.layers.UpSampling1D(
    size=2, **kwargs
)
","Upsampling layer for 1D inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.UpSampling2D,"tf.keras.layers.UpSampling2D(
    size=(2, 2), data_format=None, interpolation='nearest', **kwargs
)
","Upsampling layer for 2D inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.UpSampling3D,"tf.keras.layers.UpSampling3D(
    size=(2, 2, 2), data_format=None, **kwargs
)
","Upsampling layer for 3D inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Wrapper,"tf.keras.layers.Wrapper(
    layer, **kwargs
)
","Abstract wrapper base class.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.ZeroPadding1D,"tf.keras.layers.ZeroPadding1D(
    padding=1, **kwargs
)
","Zero-padding layer for 1D input (e.g. temporal sequence).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.ZeroPadding2D,"tf.keras.layers.ZeroPadding2D(
    padding=(1, 1), data_format=None, **kwargs
)
","Zero-padding layer for 2D input (e.g. picture).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.ZeroPadding3D,"tf.keras.layers.ZeroPadding3D(
    padding=(1, 1, 1), data_format=None, **kwargs
)
","Zero-padding layer for 3D data (spatial or spatio-temporal).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.add,"tf.keras.layers.add(
    inputs, **kwargs
)
",Functional interface to the tf.keras.layers.Add layer.View aliases
tf.keras.layers.average,"tf.keras.layers.average(
    inputs, **kwargs
)
",Functional interface to the tf.keras.layers.Average layer.View aliases
tf.keras.layers.concatenate,"tf.keras.layers.concatenate(
    inputs, axis=-1, **kwargs
)
",Functional interface to the Concatenate layer.View aliases
tf.keras.layers.deserialize,"tf.keras.layers.deserialize(
    config, custom_objects=None
)
",Instantiates a layer from a config dictionary.View aliases
tf.keras.layers.dot,"tf.keras.layers.dot(
    inputs, axes, normalize=False, **kwargs
)
",Functional interface to the Dot layer.View aliases
tf.keras.layers.EinsumDense,"tf.keras.layers.EinsumDense(
    equation,
    output_shape,
    activation=None,
    bias_axes=None,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","A layer that uses tf.einsum as the backing computation.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.experimental.RandomFourierFeatures,"tf.keras.layers.experimental.RandomFourierFeatures(
    output_dim,
    kernel_initializer='gaussian',
    scale=None,
    trainable=False,
    name=None,
    **kwargs
)
","Layer that projects its inputs into a random feature space.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.experimental.SyncBatchNormalization,"tf.keras.layers.experimental.SyncBatchNormalization(
    axis=-1,
    momentum=0.99,
    epsilon=0.001,
    center=True,
    scale=True,
    beta_initializer='zeros',
    gamma_initializer='ones',
    moving_mean_initializer='zeros',
    moving_variance_initializer='ones',
    beta_regularizer=None,
    gamma_regularizer=None,
    beta_constraint=None,
    gamma_constraint=None,
    **kwargs
)
","Normalize and scale inputs or activations synchronously across replicas.Inherits From: Layer, Module"
tf.keras.layers.CategoryEncoding,"tf.keras.layers.CategoryEncoding(
    num_tokens=None, output_mode='multi_hot', sparse=False, **kwargs
)
","A preprocessing layer which encodes integer features.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.CenterCrop,"tf.keras.layers.CenterCrop(
    height, width, **kwargs
)
","A preprocessing layer which crops images.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Discretization,"tf.keras.layers.Discretization(
    bin_boundaries=None,
    num_bins=None,
    epsilon=0.01,
    output_mode='int',
    sparse=False,
    **kwargs
)
","A preprocessing layer which buckets continuous features by ranges.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.experimental.preprocessing.HashedCrossing,"tf.keras.layers.experimental.preprocessing.HashedCrossing(
    num_bins, output_mode='int', sparse=False, **kwargs
)
","A preprocessing layer which crosses features using the ""hashing trick"".Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Hashing,"tf.keras.layers.Hashing(
    num_bins,
    mask_value=None,
    salt=None,
    output_mode='int',
    sparse=False,
    **kwargs
)
","A preprocessing layer which hashes and bins categorical features.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.IntegerLookup,"tf.keras.layers.IntegerLookup(
    max_tokens=None,
    num_oov_indices=1,
    mask_token=None,
    oov_token=-1,
    vocabulary=None,
    vocabulary_dtype='int64',
    idf_weights=None,
    invert=False,
    output_mode='int',
    sparse=False,
    pad_to_max_tokens=False,
    **kwargs
)
","A preprocessing layer which maps integer features to contiguous ranges.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.Normalization,"tf.keras.layers.Normalization(
    axis=-1, mean=None, variance=None, invert=False, **kwargs
)
","A preprocessing layer which normalizes continuous features.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.experimental.preprocessing.PreprocessingLayer,"tf.keras.layers.experimental.preprocessing.PreprocessingLayer(
    **kwargs
)
","Base class for Preprocessing Layers.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomContrast,"tf.keras.layers.RandomContrast(
    factor, seed=None, **kwargs
)
","A preprocessing layer which randomly adjusts contrast during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomCrop,"tf.keras.layers.RandomCrop(
    height, width, seed=None, **kwargs
)
","A preprocessing layer which randomly crops images during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomFlip,"tf.keras.layers.RandomFlip(
    mode=HORIZONTAL_AND_VERTICAL, seed=None, **kwargs
)
","A preprocessing layer which randomly flips images during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomHeight,"tf.keras.layers.RandomHeight(
    factor, interpolation='bilinear', seed=None, **kwargs
)
","A preprocessing layer which randomly varies image height during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomRotation,"tf.keras.layers.RandomRotation(
    factor,
    fill_mode='reflect',
    interpolation='bilinear',
    seed=None,
    fill_value=0.0,
    **kwargs
)
","A preprocessing layer which randomly rotates images during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomTranslation,"tf.keras.layers.RandomTranslation(
    height_factor,
    width_factor,
    fill_mode='reflect',
    interpolation='bilinear',
    seed=None,
    fill_value=0.0,
    **kwargs
)
","A preprocessing layer which randomly translates images during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomWidth,"tf.keras.layers.RandomWidth(
    factor, interpolation='bilinear', seed=None, **kwargs
)
","A preprocessing layer which randomly varies image width during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RandomZoom,"tf.keras.layers.RandomZoom(
    height_factor,
    width_factor=None,
    fill_mode='reflect',
    interpolation='bilinear',
    seed=None,
    fill_value=0.0,
    **kwargs
)
","A preprocessing layer which randomly zooms images during training.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Rescaling,"tf.keras.layers.Rescaling(
    scale, offset=0.0, **kwargs
)
","A preprocessing layer which rescales input values to a new range.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Resizing,"tf.keras.layers.Resizing(
    height,
    width,
    interpolation='bilinear',
    crop_to_aspect_ratio=False,
    **kwargs
)
","A preprocessing layer which resizes images.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.StringLookup,"tf.keras.layers.StringLookup(
    max_tokens=None,
    num_oov_indices=1,
    mask_token=None,
    oov_token='[UNK]',
    vocabulary=None,
    idf_weights=None,
    encoding=None,
    invert=False,
    output_mode='int',
    sparse=False,
    pad_to_max_tokens=False,
    **kwargs
)
","A preprocessing layer which maps string features to integer indices.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.TextVectorization,"tf.keras.layers.TextVectorization(
    max_tokens=None,
    standardize='lower_and_strip_punctuation',
    split='whitespace',
    ngrams=None,
    output_mode='int',
    output_sequence_length=None,
    pad_to_max_tokens=False,
    vocabulary=None,
    idf_weights=None,
    sparse=False,
    ragged=False,
    **kwargs
)
","A preprocessing layer which maps text features to integer sequences.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.maximum,"tf.keras.layers.maximum(
    inputs, **kwargs
)
",Functional interface to compute maximum (element-wise) list of inputs.View aliases
tf.keras.layers.minimum,"tf.keras.layers.minimum(
    inputs, **kwargs
)
",Functional interface to the Minimum layer.View aliases
tf.keras.layers.multiply,"tf.keras.layers.multiply(
    inputs, **kwargs
)
",Functional interface to the Multiply layer.View aliases
tf.keras.layers.serialize,"tf.keras.layers.serialize(
    layer
)
",Serializes a Layer object into a JSON-compatible representation.View aliases
tf.keras.layers.subtract,"tf.keras.layers.subtract(
    inputs, **kwargs
)
",Functional interface to the Subtract layer.View aliases
tf.keras.losses.BinaryCrossentropy,"tf.keras.losses.BinaryCrossentropy(
    from_logits=False,
    label_smoothing=0.0,
    axis=-1,
    reduction=losses_utils.ReductionV2.AUTO,
    name='binary_crossentropy'
)
",Computes the cross-entropy loss between true labels and predicted labels.Inherits From: LossView aliases
tf.keras.losses.BinaryFocalCrossentropy,"tf.keras.losses.BinaryFocalCrossentropy(
    apply_class_balancing=False,
    alpha=0.25,
    gamma=2.0,
    from_logits=False,
    label_smoothing=0.0,
    axis=-1,
    reduction=losses_utils.ReductionV2.AUTO,
    name='binary_focal_crossentropy'
)
",Computes the focal cross-entropy loss between true labels and predictions.Inherits From: LossView aliases
tf.keras.losses.CategoricalCrossentropy,"tf.keras.losses.CategoricalCrossentropy(
    from_logits=False,
    label_smoothing=0.0,
    axis=-1,
    reduction=losses_utils.ReductionV2.AUTO,
    name='categorical_crossentropy'
)
",Computes the crossentropy loss between the labels and predictions.Inherits From: LossView aliases
tf.keras.losses.CategoricalHinge,"tf.keras.losses.CategoricalHinge(
    reduction=losses_utils.ReductionV2.AUTO, name='categorical_hinge'
)
",Computes the categorical hinge loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.CosineSimilarity,"tf.keras.losses.CosineSimilarity(
    axis=-1,
    reduction=losses_utils.ReductionV2.AUTO,
    name='cosine_similarity'
)
",Computes the cosine similarity between labels and predictions.Inherits From: LossView aliases
tf.keras.losses.Hinge,"tf.keras.losses.Hinge(
    reduction=losses_utils.ReductionV2.AUTO, name='hinge'
)
",Computes the hinge loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.Huber,"tf.keras.losses.Huber(
    delta=1.0,
    reduction=losses_utils.ReductionV2.AUTO,
    name='huber_loss'
)
",Computes the Huber loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.losses.KLDivergence,"tf.keras.losses.KLDivergence(
    reduction=losses_utils.ReductionV2.AUTO, name='kl_divergence'
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.LogCosh,"tf.keras.losses.LogCosh(
    reduction=losses_utils.ReductionV2.AUTO, name='log_cosh'
)
",Computes the logarithm of the hyperbolic cosine of the prediction error.Inherits From: LossView aliases
tf.keras.losses.Loss,"tf.keras.losses.Loss(
    reduction=losses_utils.ReductionV2.AUTO, name=None
)
",Loss base class.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.losses.MeanAbsoluteError,"tf.keras.losses.MeanAbsoluteError(
    reduction=losses_utils.ReductionV2.AUTO,
    name='mean_absolute_error'
)
",Computes the mean of absolute difference between labels and predictions.Inherits From: LossView aliases
tf.keras.losses.MeanAbsolutePercentageError,"tf.keras.losses.MeanAbsolutePercentageError(
    reduction=losses_utils.ReductionV2.AUTO,
    name='mean_absolute_percentage_error'
)
",Computes the mean absolute percentage error between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.MeanSquaredError,"tf.keras.losses.MeanSquaredError(
    reduction=losses_utils.ReductionV2.AUTO,
    name='mean_squared_error'
)
",Computes the mean of squares of errors between labels and predictions.Inherits From: LossView aliases
tf.keras.losses.MeanSquaredLogarithmicError,"tf.keras.losses.MeanSquaredLogarithmicError(
    reduction=losses_utils.ReductionV2.AUTO,
    name='mean_squared_logarithmic_error'
)
",Computes the mean squared logarithmic error between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.Poisson,"tf.keras.losses.Poisson(
    reduction=losses_utils.ReductionV2.AUTO, name='poisson'
)
",Computes the Poisson loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.SparseCategoricalCrossentropy,"tf.keras.losses.SparseCategoricalCrossentropy(
    from_logits=False,
    ignore_class=None,
    reduction=losses_utils.ReductionV2.AUTO,
    name='sparse_categorical_crossentropy'
)
",Computes the crossentropy loss between the labels and predictions.Inherits From: LossView aliases
tf.keras.losses.SquaredHinge,"tf.keras.losses.SquaredHinge(
    reduction=losses_utils.ReductionV2.AUTO, name='squared_hinge'
)
",Computes the squared hinge loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.metrics.binary_crossentropy,"tf.keras.metrics.binary_crossentropy(
    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1
)
",Computes the binary crossentropy loss.View aliases
tf.keras.metrics.binary_focal_crossentropy,"tf.keras.metrics.binary_focal_crossentropy(
    y_true,
    y_pred,
    apply_class_balancing=False,
    alpha=0.25,
    gamma=2.0,
    from_logits=False,
    label_smoothing=0.0,
    axis=-1
)
",Computes the binary focal crossentropy loss.View aliases
tf.keras.metrics.categorical_crossentropy,"tf.keras.metrics.categorical_crossentropy(
    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1
)
",Computes the categorical crossentropy loss.View aliases
tf.keras.losses.categorical_hinge,"tf.keras.losses.categorical_hinge(
    y_true, y_pred
)
",Computes the categorical hinge loss between y_true and y_pred.View aliases
tf.keras.losses.cosine_similarity,"tf.keras.losses.cosine_similarity(
    y_true, y_pred, axis=-1
)
",Computes the cosine similarity between labels and predictions.View aliases
tf.keras.losses.deserialize,"tf.keras.losses.deserialize(
    name, custom_objects=None
)
",Deserializes a serialized loss class/function instance.View aliases
tf.keras.losses.get,"tf.keras.losses.get(
    identifier
)
",Retrieves a Keras loss as a function/Loss class instance.View aliases
tf.keras.metrics.hinge,"tf.keras.metrics.hinge(
    y_true, y_pred
)
",Computes the hinge loss between y_true and y_pred.View aliases
tf.keras.losses.huber,"tf.keras.losses.huber(
    y_true, y_pred, delta=1.0
)
",Computes Huber loss value.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.losses.log_cosh,"tf.keras.losses.log_cosh(
    y_true, y_pred
)
",Logarithm of the hyperbolic cosine of the prediction error.View aliases
tf.keras.losses.log_cosh,"tf.keras.losses.log_cosh(
    y_true, y_pred
)
",Logarithm of the hyperbolic cosine of the prediction error.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.poisson,"tf.keras.metrics.poisson(
    y_true, y_pred
)
",Computes the Poisson loss between y_true and y_pred.View aliases
tf.keras.losses.serialize,"tf.keras.losses.serialize(
    loss
)
",Serializes loss function or Loss instance.View aliases
tf.keras.metrics.sparse_categorical_crossentropy,"tf.keras.metrics.sparse_categorical_crossentropy(
    y_true, y_pred, from_logits=False, axis=-1, ignore_class=None
)
",Computes the sparse categorical crossentropy loss.View aliases
tf.keras.metrics.squared_hinge,"tf.keras.metrics.squared_hinge(
    y_true, y_pred
)
",Computes the squared hinge loss between y_true and y_pred.View aliases
tf.keras.metrics.AUC,"tf.keras.metrics.AUC(
    num_thresholds=200,
    curve='ROC',
    summation_method='interpolation',
    name=None,
    dtype=None,
    thresholds=None,
    multi_label=False,
    num_labels=None,
    label_weights=None,
    from_logits=False
)
","Approximates the AUC (Area under the curve) of the ROC or PR curves.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.Accuracy,"tf.keras.metrics.Accuracy(
    name='accuracy', dtype=None
)
","Calculates how often predictions equal labels.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.BinaryAccuracy,"tf.keras.metrics.BinaryAccuracy(
    name='binary_accuracy', dtype=None, threshold=0.5
)
","Calculates how often predictions match binary labels.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.BinaryCrossentropy,"tf.keras.metrics.BinaryCrossentropy(
    name='binary_crossentropy',
    dtype=None,
    from_logits=False,
    label_smoothing=0
)
","Computes the crossentropy metric between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.BinaryIoU,"tf.keras.metrics.BinaryIoU(
    target_class_ids: Union[List[int], Tuple[int, ...]] = (0, 1),
    threshold=0.5,
    name=None,
    dtype=None
)
","Computes the Intersection-Over-Union metric for class 0 and/or 1.Inherits From: IoU, Metric, Layer, ModuleView aliases"
tf.keras.metrics.CategoricalAccuracy,"tf.keras.metrics.CategoricalAccuracy(
    name='categorical_accuracy', dtype=None
)
","Calculates how often predictions match one-hot labels.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.CategoricalCrossentropy,"tf.keras.metrics.CategoricalCrossentropy(
    name='categorical_crossentropy',
    dtype=None,
    from_logits=False,
    label_smoothing=0,
    axis=-1
)
","Computes the crossentropy metric between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.CategoricalHinge,"tf.keras.metrics.CategoricalHinge(
    name='categorical_hinge', dtype=None
)
","Computes the categorical hinge metric between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.CosineSimilarity,"tf.keras.metrics.CosineSimilarity(
    name='cosine_similarity', dtype=None, axis=-1
)
","Computes the cosine similarity between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.FalseNegatives,"tf.keras.metrics.FalseNegatives(
    thresholds=None, name=None, dtype=None
)
","Calculates the number of false negatives.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.FalsePositives,"tf.keras.metrics.FalsePositives(
    thresholds=None, name=None, dtype=None
)
","Calculates the number of false positives.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.Hinge,"tf.keras.metrics.Hinge(
    name='hinge', dtype=None
)
","Computes the hinge metric between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.IoU,"tf.keras.metrics.IoU(
    num_classes: int,
    target_class_ids: Union[List[int], Tuple[int, ...]],
    name: Optional[str] = None,
    dtype: Optional[Union[str, tf.dtypes.DType]] = None,
    ignore_class: Optional[int] = None,
    sparse_y_true: bool = True,
    sparse_y_pred: bool = True,
    axis: int = -1
)
","Computes the Intersection-Over-Union metric for specific target classes.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.KLDivergence,"tf.keras.metrics.KLDivergence(
    name='kullback_leibler_divergence', dtype=None
)
","Computes Kullback-Leibler divergence metric between y_true andInherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.LogCoshError,"tf.keras.metrics.LogCoshError(
    name='logcosh', dtype=None
)
","Computes the logarithm of the hyperbolic cosine of the prediction error.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.Mean,"tf.keras.metrics.Mean(
    name='mean', dtype=None
)
","Computes the (weighted) mean of the given values.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanAbsoluteError,"tf.keras.metrics.MeanAbsoluteError(
    name='mean_absolute_error', dtype=None
)
","Computes the mean absolute error between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanAbsolutePercentageError,"tf.keras.metrics.MeanAbsolutePercentageError(
    name='mean_absolute_percentage_error', dtype=None
)
","Computes the mean absolute percentage error between y_true andInherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanIoU,"tf.keras.metrics.MeanIoU(
    num_classes: int,
    name: Optional[str] = None,
    dtype: Optional[Union[str, tf.dtypes.DType]] = None,
    ignore_class: Optional[int] = None,
    sparse_y_true: bool = True,
    sparse_y_pred: bool = True,
    axis: int = -1
)
","Computes the mean Intersection-Over-Union metric.Inherits From: IoU, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanMetricWrapper,"tf.keras.metrics.MeanMetricWrapper(
    fn, name=None, dtype=None, **kwargs
)
","Wraps a stateless metric function with the Mean metric.Inherits From: Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanRelativeError,"tf.keras.metrics.MeanRelativeError(
    normalizer, name=None, dtype=None
)
","Computes the mean relative error by normalizing with the given values.Inherits From: Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanSquaredError,"tf.keras.metrics.MeanSquaredError(
    name='mean_squared_error', dtype=None
)
","Computes the mean squared error between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanSquaredLogarithmicError,"tf.keras.metrics.MeanSquaredLogarithmicError(
    name='mean_squared_logarithmic_error', dtype=None
)
","Computes the mean squared logarithmic error between y_true andInherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanTensor,"tf.keras.metrics.MeanTensor(
    name='mean_tensor', dtype=None, shape=None
)
","Computes the element-wise (weighted) mean of the given tensors.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.Metric,"tf.keras.metrics.Metric(
    name=None, dtype=None, **kwargs
)
","Encapsulates metric logic and state.Inherits From: Layer, ModuleView aliases"
tf.keras.metrics.OneHotIoU,"tf.keras.metrics.OneHotIoU(
    num_classes: int,
    target_class_ids: Union[List[int], Tuple[int, ...]],
    name=None,
    dtype=None,
    ignore_class: Optional[int] = None,
    sparse_y_pred: bool = False,
    axis: int = -1
)
","Computes the Intersection-Over-Union metric for one-hot encoded labels.Inherits From: IoU, Metric, Layer, ModuleView aliases"
tf.keras.metrics.OneHotMeanIoU,"tf.keras.metrics.OneHotMeanIoU(
    num_classes: int,
    name: str = None,
    dtype: Optional[Union[str, tf.dtypes.DType]] = None,
    ignore_class: Optional[int] = None,
    sparse_y_pred: bool = False,
    axis: int = -1
)
","Computes mean Intersection-Over-Union metric for one-hot encoded labels.Inherits From: MeanIoU, IoU, Metric, Layer, ModuleView aliases"
tf.keras.metrics.Poisson,"tf.keras.metrics.Poisson(
    name='poisson', dtype=None
)
","Computes the Poisson metric between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.Precision,"tf.keras.metrics.Precision(
    thresholds=None, top_k=None, class_id=None, name=None, dtype=None
)
","Computes the precision of the predictions with respect to the labels.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.PrecisionAtRecall,"tf.keras.metrics.PrecisionAtRecall(
    recall, num_thresholds=200, class_id=None, name=None, dtype=None
)
","Computes best precision where recall is >= specified value.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.Recall,"tf.keras.metrics.Recall(
    thresholds=None, top_k=None, class_id=None, name=None, dtype=None
)
","Computes the recall of the predictions with respect to the labels.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.RecallAtPrecision,"tf.keras.metrics.RecallAtPrecision(
    precision, num_thresholds=200, class_id=None, name=None, dtype=None
)
","Computes best recall where precision is >= specified value.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.RootMeanSquaredError,"tf.keras.metrics.RootMeanSquaredError(
    name='root_mean_squared_error', dtype=None
)
","Computes root mean squared error metric between y_true and y_pred.Inherits From: Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.SensitivityAtSpecificity,"tf.keras.metrics.SensitivityAtSpecificity(
    specificity, num_thresholds=200, class_id=None, name=None, dtype=None
)
","Computes best sensitivity where specificity is >= specified value.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.SparseCategoricalAccuracy,"tf.keras.metrics.SparseCategoricalAccuracy(
    name='sparse_categorical_accuracy', dtype=None
)
","Calculates how often predictions match integer labels.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.SparseCategoricalCrossentropy,"tf.keras.metrics.SparseCategoricalCrossentropy(
    name: str = 'sparse_categorical_crossentropy',
    dtype: Optional[Union[str, tf.dtypes.DType]] = None,
    from_logits: bool = False,
    ignore_class: Optional[int] = None,
    axis: int = -1
)
","Computes the crossentropy metric between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.SparseTopKCategoricalAccuracy,"tf.keras.metrics.SparseTopKCategoricalAccuracy(
    k=5, name='sparse_top_k_categorical_accuracy', dtype=None
)
","Computes how often integer targets are in the top K predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.SpecificityAtSensitivity,"tf.keras.metrics.SpecificityAtSensitivity(
    sensitivity, num_thresholds=200, class_id=None, name=None, dtype=None
)
","Computes best specificity where sensitivity is >= specified value.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.SquaredHinge,"tf.keras.metrics.SquaredHinge(
    name='squared_hinge', dtype=None
)
","Computes the squared hinge metric between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.Sum,"tf.keras.metrics.Sum(
    name='sum', dtype=None
)
","Computes the (weighted) sum of the given values.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.TopKCategoricalAccuracy,"tf.keras.metrics.TopKCategoricalAccuracy(
    k=5, name='top_k_categorical_accuracy', dtype=None
)
","Computes how often targets are in the top K predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.TrueNegatives,"tf.keras.metrics.TrueNegatives(
    thresholds=None, name=None, dtype=None
)
","Calculates the number of true negatives.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.TruePositives,"tf.keras.metrics.TruePositives(
    thresholds=None, name=None, dtype=None
)
","Calculates the number of true positives.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.binary_accuracy,"tf.keras.metrics.binary_accuracy(
    y_true, y_pred, threshold=0.5
)
",Calculates how often predictions match binary labels.View aliases
tf.keras.metrics.binary_crossentropy,"tf.keras.metrics.binary_crossentropy(
    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1
)
",Computes the binary crossentropy loss.View aliases
tf.keras.metrics.binary_focal_crossentropy,"tf.keras.metrics.binary_focal_crossentropy(
    y_true,
    y_pred,
    apply_class_balancing=False,
    alpha=0.25,
    gamma=2.0,
    from_logits=False,
    label_smoothing=0.0,
    axis=-1
)
",Computes the binary focal crossentropy loss.View aliases
tf.keras.metrics.categorical_accuracy,"tf.keras.metrics.categorical_accuracy(
    y_true, y_pred
)
",Calculates how often predictions match one-hot labels.View aliases
tf.keras.metrics.categorical_crossentropy,"tf.keras.metrics.categorical_crossentropy(
    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1
)
",Computes the categorical crossentropy loss.View aliases
tf.keras.metrics.deserialize,"tf.keras.metrics.deserialize(
    config, custom_objects=None
)
",Deserializes a serialized metric class/function instance.View aliases
tf.keras.metrics.get,"tf.keras.metrics.get(
    identifier
)
",Retrieves a Keras metric as a function/Metric class instance.View aliases
tf.keras.metrics.hinge,"tf.keras.metrics.hinge(
    y_true, y_pred
)
",Computes the hinge loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.losses.log_cosh,"tf.keras.losses.log_cosh(
    y_true, y_pred
)
",Logarithm of the hyperbolic cosine of the prediction error.View aliases
tf.keras.losses.log_cosh,"tf.keras.losses.log_cosh(
    y_true, y_pred
)
",Logarithm of the hyperbolic cosine of the prediction error.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.poisson,"tf.keras.metrics.poisson(
    y_true, y_pred
)
",Computes the Poisson loss between y_true and y_pred.View aliases
tf.keras.metrics.serialize,"tf.keras.metrics.serialize(
    metric
)
",Serializes metric function or Metric instance.View aliases
tf.keras.metrics.sparse_categorical_accuracy,"tf.keras.metrics.sparse_categorical_accuracy(
    y_true, y_pred
)
",Calculates how often predictions match integer labels.View aliases
tf.keras.metrics.sparse_categorical_crossentropy,"tf.keras.metrics.sparse_categorical_crossentropy(
    y_true, y_pred, from_logits=False, axis=-1, ignore_class=None
)
",Computes the sparse categorical crossentropy loss.View aliases
tf.keras.metrics.sparse_top_k_categorical_accuracy,"tf.keras.metrics.sparse_top_k_categorical_accuracy(
    y_true, y_pred, k=5
)
",Computes how often integer targets are in the top K predictions.View aliases
tf.keras.metrics.squared_hinge,"tf.keras.metrics.squared_hinge(
    y_true, y_pred
)
",Computes the squared hinge loss between y_true and y_pred.View aliases
tf.keras.metrics.top_k_categorical_accuracy,"tf.keras.metrics.top_k_categorical_accuracy(
    y_true, y_pred, k=5
)
",Computes how often targets are in the top K predictions.View aliases
tf.keras.mixed_precision.Policy,"tf.keras.mixed_precision.Policy(
    name
)
",A dtype policy for a Keras layer.
tf.keras.mixed_precision.set_global_policy,"tf.keras.mixed_precision.set_global_policy(
    policy
)
",Sets the global dtype policy.
tf.keras.Model,"tf.keras.Model(
    *args, **kwargs
)
","Model groups layers into an object with training and inference features.Inherits From: Layer, ModuleView aliases"
tf.keras.Sequential,"tf.keras.Sequential(
    layers=None, name=None
)
","Sequential groups a linear stack of layers into a tf.keras.Model.Inherits From: Model, Layer, ModuleView aliases"
tf.keras.models.clone_model,"tf.keras.models.clone_model(
    model, input_tensors=None, clone_function=None
)
",Clone a Functional or Sequential Model instance.View aliases
tf.keras.models.experimental.SharpnessAwareMinimization,"tf.keras.models.experimental.SharpnessAwareMinimization(
    model, rho=0.05, num_batch_splits=None, name=None
)
","Sharpness aware minimization (SAM) training flow.Inherits From: Model, Layer, Module"
tf.keras.models.load_model,"tf.keras.models.load_model(
    filepath, custom_objects=None, compile=True, options=None
)
",Loads a model saved via model.save().View aliases
tf.keras.models.model_from_config,"tf.keras.models.model_from_config(
    config, custom_objects=None
)
",Instantiates a Keras model from its config.View aliases
tf.keras.models.model_from_json,"tf.keras.models.model_from_json(
    json_string, custom_objects=None
)
",Parses a JSON model configuration string and returns a model instance.View aliases
tf.keras.models.model_from_yaml,"tf.keras.models.model_from_yaml(
    yaml_string, custom_objects=None
)
",Parses a yaml model configuration file and returns a model instance.View aliases
tf.keras.models.save_model,"tf.keras.models.save_model(
    model,
    filepath,
    overwrite=True,
    include_optimizer=True,
    save_format=None,
    signatures=None,
    options=None,
    save_traces=True
)
",Saves a model as a TensorFlow SavedModel or HDF5 file.View aliases
tf.keras.optimizers.Adadelta,"tf.keras.optimizers.Adadelta(
    learning_rate=0.001,
    rho=0.95,
    epsilon=1e-07,
    name='Adadelta',
    **kwargs
)
",Optimizer that implements the Adadelta algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Adagrad,"tf.keras.optimizers.Adagrad(
    learning_rate=0.001,
    initial_accumulator_value=0.1,
    epsilon=1e-07,
    name='Adagrad',
    **kwargs
)
",Optimizer that implements the Adagrad algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Adam,"tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    name='Adam',
    **kwargs
)
",Optimizer that implements the Adam algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Adamax,"tf.keras.optimizers.Adamax(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    name='Adamax',
    **kwargs
)
",Optimizer that implements the Adamax algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Ftrl,"tf.keras.optimizers.Ftrl(
    learning_rate=0.001,
    learning_rate_power=-0.5,
    initial_accumulator_value=0.1,
    l1_regularization_strength=0.0,
    l2_regularization_strength=0.0,
    name='Ftrl',
    l2_shrinkage_regularization_strength=0.0,
    beta=0.0,
    **kwargs
)
",Optimizer that implements the FTRL algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Nadam,"tf.keras.optimizers.Nadam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    name='Nadam',
    **kwargs
)
",Optimizer that implements the NAdam algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Optimizer,"tf.keras.optimizers.Optimizer(
    name, gradient_aggregator=None, gradient_transformers=None, **kwargs
)
",Base class for Keras optimizers.View aliases
tf.keras.optimizers.RMSprop,"tf.keras.optimizers.RMSprop(
    learning_rate=0.001,
    rho=0.9,
    momentum=0.0,
    epsilon=1e-07,
    centered=False,
    name='RMSprop',
    **kwargs
)
",Optimizer that implements the RMSprop algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.SGD,"tf.keras.optimizers.SGD(
    learning_rate=0.01,
    momentum=0.0,
    nesterov=False,
    name='SGD',
    **kwargs
)
",Gradient descent (with momentum) optimizer.Inherits From: OptimizerView aliases
tf.keras.optimizers.deserialize,"tf.keras.optimizers.deserialize(
    config, custom_objects=None, **kwargs
)
",Inverse of the serialize function.View aliases
tf.keras.optimizers.experimental.Adadelta,"tf.keras.optimizers.experimental.Adadelta(
    learning_rate=0.001,
    rho=0.95,
    epsilon=1e-07,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='Adadelta',
    **kwargs
)
",Optimizer that implements the Adadelta algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.Adagrad,"tf.keras.optimizers.experimental.Adagrad(
    learning_rate=0.001,
    initial_accumulator_value=0.1,
    epsilon=1e-07,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='Adagrad',
    **kwargs
)
",Optimizer that implements the Adagrad algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.Adam,"tf.keras.optimizers.experimental.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='Adam',
    **kwargs
)
",Optimizer that implements the Adam algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.AdamW,"tf.keras.optimizers.experimental.AdamW(
    learning_rate=0.001,
    weight_decay=0.004,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='AdamW',
    **kwargs
)
",Optimizer that implements the AdamW algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.Adamax,"tf.keras.optimizers.experimental.Adamax(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='Adamax',
    **kwargs
)
",Optimizer that implements the Adamax algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.Ftrl,"tf.keras.optimizers.experimental.Ftrl(
    learning_rate=0.001,
    learning_rate_power=-0.5,
    initial_accumulator_value=0.1,
    l1_regularization_strength=0.0,
    l2_regularization_strength=0.0,
    l2_shrinkage_regularization_strength=0.0,
    beta=0.0,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='Ftrl',
    **kwargs
)
",Optimizer that implements the FTRL algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.Nadam,"tf.keras.optimizers.experimental.Nadam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='Nadam',
    **kwargs
)
",Optimizer that implements the Nadam algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.Optimizer,"tf.keras.optimizers.experimental.Optimizer(
    name,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    **kwargs
)
",Abstract optimizer base class.View aliases
tf.keras.optimizers.experimental.RMSprop,"tf.keras.optimizers.experimental.RMSprop(
    learning_rate=0.001,
    rho=0.9,
    momentum=0.0,
    epsilon=1e-07,
    centered=False,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=100,
    jit_compile=True,
    name='RMSprop',
    **kwargs
)
",Optimizer that implements the RMSprop algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.SGD,"tf.keras.optimizers.experimental.SGD(
    learning_rate=0.01,
    momentum=0.0,
    nesterov=False,
    amsgrad=False,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='SGD',
    **kwargs
)
",Gradient descent (with momentum) optimizer.Inherits From: OptimizerView aliases
tf.keras.optimizers.get,"tf.keras.optimizers.get(
    identifier, **kwargs
)
",Retrieves a Keras Optimizer instance.View aliases
tf.keras.optimizers.legacy.Adadelta,"tf.keras.optimizers.legacy.Adadelta(
    learning_rate=0.001,
    rho=0.95,
    epsilon=1e-07,
    name='Adadelta',
    **kwargs
)
","Optimizer that implements the Adadelta algorithm.Inherits From: Adadelta, OptimizerView aliases"
tf.keras.optimizers.legacy.Adagrad,"tf.keras.optimizers.legacy.Adagrad(
    learning_rate=0.001,
    initial_accumulator_value=0.1,
    epsilon=1e-07,
    name='Adagrad',
    **kwargs
)
","Optimizer that implements the Adagrad algorithm.Inherits From: Adagrad, OptimizerView aliases"
tf.keras.optimizers.legacy.Adam,"tf.keras.optimizers.legacy.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    name='Adam',
    **kwargs
)
","Optimizer that implements the Adam algorithm.Inherits From: Adam, OptimizerView aliases"
tf.keras.optimizers.legacy.Adamax,"tf.keras.optimizers.legacy.Adamax(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    name='Adamax',
    **kwargs
)
","Optimizer that implements the Adamax algorithm.Inherits From: Adamax, OptimizerView aliases"
tf.keras.optimizers.legacy.Ftrl,"tf.keras.optimizers.legacy.Ftrl(
    learning_rate=0.001,
    learning_rate_power=-0.5,
    initial_accumulator_value=0.1,
    l1_regularization_strength=0.0,
    l2_regularization_strength=0.0,
    name='Ftrl',
    l2_shrinkage_regularization_strength=0.0,
    beta=0.0,
    **kwargs
)
","Optimizer that implements the FTRL algorithm.Inherits From: Ftrl, OptimizerView aliases"
tf.keras.optimizers.legacy.Nadam,"tf.keras.optimizers.legacy.Nadam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    name='Nadam',
    **kwargs
)
","Optimizer that implements the NAdam algorithm.Inherits From: Nadam, OptimizerView aliases"
tf.keras.optimizers.legacy.Optimizer,"tf.keras.optimizers.legacy.Optimizer(
    name, gradient_aggregator=None, gradient_transformers=None, **kwargs
)
",Base class for Keras optimizers.Inherits From: OptimizerView aliases
tf.keras.optimizers.legacy.RMSprop,"tf.keras.optimizers.legacy.RMSprop(
    learning_rate=0.001,
    rho=0.9,
    momentum=0.0,
    epsilon=1e-07,
    centered=False,
    name='RMSprop',
    **kwargs
)
","Optimizer that implements the RMSprop algorithm.Inherits From: RMSprop, OptimizerView aliases"
tf.keras.optimizers.legacy.SGD,"tf.keras.optimizers.legacy.SGD(
    learning_rate=0.01,
    momentum=0.0,
    nesterov=False,
    name='SGD',
    **kwargs
)
","Gradient descent (with momentum) optimizer.Inherits From: SGD, OptimizerView aliases"
tf.keras.optimizers.schedules.CosineDecay,"tf.keras.optimizers.schedules.CosineDecay(
    initial_learning_rate, decay_steps, alpha=0.0, name=None
)
",A LearningRateSchedule that uses a cosine decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.CosineDecayRestarts,"tf.keras.optimizers.schedules.CosineDecayRestarts(
    initial_learning_rate,
    first_decay_steps,
    t_mul=2.0,
    m_mul=1.0,
    alpha=0.0,
    name=None
)
",A LearningRateSchedule that uses a cosine decay schedule with restarts.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.ExponentialDecay,"tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate, decay_steps, decay_rate, staircase=False, name=None
)
",A LearningRateSchedule that uses an exponential decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.InverseTimeDecay,"tf.keras.optimizers.schedules.InverseTimeDecay(
    initial_learning_rate, decay_steps, decay_rate, staircase=False, name=None
)
",A LearningRateSchedule that uses an inverse time decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.PiecewiseConstantDecay,"tf.keras.optimizers.schedules.PiecewiseConstantDecay(
    boundaries, values, name=None
)
",A LearningRateSchedule that uses a piecewise constant decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.PolynomialDecay,"tf.keras.optimizers.schedules.PolynomialDecay(
    initial_learning_rate,
    decay_steps,
    end_learning_rate=0.0001,
    power=1.0,
    cycle=False,
    name=None
)
",A LearningRateSchedule that uses a polynomial decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.deserialize,"tf.keras.optimizers.schedules.deserialize(
    config, custom_objects=None
)
",Instantiates a LearningRateSchedule object from a serialized form.View aliases
tf.keras.optimizers.schedules.serialize,"tf.keras.optimizers.schedules.serialize(
    learning_rate_schedule
)
",Serializes a LearningRateSchedule into a JSON-compatible representation.View aliases
tf.keras.optimizers.serialize,"tf.keras.optimizers.serialize(
    optimizer
)
",Serialize the optimizer configuration to JSON compatible python dict.View aliases
tf.keras.preprocessing.image.DirectoryIterator,"tf.keras.preprocessing.image.DirectoryIterator(
    directory,
    image_data_generator,
    target_size=(256, 256),
    color_mode='rgb',
    classes=None,
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=None,
    data_format=None,
    save_to_dir=None,
    save_prefix='',
    save_format='png',
    follow_links=False,
    subset=None,
    interpolation='nearest',
    keep_aspect_ratio=False,
    dtype=None
)
","Iterator capable of reading images from a directory on disk.Inherits From: Iterator, SequenceView aliases"
tf.keras.preprocessing.image.ImageDataGenerator,"tf.keras.preprocessing.image.ImageDataGenerator(
    featurewise_center=False,
    samplewise_center=False,
    featurewise_std_normalization=False,
    samplewise_std_normalization=False,
    zca_whitening=False,
    zca_epsilon=1e-06,
    rotation_range=0,
    width_shift_range=0.0,
    height_shift_range=0.0,
    brightness_range=None,
    shear_range=0.0,
    zoom_range=0.0,
    channel_shift_range=0.0,
    fill_mode='nearest',
    cval=0.0,
    horizontal_flip=False,
    vertical_flip=False,
    rescale=None,
    preprocessing_function=None,
    data_format=None,
    validation_split=0.0,
    interpolation_order=1,
    dtype=None
)
",Generate batches of tensor image data with real-time data augmentation.View aliases
tf.keras.preprocessing.image.Iterator,"tf.keras.preprocessing.image.Iterator(
    n, batch_size, shuffle, seed
)
",Base class for image data iterators.Inherits From: SequenceView aliases
tf.keras.preprocessing.image.NumpyArrayIterator,"tf.keras.preprocessing.image.NumpyArrayIterator(
    x,
    y,
    image_data_generator,
    batch_size=32,
    shuffle=False,
    sample_weight=None,
    seed=None,
    data_format=None,
    save_to_dir=None,
    save_prefix='',
    save_format='png',
    subset=None,
    ignore_class_split=False,
    dtype=None
)
","Iterator yielding data from a Numpy array.Inherits From: Iterator, SequenceView aliases"
tf.keras.preprocessing.image.apply_affine_transform,"tf.keras.preprocessing.image.apply_affine_transform(
    x,
    theta=0,
    tx=0,
    ty=0,
    shear=0,
    zx=1,
    zy=1,
    row_axis=1,
    col_axis=2,
    channel_axis=0,
    fill_mode='nearest',
    cval=0.0,
    order=1
)
",Applies an affine transformation specified by the parameters given.View aliases
tf.keras.preprocessing.image.apply_brightness_shift,"tf.keras.preprocessing.image.apply_brightness_shift(
    x, brightness, scale=True
)
",Performs a brightness shift.View aliases
tf.keras.preprocessing.image.apply_channel_shift,"tf.keras.preprocessing.image.apply_channel_shift(
    x, intensity, channel_axis=0
)
",Performs a channel shift.View aliases
tf.keras.utils.array_to_img,"tf.keras.utils.array_to_img(
    x, data_format=None, scale=True, dtype=None
)
",Converts a 3D Numpy array to a PIL Image instance.View aliases
tf.keras.utils.img_to_array,"tf.keras.utils.img_to_array(
    img, data_format=None, dtype=None
)
",Converts a PIL Image instance to a Numpy array.View aliases
tf.keras.utils.load_img,"tf.keras.utils.load_img(
    path,
    grayscale=False,
    color_mode='rgb',
    target_size=None,
    interpolation='nearest',
    keep_aspect_ratio=False
)
",Loads an image into PIL format.View aliases
tf.keras.preprocessing.image.random_brightness,"tf.keras.preprocessing.image.random_brightness(
    x, brightness_range, scale=True
)
",Performs a random brightness shift.View aliases
tf.keras.preprocessing.image.random_channel_shift,"tf.keras.preprocessing.image.random_channel_shift(
    x, intensity_range, channel_axis=0
)
",Performs a random channel shift.View aliases
tf.keras.preprocessing.image.random_rotation,"tf.keras.preprocessing.image.random_rotation(
    x,
    rg,
    row_axis=1,
    col_axis=2,
    channel_axis=0,
    fill_mode='nearest',
    cval=0.0,
    interpolation_order=1
)
",Performs a random rotation of a Numpy image tensor.View aliases
tf.keras.preprocessing.image.random_shear,"tf.keras.preprocessing.image.random_shear(
    x,
    intensity,
    row_axis=1,
    col_axis=2,
    channel_axis=0,
    fill_mode='nearest',
    cval=0.0,
    interpolation_order=1
)
",Performs a random spatial shear of a Numpy image tensor.View aliases
tf.keras.preprocessing.image.random_shift,"tf.keras.preprocessing.image.random_shift(
    x,
    wrg,
    hrg,
    row_axis=1,
    col_axis=2,
    channel_axis=0,
    fill_mode='nearest',
    cval=0.0,
    interpolation_order=1
)
",Performs a random spatial shift of a Numpy image tensor.View aliases
tf.keras.preprocessing.image.random_zoom,"tf.keras.preprocessing.image.random_zoom(
    x,
    zoom_range,
    row_axis=1,
    col_axis=2,
    channel_axis=0,
    fill_mode='nearest',
    cval=0.0,
    interpolation_order=1
)
",Performs a random spatial zoom of a Numpy image tensor.View aliases
tf.keras.utils.save_img,"tf.keras.utils.save_img(
    path, x, data_format=None, file_format=None, scale=True, **kwargs
)
",Saves an image stored as a Numpy array to a path or file object.View aliases
tf.keras.preprocessing.image.smart_resize,"tf.keras.preprocessing.image.smart_resize(
    x, size, interpolation='bilinear'
)
",Resize images to a target size without aspect ratio distortion.
tf.keras.utils.image_dataset_from_directory,"tf.keras.utils.image_dataset_from_directory(
    directory,
    labels='inferred',
    label_mode='int',
    class_names=None,
    color_mode='rgb',
    batch_size=32,
    image_size=(256, 256),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation='bilinear',
    follow_links=False,
    crop_to_aspect_ratio=False,
    **kwargs
)
",Generates a tf.data.Dataset from image files in a directory.View aliases
tf.keras.preprocessing.sequence.TimeseriesGenerator,"tf.keras.preprocessing.sequence.TimeseriesGenerator(
    data,
    targets,
    length,
    sampling_rate=1,
    stride=1,
    start_index=0,
    end_index=None,
    shuffle=False,
    reverse=False,
    batch_size=128
)
",Utility class for generating batches of temporal data.Inherits From: SequenceView aliases
tf.keras.preprocessing.sequence.make_sampling_table,"tf.keras.preprocessing.sequence.make_sampling_table(
    size, sampling_factor=1e-05
)
",Generates a word rank-based probabilistic sampling table.View aliases
tf.keras.utils.pad_sequences,"tf.keras.utils.pad_sequences(
    sequences,
    maxlen=None,
    dtype='int32',
    padding='pre',
    truncating='pre',
    value=0.0
)
",Pads sequences to the same length.View aliases
tf.keras.preprocessing.sequence.skipgrams,"tf.keras.preprocessing.sequence.skipgrams(
    sequence,
    vocabulary_size,
    window_size=4,
    negative_samples=1.0,
    shuffle=True,
    categorical=False,
    sampling_table=None,
    seed=None
)
",Generates skipgram word pairs.View aliases
tf.keras.preprocessing.text.Tokenizer,"tf.keras.preprocessing.text.Tokenizer(
    num_words=None,
    filters='!""#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
    lower=True,
    split=' ',
    char_level=False,
    oov_token=None,
    analyzer=None,
    **kwargs
)
",Text tokenization utility class.View aliases
tf.keras.preprocessing.text.hashing_trick,"tf.keras.preprocessing.text.hashing_trick(
    text,
    n,
    hash_function=None,
    filters='!""#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
    lower=True,
    split=' ',
    analyzer=None
)
",Converts a text to a sequence of indexes in a fixed-size hashing space.View aliases
tf.keras.preprocessing.text.one_hot,"tf.keras.preprocessing.text.one_hot(
    input_text,
    n,
    filters='!""#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
    lower=True,
    split=' ',
    analyzer=None
)
",One-hot encodes a text into a list of word indexes of size n.View aliases
tf.keras.preprocessing.text.text_to_word_sequence,"tf.keras.preprocessing.text.text_to_word_sequence(
    input_text,
    filters='!""#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
    lower=True,
    split=' '
)
",Converts a text to a sequence of words (or tokens).View aliases
tf.keras.preprocessing.text.tokenizer_from_json,"tf.keras.preprocessing.text.tokenizer_from_json(
    json_string
)
",Parses a JSON tokenizer configuration and returns a tokenizer instance.View aliases
tf.keras.utils.text_dataset_from_directory,"tf.keras.utils.text_dataset_from_directory(
    directory,
    labels='inferred',
    label_mode='int',
    class_names=None,
    batch_size=32,
    max_length=None,
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    follow_links=False
)
",Generates a tf.data.Dataset from text files in a directory.View aliases
tf.keras.utils.timeseries_dataset_from_array,"tf.keras.utils.timeseries_dataset_from_array(
    data,
    targets,
    sequence_length,
    sequence_stride=1,
    sampling_rate=1,
    batch_size=128,
    shuffle=False,
    seed=None,
    start_index=None,
    end_index=None
)
",Creates a dataset of sliding windows over a timeseries provided as array.View aliases
tf.keras.regularizers.L1,"tf.keras.regularizers.L1(
    l1=0.01, **kwargs
)
",A regularizer that applies a L1 regularization penalty.Inherits From: RegularizerView aliases
tf.keras.regularizers.L1L2,"tf.keras.regularizers.L1L2(
    l1=0.0, l2=0.0
)
",A regularizer that applies both L1 and L2 regularization penalties.Inherits From: RegularizerView aliases
tf.keras.regularizers.L2,"tf.keras.regularizers.L2(
    l2=0.01, **kwargs
)
",A regularizer that applies a L2 regularization penalty.Inherits From: RegularizerView aliases
tf.keras.regularizers.OrthogonalRegularizer,"tf.keras.regularizers.OrthogonalRegularizer(
    factor=0.01, mode='rows'
)
",A regularizer that encourages input vectors to be orthogonal to each other.Inherits From: RegularizerView aliases
tf.keras.regularizers.deserialize,"tf.keras.regularizers.deserialize(
    config, custom_objects=None
)
",View aliases
tf.keras.regularizers.get,"tf.keras.regularizers.get(
    identifier
)
",Retrieve a regularizer instance from a config or identifier.View aliases
tf.keras.regularizers.L1,"tf.keras.regularizers.L1(
    l1=0.01, **kwargs
)
",A regularizer that applies a L1 regularization penalty.Inherits From: RegularizerView aliases
tf.keras.regularizers.l1_l2,"tf.keras.regularizers.l1_l2(
    l1=0.01, l2=0.01
)
",Create a regularizer that applies both L1 and L2 penalties.View aliases
tf.keras.regularizers.L2,"tf.keras.regularizers.L2(
    l2=0.01, **kwargs
)
",A regularizer that applies a L2 regularization penalty.Inherits From: RegularizerView aliases
tf.keras.regularizers.OrthogonalRegularizer,"tf.keras.regularizers.OrthogonalRegularizer(
    factor=0.01, mode='rows'
)
",A regularizer that encourages input vectors to be orthogonal to each other.Inherits From: RegularizerView aliases
tf.keras.regularizers.serialize,"tf.keras.regularizers.serialize(
    regularizer
)
",View aliases
tf.keras.utils.custom_object_scope,"tf.keras.utils.custom_object_scope(
    *args
)
",Exposes custom classes/functions to Keras deserialization internals.View aliases
tf.keras.utils.GeneratorEnqueuer,"tf.keras.utils.GeneratorEnqueuer(
    generator, use_multiprocessing=False, random_seed=None
)
",Builds a queue out of a data generator.Inherits From: SequenceEnqueuerView aliases
tf.keras.utils.OrderedEnqueuer,"tf.keras.utils.OrderedEnqueuer(
    sequence, use_multiprocessing=False, shuffle=False
)
",Builds a Enqueuer from a Sequence.Inherits From: SequenceEnqueuerView aliases
tf.keras.utils.Progbar,"tf.keras.utils.Progbar(
    target,
    width=30,
    verbose=1,
    interval=0.05,
    stateful_metrics=None,
    unit_name='step'
)
",Displays a progress bar.View aliases
tf.keras.utils.SequenceEnqueuer,"tf.keras.utils.SequenceEnqueuer(
    sequence, use_multiprocessing=False
)
",Base class to enqueue inputs.View aliases
tf.keras.utils.SidecarEvaluator,"tf.keras.utils.SidecarEvaluator(
    model,
    data,
    checkpoint_dir,
    steps=None,
    max_evaluations=None,
    callbacks=None
)
",A class designed for a dedicated evaluator task.
tf.keras.utils.array_to_img,"tf.keras.utils.array_to_img(
    x, data_format=None, scale=True, dtype=None
)
",Converts a 3D Numpy array to a PIL Image instance.View aliases
tf.keras.utils.audio_dataset_from_directory,"tf.keras.utils.audio_dataset_from_directory(
    directory,
    labels='inferred',
    label_mode='int',
    class_names=None,
    batch_size=32,
    sampling_rate=None,
    output_sequence_length=None,
    ragged=False,
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    follow_links=False
)
",Generates a tf.data.Dataset from audio files in a directory.
tf.keras.utils.custom_object_scope,"tf.keras.utils.custom_object_scope(
    *args
)
",Exposes custom classes/functions to Keras deserialization internals.View aliases
tf.keras.utils.deserialize_keras_object,"tf.keras.utils.deserialize_keras_object(
    identifier,
    module_objects=None,
    custom_objects=None,
    printable_module_name='object'
)
",Turns the serialized form of a Keras object back into an actual object.View aliases
tf.keras.utils.experimental.DatasetCreator,"tf.keras.utils.experimental.DatasetCreator(
    dataset_fn, input_options=None
)
",Object that returns a tf.data.Dataset upon invoking.
tf.keras.utils.get_file,"tf.keras.utils.get_file(
    fname=None,
    origin=None,
    untar=False,
    md5_hash=None,
    file_hash=None,
    cache_subdir='datasets',
    hash_algorithm='auto',
    extract=False,
    archive_format='auto',
    cache_dir=None
)
",Downloads a file from a URL if it not already in the cache.View aliases
tf.keras.utils.get_registered_name,"tf.keras.utils.get_registered_name(
    obj
)
",Returns the name registered to an object within the Keras framework.View aliases
tf.keras.utils.get_registered_object,"tf.keras.utils.get_registered_object(
    name, custom_objects=None, module_objects=None
)
",Returns the class associated with name if it is registered with Keras.View aliases
tf.keras.utils.get_source_inputs,"tf.keras.utils.get_source_inputs(
    tensor, layer=None, node_index=None
)
",Returns the list of input tensors necessary to compute tensor.View aliases
tf.keras.utils.image_dataset_from_directory,"tf.keras.utils.image_dataset_from_directory(
    directory,
    labels='inferred',
    label_mode='int',
    class_names=None,
    color_mode='rgb',
    batch_size=32,
    image_size=(256, 256),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation='bilinear',
    follow_links=False,
    crop_to_aspect_ratio=False,
    **kwargs
)
",Generates a tf.data.Dataset from image files in a directory.View aliases
tf.keras.utils.img_to_array,"tf.keras.utils.img_to_array(
    img, data_format=None, dtype=None
)
",Converts a PIL Image instance to a Numpy array.View aliases
tf.keras.utils.load_img,"tf.keras.utils.load_img(
    path,
    grayscale=False,
    color_mode='rgb',
    target_size=None,
    interpolation='nearest',
    keep_aspect_ratio=False
)
",Loads an image into PIL format.View aliases
tf.keras.utils.model_to_dot,"tf.keras.utils.model_to_dot(
    model,
    show_shapes=False,
    show_dtype=False,
    show_layer_names=True,
    rankdir='TB',
    expand_nested=False,
    dpi=96,
    subgraph=False,
    layer_range=None,
    show_layer_activations=False
)
",Convert a Keras model to dot format.View aliases
tf.keras.utils.normalize,"tf.keras.utils.normalize(
    x, axis=-1, order=2
)
",Normalizes a Numpy array.View aliases
tf.keras.utils.pack_x_y_sample_weight,"tf.keras.utils.pack_x_y_sample_weight(
    x, y=None, sample_weight=None
)
",Packs user-provided data into a tuple.
tf.keras.utils.pad_sequences,"tf.keras.utils.pad_sequences(
    sequences,
    maxlen=None,
    dtype='int32',
    padding='pre',
    truncating='pre',
    value=0.0
)
",Pads sequences to the same length.View aliases
tf.keras.utils.plot_model,"tf.keras.utils.plot_model(
    model,
    to_file='model.png',
    show_shapes=False,
    show_dtype=False,
    show_layer_names=True,
    rankdir='TB',
    expand_nested=False,
    dpi=96,
    layer_range=None,
    show_layer_activations=False
)
",Converts a Keras model to dot format and save to a file.View aliases
tf.keras.utils.register_keras_serializable,"tf.keras.utils.register_keras_serializable(
    package='Custom', name=None
)
",Registers an object with the Keras serialization framework.View aliases
tf.keras.utils.save_img,"tf.keras.utils.save_img(
    path, x, data_format=None, file_format=None, scale=True, **kwargs
)
",Saves an image stored as a Numpy array to a path or file object.View aliases
tf.keras.utils.serialize_keras_object,"tf.keras.utils.serialize_keras_object(
    instance
)
",Serialize a Keras object into a JSON-compatible representation.View aliases
tf.keras.utils.set_random_seed,"tf.keras.utils.set_random_seed(
    seed
)
","Sets all random seeds for the program (Python, NumPy, and TensorFlow)."
tf.keras.utils.split_dataset,"tf.keras.utils.split_dataset(
    dataset, left_size=None, right_size=None, shuffle=False, seed=None
)
",Split a dataset into a left half and a right half (e.g. train / test).
tf.keras.utils.text_dataset_from_directory,"tf.keras.utils.text_dataset_from_directory(
    directory,
    labels='inferred',
    label_mode='int',
    class_names=None,
    batch_size=32,
    max_length=None,
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    follow_links=False
)
",Generates a tf.data.Dataset from text files in a directory.View aliases
tf.keras.utils.timeseries_dataset_from_array,"tf.keras.utils.timeseries_dataset_from_array(
    data,
    targets,
    sequence_length,
    sequence_stride=1,
    sampling_rate=1,
    batch_size=128,
    shuffle=False,
    seed=None,
    start_index=None,
    end_index=None
)
",Creates a dataset of sliding windows over a timeseries provided as array.View aliases
tf.keras.utils.to_categorical,"tf.keras.utils.to_categorical(
    y, num_classes=None, dtype='float32'
)
",Converts a class vector (integers) to binary class matrix.View aliases
tf.keras.utils.unpack_x_y_sample_weight,"tf.keras.utils.unpack_x_y_sample_weight(
    data
)
",Unpacks user-provided data tuple.
tf.math.less,"tf.math.less(
    x, y, name=None
)
",Returns the truth value of (x < y) element-wise.View aliases
tf.math.less_equal,"tf.math.less_equal(
    x, y, name=None
)
",Returns the truth value of (x <= y) element-wise.View aliases
tf.linalg.LinearOperator,"tf.linalg.LinearOperator(
    dtype,
    graph_parents=None,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name=None,
    parameters=None
)
",Base class defining a [batch of] linear operator[s].Inherits From: ModuleView aliases
tf.linalg.LinearOperatorAdjoint,"tf.linalg.LinearOperatorAdjoint(
    operator,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name=None
)
","LinearOperator representing the adjoint of another operator.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorBlockDiag,"tf.linalg.LinearOperatorBlockDiag(
    operators,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=True,
    name=None
)
","Combines one or more LinearOperators in to a Block Diagonal matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorBlockLowerTriangular,"tf.linalg.LinearOperatorBlockLowerTriangular(
    operators,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorBlockLowerTriangular'
)
","Combines LinearOperators into a blockwise lower-triangular matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorCirculant,"tf.linalg.LinearOperatorCirculant(
    spectrum,
    input_output_dtype=tf.dtypes.complex64,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=True,
    name='LinearOperatorCirculant'
)
","LinearOperator acting like a circulant matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorCirculant2D,"tf.linalg.LinearOperatorCirculant2D(
    spectrum,
    input_output_dtype=tf.dtypes.complex64,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=True,
    name='LinearOperatorCirculant2D'
)
","LinearOperator acting like a block circulant matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorCirculant3D,"tf.linalg.LinearOperatorCirculant3D(
    spectrum,
    input_output_dtype=tf.dtypes.complex64,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=True,
    name='LinearOperatorCirculant3D'
)
","LinearOperator acting like a nested block circulant matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorComposition,"tf.linalg.LinearOperatorComposition(
    operators,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name=None
)
","Composes one or more LinearOperators.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorDiag,"tf.linalg.LinearOperatorDiag(
    diag,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorDiag'
)
","LinearOperator acting like a [batch] square diagonal matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorFullMatrix,"tf.linalg.LinearOperatorFullMatrix(
    matrix,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorFullMatrix'
)
","LinearOperator that wraps a [batch] matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorHouseholder,"tf.linalg.LinearOperatorHouseholder(
    reflection_axis,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorHouseholder'
)
","LinearOperator acting like a [batch] of Householder transformations.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorIdentity,"tf.linalg.LinearOperatorIdentity(
    num_rows,
    batch_shape=None,
    dtype=None,
    is_non_singular=True,
    is_self_adjoint=True,
    is_positive_definite=True,
    is_square=True,
    assert_proper_shapes=False,
    name='LinearOperatorIdentity'
)
","LinearOperator acting like a [batch] square identity matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorInversion,"tf.linalg.LinearOperatorInversion(
    operator,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name=None
)
","LinearOperator representing the inverse of another operator.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorKronecker,"tf.linalg.LinearOperatorKronecker(
    operators,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name=None
)
","Kronecker product between two LinearOperators.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorLowRankUpdate,"tf.linalg.LinearOperatorLowRankUpdate(
    base_operator,
    u,
    diag_update=None,
    v=None,
    is_diag_update_positive=None,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorLowRankUpdate'
)
","Perturb a LinearOperator with a rank K update.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorLowerTriangular,"tf.linalg.LinearOperatorLowerTriangular(
    tril,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorLowerTriangular'
)
","LinearOperator acting like a [batch] square lower triangular matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorPermutation,"tf.linalg.LinearOperatorPermutation(
    perm,
    dtype=tf.dtypes.float32,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorPermutation'
)
","LinearOperator acting like a [batch] of permutation matrices.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorScaledIdentity,"tf.linalg.LinearOperatorScaledIdentity(
    num_rows,
    multiplier,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=True,
    assert_proper_shapes=False,
    name='LinearOperatorScaledIdentity'
)
","LinearOperator acting like a scaled [batch] identity matrix A = c I.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorToeplitz,"tf.linalg.LinearOperatorToeplitz(
    col,
    row,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorToeplitz'
)
","LinearOperator acting like a [batch] of toeplitz matrices.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorTridiag,"tf.linalg.LinearOperatorTridiag(
    diagonals,
    diagonals_format=_COMPACT,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorTridiag'
)
","LinearOperator acting like a [batch] square tridiagonal matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorZeros,"tf.linalg.LinearOperatorZeros(
    num_rows,
    num_columns=None,
    batch_shape=None,
    dtype=None,
    is_non_singular=False,
    is_self_adjoint=True,
    is_positive_definite=False,
    is_square=True,
    assert_proper_shapes=False,
    name='LinearOperatorZeros'
)
","LinearOperator acting like a [batch] zero matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.adjoint,"tf.linalg.adjoint(
    matrix, name=None
)
",Transposes the last two dimensions of and conjugates tensor matrix.View aliases
tf.linalg.band_part,"tf.linalg.band_part(
    input, num_lower, num_upper, name=None
)
",Copy a tensor setting everything outside a central band in each innermost matrix to zero.View aliases
tf.linalg.banded_triangular_solve,"tf.linalg.banded_triangular_solve(
    bands, rhs, lower=True, adjoint=False, name=None
)
",Solve triangular systems of equations with a banded solver.
tf.linalg.cholesky,"tf.linalg.cholesky(
    input, name=None
)
",Computes the Cholesky decomposition of one or more square matrices.View aliases
tf.linalg.cholesky_solve,"tf.linalg.cholesky_solve(
    chol, rhs, name=None
)
","Solves systems of linear eqns A X = RHS, given Cholesky factorizations.View aliases"
tf.linalg.cross,"tf.linalg.cross(
    a, b, name=None
)
",Compute the pairwise cross product.View aliases
tf.linalg.det,"tf.linalg.det(
    input, name=None
)
",Computes the determinant of one or more square matrices.View aliases
tf.linalg.diag,"tf.linalg.diag(
    diagonal,
    name='diag',
    k=0,
    num_rows=-1,
    num_cols=-1,
    padding_value=0,
    align='RIGHT_LEFT'
)
",Returns a batched diagonal tensor with given batched diagonal values.View aliases
tf.linalg.diag_part,"tf.linalg.diag_part(
    input,
    name='diag_part',
    k=0,
    padding_value=0,
    align='RIGHT_LEFT'
)
",Returns the batched diagonal part of a batched tensor.View aliases
tf.linalg.eig,"tf.linalg.eig(
    tensor, name=None
)
",Computes the eigen decomposition of a batch of matrices.View aliases
tf.linalg.eigh,"tf.linalg.eigh(
    tensor, name=None
)
",Computes the eigen decomposition of a batch of self-adjoint matrices.View aliases
tf.linalg.eigh_tridiagonal,"tf.linalg.eigh_tridiagonal(
    alpha,
    beta,
    eigvals_only=True,
    select='a',
    select_range=None,
    tol=None,
    name=None
)
",Computes the eigenvalues of a Hermitian tridiagonal matrix.View aliases
tf.linalg.eigvals,"tf.linalg.eigvals(
    tensor, name=None
)
",Computes the eigenvalues of one or more matrices.View aliases
tf.linalg.eigvalsh,"tf.linalg.eigvalsh(
    tensor, name=None
)
",Computes the eigenvalues of one or more self-adjoint matrices.View aliases
tf.einsum,"tf.einsum(
    equation, *inputs, **kwargs
)
",Tensor contraction over specified indices and outer product.View aliases
tf.linalg.experimental.conjugate_gradient,"tf.linalg.experimental.conjugate_gradient(
    operator,
    rhs,
    preconditioner=None,
    x=None,
    tol=1e-05,
    max_iter=20,
    name='conjugate_gradient'
)
",Conjugate gradient solver.View aliases
tf.linalg.expm,"tf.linalg.expm(
    input, name=None
)
",Computes the matrix exponential of one or more square matrices.View aliases
tf.eye,"tf.eye(
    num_rows,
    num_columns=None,
    batch_shape=None,
    dtype=tf.dtypes.float32,
    name=None
)
","Construct an identity matrix, or a batch of matrices.View aliases"
tf.linalg.global_norm,"tf.linalg.global_norm(
    t_list, name=None
)
",Computes the global norm of multiple tensors.View aliases
tf.linalg.inv,"tf.linalg.inv(
    input, adjoint=False, name=None
)
",Computes the inverse of one or more square invertible matrices or their adjoints (conjugate transposes).View aliases
tf.math.l2_normalize,"tf.math.l2_normalize(
    x, axis=None, epsilon=1e-12, name=None, dim=None
)
",Normalizes along dimension axis using an L2 norm. (deprecated arguments)View aliases
tf.linalg.logdet,"tf.linalg.logdet(
    matrix, name=None
)
",Computes log of the determinant of a hermitian positive definite matrix.View aliases
tf.linalg.logm,"tf.linalg.logm(
    input, name=None
)
",Computes the matrix logarithm of one or more square matrices:View aliases
tf.linalg.lstsq,"tf.linalg.lstsq(
    matrix, rhs, l2_regularizer=0.0, fast=True, name=None
)
",Solves one or more linear least-squares problems.View aliases
tf.linalg.lu,"tf.linalg.lu(
    input,
    output_idx_type=tf.dtypes.int32,
    name=None
)
",Computes the LU decomposition of one or more square matrices.View aliases
tf.linalg.lu_matrix_inverse,"tf.linalg.lu_matrix_inverse(
    lower_upper, perm, validate_args=False, name=None
)
",Computes the inverse given the LU decomposition(s) of one or more matrices.View aliases
tf.linalg.lu_reconstruct,"tf.linalg.lu_reconstruct(
    lower_upper, perm, validate_args=False, name=None
)
",The reconstruct one or more matrices from their LU decomposition(s).View aliases
tf.linalg.lu_solve,"tf.linalg.lu_solve(
    lower_upper, perm, rhs, validate_args=False, name=None
)
","Solves systems of linear eqns A X = RHS, given LU factorizations.View aliases"
tf.linalg.matmul,"tf.linalg.matmul(
    a,
    b,
    transpose_a=False,
    transpose_b=False,
    adjoint_a=False,
    adjoint_b=False,
    a_is_sparse=False,
    b_is_sparse=False,
    output_type=None,
    name=None
)
","Multiplies matrix a by matrix b, producing a * b.View aliases"
tf.linalg.matrix_rank,"tf.linalg.matrix_rank(
    a, tol=None, validate_args=False, name=None
)
",Compute the matrix rank of one or more matrices.View aliases
tf.linalg.matrix_transpose,"tf.linalg.matrix_transpose(
    a, name='matrix_transpose', conjugate=False
)
",Transposes last two dimensions of tensor a.View aliases
tf.linalg.matvec,"tf.linalg.matvec(
    a,
    b,
    transpose_a=False,
    adjoint_a=False,
    a_is_sparse=False,
    b_is_sparse=False,
    name=None
)
","Multiplies matrix a by vector b, producing a * b.View aliases"
tf.norm,"tf.norm(
    tensor, ord='euclidean', axis=None, keepdims=None, name=None
)
","Computes the norm of vectors, matrices, and tensors.View aliases"
tf.linalg.normalize,"tf.linalg.normalize(
    tensor, ord='euclidean', axis=None, name=None
)
",Normalizes tensor along dimension axis using specified norm.View aliases
tf.linalg.pinv,"tf.linalg.pinv(
    a, rcond=None, validate_args=False, name=None
)
",Compute the Moore-Penrose pseudo-inverse of one or more matrices.View aliases
tf.linalg.qr,"tf.linalg.qr(
    input, full_matrices=False, name=None
)
",Computes the QR decompositions of one or more matrices.View aliases
tf.linalg.set_diag,"tf.linalg.set_diag(
    input,
    diagonal,
    name='set_diag',
    k=0,
    align='RIGHT_LEFT'
)
",Returns a batched matrix tensor with new batched diagonal values.View aliases
tf.linalg.slogdet,"tf.linalg.slogdet(
    input, name=None
)
",Computes the sign and the log of the absolute value of the determinant ofView aliases
tf.linalg.solve,"tf.linalg.solve(
    matrix, rhs, adjoint=False, name=None
)
",Solves systems of linear equations.View aliases
tf.linalg.sqrtm,"tf.linalg.sqrtm(
    input, name=None
)
",Computes the matrix square root of one or more square matrices:View aliases
tf.linalg.svd,"tf.linalg.svd(
    tensor, full_matrices=False, compute_uv=True, name=None
)
",Computes the singular value decompositions of one or more matrices.View aliases
tf.linalg.tensor_diag,"tf.linalg.tensor_diag(
    diagonal, name=None
)
",Returns a diagonal tensor with a given diagonal values.View aliases
tf.linalg.tensor_diag_part,"tf.linalg.tensor_diag_part(
    input, name=None
)
",Returns the diagonal part of the tensor.View aliases
tf.tensordot,"tf.tensordot(
    a, b, axes, name=None
)
",Tensor contraction of a and b along specified axes and outer product.View aliases
tf.linalg.trace,"tf.linalg.trace(
    x, name=None
)
",Compute the trace of a tensor x.View aliases
tf.linalg.triangular_solve,"tf.linalg.triangular_solve(
    matrix, rhs, lower=True, adjoint=False, name=None
)
",Solve systems of linear equations with upper or lower triangular matrices.View aliases
tf.linalg.tridiagonal_matmul,"tf.linalg.tridiagonal_matmul(
    diagonals, rhs, diagonals_format='compact', name=None
)
",Multiplies tridiagonal matrix by matrix.View aliases
tf.linalg.tridiagonal_solve,"tf.linalg.tridiagonal_solve(
    diagonals,
    rhs,
    diagonals_format='compact',
    transpose_rhs=False,
    conjugate_rhs=False,
    name=None,
    partial_pivoting=True,
    perturb_singular=False
)
",Solves tridiagonal systems of equations.View aliases
tf.linspace,"tf.linspace(
    start, stop, num, name=None, axis=0
)
",Generates evenly-spaced values in an interval along a given axis.View aliases
tf.lite.Interpreter,"tf.lite.Interpreter(
    model_path=None,
    model_content=None,
    experimental_delegates=None,
    num_threads=None,
    experimental_op_resolver_type=tf.lite.experimental.OpResolverType.AUTO,
    experimental_preserve_all_tensors=False
)
",Interpreter interface for running TensorFlow Lite models.View aliases
tf.lite.RepresentativeDataset,"tf.lite.RepresentativeDataset(
    input_gen
)
",Representative dataset used to optimize the model.View aliases
tf.lite.TFLiteConverter,"tf.lite.TFLiteConverter(
    funcs, trackable_obj=None
)
",Converts a TensorFlow model into TensorFlow Lite model.
tf.lite.TargetSpec,"tf.lite.TargetSpec(
    supported_ops=None,
    supported_types=None,
    experimental_select_user_tf_ops=None,
    experimental_supported_backends=None
)
",Specification of target device used to optimize the model.View aliases
tf.lite.experimental.QuantizationDebugOptions,"tf.lite.experimental.QuantizationDebugOptions(
    layer_debug_metrics: Optional[Mapping[str, Callable[[np.ndarray], float]]] = None,
    model_debug_metrics: Optional[Mapping[str, Callable[[Sequence[np.ndarray], Sequence[np.ndarray]],
        float]]] = None,
    layer_direct_compare_metrics: Optional[Mapping[str, Callable[[Sequence[np.ndarray], Sequence[np.ndarray],
        float, int], float]]] = None,
    denylisted_ops: Optional[List[str]] = None,
    denylisted_nodes: Optional[List[str]] = None,
    fully_quantize: bool = False
) -> None
",Debug options to set up a given QuantizationDebugger.View aliases
tf.lite.experimental.QuantizationDebugger,"tf.lite.experimental.QuantizationDebugger(
    quant_debug_model_path: Optional[str] = None,
    quant_debug_model_content: Optional[bytes] = None,
    float_model_path: Optional[str] = None,
    float_model_content: Optional[bytes] = None,
    debug_dataset: Optional[Callable[[], Iterable[Sequence[np.ndarray]]]] = None,
    debug_options: Optional[tf.lite.experimental.QuantizationDebugOptions] = None,
    converter: Optional[TFLiteConverter] = None
) -> None
",Debugger for Quantized TensorFlow Lite debug mode models.View aliases
tf.lite.experimental.authoring.compatible,"tf.lite.experimental.authoring.compatible(
    target=None, converter_target_spec=None, **kwargs
)
",Wraps tf.function into a callable function with TFLite compatibility checking.View aliases
tf.lite.experimental.load_delegate,"tf.lite.experimental.load_delegate(
    library, options=None
)
",Returns loaded Delegate object.View aliases
tf.load_library,"tf.load_library(
    library_location
)
",Loads a TensorFlow plugin.View aliases
tf.load_op_library,"tf.load_op_library(
    library_filename
)
","Loads a TensorFlow plugin, containing custom ops and kernels.View aliases"
tf.math.logical_and,"tf.math.logical_and(
    x, y, name=None
)
",Returns the truth value of x AND y element-wise.View aliases
tf.math.logical_not,"tf.math.logical_not(
    x, name=None
)
",Returns the truth value of NOT x element-wise.View aliases
tf.math.logical_or,"tf.math.logical_or(
    x, y, name=None
)
",Returns the truth value of x OR y element-wise.View aliases
tf.lookup.KeyValueTensorInitializer,"tf.lookup.KeyValueTensorInitializer(
    keys, values, key_dtype=None, value_dtype=None, name=None
)
",Table initializers given keys and values tensors.View aliases
tf.lookup.StaticHashTable,"tf.lookup.StaticHashTable(
    initializer, default_value, name=None, experimental_is_anonymous=False
)
",A generic hash table that is immutable once initialized.Inherits From: TrackableResource
tf.lookup.StaticVocabularyTable,"tf.lookup.StaticVocabularyTable(
    initializer,
    num_oov_buckets,
    lookup_key_dtype=None,
    name=None,
    experimental_is_anonymous=False
)
",String to Id table that assigns out-of-vocabulary keys to hash buckets.Inherits From: TrackableResource
tf.lookup.TextFileInitializer,"tf.lookup.TextFileInitializer(
    filename,
    key_dtype,
    key_index,
    value_dtype,
    value_index,
    vocab_size=None,
    delimiter='\t',
    name=None,
    value_index_offset=0
)
",Table initializers from a text file.View aliases
tf.lookup.experimental.DenseHashTable,"tf.lookup.experimental.DenseHashTable(
    key_dtype,
    value_dtype,
    default_value,
    empty_key,
    deleted_key,
    initial_num_buckets=None,
    name='MutableDenseHashTable',
    checkpoint=True,
    experimental_is_anonymous=False
)
",A mutable hash table with faster lookups and higher memory usage.Inherits From: TrackableResourceView aliases
tf.lookup.experimental.MutableHashTable,"tf.lookup.experimental.MutableHashTable(
    key_dtype,
    value_dtype,
    default_value,
    name='MutableHashTable',
    checkpoint=True,
    experimental_is_anonymous=False
)
",A generic mutable hash table implementation.Inherits From: TrackableResourceView aliases
tf.keras.losses.BinaryCrossentropy,"tf.keras.losses.BinaryCrossentropy(
    from_logits=False,
    label_smoothing=0.0,
    axis=-1,
    reduction=losses_utils.ReductionV2.AUTO,
    name='binary_crossentropy'
)
",Computes the cross-entropy loss between true labels and predicted labels.Inherits From: LossView aliases
tf.keras.losses.BinaryFocalCrossentropy,"tf.keras.losses.BinaryFocalCrossentropy(
    apply_class_balancing=False,
    alpha=0.25,
    gamma=2.0,
    from_logits=False,
    label_smoothing=0.0,
    axis=-1,
    reduction=losses_utils.ReductionV2.AUTO,
    name='binary_focal_crossentropy'
)
",Computes the focal cross-entropy loss between true labels and predictions.Inherits From: LossView aliases
tf.keras.losses.CategoricalCrossentropy,"tf.keras.losses.CategoricalCrossentropy(
    from_logits=False,
    label_smoothing=0.0,
    axis=-1,
    reduction=losses_utils.ReductionV2.AUTO,
    name='categorical_crossentropy'
)
",Computes the crossentropy loss between the labels and predictions.Inherits From: LossView aliases
tf.keras.losses.CategoricalHinge,"tf.keras.losses.CategoricalHinge(
    reduction=losses_utils.ReductionV2.AUTO, name='categorical_hinge'
)
",Computes the categorical hinge loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.CosineSimilarity,"tf.keras.losses.CosineSimilarity(
    axis=-1,
    reduction=losses_utils.ReductionV2.AUTO,
    name='cosine_similarity'
)
",Computes the cosine similarity between labels and predictions.Inherits From: LossView aliases
tf.keras.losses.Hinge,"tf.keras.losses.Hinge(
    reduction=losses_utils.ReductionV2.AUTO, name='hinge'
)
",Computes the hinge loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.Huber,"tf.keras.losses.Huber(
    delta=1.0,
    reduction=losses_utils.ReductionV2.AUTO,
    name='huber_loss'
)
",Computes the Huber loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.losses.KLDivergence,"tf.keras.losses.KLDivergence(
    reduction=losses_utils.ReductionV2.AUTO, name='kl_divergence'
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.LogCosh,"tf.keras.losses.LogCosh(
    reduction=losses_utils.ReductionV2.AUTO, name='log_cosh'
)
",Computes the logarithm of the hyperbolic cosine of the prediction error.Inherits From: LossView aliases
tf.keras.losses.Loss,"tf.keras.losses.Loss(
    reduction=losses_utils.ReductionV2.AUTO, name=None
)
",Loss base class.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.losses.MeanAbsoluteError,"tf.keras.losses.MeanAbsoluteError(
    reduction=losses_utils.ReductionV2.AUTO,
    name='mean_absolute_error'
)
",Computes the mean of absolute difference between labels and predictions.Inherits From: LossView aliases
tf.keras.losses.MeanAbsolutePercentageError,"tf.keras.losses.MeanAbsolutePercentageError(
    reduction=losses_utils.ReductionV2.AUTO,
    name='mean_absolute_percentage_error'
)
",Computes the mean absolute percentage error between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.MeanSquaredError,"tf.keras.losses.MeanSquaredError(
    reduction=losses_utils.ReductionV2.AUTO,
    name='mean_squared_error'
)
",Computes the mean of squares of errors between labels and predictions.Inherits From: LossView aliases
tf.keras.losses.MeanSquaredLogarithmicError,"tf.keras.losses.MeanSquaredLogarithmicError(
    reduction=losses_utils.ReductionV2.AUTO,
    name='mean_squared_logarithmic_error'
)
",Computes the mean squared logarithmic error between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.Poisson,"tf.keras.losses.Poisson(
    reduction=losses_utils.ReductionV2.AUTO, name='poisson'
)
",Computes the Poisson loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.SparseCategoricalCrossentropy,"tf.keras.losses.SparseCategoricalCrossentropy(
    from_logits=False,
    ignore_class=None,
    reduction=losses_utils.ReductionV2.AUTO,
    name='sparse_categorical_crossentropy'
)
",Computes the crossentropy loss between the labels and predictions.Inherits From: LossView aliases
tf.keras.losses.SquaredHinge,"tf.keras.losses.SquaredHinge(
    reduction=losses_utils.ReductionV2.AUTO, name='squared_hinge'
)
",Computes the squared hinge loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.metrics.binary_crossentropy,"tf.keras.metrics.binary_crossentropy(
    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1
)
",Computes the binary crossentropy loss.View aliases
tf.keras.metrics.binary_focal_crossentropy,"tf.keras.metrics.binary_focal_crossentropy(
    y_true,
    y_pred,
    apply_class_balancing=False,
    alpha=0.25,
    gamma=2.0,
    from_logits=False,
    label_smoothing=0.0,
    axis=-1
)
",Computes the binary focal crossentropy loss.View aliases
tf.keras.metrics.categorical_crossentropy,"tf.keras.metrics.categorical_crossentropy(
    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1
)
",Computes the categorical crossentropy loss.View aliases
tf.keras.losses.categorical_hinge,"tf.keras.losses.categorical_hinge(
    y_true, y_pred
)
",Computes the categorical hinge loss between y_true and y_pred.View aliases
tf.keras.losses.cosine_similarity,"tf.keras.losses.cosine_similarity(
    y_true, y_pred, axis=-1
)
",Computes the cosine similarity between labels and predictions.View aliases
tf.keras.losses.deserialize,"tf.keras.losses.deserialize(
    name, custom_objects=None
)
",Deserializes a serialized loss class/function instance.View aliases
tf.keras.losses.get,"tf.keras.losses.get(
    identifier
)
",Retrieves a Keras loss as a function/Loss class instance.View aliases
tf.keras.metrics.hinge,"tf.keras.metrics.hinge(
    y_true, y_pred
)
",Computes the hinge loss between y_true and y_pred.View aliases
tf.keras.losses.huber,"tf.keras.losses.huber(
    y_true, y_pred, delta=1.0
)
",Computes Huber loss value.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.losses.log_cosh,"tf.keras.losses.log_cosh(
    y_true, y_pred
)
",Logarithm of the hyperbolic cosine of the prediction error.View aliases
tf.keras.losses.log_cosh,"tf.keras.losses.log_cosh(
    y_true, y_pred
)
",Logarithm of the hyperbolic cosine of the prediction error.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.poisson,"tf.keras.metrics.poisson(
    y_true, y_pred
)
",Computes the Poisson loss between y_true and y_pred.View aliases
tf.keras.losses.serialize,"tf.keras.losses.serialize(
    loss
)
",Serializes loss function or Loss instance.View aliases
tf.keras.metrics.sparse_categorical_crossentropy,"tf.keras.metrics.sparse_categorical_crossentropy(
    y_true, y_pred, from_logits=False, axis=-1, ignore_class=None
)
",Computes the sparse categorical crossentropy loss.View aliases
tf.keras.metrics.squared_hinge,"tf.keras.metrics.squared_hinge(
    y_true, y_pred
)
",Computes the squared hinge loss between y_true and y_pred.View aliases
tf.make_ndarray,"tf.make_ndarray(
    tensor
)
",Create a numpy ndarray from a tensor.View aliases
tf.make_tensor_proto,"tf.make_tensor_proto(
    values, dtype=None, shape=None, verify_shape=False, allow_broadcast=False
)
",Create a TensorProto.View aliases
tf.map_fn,"tf.map_fn(
    fn,
    elems,
    dtype=None,
    parallel_iterations=None,
    back_prop=True,
    swap_memory=False,
    infer_shape=True,
    name=None,
    fn_output_signature=None
)
",Transforms elems by applying fn to each element unstacked on axis 0. (deprecated arguments)
tf.map_fn,"tf.map_fn(fn=tf.strings.length,  # input & output have different dtypes","Transforms elems by applying fn to each element unstacked on axis 0. (deprecated arguments)tf.map_fn(    fn,    elems,    dtype=None,    parallel_iterations=None,    back_prop=True,    swap_memory=False,    infer_shape=True,    name=None,    fn_output_signature=None)Used in the notebooksDeprecated: SOME ARGUMENTS ARE DEPRECATED: See also tf.scan.map_fn unstacks elems on axis 0 to obtain a sequence of elements;calls fn to transform each element; and then stacks the transformedvalues back together.Mapping functions with single-Tensor inputs and outputsIf elems is a single tensor and fn's signature is tf.Tensor->tf.Tensor,then map_fn(fn, elems) is equivalent totf.stack([fn(elem) for elem in tf.unstack(elems)]).  E.g.:tf.map_fn(fn=lambda t: tf.range(t, t + 3), elems=tf.constant([3, 5, 2]))<tf.Tensor: shape=(3, 3), dtype=int32, numpy=  array([[3, 4, 5],         [5, 6, 7],         [2, 3, 4]], dtype=int32)>map_fn(fn, elems).shape = [elems.shape[0]] + fn(elems[0]).shape.Mapping functions with multi-arity inputs and outputsmap_fn also supports functions with multi-arity inputs and outputs:If If Specifying fn's output signatureIf fn's input and output signatures are different, then the outputsignature must be specified using fn_output_signature.  (The input andoutput signatures are differ if their structures, dtypes, or tensor types donot match).  E.g.:"
tf.math.abs,"tf.math.abs(
    x, name=None
)
",Computes the absolute value of a tensor.View aliases
tf.math.accumulate_n,"tf.math.accumulate_n(
    inputs, shape=None, tensor_dtype=None, name=None
)
",Returns the element-wise sum of a list of tensors.View aliases
tf.math.acos,"tf.math.acos(
    x, name=None
)
",Computes acos of x element-wise.View aliases
tf.math.acosh,"tf.math.acosh(
    x, name=None
)
",Computes inverse hyperbolic cosine of x element-wise.View aliases
tf.math.add,"tf.math.add(
    x, y, name=None
)
",Returns x + y element-wise.View aliases
tf.math.add_n,"tf.math.add_n(
    inputs, name=None
)
",Adds all input tensors element-wise.View aliases
tf.math.angle,"tf.math.angle(
    input, name=None
)
",Returns the element-wise argument of a complex (or real) tensor.View aliases
tf.math.approx_max_k,"tf.math.approx_max_k(
    operand,
    k,
    reduction_dimension=-1,
    recall_target=0.95,
    reduction_input_size_override=-1,
    aggregate_to_topk=True,
    name=None
)
",Returns max k values and their indices of the input operand in an approximate manner.View aliases
tf.math.approx_min_k,"tf.math.approx_min_k(
    operand,
    k,
    reduction_dimension=-1,
    recall_target=0.95,
    reduction_input_size_override=-1,
    aggregate_to_topk=True,
    name=None
)
",Returns min k values and their indices of the input operand in an approximate manner.View aliases
tf.math.argmax,"tf.math.argmax(
    input,
    axis=None,
    output_type=tf.dtypes.int64,
    name=None
)
",Returns the index with the largest value across axes of a tensor.View aliases
tf.math.argmin,"tf.math.argmin(
    input,
    axis=None,
    output_type=tf.dtypes.int64,
    name=None
)
",Returns the index with the smallest value across axes of a tensor.View aliases
tf.math.asin,"tf.math.asin(
    x, name=None
)
",Computes the trignometric inverse sine of x element-wise.View aliases
tf.math.asinh,"tf.math.asinh(
    x, name=None
)
",Computes inverse hyperbolic sine of x element-wise.View aliases
tf.math.atan,"tf.math.atan(
    x, name=None
)
",Computes the trignometric inverse tangent of x element-wise.View aliases
tf.math.atan2,"tf.math.atan2(
    y, x, name=None
)
","Computes arctangent of y/x element-wise, respecting signs of the arguments.View aliases"
tf.math.atanh,"tf.math.atanh(
    x, name=None
)
",Computes inverse hyperbolic tangent of x element-wise.View aliases
tf.math.bessel_i0,"tf.math.bessel_i0(
    x, name=None
)
",Computes the Bessel i0 function of x element-wise.View aliases
tf.math.bessel_i0e,"tf.math.bessel_i0e(
    x, name=None
)
",Computes the Bessel i0e function of x element-wise.View aliases
tf.math.bessel_i1,"tf.math.bessel_i1(
    x, name=None
)
",Computes the Bessel i1 function of x element-wise.View aliases
tf.math.bessel_i1e,"tf.math.bessel_i1e(
    x, name=None
)
",Computes the Bessel i1e function of x element-wise.View aliases
tf.math.betainc,"tf.math.betainc(
    a, b, x, name=None
)
","Compute the regularized incomplete beta integral \(I_x(a, b)\).View aliases"
tf.math.bincount,"tf.math.bincount(
    arr,
    weights=None,
    minlength=None,
    maxlength=None,
    dtype=tf.dtypes.int32,
    name=None,
    axis=None,
    binary_output=False
)
",Counts the number of occurrences of each value in an integer array.
tf.math.ceil,"tf.math.ceil(
    x, name=None
)
","Return the ceiling of the input, element-wise.View aliases"
tf.math.confusion_matrix,"tf.math.confusion_matrix(
    labels,
    predictions,
    num_classes=None,
    weights=None,
    dtype=tf.dtypes.int32,
    name=None
)
",Computes the confusion matrix from predictions and labels.
tf.math.conj,"tf.math.conj(
    x, name=None
)
",Returns the complex conjugate of a complex number.View aliases
tf.math.cos,"tf.math.cos(
    x, name=None
)
",Computes cos of x element-wise.View aliases
tf.math.cosh,"tf.math.cosh(
    x, name=None
)
",Computes hyperbolic cosine of x element-wise.View aliases
tf.math.count_nonzero,"tf.math.count_nonzero(
    input,
    axis=None,
    keepdims=None,
    dtype=tf.dtypes.int64,
    name=None
)
",Computes number of nonzero elements across dimensions of a tensor.
tf.math.cumprod,"tf.math.cumprod(
    x, axis=0, exclusive=False, reverse=False, name=None
)
",Compute the cumulative product of the tensor x along axis.View aliases
tf.math.cumsum,"tf.math.cumsum(
    x, axis=0, exclusive=False, reverse=False, name=None
)
",Compute the cumulative sum of the tensor x along axis.View aliases
tf.math.cumulative_logsumexp,"tf.math.cumulative_logsumexp(
    x, axis=0, exclusive=False, reverse=False, name=None
)
",Compute the cumulative log-sum-exp of the tensor x along axis.View aliases
tf.math.digamma,"tf.math.digamma(
    x, name=None
)
","Computes Psi, the derivative of Lgamma (the log of the absolute value ofView aliases"
tf.math.divide,"tf.math.divide(
    x, y, name=None
)
",Computes Python style division of x by y.View aliases
tf.math.divide_no_nan,"tf.math.divide_no_nan(
    x, y, name=None
)
",Computes a safe divide which returns 0 if y (denominator) is zero.View aliases
tf.constant,tf.constant(3.0) / 0.0,"Computes a safe divide which returns 0 if y (denominator) is zero.View aliasestf.math.divide_no_nan(    x, y, name=None)For example:"
tf.math.equal,"tf.math.equal(
    x, y, name=None
)
",Returns the truth value of (x == y) element-wise.View aliases
tf.math.erf,"tf.math.erf(
    x, name=None
)
","Computes the Gauss error function of x element-wise. In statistics, for non-negative values of \(x\), the error function has the following interpretation: for a random variable \(Y\) that is normally distributed with mean 0 and variance \(1/\sqrt{2}\), \(erf(x)\) is the probability that \(Y\) falls in the range \([x, x]\).View aliases"
tf.math.erfc,"tf.math.erfc(
    x, name=None
)
",Computes the complementary error function of x element-wise.View aliases
tf.math.erfcinv,"tf.math.erfcinv(
    x, name=None
)
",Computes the inverse of complementary error function.View aliases
tf.math.erfinv,"tf.math.erfinv(
    x, name=None
)
",Compute inverse error function.View aliases
tf.math.exp,"tf.math.exp(
    x, name=None
)
",Computes exponential of x element-wise.  \(y = e^x\).View aliases
tf.math.expm1,"tf.math.expm1(
    x, name=None
)
",Computes exp(x) - 1 element-wise.View aliases
tf.math.floor,"tf.math.floor(
    x, name=None
)
",Returns element-wise largest integer not greater than x.View aliases
tf.math.floordiv,"tf.math.floordiv(
    x, y, name=None
)
","Divides x / y elementwise, rounding toward the most negative integer.View aliases"
tf.math.floormod,"tf.math.floormod(
    x, y, name=None
)
",Returns element-wise remainder of division. When x < 0 xor y < 0 isView aliases
tf.math.greater,"tf.math.greater(
    x, y, name=None
)
",Returns the truth value of (x > y) element-wise.View aliases
tf.math.greater_equal,"tf.math.greater_equal(
    x, y, name=None
)
",Returns the truth value of (x >= y) element-wise.View aliases
tf.math.igamma,"tf.math.igamma(
    a, x, name=None
)
","Compute the lower regularized incomplete Gamma function P(a, x).View aliases"
tf.math.igammac,"tf.math.igammac(
    a, x, name=None
)
","Compute the upper regularized incomplete Gamma function Q(a, x).View aliases"
tf.math.imag,"tf.math.imag(
    input, name=None
)
",Returns the imaginary part of a complex (or real) tensor.View aliases
tf.math.in_top_k,"tf.math.in_top_k(
    targets, predictions, k, name=None
)
",Says whether the targets are in the top K predictions.View aliases
tf.math.invert_permutation,"tf.math.invert_permutation(
    x, name=None
)
",Computes the inverse permutation of a tensor.View aliases
tf.math.is_finite,"tf.math.is_finite(
    x, name=None
)
",Returns which elements of x are finite.View aliases
tf.math.is_inf,"tf.math.is_inf(
    x, name=None
)
",Returns which elements of x are Inf.View aliases
tf.math.is_nan,"tf.math.is_nan(
    x, name=None
)
",Returns which elements of x are NaN.View aliases
tf.math.is_non_decreasing,"tf.math.is_non_decreasing(
    x, name=None
)
",Returns True if x is non-decreasing.View aliases
tf.math.is_strictly_increasing,"tf.math.is_strictly_increasing(
    x, name=None
)
",Returns True if x is strictly increasing.View aliases
tf.math.l2_normalize,"tf.math.l2_normalize(
    x, axis=None, epsilon=1e-12, name=None, dim=None
)
",Normalizes along dimension axis using an L2 norm. (deprecated arguments)View aliases
tf.math.lbeta,"tf.math.lbeta(
    x, name=None
)
","Computes \(ln(|Beta(x)|)\), reducing along the last dimension.View aliases"
tf.math.less,"tf.math.less(
    x, y, name=None
)
",Returns the truth value of (x < y) element-wise.View aliases
tf.math.less_equal,"tf.math.less_equal(
    x, y, name=None
)
",Returns the truth value of (x <= y) element-wise.View aliases
tf.math.lgamma,"tf.math.lgamma(
    x, name=None
)
",Computes the log of the absolute value of Gamma(x) element-wise.View aliases
tf.math.log,"tf.math.log(
    x, name=None
)
",Computes natural logarithm of x element-wise.View aliases
tf.math.log1p,"tf.math.log1p(
    x, name=None
)
",Computes natural logarithm of (1 + x) element-wise.View aliases
tf.math.log_sigmoid,"tf.math.log_sigmoid(
    x, name=None
)
",Computes log sigmoid of x element-wise.View aliases
tf.nn.log_softmax,"tf.nn.log_softmax(
    logits, axis=None, name=None
)
",Computes log softmax activations.View aliases
tf.math.logical_and,"tf.math.logical_and(
    x, y, name=None
)
",Returns the truth value of x AND y element-wise.View aliases
tf.math.logical_not,"tf.math.logical_not(
    x, name=None
)
",Returns the truth value of NOT x element-wise.View aliases
tf.math.logical_or,"tf.math.logical_or(
    x, y, name=None
)
",Returns the truth value of x OR y element-wise.View aliases
tf.math.logical_xor,"tf.math.logical_xor(
    x, y, name='LogicalXor'
)
",Logical XOR function.View aliases
tf.math.maximum,"tf.math.maximum(
    x, y, name=None
)
",Returns the max of x and y (i.e. x > y ? x : y) element-wise.View aliases
tf.math.minimum,"tf.math.minimum(
    x, y, name=None
)
",Returns the min of x and y (i.e. x < y ? x : y) element-wise.View aliases
tf.math.floormod,"tf.math.floormod(
    x, y, name=None
)
",Returns element-wise remainder of division. When x < 0 xor y < 0 isView aliases
tf.math.multiply,"tf.math.multiply(
    x, y, name=None
)
",Returns an element-wise x * y.View aliases
tf.math.multiply_no_nan,"tf.math.multiply_no_nan(
    x, y, name=None
)
","Computes the product of x and y and returns 0 if the y is zero, even if x is NaN or infinite.View aliases"
tf.math.ndtri,"tf.math.ndtri(
    x, name=None
)
",Compute quantile of Standard Normal.View aliases
tf.math.negative,"tf.math.negative(
    x, name=None
)
",Computes numerical negative value element-wise.View aliases
tf.math.nextafter,"tf.math.nextafter(
    x1, x2, name=None
)
","Returns the next representable value of x1 in the direction of x2, element-wise.View aliases"
tf.math.not_equal,"tf.math.not_equal(
    x, y, name=None
)
",Returns the truth value of (x != y) element-wise.View aliases
tf.math.polygamma,"tf.math.polygamma(
    a, x, name=None
)
",Compute the polygamma function \(\psi^{(n)}(x)\).View aliases
tf.math.polyval,"tf.math.polyval(
    coeffs, x, name=None
)
",Computes the elementwise value of a polynomial.View aliases
tf.math.pow,"tf.math.pow(
    x, y, name=None
)
",Computes the power of one value to another.View aliases
tf.math.real,"tf.math.real(
    input, name=None
)
",Returns the real part of a complex (or real) tensor.View aliases
tf.math.reciprocal,"tf.math.reciprocal(
    x, name=None
)
",Computes the reciprocal of x element-wise.View aliases
tf.math.reciprocal_no_nan,"tf.math.reciprocal_no_nan(
    x, name=None
)
","Performs a safe reciprocal operation, element wise.View aliases"
tf.math.reduce_all,"tf.math.reduce_all(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes tf.math.logical_and of elements across dimensions of a tensor.View aliases
tf.math.reduce_any,"tf.math.reduce_any(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes tf.math.logical_or of elements across dimensions of a tensor.View aliases
tf.math.reduce_euclidean_norm,"tf.math.reduce_euclidean_norm(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes the Euclidean norm of elements across dimensions of a tensor.View aliases
tf.math.reduce_logsumexp,"tf.math.reduce_logsumexp(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes log(sum(exp(elements across dimensions of a tensor))).View aliases
tf.math.reduce_max,"tf.math.reduce_max(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes tf.math.maximum of elements across dimensions of a tensor.View aliases
tf.math.reduce_mean,"tf.math.reduce_mean(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes the mean of elements across dimensions of a tensor.View aliases
tf.math.reduce_min,"tf.math.reduce_min(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes the tf.math.minimum of elements across dimensions of a tensor.View aliases
tf.math.reduce_prod,"tf.math.reduce_prod(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes tf.math.multiply of elements across dimensions of a tensor.View aliases
tf.math.reduce_std,"tf.math.reduce_std(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes the standard deviation of elements across dimensions of a tensor.View aliases
tf.math.reduce_sum,"tf.math.reduce_sum(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes the sum of elements across dimensions of a tensor.View aliases
tf.math.reduce_variance,"tf.math.reduce_variance(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes the variance of elements across dimensions of a tensor.View aliases
tf.math.rint,"tf.math.rint(
    x, name=None
)
",Returns element-wise integer closest to x.View aliases
tf.math.round,"tf.math.round(
    x, name=None
)
","Rounds the values of a tensor to the nearest integer, element-wise.View aliases"
tf.math.rsqrt,"tf.math.rsqrt(
    x, name=None
)
",Computes reciprocal of square root of x element-wise.View aliases
tf.math.scalar_mul,"tf.math.scalar_mul(
    scalar, x, name=None
)
",Multiplies a scalar times a Tensor or IndexedSlices object.View aliases
tf.math.segment_max,"tf.math.segment_max(
    data, segment_ids, name=None
)
",Computes the maximum along segments of a tensor.View aliases
tf.math.segment_mean,"tf.math.segment_mean(
    data, segment_ids, name=None
)
",Computes the mean along segments of a tensor.View aliases
tf.math.segment_min,"tf.math.segment_min(
    data, segment_ids, name=None
)
",Computes the minimum along segments of a tensor.View aliases
tf.math.segment_prod,"tf.math.segment_prod(
    data, segment_ids, name=None
)
",Computes the product along segments of a tensor.View aliases
tf.math.segment_sum,"tf.math.segment_sum(
    data, segment_ids, name=None
)
",Computes the sum along segments of a tensor.View aliases
tf.math.sigmoid,"tf.math.sigmoid(
    x, name=None
)
",Computes sigmoid of x element-wise.View aliases
tf.math.sign,"tf.math.sign(
    x, name=None
)
",Returns an element-wise indication of the sign of a number.View aliases
tf.math.sin,"tf.math.sin(
    x, name=None
)
",Computes sine of x element-wise.View aliases
tf.math.sinh,"tf.math.sinh(
    x, name=None
)
",Computes hyperbolic sine of x element-wise.View aliases
tf.math.sobol_sample,"tf.math.sobol_sample(
    dim,
    num_results,
    skip=0,
    dtype=tf.dtypes.float32,
    name=None
)
",Generates points from the Sobol sequence.View aliases
tf.nn.softmax,"tf.nn.softmax(
    logits, axis=None, name=None
)
",Computes softmax activations.View aliases
tf.math.softplus,"tf.math.softplus(
    features, name=None
)
",Computes elementwise softplus: softplus(x) = log(exp(x) + 1).View aliases
tf.nn.softsign,"tf.nn.softsign(
    features, name=None
)
",Computes softsign: features / (abs(features) + 1).View aliases
tf.math.bessel_i0,"tf.math.bessel_i0(
    x, name=None
)
",Computes the Bessel i0 function of x element-wise.View aliases
tf.math.bessel_i0e,"tf.math.bessel_i0e(
    x, name=None
)
",Computes the Bessel i0e function of x element-wise.View aliases
tf.math.bessel_i1,"tf.math.bessel_i1(
    x, name=None
)
",Computes the Bessel i1 function of x element-wise.View aliases
tf.math.bessel_i1e,"tf.math.bessel_i1e(
    x, name=None
)
",Computes the Bessel i1e function of x element-wise.View aliases
tf.math.special.bessel_j0,"tf.math.special.bessel_j0(
    x, name=None
)
",Computes the Bessel j0 function of x element-wise.View aliases
tf.math.special.bessel_j1,"tf.math.special.bessel_j1(
    x, name=None
)
",Computes the Bessel j1 function of x element-wise.View aliases
tf.math.special.bessel_k0,"tf.math.special.bessel_k0(
    x, name=None
)
",Computes the Bessel k0 function of x element-wise.View aliases
tf.math.special.bessel_k0e,"tf.math.special.bessel_k0e(
    x, name=None
)
",Computes the Bessel k0e function of x element-wise.View aliases
tf.math.special.bessel_k1,"tf.math.special.bessel_k1(
    x, name=None
)
",Computes the Bessel k1 function of x element-wise.View aliases
tf.math.special.bessel_k1e,"tf.math.special.bessel_k1e(
    x, name=None
)
",Computes the Bessel k1e function of x element-wise.View aliases
tf.math.special.bessel_y0,"tf.math.special.bessel_y0(
    x, name=None
)
",Computes the Bessel y0 function of x element-wise.View aliases
tf.math.special.bessel_y1,"tf.math.special.bessel_y1(
    x, name=None
)
",Computes the Bessel y1 function of x element-wise.View aliases
tf.math.special.dawsn,"tf.math.special.dawsn(
    x, name=None
)
",Computes Dawson's integral of x element-wise.View aliases
tf.math.special.expint,"tf.math.special.expint(
    x, name=None
)
",Computes the Exponential integral of x element-wise.View aliases
tf.math.special.fresnel_cos,"tf.math.special.fresnel_cos(
    x, name=None
)
",Computes Fresnel's cosine integral of x element-wise.View aliases
tf.math.special.fresnel_sin,"tf.math.special.fresnel_sin(
    x, name=None
)
",Computes Fresnel's sine integral of x element-wise.View aliases
tf.math.special.spence,"tf.math.special.spence(
    x, name=None
)
",Computes Spence's integral of x element-wise.View aliases
tf.math.sqrt,"tf.math.sqrt(
    x, name=None
)
",Computes element-wise square root of the input tensor.View aliases
tf.math.square,"tf.math.square(
    x, name=None
)
",Computes square of x element-wise.View aliases
tf.math.squared_difference,"tf.math.squared_difference(
    x, y, name=None
)
",Returns conj(x - y)(x - y) element-wise.View aliases
tf.math.subtract,"tf.math.subtract(
    x, y, name=None
)
",Returns x - y element-wise.View aliases
tf.math.tan,"tf.math.tan(
    x, name=None
)
",Computes tan of x element-wise.View aliases
tf.math.tanh,"tf.math.tanh(
    x, name=None
)
",Computes hyperbolic tangent of x element-wise.View aliases
tf.math.top_k,"tf.math.top_k(
    input, k=1, sorted=True, name=None
)
",Finds values and indices of the k largest entries for the last dimension.View aliases
tf.math.truediv,"tf.math.truediv(
    x, y, name=None
)
",Divides x / y elementwise (using Python 3 division operator semantics).View aliases
tf.math.unsorted_segment_max,"tf.math.unsorted_segment_max(
    data, segment_ids, num_segments, name=None
)
",Computes the maximum along segments of a tensor.View aliases
tf.math.unsorted_segment_mean,"tf.math.unsorted_segment_mean(
    data, segment_ids, num_segments, name=None
)
",Computes the mean along segments of a tensor.View aliases
tf.math.unsorted_segment_min,"tf.math.unsorted_segment_min(
    data, segment_ids, num_segments, name=None
)
",Computes the minimum along segments of a tensor.View aliases
tf.math.unsorted_segment_prod,"tf.math.unsorted_segment_prod(
    data, segment_ids, num_segments, name=None
)
",Computes the product along segments of a tensor.View aliases
tf.math.unsorted_segment_sqrt_n,"tf.math.unsorted_segment_sqrt_n(
    data, segment_ids, num_segments, name=None
)
",Computes the sum along segments of a tensor divided by the sqrt(N).View aliases
tf.math.unsorted_segment_sum,"tf.math.unsorted_segment_sum(
    data, segment_ids, num_segments, name=None
)
",Computes the sum along segments of a tensor.View aliases
tf.math.xdivy,"tf.math.xdivy(
    x, y, name=None
)
","Returns 0 if x == 0, and x / y otherwise, elementwise.View aliases"
tf.math.xlog1py,"tf.math.xlog1py(
    x, y, name=None
)
",Compute x * log1p(y).View aliases
tf.math.xlogy,"tf.math.xlogy(
    x, y, name=None
)
","Returns 0 if x == 0, and x * log(y) otherwise, elementwise.View aliases"
tf.math.zero_fraction,"tf.math.zero_fraction(
    value, name=None
)
",Returns the fraction of zeros in value.View aliases
tf.math.zeta,"tf.math.zeta(
    x, q, name=None
)
","Compute the Hurwitz zeta function \(\zeta(x, q)\).View aliases"
tf.linalg.matmul,"tf.linalg.matmul(
    a,
    b,
    transpose_a=False,
    transpose_b=False,
    adjoint_a=False,
    adjoint_b=False,
    a_is_sparse=False,
    b_is_sparse=False,
    output_type=None,
    name=None
)
","Multiplies matrix a by matrix b, producing a * b.View aliases"
tf.linalg.sqrtm,"tf.linalg.sqrtm(
    input, name=None
)
",Computes the matrix square root of one or more square matrices:View aliases
tf.math.maximum,"tf.math.maximum(
    x, y, name=None
)
",Returns the max of x and y (i.e. x > y ? x : y) element-wise.View aliases
tf.meshgrid,"tf.meshgrid(
    *args, **kwargs
)
",Broadcasts parameters for evaluation on an N-D grid.View aliases
tf.keras.metrics.AUC,"tf.keras.metrics.AUC(
    num_thresholds=200,
    curve='ROC',
    summation_method='interpolation',
    name=None,
    dtype=None,
    thresholds=None,
    multi_label=False,
    num_labels=None,
    label_weights=None,
    from_logits=False
)
","Approximates the AUC (Area under the curve) of the ROC or PR curves.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.Accuracy,"tf.keras.metrics.Accuracy(
    name='accuracy', dtype=None
)
","Calculates how often predictions equal labels.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.BinaryAccuracy,"tf.keras.metrics.BinaryAccuracy(
    name='binary_accuracy', dtype=None, threshold=0.5
)
","Calculates how often predictions match binary labels.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.BinaryCrossentropy,"tf.keras.metrics.BinaryCrossentropy(
    name='binary_crossentropy',
    dtype=None,
    from_logits=False,
    label_smoothing=0
)
","Computes the crossentropy metric between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.BinaryIoU,"tf.keras.metrics.BinaryIoU(
    target_class_ids: Union[List[int], Tuple[int, ...]] = (0, 1),
    threshold=0.5,
    name=None,
    dtype=None
)
","Computes the Intersection-Over-Union metric for class 0 and/or 1.Inherits From: IoU, Metric, Layer, ModuleView aliases"
tf.keras.metrics.CategoricalAccuracy,"tf.keras.metrics.CategoricalAccuracy(
    name='categorical_accuracy', dtype=None
)
","Calculates how often predictions match one-hot labels.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.CategoricalCrossentropy,"tf.keras.metrics.CategoricalCrossentropy(
    name='categorical_crossentropy',
    dtype=None,
    from_logits=False,
    label_smoothing=0,
    axis=-1
)
","Computes the crossentropy metric between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.CategoricalHinge,"tf.keras.metrics.CategoricalHinge(
    name='categorical_hinge', dtype=None
)
","Computes the categorical hinge metric between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.CosineSimilarity,"tf.keras.metrics.CosineSimilarity(
    name='cosine_similarity', dtype=None, axis=-1
)
","Computes the cosine similarity between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.FalseNegatives,"tf.keras.metrics.FalseNegatives(
    thresholds=None, name=None, dtype=None
)
","Calculates the number of false negatives.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.FalsePositives,"tf.keras.metrics.FalsePositives(
    thresholds=None, name=None, dtype=None
)
","Calculates the number of false positives.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.Hinge,"tf.keras.metrics.Hinge(
    name='hinge', dtype=None
)
","Computes the hinge metric between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.IoU,"tf.keras.metrics.IoU(
    num_classes: int,
    target_class_ids: Union[List[int], Tuple[int, ...]],
    name: Optional[str] = None,
    dtype: Optional[Union[str, tf.dtypes.DType]] = None,
    ignore_class: Optional[int] = None,
    sparse_y_true: bool = True,
    sparse_y_pred: bool = True,
    axis: int = -1
)
","Computes the Intersection-Over-Union metric for specific target classes.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.KLDivergence,"tf.keras.metrics.KLDivergence(
    name='kullback_leibler_divergence', dtype=None
)
","Computes Kullback-Leibler divergence metric between y_true andInherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.LogCoshError,"tf.keras.metrics.LogCoshError(
    name='logcosh', dtype=None
)
","Computes the logarithm of the hyperbolic cosine of the prediction error.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.Mean,"tf.keras.metrics.Mean(
    name='mean', dtype=None
)
","Computes the (weighted) mean of the given values.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanAbsoluteError,"tf.keras.metrics.MeanAbsoluteError(
    name='mean_absolute_error', dtype=None
)
","Computes the mean absolute error between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanAbsolutePercentageError,"tf.keras.metrics.MeanAbsolutePercentageError(
    name='mean_absolute_percentage_error', dtype=None
)
","Computes the mean absolute percentage error between y_true andInherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanIoU,"tf.keras.metrics.MeanIoU(
    num_classes: int,
    name: Optional[str] = None,
    dtype: Optional[Union[str, tf.dtypes.DType]] = None,
    ignore_class: Optional[int] = None,
    sparse_y_true: bool = True,
    sparse_y_pred: bool = True,
    axis: int = -1
)
","Computes the mean Intersection-Over-Union metric.Inherits From: IoU, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanMetricWrapper,"tf.keras.metrics.MeanMetricWrapper(
    fn, name=None, dtype=None, **kwargs
)
","Wraps a stateless metric function with the Mean metric.Inherits From: Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanRelativeError,"tf.keras.metrics.MeanRelativeError(
    normalizer, name=None, dtype=None
)
","Computes the mean relative error by normalizing with the given values.Inherits From: Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanSquaredError,"tf.keras.metrics.MeanSquaredError(
    name='mean_squared_error', dtype=None
)
","Computes the mean squared error between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanSquaredLogarithmicError,"tf.keras.metrics.MeanSquaredLogarithmicError(
    name='mean_squared_logarithmic_error', dtype=None
)
","Computes the mean squared logarithmic error between y_true andInherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanTensor,"tf.keras.metrics.MeanTensor(
    name='mean_tensor', dtype=None, shape=None
)
","Computes the element-wise (weighted) mean of the given tensors.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.Metric,"tf.keras.metrics.Metric(
    name=None, dtype=None, **kwargs
)
","Encapsulates metric logic and state.Inherits From: Layer, ModuleView aliases"
tf.keras.metrics.OneHotIoU,"tf.keras.metrics.OneHotIoU(
    num_classes: int,
    target_class_ids: Union[List[int], Tuple[int, ...]],
    name=None,
    dtype=None,
    ignore_class: Optional[int] = None,
    sparse_y_pred: bool = False,
    axis: int = -1
)
","Computes the Intersection-Over-Union metric for one-hot encoded labels.Inherits From: IoU, Metric, Layer, ModuleView aliases"
tf.keras.metrics.OneHotMeanIoU,"tf.keras.metrics.OneHotMeanIoU(
    num_classes: int,
    name: str = None,
    dtype: Optional[Union[str, tf.dtypes.DType]] = None,
    ignore_class: Optional[int] = None,
    sparse_y_pred: bool = False,
    axis: int = -1
)
","Computes mean Intersection-Over-Union metric for one-hot encoded labels.Inherits From: MeanIoU, IoU, Metric, Layer, ModuleView aliases"
tf.keras.metrics.Poisson,"tf.keras.metrics.Poisson(
    name='poisson', dtype=None
)
","Computes the Poisson metric between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.Precision,"tf.keras.metrics.Precision(
    thresholds=None, top_k=None, class_id=None, name=None, dtype=None
)
","Computes the precision of the predictions with respect to the labels.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.PrecisionAtRecall,"tf.keras.metrics.PrecisionAtRecall(
    recall, num_thresholds=200, class_id=None, name=None, dtype=None
)
","Computes best precision where recall is >= specified value.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.Recall,"tf.keras.metrics.Recall(
    thresholds=None, top_k=None, class_id=None, name=None, dtype=None
)
","Computes the recall of the predictions with respect to the labels.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.RecallAtPrecision,"tf.keras.metrics.RecallAtPrecision(
    precision, num_thresholds=200, class_id=None, name=None, dtype=None
)
","Computes best recall where precision is >= specified value.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.RootMeanSquaredError,"tf.keras.metrics.RootMeanSquaredError(
    name='root_mean_squared_error', dtype=None
)
","Computes root mean squared error metric between y_true and y_pred.Inherits From: Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.SensitivityAtSpecificity,"tf.keras.metrics.SensitivityAtSpecificity(
    specificity, num_thresholds=200, class_id=None, name=None, dtype=None
)
","Computes best sensitivity where specificity is >= specified value.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.SparseCategoricalAccuracy,"tf.keras.metrics.SparseCategoricalAccuracy(
    name='sparse_categorical_accuracy', dtype=None
)
","Calculates how often predictions match integer labels.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.SparseCategoricalCrossentropy,"tf.keras.metrics.SparseCategoricalCrossentropy(
    name: str = 'sparse_categorical_crossentropy',
    dtype: Optional[Union[str, tf.dtypes.DType]] = None,
    from_logits: bool = False,
    ignore_class: Optional[int] = None,
    axis: int = -1
)
","Computes the crossentropy metric between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.SparseTopKCategoricalAccuracy,"tf.keras.metrics.SparseTopKCategoricalAccuracy(
    k=5, name='sparse_top_k_categorical_accuracy', dtype=None
)
","Computes how often integer targets are in the top K predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.SpecificityAtSensitivity,"tf.keras.metrics.SpecificityAtSensitivity(
    sensitivity, num_thresholds=200, class_id=None, name=None, dtype=None
)
","Computes best specificity where sensitivity is >= specified value.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.SquaredHinge,"tf.keras.metrics.SquaredHinge(
    name='squared_hinge', dtype=None
)
","Computes the squared hinge metric between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.Sum,"tf.keras.metrics.Sum(
    name='sum', dtype=None
)
","Computes the (weighted) sum of the given values.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.TopKCategoricalAccuracy,"tf.keras.metrics.TopKCategoricalAccuracy(
    k=5, name='top_k_categorical_accuracy', dtype=None
)
","Computes how often targets are in the top K predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.TrueNegatives,"tf.keras.metrics.TrueNegatives(
    thresholds=None, name=None, dtype=None
)
","Calculates the number of true negatives.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.TruePositives,"tf.keras.metrics.TruePositives(
    thresholds=None, name=None, dtype=None
)
","Calculates the number of true positives.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.binary_accuracy,"tf.keras.metrics.binary_accuracy(
    y_true, y_pred, threshold=0.5
)
",Calculates how often predictions match binary labels.View aliases
tf.keras.metrics.binary_crossentropy,"tf.keras.metrics.binary_crossentropy(
    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1
)
",Computes the binary crossentropy loss.View aliases
tf.keras.metrics.binary_focal_crossentropy,"tf.keras.metrics.binary_focal_crossentropy(
    y_true,
    y_pred,
    apply_class_balancing=False,
    alpha=0.25,
    gamma=2.0,
    from_logits=False,
    label_smoothing=0.0,
    axis=-1
)
",Computes the binary focal crossentropy loss.View aliases
tf.keras.metrics.categorical_accuracy,"tf.keras.metrics.categorical_accuracy(
    y_true, y_pred
)
",Calculates how often predictions match one-hot labels.View aliases
tf.keras.metrics.categorical_crossentropy,"tf.keras.metrics.categorical_crossentropy(
    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1
)
",Computes the categorical crossentropy loss.View aliases
tf.keras.metrics.deserialize,"tf.keras.metrics.deserialize(
    config, custom_objects=None
)
",Deserializes a serialized metric class/function instance.View aliases
tf.keras.metrics.get,"tf.keras.metrics.get(
    identifier
)
",Retrieves a Keras metric as a function/Metric class instance.View aliases
tf.keras.metrics.hinge,"tf.keras.metrics.hinge(
    y_true, y_pred
)
",Computes the hinge loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.losses.log_cosh,"tf.keras.losses.log_cosh(
    y_true, y_pred
)
",Logarithm of the hyperbolic cosine of the prediction error.View aliases
tf.keras.losses.log_cosh,"tf.keras.losses.log_cosh(
    y_true, y_pred
)
",Logarithm of the hyperbolic cosine of the prediction error.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.poisson,"tf.keras.metrics.poisson(
    y_true, y_pred
)
",Computes the Poisson loss between y_true and y_pred.View aliases
tf.keras.metrics.serialize,"tf.keras.metrics.serialize(
    metric
)
",Serializes metric function or Metric instance.View aliases
tf.keras.metrics.sparse_categorical_accuracy,"tf.keras.metrics.sparse_categorical_accuracy(
    y_true, y_pred
)
",Calculates how often predictions match integer labels.View aliases
tf.keras.metrics.sparse_categorical_crossentropy,"tf.keras.metrics.sparse_categorical_crossentropy(
    y_true, y_pred, from_logits=False, axis=-1, ignore_class=None
)
",Computes the sparse categorical crossentropy loss.View aliases
tf.keras.metrics.sparse_top_k_categorical_accuracy,"tf.keras.metrics.sparse_top_k_categorical_accuracy(
    y_true, y_pred, k=5
)
",Computes how often integer targets are in the top K predictions.View aliases
tf.keras.metrics.squared_hinge,"tf.keras.metrics.squared_hinge(
    y_true, y_pred
)
",Computes the squared hinge loss between y_true and y_pred.View aliases
tf.keras.metrics.top_k_categorical_accuracy,"tf.keras.metrics.top_k_categorical_accuracy(
    y_true, y_pred, k=5
)
",Computes how often targets are in the top K predictions.View aliases
tf.math.minimum,"tf.math.minimum(
    x, y, name=None
)
",Returns the min of x and y (i.e. x < y ? x : y) element-wise.View aliases
tf.mlir.experimental.convert_function,"tf.mlir.experimental.convert_function(
    concrete_function,
    pass_pipeline='tf-standard-pipeline',
    show_debug_info=False
)
",Import a ConcreteFunction and convert it to a textual MLIR module.View aliases
tf.mlir.experimental.convert_graph_def,"tf.mlir.experimental.convert_graph_def(
    graph_def,
    pass_pipeline='tf-standard-pipeline',
    show_debug_info=False
)
",Import a GraphDef and convert it to a textual MLIR module.View aliases
tf.math.multiply,"tf.math.multiply(
    x, y, name=None
)
",Returns an element-wise x * y.View aliases
tf.name_scope,"tf.name_scope(
    name
)
",A context manager for use when defining a Python op.
tf.math.negative,"tf.math.negative(
    x, name=None
)
",Computes numerical negative value element-wise.View aliases
tf.nest.assert_same_structure,"tf.nest.assert_same_structure(
    nest1, nest2, check_types=True, expand_composites=False
)
",Asserts that two structures are nested in the same way.View aliases
tf.nest.flatten,"tf.nest.flatten(
    structure, expand_composites=False
)
",Returns a flat list from a given structure.View aliases
tf.nest.is_nested,"tf.nest.is_nested(
    seq
)
",Returns true if its input is a nested structure.View aliases
tf.nest.map_structure,"tf.nest.map_structure(
    func, *structure, **kwargs
)
",Creates a new structure by applying func to each atom in structure.View aliases
tf.nest.pack_sequence_as,"tf.nest.pack_sequence_as(
    structure, flat_sequence, expand_composites=False
)
",Returns a given flattened sequence packed into a given structure.View aliases
tf.nn.RNNCellDeviceWrapper,"tf.nn.RNNCellDeviceWrapper(
    *args, **kwargs
)
",Operator that ensures an RNNCell runs on a particular device.Inherits From: Module
tf.nn.RNNCellDropoutWrapper,"tf.nn.RNNCellDropoutWrapper(
    *args, **kwargs
)
",Operator adding dropout to inputs and outputs of the given cell.Inherits From: Module
tf.nn.RNNCellResidualWrapper,"tf.nn.RNNCellResidualWrapper(
    *args, **kwargs
)
",RNNCell wrapper that ensures cell inputs are added to the outputs.Inherits From: Module
tf.random.all_candidate_sampler,"tf.random.all_candidate_sampler(
    true_classes, num_true, num_sampled, unique, seed=None, name=None
)
",Generate the set of all classes.View aliases
tf.math.approx_max_k,"tf.math.approx_max_k(
    operand,
    k,
    reduction_dimension=-1,
    recall_target=0.95,
    reduction_input_size_override=-1,
    aggregate_to_topk=True,
    name=None
)
",Returns max k values and their indices of the input operand in an approximate manner.View aliases
tf.math.approx_min_k,"tf.math.approx_min_k(
    operand,
    k,
    reduction_dimension=-1,
    recall_target=0.95,
    reduction_input_size_override=-1,
    aggregate_to_topk=True,
    name=None
)
",Returns min k values and their indices of the input operand in an approximate manner.View aliases
tf.nn.atrous_conv2d,"tf.nn.atrous_conv2d(
    value, filters, rate, padding, name=None
)
",Atrous convolution (a.k.a. convolution with holes or dilated convolution).View aliases
tf.nn.atrous_conv2d_transpose,"tf.nn.atrous_conv2d_transpose(
    value, filters, output_shape, rate, padding, name=None
)
",The transpose of atrous_conv2d.View aliases
tf.nn.avg_pool,"tf.nn.avg_pool(
    input, ksize, strides, padding, data_format=None, name=None
)
",Performs the avg pooling on the input.View aliases
tf.nn.avg_pool1d,"tf.nn.avg_pool1d(
    input, ksize, strides, padding, data_format='NWC', name=None
)
",Performs the average pooling on the input.View aliases
tf.nn.avg_pool2d,"tf.nn.avg_pool2d(
    input, ksize, strides, padding, data_format='NHWC', name=None
)
",Performs the average pooling on the input.
tf.nn.avg_pool3d,"tf.nn.avg_pool3d(
    input, ksize, strides, padding, data_format='NDHWC', name=None
)
",Performs the average pooling on the input.View aliases
tf.nn.batch_norm_with_global_normalization,"tf.nn.batch_norm_with_global_normalization(
    input,
    mean,
    variance,
    beta,
    gamma,
    variance_epsilon,
    scale_after_normalization,
    name=None
)
",Batch normalization.
tf.nn.batch_normalization,"tf.nn.batch_normalization(
    x, mean, variance, offset, scale, variance_epsilon, name=None
)
",Batch normalization.View aliases
tf.nn.bias_add,"tf.nn.bias_add(
    value, bias, data_format=None, name=None
)
",Adds bias to value.View aliases
tf.nn.collapse_repeated,"tf.nn.collapse_repeated(
    labels, seq_length, name=None
)
",Merge repeated labels into single labels.View aliases
tf.nn.compute_accidental_hits,"tf.nn.compute_accidental_hits(
    true_classes, sampled_candidates, num_true, seed=None, name=None
)
",Compute the position ids in sampled_candidates matching true_classes.View aliases
tf.nn.compute_average_loss,"tf.nn.compute_average_loss(
    per_example_loss, sample_weight=None, global_batch_size=None
)
",Scales per-example losses with sample_weights and computes their average.View aliases
tf.nn.conv1d,"tf.nn.conv1d(
    input,
    filters,
    stride,
    padding,
    data_format='NWC',
    dilations=None,
    name=None
)
",Computes a 1-D convolution given 3-D input and filter tensors.
tf.nn.conv1d_transpose,"tf.nn.conv1d_transpose(
    input,
    filters,
    output_shape,
    strides,
    padding='SAME',
    data_format='NWC',
    dilations=None,
    name=None
)
",The transpose of conv1d.View aliases
tf.nn.conv2d,"tf.nn.conv2d(
    input,
    filters,
    strides,
    padding,
    data_format='NHWC',
    dilations=None,
    name=None
)
",Computes a 2-D convolution given input and 4-D filters tensors.
tf.nn.conv2d_transpose,"tf.nn.conv2d_transpose(
    input,
    filters,
    output_shape,
    strides,
    padding='SAME',
    data_format='NHWC',
    dilations=None,
    name=None
)
",The transpose of conv2d.
tf.nn.conv3d,"tf.nn.conv3d(
    input,
    filters,
    strides,
    padding,
    data_format='NDHWC',
    dilations=None,
    name=None
)
",Computes a 3-D convolution given 5-D input and filters tensors.
tf.nn.conv3d_transpose,"tf.nn.conv3d_transpose(
    input,
    filters,
    output_shape,
    strides,
    padding='SAME',
    data_format='NDHWC',
    dilations=None,
    name=None
)
",The transpose of conv3d.
tf.nn.conv_transpose,"tf.nn.conv_transpose(
    input,
    filters,
    output_shape,
    strides,
    padding='SAME',
    data_format=None,
    dilations=None,
    name=None
)
",The transpose of convolution.View aliases
tf.nn.convolution,"tf.nn.convolution(
    input,
    filters,
    strides=None,
    padding='VALID',
    data_format=None,
    dilations=None,
    name=None
)
",Computes sums of N-D convolutions (actually cross-correlation).
tf.nn.crelu,"tf.nn.crelu(
    features, axis=-1, name=None
)
",Computes Concatenated ReLU.
tf.nn.ctc_beam_search_decoder,"tf.nn.ctc_beam_search_decoder(
    inputs, sequence_length, beam_width=100, top_paths=1
)
",Performs beam search decoding on the logits given in input.View aliases
tf.nn.ctc_greedy_decoder,"tf.nn.ctc_greedy_decoder(
    inputs, sequence_length, merge_repeated=True, blank_index=None
)
",Performs greedy decoding on the logits given in input (best path).View aliases
tf.nn.ctc_loss,"tf.nn.ctc_loss(
    labels,
    logits,
    label_length,
    logit_length,
    logits_time_major=True,
    unique=None,
    blank_index=None,
    name=None
)
",Computes CTC (Connectionist Temporal Classification) loss.
tf.nn.ctc_unique_labels,"tf.nn.ctc_unique_labels(
    labels, name=None
)
",Get unique labels and indices for batched labels for tf.nn.ctc_loss.View aliases
tf.nn.depth_to_space,"tf.nn.depth_to_space(
    input, block_size, data_format='NHWC', name=None
)
",DepthToSpace for tensors of type T.
tf.nn.depthwise_conv2d,"tf.nn.depthwise_conv2d(
    input,
    filter,
    strides,
    padding,
    data_format=None,
    dilations=None,
    name=None
)
",Depthwise 2-D convolution.
tf.nn.depthwise_conv2d,"tf.nn.depthwise_conv2d(x, kernel, strides=[1, 1, 1, 1],","Depthwise 2-D convolution.tf.nn.depthwise_conv2d(    input,    filter,    strides,    padding,    data_format=None,    dilations=None,    name=None)Given a 4D input tensor ('NHWC' or 'NCHW' data formats)and a filter tensor of shape[filter_height, filter_width, in_channels, channel_multiplier]containing in_channels convolutional filters of depth 1, depthwise_conv2dapplies a different filter to each input channel (expanding from 1 channelto channel_multiplier channels for each), then concatenates the resultstogether.  The output has in_channels * channel_multiplier channels.In detail, with the default NHWC format,output[b, i, j, k * channel_multiplier + q] =    sum_{di, dj} filter[di, dj, k, q] *                 input[b, strides[1] * i + dilations[0] * di,                          strides[2] * j + dilations[1] * dj, k]Must have strides[0] = strides[3] = 1.  For the most common case of thesame horizontal and vertical strides, strides = [1, stride, stride, 1].If any value in dilations is greater than 1, we perform atrous depthwiseconvolution, in which case all values in the strides tensor must be equalto 1.Usage Example:x = np.array([    [1., 2.],    [3., 4.],    [5., 6.]], dtype=np.float32).reshape((1, 3, 2, 1))kernel = np.array([    [1., 2.],    [3., 4]], dtype=np.float32).reshape((2, 1, 1, 2))tf.nn.depthwise_conv2d(x, kernel, strides=[1, 1, 1, 1],                       padding='VALID').numpy()  array([[[[10., 14.],           [14., 20.]],          [[18., 26.],           [22., 32.]]]], dtype=float32)"
tf.nn.depthwise_conv2d_backprop_filter,"tf.nn.depthwise_conv2d_backprop_filter(
    input,
    filter_sizes,
    out_backprop,
    strides,
    padding,
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes the gradients of depthwise convolution with respect to the filter.View aliases
tf.nn.depthwise_conv2d_backprop_input,"tf.nn.depthwise_conv2d_backprop_input(
    input_sizes,
    filter,
    out_backprop,
    strides,
    padding,
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes the gradients of depthwise convolution with respect to the input.View aliases
tf.nn.dilation2d,"tf.nn.dilation2d(
    input, filters, strides, padding, data_format, dilations, name=None
)
",Computes the grayscale dilation of 4-D input and 3-D filters tensors.
tf.nn.dropout,"tf.nn.dropout(
    x, rate, noise_shape=None, seed=None, name=None
)
",Computes dropout: randomly sets elements to zero to prevent overfitting.
tf.nn.dropout,"tf.nn.dropout(x, rate = 0.0) == x","Computes dropout: randomly sets elements to zero to prevent overfitting.tf.nn.dropout(    x, rate, noise_shape=None, seed=None, name=None)Used in the notebooksWarning: You should consider usingNote: The behavior of dropout has changed between TensorFlow 1.x and 2.x.When converting 1.x code, please use named arguments to ensure behavior staysconsistent.See also: tf.keras.layers.Dropout for a dropout layer.Dropout is useful for regularizing DNNmodels. Inputs elements are randomly set to zero (and the other elements arerescaled). This encourages each node to be independently useful, as it cannotrely on the output of other nodes.More precisely: With probability rate elements of x are set to 0.The remaining elements are scaled up by 1.0 / (1 - rate), so that theexpected value is preserved.tf.random.set_seed(0)x = tf.ones([3,5])tf.nn.dropout(x, rate = 0.5, seed = 1).numpy()array([[2., 0., 0., 2., 2.],     [2., 2., 2., 2., 2.],     [2., 0., 2., 0., 2.]], dtype=float32)tf.random.set_seed(0)x = tf.ones([3,5])tf.nn.dropout(x, rate = 0.8, seed = 1).numpy()array([[0., 0., 0., 5., 5.],     [0., 5., 0., 5., 0.],     [5., 0., 5., 0., 5.]], dtype=float32)"
tf.nn.elu,"tf.nn.elu(
    features, name=None
)
",Computes the exponential linear function.View aliases
tf.nn.embedding_lookup,"tf.nn.embedding_lookup(
    params, ids, max_norm=None, name=None
)
",Looks up embeddings for the given ids from a list of tensors.
tf.nn.embedding_lookup_sparse,"tf.nn.embedding_lookup_sparse(
    params, sp_ids, sp_weights, combiner=None, max_norm=None, name=None
)
",Looks up embeddings for the given ids and weights from a list of tensors.
tf.nn.erosion2d,"tf.nn.erosion2d(
    value, filters, strides, padding, data_format, dilations, name=None
)
",Computes the grayscale erosion of 4-D value and 3-D filters tensors.
tf.nn.experimental.stateless_dropout,"tf.nn.experimental.stateless_dropout(
    x, rate, seed, rng_alg=None, noise_shape=None, name=None
)
",Computes dropout: randomly sets elements to zero to prevent overfitting.View aliases
tf.nn.experimental.stateless_dropout,"tf.nn.experimental.stateless_dropout(x, rate=0.0, seed=[1, 0]) == x","Computes dropout: randomly sets elements to zero to prevent overfitting.View aliasestf.nn.experimental.stateless_dropout(    x, rate, seed, rng_alg=None, noise_shape=None, name=None)Dropout is useful for regularizing DNNmodels. Inputs elements are randomly set to zero (and the other elements arerescaled). This encourages each node to be independently useful, as it cannotrely on the output of other nodes.More precisely: With probability rate elements of x are set to 0.The remaining elements are scaled up by 1.0 / (1 - rate), so that theexpected value is preserved.x = tf.ones([3,5])tf.nn.experimental.stateless_dropout(x, rate=0.5, seed=[1, 0])<tf.Tensor: shape=(3, 5), dtype=float32, numpy=array([[2., 0., 2., 0., 0.],       [0., 0., 2., 0., 2.],       [0., 0., 0., 0., 2.]], dtype=float32)>x = tf.ones([3,5])tf.nn.experimental.stateless_dropout(x, rate=0.8, seed=[1, 0])<tf.Tensor: shape=(3, 5), dtype=float32, numpy=array([[5., 0., 0., 0., 0.],       [0., 0., 0., 0., 5.],       [0., 0., 0., 0., 5.]], dtype=float32)>"
tf.random.fixed_unigram_candidate_sampler,"tf.random.fixed_unigram_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    vocab_file='',
    distortion=1.0,
    num_reserved_ids=0,
    num_shards=1,
    shard=0,
    unigrams=(),
    seed=None,
    name=None
)
",Samples a set of classes using the provided (fixed) base distribution.View aliases
tf.nn.fractional_avg_pool,"tf.nn.fractional_avg_pool(
    value,
    pooling_ratio,
    pseudo_random=False,
    overlapping=False,
    seed=0,
    name=None
)
",Performs fractional average pooling on the input.
tf.nn.fractional_max_pool,"tf.nn.fractional_max_pool(
    value,
    pooling_ratio,
    pseudo_random=False,
    overlapping=False,
    seed=0,
    name=None
)
",Performs fractional max pooling on the input.
tf.nn.gelu,"tf.nn.gelu(
    features, approximate=False, name=None
)
",Compute the Gaussian Error Linear Unit (GELU) activation function.
tf.math.in_top_k,"tf.math.in_top_k(
    targets, predictions, k, name=None
)
",Says whether the targets are in the top K predictions.View aliases
tf.nn.isotonic_regression,"tf.nn.isotonic_regression(
    inputs, decreasing=True, axis=-1
)
",Solves isotonic regression problems along the given axis.
tf.nn.l2_loss,"tf.nn.l2_loss(
    t, name=None
)
",L2 Loss.View aliases
tf.math.l2_normalize,"tf.math.l2_normalize(
    x, axis=None, epsilon=1e-12, name=None, dim=None
)
",Normalizes along dimension axis using an L2 norm. (deprecated arguments)View aliases
tf.nn.leaky_relu,"tf.nn.leaky_relu(
    features, alpha=0.2, name=None
)
",Compute the Leaky ReLU activation function.View aliases
tf.random.learned_unigram_candidate_sampler,"tf.random.learned_unigram_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=None,
    name=None
)
",Samples a set of classes from a distribution learned during training.View aliases
tf.nn.local_response_normalization,"tf.nn.local_response_normalization(
    input, depth_radius=5, bias=1, alpha=1, beta=0.5, name=None
)
",Local Response Normalization.View aliases
tf.nn.log_poisson_loss,"tf.nn.log_poisson_loss(
    targets, log_input, compute_full_loss=False, name=None
)
",Computes log Poisson loss given log_input.View aliases
tf.nn.log_softmax,"tf.nn.log_softmax(
    logits, axis=None, name=None
)
",Computes log softmax activations.View aliases
tf.nn.local_response_normalization,"tf.nn.local_response_normalization(
    input, depth_radius=5, bias=1, alpha=1, beta=0.5, name=None
)
",Local Response Normalization.View aliases
tf.nn.max_pool,"tf.nn.max_pool(
    input, ksize, strides, padding, data_format=None, name=None
)
",Performs max pooling on the input.View aliases
tf.nn.max_pool1d,"tf.nn.max_pool1d(
    input, ksize, strides, padding, data_format='NWC', name=None
)
",Performs the max pooling on the input.View aliases
tf.nn.max_pool2d,"tf.nn.max_pool2d(
    input, ksize, strides, padding, data_format='NHWC', name=None
)
",Performs max pooling on 2D spatial data such as images.View aliases
tf.nn.max_pool3d,"tf.nn.max_pool3d(
    input, ksize, strides, padding, data_format='NDHWC', name=None
)
",Performs the max pooling on the input.View aliases
tf.nn.max_pool_with_argmax,"tf.nn.max_pool_with_argmax(
    input,
    ksize,
    strides,
    padding,
    data_format='NHWC',
    output_dtype=tf.dtypes.int64,
    include_batch_in_index=False,
    name=None
)
",Performs max pooling on the input and outputs both max values and indices.
tf.nn.moments,"tf.nn.moments(
    x, axes, shift=None, keepdims=False, name=None
)
",Calculates the mean and variance of x.
tf.nn.nce_loss,"tf.nn.nce_loss(
    weights,
    biases,
    labels,
    inputs,
    num_sampled,
    num_classes,
    num_true=1,
    sampled_values=None,
    remove_accidental_hits=False,
    name='nce_loss'
)
",Computes and returns the noise-contrastive estimation training loss.
tf.nn.normalize_moments,"tf.nn.normalize_moments(
    counts, mean_ss, variance_ss, shift, name=None
)
",Calculate the mean and variance of based on the sufficient statistics.View aliases
tf.nn.pool,"tf.nn.pool(
    input,
    window_shape,
    pooling_type,
    strides=None,
    padding='VALID',
    data_format=None,
    dilations=None,
    name=None
)
",Performs an N-D pooling operation.
tf.nn.relu,"tf.nn.relu(
    features, name=None
)
","Computes rectified linear: max(features, 0).View aliases"
tf.nn.relu6,"tf.nn.relu6(
    features, name=None
)
","Computes Rectified Linear 6: min(max(features, 0), 6).View aliases"
tf.nn.safe_embedding_lookup_sparse,"tf.nn.safe_embedding_lookup_sparse(
    embedding_weights,
    sparse_ids,
    sparse_weights=None,
    combiner='mean',
    default_id=None,
    max_norm=None,
    name=None
)
","Lookup embedding results, accounting for invalid IDs and empty features."
tf.nn.sampled_softmax_loss,"tf.nn.sampled_softmax_loss(
    weights,
    biases,
    labels,
    inputs,
    num_sampled,
    num_classes,
    num_true=1,
    sampled_values=None,
    remove_accidental_hits=True,
    seed=None,
    name='sampled_softmax_loss'
)
",Computes and returns the sampled softmax training loss.
tf.nn.scale_regularization_loss,"tf.nn.scale_regularization_loss(
    regularization_loss
)
",Scales the sum of the given regularization losses by number of replicas.View aliases
tf.nn.selu,"tf.nn.selu(
    features, name=None
)
",Computes scaled exponential linear: scale * alpha * (exp(features) - 1)View aliases
tf.nn.separable_conv2d,"tf.nn.separable_conv2d(
    input,
    depthwise_filter,
    pointwise_filter,
    strides,
    padding,
    data_format=None,
    dilations=None,
    name=None
)
",2-D convolution with separable filters.
tf.math.sigmoid,"tf.math.sigmoid(
    x, name=None
)
",Computes sigmoid of x element-wise.View aliases
tf.nn.sigmoid_cross_entropy_with_logits,"tf.nn.sigmoid_cross_entropy_with_logits(
    labels=None, logits=None, name=None
)
",Computes sigmoid cross entropy given logits.
tf.nn.silu,"tf.nn.silu(
    features, beta=1.0
)
",Computes the SiLU or Swish activation function: x * sigmoid(beta * x).View aliases
tf.nn.softmax,"tf.nn.softmax(
    logits, axis=None, name=None
)
",Computes softmax activations.View aliases
tf.nn.softmax_cross_entropy_with_logits,"tf.nn.softmax_cross_entropy_with_logits(
    labels, logits, axis=-1, name=None
)
",Computes softmax cross entropy between logits and labels.
tf.math.softplus,"tf.math.softplus(
    features, name=None
)
",Computes elementwise softplus: softplus(x) = log(exp(x) + 1).View aliases
tf.nn.softsign,"tf.nn.softsign(
    features, name=None
)
",Computes softsign: features / (abs(features) + 1).View aliases
tf.space_to_batch,"tf.space_to_batch(
    input, block_shape, paddings, name=None
)
",SpaceToBatch for N-D tensors of type T.View aliases
tf.nn.space_to_depth,"tf.nn.space_to_depth(
    input, block_size, data_format='NHWC', name=None
)
",SpaceToDepth for tensors of type T.
tf.nn.sparse_softmax_cross_entropy_with_logits,"tf.nn.sparse_softmax_cross_entropy_with_logits(
    labels, logits, name=None
)
",Computes sparse softmax cross entropy between logits and labels.
tf.nn.sufficient_statistics,"tf.nn.sufficient_statistics(
    x, axes, shift=None, keepdims=False, name=None
)
",Calculate the sufficient statistics for the mean and variance of x.
tf.nn.silu,"tf.nn.silu(
    features, beta=1.0
)
",Computes the SiLU or Swish activation function: x * sigmoid(beta * x).View aliases
tf.math.tanh,"tf.math.tanh(
    x, name=None
)
",Computes hyperbolic tangent of x element-wise.View aliases
tf.math.top_k,"tf.math.top_k(
    input, k=1, sorted=True, name=None
)
",Finds values and indices of the k largest entries for the last dimension.View aliases
tf.nn.weighted_cross_entropy_with_logits,"tf.nn.weighted_cross_entropy_with_logits(
    labels, logits, pos_weight, name=None
)
",Computes a weighted cross entropy.
tf.nn.weighted_moments,"tf.nn.weighted_moments(
    x, axes, frequency_weights, keepdims=False, name=None
)
",Returns the frequency-weighted mean and variance of x.
tf.nn.with_space_to_batch,"tf.nn.with_space_to_batch(
    input,
    dilation_rate,
    padding,
    op,
    filter_shape=None,
    spatial_dims=None,
    data_format=None
)
",Performs op on the space-to-batch representation of input.View aliases
tf.math.zero_fraction,"tf.math.zero_fraction(
    value, name=None
)
",Returns the fraction of zeros in value.View aliases
tf.no_gradient,"tf.no_gradient(
    op_type
)
",Specifies that ops of type op_type is not differentiable.View aliases
tf.no_op,"tf.no_op(
    name=None
)
",Does nothing. Only useful as a placeholder for control edges.View aliases
tf.nondifferentiable_batch_function,"tf.nondifferentiable_batch_function(
    num_batch_threads,
    max_batch_size,
    batch_timeout_micros,
    allowed_batch_sizes=None,
    max_enqueued_batches=10,
    autograph=True,
    enable_large_batch_splitting=True
)
",Batches the computation done by the decorated function.View aliases
tf.norm,"tf.norm(
    tensor, ord='euclidean', axis=None, keepdims=None, name=None
)
","Computes the norm of vectors, matrices, and tensors.View aliases"
tf.math.not_equal,"tf.math.not_equal(
    x, y, name=None
)
",Returns the truth value of (x != y) element-wise.View aliases
tf.numpy_function,"tf.numpy_function(
    func, inp, Tout, stateful=True, name=None
)
",Wraps a python function and uses it as a TensorFlow op.View aliases
tf.one_hot,"tf.one_hot(
    indices,
    depth,
    on_value=None,
    off_value=None,
    axis=None,
    dtype=None,
    name=None
)
",Returns a one-hot tensor.View aliases
tf.ones,"tf.ones(
    shape,
    dtype=tf.dtypes.float32,
    name=None
)
",Creates a tensor with all elements set to one (1).View aliases
tf.ones_like,"tf.ones_like(
    input, dtype=None, name=None
)
",Creates a tensor of all ones that has the same shape as the input.
tf.keras.optimizers.Adadelta,"tf.keras.optimizers.Adadelta(
    learning_rate=0.001,
    rho=0.95,
    epsilon=1e-07,
    name='Adadelta',
    **kwargs
)
",Optimizer that implements the Adadelta algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Adagrad,"tf.keras.optimizers.Adagrad(
    learning_rate=0.001,
    initial_accumulator_value=0.1,
    epsilon=1e-07,
    name='Adagrad',
    **kwargs
)
",Optimizer that implements the Adagrad algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Adam,"tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    name='Adam',
    **kwargs
)
",Optimizer that implements the Adam algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Adamax,"tf.keras.optimizers.Adamax(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    name='Adamax',
    **kwargs
)
",Optimizer that implements the Adamax algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Ftrl,"tf.keras.optimizers.Ftrl(
    learning_rate=0.001,
    learning_rate_power=-0.5,
    initial_accumulator_value=0.1,
    l1_regularization_strength=0.0,
    l2_regularization_strength=0.0,
    name='Ftrl',
    l2_shrinkage_regularization_strength=0.0,
    beta=0.0,
    **kwargs
)
",Optimizer that implements the FTRL algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Nadam,"tf.keras.optimizers.Nadam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    name='Nadam',
    **kwargs
)
",Optimizer that implements the NAdam algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Optimizer,"tf.keras.optimizers.Optimizer(
    name, gradient_aggregator=None, gradient_transformers=None, **kwargs
)
",Base class for Keras optimizers.View aliases
tf.keras.optimizers.RMSprop,"tf.keras.optimizers.RMSprop(
    learning_rate=0.001,
    rho=0.9,
    momentum=0.0,
    epsilon=1e-07,
    centered=False,
    name='RMSprop',
    **kwargs
)
",Optimizer that implements the RMSprop algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.SGD,"tf.keras.optimizers.SGD(
    learning_rate=0.01,
    momentum=0.0,
    nesterov=False,
    name='SGD',
    **kwargs
)
",Gradient descent (with momentum) optimizer.Inherits From: OptimizerView aliases
tf.keras.optimizers.deserialize,"tf.keras.optimizers.deserialize(
    config, custom_objects=None, **kwargs
)
",Inverse of the serialize function.View aliases
tf.keras.optimizers.experimental.Adadelta,"tf.keras.optimizers.experimental.Adadelta(
    learning_rate=0.001,
    rho=0.95,
    epsilon=1e-07,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='Adadelta',
    **kwargs
)
",Optimizer that implements the Adadelta algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.Adagrad,"tf.keras.optimizers.experimental.Adagrad(
    learning_rate=0.001,
    initial_accumulator_value=0.1,
    epsilon=1e-07,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='Adagrad',
    **kwargs
)
",Optimizer that implements the Adagrad algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.Adam,"tf.keras.optimizers.experimental.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='Adam',
    **kwargs
)
",Optimizer that implements the Adam algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.AdamW,"tf.keras.optimizers.experimental.AdamW(
    learning_rate=0.001,
    weight_decay=0.004,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='AdamW',
    **kwargs
)
",Optimizer that implements the AdamW algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.Adamax,"tf.keras.optimizers.experimental.Adamax(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='Adamax',
    **kwargs
)
",Optimizer that implements the Adamax algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.Ftrl,"tf.keras.optimizers.experimental.Ftrl(
    learning_rate=0.001,
    learning_rate_power=-0.5,
    initial_accumulator_value=0.1,
    l1_regularization_strength=0.0,
    l2_regularization_strength=0.0,
    l2_shrinkage_regularization_strength=0.0,
    beta=0.0,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='Ftrl',
    **kwargs
)
",Optimizer that implements the FTRL algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.Nadam,"tf.keras.optimizers.experimental.Nadam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='Nadam',
    **kwargs
)
",Optimizer that implements the Nadam algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.Optimizer,"tf.keras.optimizers.experimental.Optimizer(
    name,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    **kwargs
)
",Abstract optimizer base class.View aliases
tf.keras.optimizers.experimental.RMSprop,"tf.keras.optimizers.experimental.RMSprop(
    learning_rate=0.001,
    rho=0.9,
    momentum=0.0,
    epsilon=1e-07,
    centered=False,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=100,
    jit_compile=True,
    name='RMSprop',
    **kwargs
)
",Optimizer that implements the RMSprop algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.experimental.SGD,"tf.keras.optimizers.experimental.SGD(
    learning_rate=0.01,
    momentum=0.0,
    nesterov=False,
    amsgrad=False,
    clipnorm=None,
    clipvalue=None,
    global_clipnorm=None,
    use_ema=False,
    ema_momentum=0.99,
    ema_overwrite_frequency=None,
    jit_compile=True,
    name='SGD',
    **kwargs
)
",Gradient descent (with momentum) optimizer.Inherits From: OptimizerView aliases
tf.keras.optimizers.get,"tf.keras.optimizers.get(
    identifier, **kwargs
)
",Retrieves a Keras Optimizer instance.View aliases
tf.keras.optimizers.legacy.Adadelta,"tf.keras.optimizers.legacy.Adadelta(
    learning_rate=0.001,
    rho=0.95,
    epsilon=1e-07,
    name='Adadelta',
    **kwargs
)
","Optimizer that implements the Adadelta algorithm.Inherits From: Adadelta, OptimizerView aliases"
tf.keras.optimizers.legacy.Adagrad,"tf.keras.optimizers.legacy.Adagrad(
    learning_rate=0.001,
    initial_accumulator_value=0.1,
    epsilon=1e-07,
    name='Adagrad',
    **kwargs
)
","Optimizer that implements the Adagrad algorithm.Inherits From: Adagrad, OptimizerView aliases"
tf.keras.optimizers.legacy.Adam,"tf.keras.optimizers.legacy.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    name='Adam',
    **kwargs
)
","Optimizer that implements the Adam algorithm.Inherits From: Adam, OptimizerView aliases"
tf.keras.optimizers.legacy.Adamax,"tf.keras.optimizers.legacy.Adamax(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    name='Adamax',
    **kwargs
)
","Optimizer that implements the Adamax algorithm.Inherits From: Adamax, OptimizerView aliases"
tf.keras.optimizers.legacy.Ftrl,"tf.keras.optimizers.legacy.Ftrl(
    learning_rate=0.001,
    learning_rate_power=-0.5,
    initial_accumulator_value=0.1,
    l1_regularization_strength=0.0,
    l2_regularization_strength=0.0,
    name='Ftrl',
    l2_shrinkage_regularization_strength=0.0,
    beta=0.0,
    **kwargs
)
","Optimizer that implements the FTRL algorithm.Inherits From: Ftrl, OptimizerView aliases"
tf.keras.optimizers.legacy.Nadam,"tf.keras.optimizers.legacy.Nadam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    name='Nadam',
    **kwargs
)
","Optimizer that implements the NAdam algorithm.Inherits From: Nadam, OptimizerView aliases"
tf.keras.optimizers.legacy.Optimizer,"tf.keras.optimizers.legacy.Optimizer(
    name, gradient_aggregator=None, gradient_transformers=None, **kwargs
)
",Base class for Keras optimizers.Inherits From: OptimizerView aliases
tf.keras.optimizers.legacy.RMSprop,"tf.keras.optimizers.legacy.RMSprop(
    learning_rate=0.001,
    rho=0.9,
    momentum=0.0,
    epsilon=1e-07,
    centered=False,
    name='RMSprop',
    **kwargs
)
","Optimizer that implements the RMSprop algorithm.Inherits From: RMSprop, OptimizerView aliases"
tf.keras.optimizers.legacy.SGD,"tf.keras.optimizers.legacy.SGD(
    learning_rate=0.01,
    momentum=0.0,
    nesterov=False,
    name='SGD',
    **kwargs
)
","Gradient descent (with momentum) optimizer.Inherits From: SGD, OptimizerView aliases"
tf.keras.optimizers.schedules.CosineDecay,"tf.keras.optimizers.schedules.CosineDecay(
    initial_learning_rate, decay_steps, alpha=0.0, name=None
)
",A LearningRateSchedule that uses a cosine decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.CosineDecayRestarts,"tf.keras.optimizers.schedules.CosineDecayRestarts(
    initial_learning_rate,
    first_decay_steps,
    t_mul=2.0,
    m_mul=1.0,
    alpha=0.0,
    name=None
)
",A LearningRateSchedule that uses a cosine decay schedule with restarts.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.ExponentialDecay,"tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate, decay_steps, decay_rate, staircase=False, name=None
)
",A LearningRateSchedule that uses an exponential decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.InverseTimeDecay,"tf.keras.optimizers.schedules.InverseTimeDecay(
    initial_learning_rate, decay_steps, decay_rate, staircase=False, name=None
)
",A LearningRateSchedule that uses an inverse time decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.PiecewiseConstantDecay,"tf.keras.optimizers.schedules.PiecewiseConstantDecay(
    boundaries, values, name=None
)
",A LearningRateSchedule that uses a piecewise constant decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.PolynomialDecay,"tf.keras.optimizers.schedules.PolynomialDecay(
    initial_learning_rate,
    decay_steps,
    end_learning_rate=0.0001,
    power=1.0,
    cycle=False,
    name=None
)
",A LearningRateSchedule that uses a polynomial decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.deserialize,"tf.keras.optimizers.schedules.deserialize(
    config, custom_objects=None
)
",Instantiates a LearningRateSchedule object from a serialized form.View aliases
tf.keras.optimizers.schedules.serialize,"tf.keras.optimizers.schedules.serialize(
    learning_rate_schedule
)
",Serializes a LearningRateSchedule into a JSON-compatible representation.View aliases
tf.keras.optimizers.serialize,"tf.keras.optimizers.serialize(
    optimizer
)
",Serialize the optimizer configuration to JSON compatible python dict.View aliases
tf.pad,"tf.pad(
    tensor, paddings, mode='CONSTANT', constant_values=0, name=None
)
",Pads a tensor.
tf.parallel_stack,"tf.parallel_stack(
    values, name='parallel_stack'
)
",Stacks a list of rank-R tensors into one rank-(R+1) tensor in parallel.View aliases
tf.math.pow,"tf.math.pow(
    x, y, name=None
)
",Computes the power of one value to another.View aliases
tf.print,"tf.print(
    *inputs, **kwargs
)
",Print the specified inputs.View aliases
tf.profiler.experimental.Profile,"tf.profiler.experimental.Profile(
    logdir, options=None
)
",Context-manager profile API.
tf.profiler.experimental.ProfilerOptions,"tf.profiler.experimental.ProfilerOptions(
    host_tracer_level=2,
    python_tracer_level=0,
    device_tracer_level=1,
    delay_ms=None
)
",Options for finer control over the profiler.
tf.profiler.experimental.Trace,"tf.profiler.experimental.Trace(
    name, **kwargs
)
",Context manager that generates a trace event in the profiler.
tf.profiler.experimental.client.monitor,"tf.profiler.experimental.client.monitor(
    service_addr, duration_ms, level=1
)
",Sends grpc requests to profiler server to perform on-demand monitoring.
tf.profiler.experimental.client.trace,"tf.profiler.experimental.client.trace(
    service_addr,
    logdir,
    duration_ms,
    worker_list='',
    num_tracing_attempts=3,
    options=None
)
",Sends gRPC requests to one or more profiler servers to perform on-demand profiling.
tf.profiler.experimental.server.start,"tf.profiler.experimental.server.start(
    port
)
",Start a profiler grpc server that listens to given port.
tf.profiler.experimental.start,"tf.profiler.experimental.start(
    logdir, options=None
)
",Start profiling TensorFlow performance.
tf.profiler.experimental.stop,"tf.profiler.experimental.stop(
    save=True
)
",Stops the current profiling session.
tf.py_function,"tf.py_function(
    func, inp, Tout, name=None
)
",Wraps a python function into a TensorFlow op that executes it eagerly.View aliases
tf.quantization.dequantize,"tf.quantization.dequantize(
    input,
    min_range,
    max_range,
    mode='MIN_COMBINED',
    name=None,
    axis=None,
    narrow_range=False,
    dtype=tf.dtypes.float32
)
",Dequantize the 'input' tensor into a float or bfloat16 Tensor.View aliases
tf.quantization.fake_quant_with_min_max_args,"tf.quantization.fake_quant_with_min_max_args(
    inputs, min=-6, max=6, num_bits=8, narrow_range=False, name=None
)
","Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.View aliases"
tf.quantization.fake_quant_with_min_max_args_gradient,"tf.quantization.fake_quant_with_min_max_args_gradient(
    gradients, inputs, min=-6, max=6, num_bits=8, narrow_range=False, name=None
)
",Compute gradients for a FakeQuantWithMinMaxArgs operation.View aliases
tf.quantization.fake_quant_with_min_max_vars,"tf.quantization.fake_quant_with_min_max_vars(
    inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Fake-quantize the 'inputs' tensor of type float via global float scalarsView aliases
tf.quantization.fake_quant_with_min_max_vars_gradient,"tf.quantization.fake_quant_with_min_max_vars_gradient(
    gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Compute gradients for a FakeQuantWithMinMaxVars operation.View aliases
tf.quantization.fake_quant_with_min_max_vars_per_channel,"tf.quantization.fake_quant_with_min_max_vars_per_channel(
    inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Fake-quantize the 'inputs' tensor of type float via per-channel floatsView aliases
tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient,"tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient(
    gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.View aliases
tf.quantization.quantize,"tf.quantization.quantize(
    input,
    min_range,
    max_range,
    T,
    mode='MIN_COMBINED',
    round_mode='HALF_AWAY_FROM_ZERO',
    name=None,
    narrow_range=False,
    axis=None,
    ensure_minimum_range=0.01
)
",Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.View aliases
tf.quantization.quantize_and_dequantize,"tf.quantization.quantize_and_dequantize(
    input,
    input_min,
    input_max,
    signed_input=True,
    num_bits=8,
    range_given=False,
    round_mode='HALF_TO_EVEN',
    name=None,
    narrow_range=False,
    axis=None
)
",Quantizes then dequantizes a tensor. (deprecated)View aliases
tf.quantization.quantize_and_dequantize_v2,"tf.quantization.quantize_and_dequantize_v2(
    input,
    input_min,
    input_max,
    signed_input=True,
    num_bits=8,
    range_given=False,
    round_mode='HALF_TO_EVEN',
    name=None,
    narrow_range=False,
    axis=None
)
",Quantizes then dequantizes a tensor.View aliases
tf.quantization.quantized_concat,"tf.quantization.quantized_concat(
    concat_dim, values, input_mins, input_maxes, name=None
)
",Concatenates quantized tensors along one dimension.View aliases
tf.queue.FIFOQueue,"tf.queue.FIFOQueue(
    capacity,
    dtypes,
    shapes=None,
    names=None,
    shared_name=None,
    name='fifo_queue'
)
",A queue implementation that dequeues elements in first-in first-out order.Inherits From: QueueBaseView aliases
tf.queue.PaddingFIFOQueue,"tf.queue.PaddingFIFOQueue(
    capacity,
    dtypes,
    shapes,
    names=None,
    shared_name=None,
    name='padding_fifo_queue'
)
",A FIFOQueue that supports batching variable-sized tensors by padding.Inherits From: QueueBaseView aliases
tf.queue.PriorityQueue,"tf.queue.PriorityQueue(
    capacity,
    types,
    shapes=None,
    names=None,
    shared_name=None,
    name='priority_queue'
)
",A queue implementation that dequeues elements in prioritized order.Inherits From: QueueBaseView aliases
tf.queue.QueueBase,"tf.queue.QueueBase(
    dtypes, shapes, names, queue_ref
)
",Base class for queue implementations.View aliases
tf.queue.RandomShuffleQueue,"tf.queue.RandomShuffleQueue(
    capacity,
    min_after_dequeue,
    dtypes,
    shapes=None,
    names=None,
    seed=None,
    shared_name=None,
    name='random_shuffle_queue'
)
",A queue implementation that dequeues elements in a random order.Inherits From: QueueBaseView aliases
tf.ragged.boolean_mask,"tf.ragged.boolean_mask(
    data, mask, name=None
)
",Applies a boolean mask to data without flattening the mask dimensions.View aliases
tf.ragged.boolean_mask,tf.ragged.boolean_mask(  # Mask a 2D Tensor.,"Applies a boolean mask to data without flattening the mask dimensions.View aliasestf.ragged.boolean_mask(    data, mask, name=None)Used in the notebooksReturns a potentially ragged tensor that is formed by retaining the elementsin data where the corresponding value in mask is True.output[a1...aA, i, b1...bB] = data[a1...aA, j, b1...bB]Note that output preserves the mask dimensions a1...aA; this differsfrom tf.boolean_mask, which flattens those dimensions.rank(output) = rank(data)output.ragged_rank = max(data.ragged_rank, rank(mask) - 1)Examples:# Aliases for True & False so data and mask line up.T, F = (True, False)"
tf.ragged.boolean_mask,tf.ragged.boolean_mask(  # Mask a 2D RaggedTensor.,"Applies a boolean mask to data without flattening the mask dimensions.View aliasestf.ragged.boolean_mask(    data, mask, name=None)Used in the notebooksReturns a potentially ragged tensor that is formed by retaining the elementsin data where the corresponding value in mask is True.output[a1...aA, i, b1...bB] = data[a1...aA, j, b1...bB]Note that output preserves the mask dimensions a1...aA; this differsfrom tf.boolean_mask, which flattens those dimensions.rank(output) = rank(data)output.ragged_rank = max(data.ragged_rank, rank(mask) - 1)Examples:# Aliases for True & False so data and mask line up.T, F = (True, False)tf.ragged.boolean_mask(  # Mask a 2D Tensor.    data=[[1, 2, 3], [4, 5, 6], [7, 8, 9]],    mask=[[T, F, T], [F, F, F], [T, F, F]]).to_list()[[1, 3], [], [7]]"
tf.ragged.boolean_mask,tf.ragged.boolean_mask(  # Mask rows of a 2D RaggedTensor.,"Applies a boolean mask to data without flattening the mask dimensions.View aliasestf.ragged.boolean_mask(    data, mask, name=None)Used in the notebooksReturns a potentially ragged tensor that is formed by retaining the elementsin data where the corresponding value in mask is True.output[a1...aA, i, b1...bB] = data[a1...aA, j, b1...bB]Note that output preserves the mask dimensions a1...aA; this differsfrom tf.boolean_mask, which flattens those dimensions.rank(output) = rank(data)output.ragged_rank = max(data.ragged_rank, rank(mask) - 1)Examples:# Aliases for True & False so data and mask line up.T, F = (True, False)tf.ragged.boolean_mask(  # Mask a 2D Tensor.    data=[[1, 2, 3], [4, 5, 6], [7, 8, 9]],    mask=[[T, F, T], [F, F, F], [T, F, F]]).to_list()[[1, 3], [], [7]]tf.ragged.boolean_mask(  # Mask a 2D RaggedTensor.    tf.ragged.constant([[1, 2, 3], [4], [5, 6]]),    tf.ragged.constant([[F, F, T], [F], [T, T]])).to_list()[[3], [], [5, 6]]"
tf.ragged.constant,"tf.ragged.constant(
    pylist,
    dtype=None,
    ragged_rank=None,
    inner_shape=None,
    name=None,
    row_splits_dtype=tf.dtypes.int64
)
",Constructs a constant RaggedTensor from a nested Python list.View aliases
tf.ragged.cross,"tf.ragged.cross(
    inputs, name=None
)
",Generates feature cross from a list of tensors.View aliases
tf.ragged.cross,"tf.ragged.cross([tf.ragged.constant([['a'], ['b', 'c']]),","Generates feature cross from a list of tensors.View aliasestf.ragged.cross(    inputs, name=None)The input tensors must have rank=2, and must all have the same number ofrows.  The result is a RaggedTensor with the same number of rows as theinputs, where result[row] contains a list of all combinations of valuesformed by taking a single value from each input's corresponding row(inputs[i][row]).  Values are combined by joining their strings with 'X'.E.g.:"
tf.ragged.cross_hashed,"tf.ragged.cross_hashed(
    inputs, num_buckets=0, hash_key=None, name=None
)
",Generates hashed feature cross from a list of tensors.View aliases
tf.ragged.cross_hashed,"tf.ragged.cross_hashed([tf.ragged.constant([['a'], ['b', 'c']]),","Generates hashed feature cross from a list of tensors.View aliasestf.ragged.cross_hashed(    inputs, num_buckets=0, hash_key=None, name=None)The input tensors must have rank=2, and must all have the same number ofrows.  The result is a RaggedTensor with the same number of rows as theinputs, where result[row] contains a list of all combinations of valuesformed by taking a single value from each input's corresponding row(inputs[i][row]).  Values are combined by hashing together theirfingerprints. E.g.:"
tf.ragged.map_flat_values,"tf.ragged.map_flat_values(
    op, *args, **kwargs
)
",Applies op to the flat_values of one or more RaggedTensors.View aliases
tf.ragged.range,"tf.ragged.range(
    starts,
    limits=None,
    deltas=1,
    dtype=None,
    name=None,
    row_splits_dtype=tf.dtypes.int64
)
",Returns a RaggedTensor containing the specified sequences of numbers.View aliases
tf.ragged.row_splits_to_segment_ids,"tf.ragged.row_splits_to_segment_ids(
    splits, name=None, out_type=None
)
",Generates the segmentation corresponding to a RaggedTensor row_splits.View aliases
tf.ragged.segment_ids_to_row_splits,"tf.ragged.segment_ids_to_row_splits(
    segment_ids, num_segments=None, out_type=None, name=None
)
",Generates the RaggedTensor row_splits corresponding to a segmentation.View aliases
tf.ragged.stack,"tf.ragged.stack(
    values: typing.List[ragged_tensor.RaggedOrDense], axis=0, name=None
)
",Stacks a list of rank-R tensors into one rank-(R+1) RaggedTensor.View aliases
tf.ragged.stack_dynamic_partitions,"tf.ragged.stack_dynamic_partitions(
    data, partitions, num_partitions, name=None
)
",Stacks dynamic partitions of a Tensor or RaggedTensor.View aliases
tf.random.Generator,"tf.random.Generator(
    copy_from=None, state=None, alg=None
)
",Random-number generator.View aliases
tf.random.all_candidate_sampler,"tf.random.all_candidate_sampler(
    true_classes, num_true, num_sampled, unique, seed=None, name=None
)
",Generate the set of all classes.View aliases
tf.random.categorical,"tf.random.categorical(
    logits, num_samples, dtype=None, seed=None, name=None
)
",Draws samples from a categorical distribution.View aliases
tf.random.create_rng_state,"tf.random.create_rng_state(
    seed, alg
)
",Creates a RNG state from an integer or a vector.View aliases
tf.random.create_rng_state,tf.random.create_rng_state(,"Creates a RNG state from an integer or a vector.View aliasestf.random.create_rng_state(    seed, alg)Example:"
tf.random.Generator,"tf.random.Generator(
    copy_from=None, state=None, alg=None
)
",Random-number generator.View aliases
tf.random.create_rng_state,"tf.random.create_rng_state(
    seed, alg
)
",Creates a RNG state from an integer or a vector.View aliases
tf.random.create_rng_state,tf.random.create_rng_state(,"Creates a RNG state from an integer or a vector.View aliasestf.random.create_rng_state(    seed, alg)Example:"
tf.random.experimental.index_shuffle,"tf.random.experimental.index_shuffle(
    index, seed, max_index
)
","Outputs the position of index in a permutation of [0, ..., max_index].View aliases"
tf.random.set_global_generator,"tf.random.set_global_generator(
    generator
)
",Replaces the global generator with another Generator object.View aliases
tf.random.experimental.stateless_fold_in,"tf.random.experimental.stateless_fold_in(
    seed, data, alg='auto_select'
)
",Folds in data to an RNG seed to form a new RNG seed.View aliases
tf.random.experimental.stateless_shuffle,"tf.random.experimental.stateless_shuffle(
    value, seed, alg='auto_select', name=None
)
",Randomly and deterministically shuffles a tensor along its first dimension.View aliases
tf.random.experimental.stateless_split,"tf.random.experimental.stateless_split(
    seed, num=2, alg='auto_select'
)
",Splits an RNG seed into num new seeds by adding a leading axis.View aliases
tf.random.fixed_unigram_candidate_sampler,"tf.random.fixed_unigram_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    vocab_file='',
    distortion=1.0,
    num_reserved_ids=0,
    num_shards=1,
    shard=0,
    unigrams=(),
    seed=None,
    name=None
)
",Samples a set of classes using the provided (fixed) base distribution.View aliases
tf.random.gamma,"tf.random.gamma(
    shape,
    alpha,
    beta=None,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Draws shape samples from each of the given Gamma distribution(s).View aliases
tf.random.learned_unigram_candidate_sampler,"tf.random.learned_unigram_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=None,
    name=None
)
",Samples a set of classes from a distribution learned during training.View aliases
tf.random.log_uniform_candidate_sampler,"tf.random.log_uniform_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=None,
    name=None
)
",Samples a set of classes using a log-uniform (Zipfian) base distribution.View aliases
tf.random.normal,"tf.random.normal(
    shape,
    mean=0.0,
    stddev=1.0,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Outputs random values from a normal distribution.View aliases
tf.random.set_seed,tf.random.set_seed(5);,"Outputs random values from a normal distribution.View aliasestf.random.normal(    shape,    mean=0.0,    stddev=1.0,    dtype=Used in the notebooksExample that generates a new set of random values every time:"
tf.random.set_seed,tf.random.set_seed(5);,"Outputs random values from a normal distribution.View aliasestf.random.normal(    shape,    mean=0.0,    stddev=1.0,    dtype=Used in the notebooksExample that generates a new set of random values every time:tf.random.set_seed(5);tf.random.normal([4], 0, 1, tf.float32)<tf.Tensor: shape=(4,), dtype=float32, numpy=..., dtype=float32)>Example that outputs a reproducible result:"
tf.random.poisson,"tf.random.poisson(
    shape,
    lam,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Draws shape samples from each of the given Poisson distribution(s).
tf.random.set_global_generator,"tf.random.set_global_generator(
    generator
)
",Replaces the global generator with another Generator object.View aliases
tf.random.set_seed,"tf.random.set_seed(
    seed
)
",Sets the global random seed.
tf.random.shuffle,"tf.random.shuffle(
    value, seed=None, name=None
)
",Randomly shuffles a tensor along its first dimension.View aliases
tf.random.stateless_binomial,"tf.random.stateless_binomial(
    shape,
    seed,
    counts,
    probs,
    output_dtype=tf.dtypes.int32,
    name=None
)
",Outputs deterministic pseudorandom values from a binomial distribution.View aliases
tf.random.stateless_categorical,"tf.random.stateless_categorical(
    logits,
    num_samples,
    seed,
    dtype=tf.dtypes.int64,
    name=None
)
",Draws deterministic pseudorandom samples from a categorical distribution.View aliases
tf.random.stateless_gamma,"tf.random.stateless_gamma(
    shape,
    seed,
    alpha,
    beta=None,
    dtype=tf.dtypes.float32,
    name=None
)
",Outputs deterministic pseudorandom values from a gamma distribution.View aliases
tf.random.stateless_normal,"tf.random.stateless_normal(
    shape,
    seed,
    mean=0.0,
    stddev=1.0,
    dtype=tf.dtypes.float32,
    name=None,
    alg='auto_select'
)
",Outputs deterministic pseudorandom values from a normal distribution.View aliases
tf.random.stateless_parameterized_truncated_normal,"tf.random.stateless_parameterized_truncated_normal(
    shape, seed, means=0.0, stddevs=1.0, minvals=-2.0, maxvals=2.0, name=None
)
",Outputs random values from a truncated normal distribution.View aliases
tf.random.stateless_poisson,"tf.random.stateless_poisson(
    shape,
    seed,
    lam,
    dtype=tf.dtypes.int32,
    name=None
)
",Outputs deterministic pseudorandom values from a Poisson distribution.View aliases
tf.random.stateless_truncated_normal,"tf.random.stateless_truncated_normal(
    shape,
    seed,
    mean=0.0,
    stddev=1.0,
    dtype=tf.dtypes.float32,
    name=None,
    alg='auto_select'
)
","Outputs deterministic pseudorandom values, truncated normally distributed.View aliases"
tf.random.stateless_uniform,"tf.random.stateless_uniform(
    shape,
    seed,
    minval=0,
    maxval=None,
    dtype=tf.dtypes.float32,
    name=None,
    alg='auto_select'
)
",Outputs deterministic pseudorandom values from a uniform distribution.View aliases
tf.random.truncated_normal,"tf.random.truncated_normal(
    shape,
    mean=0.0,
    stddev=1.0,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Outputs random values from a truncated normal distribution.View aliases
tf.random.uniform,"tf.random.uniform(
    shape,
    minval=0,
    maxval=None,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Outputs random values from a uniform distribution.View aliases
tf.random.uniform_candidate_sampler,"tf.random.uniform_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=None,
    name=None
)
",Samples a set of classes using a uniform base distribution.View aliases
tf.random_index_shuffle,"tf.random_index_shuffle(
    index, seed, max_index, name=None
)
","Outputs the position of value in a permutation of [0, ..., max_index].View aliases"
tf.random_normal_initializer,"tf.random_normal_initializer(
    mean=0.0, stddev=0.05, seed=None
)
",Initializer that generates tensors with a normal distribution.
tf.random_uniform_initializer,"tf.random_uniform_initializer(
    minval=-0.05, maxval=0.05, seed=None
)
",Initializer that generates tensors with a uniform distribution.
tf.rank,"tf.rank(
    input, name=None
)
",Returns the rank of a tensor.View aliases
tf.raw_ops.Abort,"tf.raw_ops.Abort(
    error_msg='', exit_without_error=False, name=None
)
",Raise a exception to abort the process when called.View aliases
tf.raw_ops.Abs,"tf.raw_ops.Abs(
    x, name=None
)
",Computes the absolute value of a tensor.View aliases
tf.raw_ops.AccumulateNV2,"tf.raw_ops.AccumulateNV2(
    inputs, shape, name=None
)
",Returns the element-wise sum of a list of tensors.View aliases
tf.raw_ops.AccumulatorApplyGradient,"tf.raw_ops.AccumulatorApplyGradient(
    handle, local_step, gradient, name=None
)
",Applies a gradient to a given accumulator.View aliases
tf.raw_ops.AccumulatorNumAccumulated,"tf.raw_ops.AccumulatorNumAccumulated(
    handle, name=None
)
",Returns the number of gradients aggregated in the given accumulators.View aliases
tf.raw_ops.AccumulatorSetGlobalStep,"tf.raw_ops.AccumulatorSetGlobalStep(
    handle, new_global_step, name=None
)
",Updates the accumulator with a new value for global_step.View aliases
tf.raw_ops.AccumulatorTakeGradient,"tf.raw_ops.AccumulatorTakeGradient(
    handle, num_required, dtype, name=None
)
",Extracts the average gradient in the given ConditionalAccumulator.View aliases
tf.raw_ops.Acos,"tf.raw_ops.Acos(
    x, name=None
)
",Computes acos of x element-wise.View aliases
tf.raw_ops.Acosh,"tf.raw_ops.Acosh(
    x, name=None
)
",Computes inverse hyperbolic cosine of x element-wise.View aliases
tf.raw_ops.Add,"tf.raw_ops.Add(
    x, y, name=None
)
",Returns x + y element-wise.View aliases
tf.raw_ops.AddManySparseToTensorsMap,"tf.raw_ops.AddManySparseToTensorsMap(
    sparse_indices,
    sparse_values,
    sparse_shape,
    container='',
    shared_name='',
    name=None
)
","Add an N-minibatch SparseTensor to a SparseTensorsMap, return N handles.View aliases"
tf.raw_ops.AddN,"tf.raw_ops.AddN(
    inputs, name=None
)
",Add all input tensors element wise.View aliases
tf.raw_ops.AddSparseToTensorsMap,"tf.raw_ops.AddSparseToTensorsMap(
    sparse_indices,
    sparse_values,
    sparse_shape,
    container='',
    shared_name='',
    name=None
)
",Add a SparseTensor to a SparseTensorsMap return its handle.View aliases
tf.raw_ops.AddV2,"tf.raw_ops.AddV2(
    x, y, name=None
)
",Returns x + y element-wise.View aliases
tf.raw_ops.AdjustContrast,"tf.raw_ops.AdjustContrast(
    images, contrast_factor, min_value, max_value, name=None
)
",Deprecated. Disallowed in GraphDef version >= 2.View aliases
tf.raw_ops.AdjustContrastv2,"tf.raw_ops.AdjustContrastv2(
    images, contrast_factor, name=None
)
",Adjust the contrast of one or more images.View aliases
tf.raw_ops.AdjustHue,"tf.raw_ops.AdjustHue(
    images, delta, name=None
)
",Adjust the hue of one or more images.View aliases
tf.raw_ops.AdjustSaturation,"tf.raw_ops.AdjustSaturation(
    images, scale, name=None
)
",Adjust the saturation of one or more images.View aliases
tf.raw_ops.All,"tf.raw_ops.All(
    input, axis, keep_dims=False, name=None
)
","Computes the ""logical and"" of elements across dimensions of a tensor.View aliases"
tf.raw_ops.AllCandidateSampler,"tf.raw_ops.AllCandidateSampler(
    true_classes, num_true, num_sampled, unique, seed=0, seed2=0, name=None
)
",Generates labels for candidate sampling with a learned unigram distribution.View aliases
tf.raw_ops.AllToAll,"tf.raw_ops.AllToAll(
    input,
    group_assignment,
    concat_dimension,
    split_dimension,
    split_count,
    name=None
)
",An Op to exchange data across TPU replicas.View aliases
tf.raw_ops.Angle,"tf.raw_ops.Angle(
    input,
    Tout=tf.dtypes.float32,
    name=None
)
",Returns the argument of a complex number.View aliases
tf.raw_ops.AnonymousHashTable,"tf.raw_ops.AnonymousHashTable(
    key_dtype, value_dtype, name=None
)
",Creates a uninitialized anonymous hash table.View aliases
tf.raw_ops.AnonymousIterator,"tf.raw_ops.AnonymousIterator(
    output_types, output_shapes, name=None
)
",A container for an iterator resource.View aliases
tf.raw_ops.AnonymousIteratorV2,"tf.raw_ops.AnonymousIteratorV2(
    output_types, output_shapes, name=None
)
",A container for an iterator resource.View aliases
tf.raw_ops.AnonymousIteratorV3,"tf.raw_ops.AnonymousIteratorV3(
    output_types, output_shapes, name=None
)
",A container for an iterator resource.View aliases
tf.raw_ops.AnonymousMemoryCache,"tf.raw_ops.AnonymousMemoryCache(
    name=None
)
",View aliases
tf.raw_ops.AnonymousMultiDeviceIterator,"tf.raw_ops.AnonymousMultiDeviceIterator(
    devices, output_types, output_shapes, name=None
)
",A container for a multi device iterator resource.View aliases
tf.raw_ops.AnonymousMultiDeviceIteratorV3,"tf.raw_ops.AnonymousMultiDeviceIteratorV3(
    devices, output_types, output_shapes, name=None
)
",A container for a multi device iterator resource.View aliases
tf.raw_ops.AnonymousMutableDenseHashTable,"tf.raw_ops.AnonymousMutableDenseHashTable(
    empty_key,
    deleted_key,
    value_dtype,
    value_shape=[],
    initial_num_buckets=131072,
    max_load_factor=0.8,
    name=None
)
",Creates an empty anonymous mutable hash table that uses tensors as the backing store.View aliases
tf.raw_ops.AnonymousMutableHashTable,"tf.raw_ops.AnonymousMutableHashTable(
    key_dtype, value_dtype, name=None
)
",Creates an empty anonymous mutable hash table.View aliases
tf.raw_ops.AnonymousMutableHashTableOfTensors,"tf.raw_ops.AnonymousMutableHashTableOfTensors(
    key_dtype, value_dtype, value_shape=[], name=None
)
",Creates an empty anonymous mutable hash table of vector values.View aliases
tf.raw_ops.AnonymousRandomSeedGenerator,"tf.raw_ops.AnonymousRandomSeedGenerator(
    seed, seed2, name=None
)
",View aliases
tf.raw_ops.AnonymousSeedGenerator,"tf.raw_ops.AnonymousSeedGenerator(
    seed, seed2, reshuffle, name=None
)
",View aliases
tf.raw_ops.Any,"tf.raw_ops.Any(
    input, axis, keep_dims=False, name=None
)
","Computes the ""logical or"" of elements across dimensions of a tensor.View aliases"
tf.raw_ops.ApplyAdaMax,"tf.raw_ops.ApplyAdaMax(
    var,
    m,
    v,
    beta1_power,
    lr,
    beta1,
    beta2,
    epsilon,
    grad,
    use_locking=False,
    name=None
)
",Update '*var' according to the AdaMax algorithm.View aliases
tf.raw_ops.ApplyAdadelta,"tf.raw_ops.ApplyAdadelta(
    var,
    accum,
    accum_update,
    lr,
    rho,
    epsilon,
    grad,
    use_locking=False,
    name=None
)
",Update '*var' according to the adadelta scheme.View aliases
tf.raw_ops.ApplyAdagrad,"tf.raw_ops.ApplyAdagrad(
    var, accum, lr, grad, use_locking=False, update_slots=True, name=None
)
",Update '*var' according to the adagrad scheme.View aliases
tf.raw_ops.ApplyAdagradDA,"tf.raw_ops.ApplyAdagradDA(
    var,
    gradient_accumulator,
    gradient_squared_accumulator,
    grad,
    lr,
    l1,
    l2,
    global_step,
    use_locking=False,
    name=None
)
",Update '*var' according to the proximal adagrad scheme.View aliases
tf.raw_ops.ApplyAdagradV2,"tf.raw_ops.ApplyAdagradV2(
    var,
    accum,
    lr,
    epsilon,
    grad,
    use_locking=False,
    update_slots=True,
    name=None
)
",Update '*var' according to the adagrad scheme.View aliases
tf.raw_ops.ApplyAdam,"tf.raw_ops.ApplyAdam(
    var,
    m,
    v,
    beta1_power,
    beta2_power,
    lr,
    beta1,
    beta2,
    epsilon,
    grad,
    use_locking=False,
    use_nesterov=False,
    name=None
)
",Update '*var' according to the Adam algorithm.View aliases
tf.raw_ops.ApplyAddSign,"tf.raw_ops.ApplyAddSign(
    var, m, lr, alpha, sign_decay, beta, grad, use_locking=False, name=None
)
",Update '*var' according to the AddSign update.View aliases
tf.raw_ops.ApplyCenteredRMSProp,"tf.raw_ops.ApplyCenteredRMSProp(
    var,
    mg,
    ms,
    mom,
    lr,
    rho,
    momentum,
    epsilon,
    grad,
    use_locking=False,
    name=None
)
",Update '*var' according to the centered RMSProp algorithm.View aliases
tf.raw_ops.ApplyFtrl,"tf.raw_ops.ApplyFtrl(
    var,
    accum,
    linear,
    grad,
    lr,
    l1,
    l2,
    lr_power,
    use_locking=False,
    multiply_linear_by_lr=False,
    name=None
)
",Update '*var' according to the Ftrl-proximal scheme.View aliases
tf.raw_ops.ApplyFtrlV2,"tf.raw_ops.ApplyFtrlV2(
    var,
    accum,
    linear,
    grad,
    lr,
    l1,
    l2,
    l2_shrinkage,
    lr_power,
    use_locking=False,
    multiply_linear_by_lr=False,
    name=None
)
",Update '*var' according to the Ftrl-proximal scheme.View aliases
tf.raw_ops.ApplyGradientDescent,"tf.raw_ops.ApplyGradientDescent(
    var, alpha, delta, use_locking=False, name=None
)
",Update '*var' by subtracting 'alpha' * 'delta' from it.View aliases
tf.raw_ops.ApplyMomentum,"tf.raw_ops.ApplyMomentum(
    var,
    accum,
    lr,
    grad,
    momentum,
    use_locking=False,
    use_nesterov=False,
    name=None
)
",Update '*var' according to the momentum scheme.View aliases
tf.raw_ops.ApplyPowerSign,"tf.raw_ops.ApplyPowerSign(
    var, m, lr, logbase, sign_decay, beta, grad, use_locking=False, name=None
)
",Update '*var' according to the AddSign update.View aliases
tf.raw_ops.ApplyProximalAdagrad,"tf.raw_ops.ApplyProximalAdagrad(
    var, accum, lr, l1, l2, grad, use_locking=False, name=None
)
",Update 'var' and 'accum' according to FOBOS with Adagrad learning rate.View aliases
tf.raw_ops.ApplyProximalGradientDescent,"tf.raw_ops.ApplyProximalGradientDescent(
    var, alpha, l1, l2, delta, use_locking=False, name=None
)
",Update '*var' as FOBOS algorithm with fixed learning rate.View aliases
tf.raw_ops.ApplyRMSProp,"tf.raw_ops.ApplyRMSProp(
    var,
    ms,
    mom,
    lr,
    rho,
    momentum,
    epsilon,
    grad,
    use_locking=False,
    name=None
)
",Update '*var' according to the RMSProp algorithm.View aliases
tf.raw_ops.ApproxTopK,"tf.raw_ops.ApproxTopK(
    input,
    k,
    reduction_dimension=-1,
    recall_target=0.95,
    is_max_k=True,
    reduction_input_size_override=-1,
    aggregate_to_topk=True,
    name=None
)
",Returns min/max k values and their indices of the input operand in an approximate manner.View aliases
tf.raw_ops.ApproximateEqual,"tf.raw_ops.ApproximateEqual(
    x, y, tolerance=1e-05, name=None
)
",Returns the truth value of abs(x-y) < tolerance element-wise.View aliases
tf.raw_ops.ArgMax,"tf.raw_ops.ArgMax(
    input,
    dimension,
    output_type=tf.dtypes.int64,
    name=None
)
",Returns the index with the largest value across dimensions of a tensor.View aliases
tf.raw_ops.ArgMin,"tf.raw_ops.ArgMin(
    input,
    dimension,
    output_type=tf.dtypes.int64,
    name=None
)
",Returns the index with the smallest value across dimensions of a tensor.View aliases
tf.raw_ops.AsString,"tf.raw_ops.AsString(
    input,
    precision=-1,
    scientific=False,
    shortest=False,
    width=-1,
    fill='',
    name=None
)
",Converts each entry in the given tensor to strings.View aliases
tf.raw_ops.Asin,"tf.raw_ops.Asin(
    x, name=None
)
",Computes the trignometric inverse sine of x element-wise.View aliases
tf.raw_ops.Asinh,"tf.raw_ops.Asinh(
    x, name=None
)
",Computes inverse hyperbolic sine of x element-wise.View aliases
tf.raw_ops.Assert,"tf.raw_ops.Assert(
    condition, data, summarize=3, name=None
)
",Asserts that the given condition is true.View aliases
tf.raw_ops.AssertCardinalityDataset,"tf.raw_ops.AssertCardinalityDataset(
    input_dataset, cardinality, output_types, output_shapes, name=None
)
",View aliases
tf.raw_ops.AssertNextDataset,"tf.raw_ops.AssertNextDataset(
    input_dataset, transformations, output_types, output_shapes, name=None
)
",A transformation that asserts which transformations happen next.View aliases
tf.raw_ops.AssertPrevDataset,"tf.raw_ops.AssertPrevDataset(
    input_dataset, transformations, output_types, output_shapes, name=None
)
",A transformation that asserts which transformations happened previously.View aliases
tf.raw_ops.Assign,"tf.raw_ops.Assign(
    ref, value, validate_shape=True, use_locking=True, name=None
)
",Update 'ref' by assigning 'value' to it.View aliases
tf.raw_ops.AssignAdd,"tf.raw_ops.AssignAdd(
    ref, value, use_locking=False, name=None
)
",Update 'ref' by adding 'value' to it.View aliases
tf.raw_ops.AssignAddVariableOp,"tf.raw_ops.AssignAddVariableOp(
    resource, value, name=None
)
",Adds a value to the current value of a variable.View aliases
tf.raw_ops.AssignSub,"tf.raw_ops.AssignSub(
    ref, value, use_locking=False, name=None
)
",Update 'ref' by subtracting 'value' from it.View aliases
tf.raw_ops.AssignSubVariableOp,"tf.raw_ops.AssignSubVariableOp(
    resource, value, name=None
)
",Subtracts a value from the current value of a variable.View aliases
tf.raw_ops.AssignVariableOp,"tf.raw_ops.AssignVariableOp(
    resource, value, validate_shape=False, name=None
)
",Assigns a new value to a variable.View aliases
tf.raw_ops.AssignVariableXlaConcatND,"tf.raw_ops.AssignVariableXlaConcatND(
    resource, inputs, num_concats, paddings=[], name=None
)
",Concats input tensor across all dimensions.View aliases
tf.raw_ops.Atan,"tf.raw_ops.Atan(
    x, name=None
)
",Computes the trignometric inverse tangent of x element-wise.View aliases
tf.raw_ops.Atan2,"tf.raw_ops.Atan2(
    y, x, name=None
)
","Computes arctangent of y/x element-wise, respecting signs of the arguments.View aliases"
tf.raw_ops.Atanh,"tf.raw_ops.Atanh(
    x, name=None
)
",Computes inverse hyperbolic tangent of x element-wise.View aliases
tf.raw_ops.AudioSpectrogram,"tf.raw_ops.AudioSpectrogram(
    input, window_size, stride, magnitude_squared=False, name=None
)
",Produces a visualization of audio data over time.View aliases
tf.raw_ops.AudioSummary,"tf.raw_ops.AudioSummary(
    tag, tensor, sample_rate, max_outputs=3, name=None
)
",Outputs a Summary protocol buffer with audio.View aliases
tf.raw_ops.AudioSummaryV2,"tf.raw_ops.AudioSummaryV2(
    tag, tensor, sample_rate, max_outputs=3, name=None
)
",Outputs a Summary protocol buffer with audio.View aliases
tf.raw_ops.AutoShardDataset,"tf.raw_ops.AutoShardDataset(
    input_dataset,
    num_workers,
    index,
    output_types,
    output_shapes,
    auto_shard_policy=0,
    num_replicas=0,
    name=None
)
",Creates a dataset that shards the input dataset.View aliases
tf.raw_ops.AvgPool,"tf.raw_ops.AvgPool(
    value, ksize, strides, padding, data_format='NHWC', name=None
)
",Performs average pooling on the input.View aliases
tf.raw_ops.AvgPool3D,"tf.raw_ops.AvgPool3D(
    input, ksize, strides, padding, data_format='NDHWC', name=None
)
",Performs 3D average pooling on the input.View aliases
tf.raw_ops.AvgPool3DGrad,"tf.raw_ops.AvgPool3DGrad(
    orig_input_shape,
    grad,
    ksize,
    strides,
    padding,
    data_format='NDHWC',
    name=None
)
",Computes gradients of average pooling function.View aliases
tf.raw_ops.AvgPoolGrad,"tf.raw_ops.AvgPoolGrad(
    orig_input_shape,
    grad,
    ksize,
    strides,
    padding,
    data_format='NHWC',
    name=None
)
",Computes gradients of the average pooling function.View aliases
tf.raw_ops.BandedTriangularSolve,"tf.raw_ops.BandedTriangularSolve(
    matrix, rhs, lower=True, adjoint=False, name=None
)
",View aliases
tf.raw_ops.Barrier,"tf.raw_ops.Barrier(
    component_types,
    shapes=[],
    capacity=-1,
    container='',
    shared_name='',
    name=None
)
",Defines a barrier that persists across different graph executions.View aliases
tf.raw_ops.BarrierClose,"tf.raw_ops.BarrierClose(
    handle, cancel_pending_enqueues=False, name=None
)
",Closes the given barrier.View aliases
tf.raw_ops.BarrierIncompleteSize,"tf.raw_ops.BarrierIncompleteSize(
    handle, name=None
)
",Computes the number of incomplete elements in the given barrier.View aliases
tf.raw_ops.BarrierInsertMany,"tf.raw_ops.BarrierInsertMany(
    handle, keys, values, component_index, name=None
)
","For each key, assigns the respective value to the specified component.View aliases"
tf.raw_ops.BarrierReadySize,"tf.raw_ops.BarrierReadySize(
    handle, name=None
)
",Computes the number of complete elements in the given barrier.View aliases
tf.raw_ops.BarrierTakeMany,"tf.raw_ops.BarrierTakeMany(
    handle,
    num_elements,
    component_types,
    allow_small_batch=False,
    wait_for_incomplete=False,
    timeout_ms=-1,
    name=None
)
",Takes the given number of completed elements from a barrier.View aliases
tf.raw_ops.Batch,"tf.raw_ops.Batch(
    in_tensors,
    num_batch_threads,
    max_batch_size,
    batch_timeout_micros,
    grad_timeout_micros,
    max_enqueued_batches=10,
    allowed_batch_sizes=[],
    container='',
    shared_name='',
    batching_queue='',
    name=None
)
",Batches all input tensors nondeterministically.View aliases
tf.raw_ops.BatchCholesky,"tf.raw_ops.BatchCholesky(
    input, name=None
)
",View aliases
tf.raw_ops.BatchCholeskyGrad,"tf.raw_ops.BatchCholeskyGrad(
    l, grad, name=None
)
",View aliases
tf.raw_ops.BatchDataset,"tf.raw_ops.BatchDataset(
    input_dataset,
    batch_size,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that batches batch_size elements from input_dataset.View aliases
tf.raw_ops.BatchDatasetV2,"tf.raw_ops.BatchDatasetV2(
    input_dataset,
    batch_size,
    drop_remainder,
    output_types,
    output_shapes,
    parallel_copy=False,
    metadata='',
    name=None
)
",Creates a dataset that batches batch_size elements from input_dataset.View aliases
tf.raw_ops.BatchFFT,"tf.raw_ops.BatchFFT(
    input, name=None
)
",View aliases
tf.raw_ops.BatchFFT2D,"tf.raw_ops.BatchFFT2D(
    input, name=None
)
",View aliases
tf.raw_ops.BatchFFT3D,"tf.raw_ops.BatchFFT3D(
    input, name=None
)
",View aliases
tf.raw_ops.BatchFunction,"tf.raw_ops.BatchFunction(
    in_tensors,
    captured_tensors,
    f,
    num_batch_threads,
    max_batch_size,
    batch_timeout_micros,
    Tout,
    max_enqueued_batches=10,
    allowed_batch_sizes=[],
    container='',
    shared_name='',
    batching_queue='',
    enable_large_batch_splitting=False,
    name=None
)
",Batches all the inputs tensors to the computation done by the function.View aliases
tf.raw_ops.BatchIFFT,"tf.raw_ops.BatchIFFT(
    input, name=None
)
",View aliases
tf.raw_ops.BatchIFFT2D,"tf.raw_ops.BatchIFFT2D(
    input, name=None
)
",View aliases
tf.raw_ops.BatchIFFT3D,"tf.raw_ops.BatchIFFT3D(
    input, name=None
)
",View aliases
tf.raw_ops.BatchMatMul,"tf.raw_ops.BatchMatMul(
    x, y, adj_x=False, adj_y=False, name=None
)
",Multiplies slices of two tensors in batches.View aliases
tf.raw_ops.BatchMatMulV2,"tf.raw_ops.BatchMatMulV2(
    x, y, adj_x=False, adj_y=False, name=None
)
",Multiplies slices of two tensors in batches.View aliases
tf.raw_ops.BatchMatMulV3,"tf.raw_ops.BatchMatMulV3(
    x, y, Tout, adj_x=False, adj_y=False, name=None
)
",Multiplies slices of two tensors in batches.View aliases
tf.raw_ops.BatchMatrixBandPart,"tf.raw_ops.BatchMatrixBandPart(
    input, num_lower, num_upper, name=None
)
",View aliases
tf.raw_ops.BatchMatrixDeterminant,"tf.raw_ops.BatchMatrixDeterminant(
    input, name=None
)
",View aliases
tf.raw_ops.BatchMatrixDiag,"tf.raw_ops.BatchMatrixDiag(
    diagonal, name=None
)
",View aliases
tf.raw_ops.BatchMatrixDiagPart,"tf.raw_ops.BatchMatrixDiagPart(
    input, name=None
)
",View aliases
tf.raw_ops.BatchMatrixInverse,"tf.raw_ops.BatchMatrixInverse(
    input, adjoint=False, name=None
)
",View aliases
tf.raw_ops.BatchMatrixSetDiag,"tf.raw_ops.BatchMatrixSetDiag(
    input, diagonal, name=None
)
",View aliases
tf.raw_ops.BatchMatrixSolve,"tf.raw_ops.BatchMatrixSolve(
    matrix, rhs, adjoint=False, name=None
)
",View aliases
tf.raw_ops.BatchMatrixSolveLs,"tf.raw_ops.BatchMatrixSolveLs(
    matrix, rhs, l2_regularizer, fast=True, name=None
)
",View aliases
tf.raw_ops.BatchMatrixTriangularSolve,"tf.raw_ops.BatchMatrixTriangularSolve(
    matrix, rhs, lower=True, adjoint=False, name=None
)
",View aliases
tf.raw_ops.BatchNormWithGlobalNormalization,"tf.raw_ops.BatchNormWithGlobalNormalization(
    t,
    m,
    v,
    beta,
    gamma,
    variance_epsilon,
    scale_after_normalization,
    name=None
)
",Batch normalization.View aliases
tf.raw_ops.BatchNormWithGlobalNormalizationGrad,"tf.raw_ops.BatchNormWithGlobalNormalizationGrad(
    t,
    m,
    v,
    gamma,
    backprop,
    variance_epsilon,
    scale_after_normalization,
    name=None
)
",Gradients for batch normalization.View aliases
tf.raw_ops.BatchSelfAdjointEig,"tf.raw_ops.BatchSelfAdjointEig(
    input, name=None
)
",View aliases
tf.raw_ops.BatchSelfAdjointEigV2,"tf.raw_ops.BatchSelfAdjointEigV2(
    input, compute_v=True, name=None
)
",View aliases
tf.raw_ops.BatchSvd,"tf.raw_ops.BatchSvd(
    input, compute_uv=True, full_matrices=False, name=None
)
",View aliases
tf.raw_ops.BatchToSpace,"tf.raw_ops.BatchToSpace(
    input, crops, block_size, name=None
)
",BatchToSpace for 4-D tensors of type T.View aliases
tf.raw_ops.BatchToSpaceND,"tf.raw_ops.BatchToSpaceND(
    input, block_shape, crops, name=None
)
",BatchToSpace for N-D tensors of type T.View aliases
tf.raw_ops.BesselI0,"tf.raw_ops.BesselI0(
    x, name=None
)
",View aliases
tf.raw_ops.BesselI0e,"tf.raw_ops.BesselI0e(
    x, name=None
)
",View aliases
tf.raw_ops.BesselI1,"tf.raw_ops.BesselI1(
    x, name=None
)
",View aliases
tf.raw_ops.BesselI1e,"tf.raw_ops.BesselI1e(
    x, name=None
)
",View aliases
tf.raw_ops.BesselJ0,"tf.raw_ops.BesselJ0(
    x, name=None
)
",View aliases
tf.raw_ops.BesselJ1,"tf.raw_ops.BesselJ1(
    x, name=None
)
",View aliases
tf.raw_ops.BesselK0,"tf.raw_ops.BesselK0(
    x, name=None
)
",View aliases
tf.raw_ops.BesselK0e,"tf.raw_ops.BesselK0e(
    x, name=None
)
",View aliases
tf.raw_ops.BesselK1,"tf.raw_ops.BesselK1(
    x, name=None
)
",View aliases
tf.raw_ops.BesselK1e,"tf.raw_ops.BesselK1e(
    x, name=None
)
",View aliases
tf.raw_ops.BesselY0,"tf.raw_ops.BesselY0(
    x, name=None
)
",View aliases
tf.raw_ops.BesselY1,"tf.raw_ops.BesselY1(
    x, name=None
)
",View aliases
tf.raw_ops.Betainc,"tf.raw_ops.Betainc(
    a, b, x, name=None
)
","Compute the regularized incomplete beta integral \(I_x(a, b)\).View aliases"
tf.raw_ops.BiasAdd,"tf.raw_ops.BiasAdd(
    value, bias, data_format='NHWC', name=None
)
",Adds bias to value.View aliases
tf.raw_ops.BiasAddGrad,"tf.raw_ops.BiasAddGrad(
    out_backprop, data_format='NHWC', name=None
)
","The backward operation for ""BiasAdd"" on the ""bias"" tensor.View aliases"
tf.raw_ops.BiasAddV1,"tf.raw_ops.BiasAddV1(
    value, bias, name=None
)
",Adds bias to value.View aliases
tf.raw_ops.Bincount,"tf.raw_ops.Bincount(
    arr, size, weights, name=None
)
",Counts the number of occurrences of each value in an integer array.View aliases
tf.raw_ops.Bitcast,"tf.raw_ops.Bitcast(
    input, type, name=None
)
",Bitcasts a tensor from one type to another without copying data.View aliases
tf.raw_ops.BitwiseAnd,"tf.raw_ops.BitwiseAnd(
    x, y, name=None
)
",Elementwise computes the bitwise AND of x and y.View aliases
tf.raw_ops.BitwiseOr,"tf.raw_ops.BitwiseOr(
    x, y, name=None
)
",Elementwise computes the bitwise OR of x and y.View aliases
tf.raw_ops.BitwiseXor,"tf.raw_ops.BitwiseXor(
    x, y, name=None
)
",Elementwise computes the bitwise XOR of x and y.View aliases
tf.raw_ops.BlockLSTM,"tf.raw_ops.BlockLSTM(
    seq_len_max,
    x,
    cs_prev,
    h_prev,
    w,
    wci,
    wcf,
    wco,
    b,
    forget_bias=1,
    cell_clip=3,
    use_peephole=False,
    name=None
)
",Computes the LSTM cell forward propagation for all the time steps.View aliases
tf.raw_ops.BlockLSTMGrad,"tf.raw_ops.BlockLSTMGrad(
    seq_len_max,
    x,
    cs_prev,
    h_prev,
    w,
    wci,
    wcf,
    wco,
    b,
    i,
    cs,
    f,
    o,
    ci,
    co,
    h,
    cs_grad,
    h_grad,
    use_peephole,
    name=None
)
",Computes the LSTM cell backward propagation for the entire time sequence.View aliases
tf.raw_ops.BlockLSTMGradV2,"tf.raw_ops.BlockLSTMGradV2(
    seq_len_max,
    x,
    cs_prev,
    h_prev,
    w,
    wci,
    wcf,
    wco,
    b,
    i,
    cs,
    f,
    o,
    ci,
    co,
    h,
    cs_grad,
    h_grad,
    use_peephole,
    name=None
)
",Computes the LSTM cell backward propagation for the entire time sequence.View aliases
tf.raw_ops.BlockLSTMV2,"tf.raw_ops.BlockLSTMV2(
    seq_len_max,
    x,
    cs_prev,
    h_prev,
    w,
    wci,
    wcf,
    wco,
    b,
    cell_clip=0,
    use_peephole=False,
    name=None
)
",Computes the LSTM cell forward propagation for all the time steps.View aliases
tf.raw_ops.BoostedTreesAggregateStats,"tf.raw_ops.BoostedTreesAggregateStats(
    node_ids, gradients, hessians, feature, max_splits, num_buckets, name=None
)
",Aggregates the summary of accumulated stats for the batch.View aliases
tf.raw_ops.BoostedTreesBucketize,"tf.raw_ops.BoostedTreesBucketize(
    float_values, bucket_boundaries, name=None
)
",Bucketize each feature based on bucket boundaries.View aliases
tf.raw_ops.BoostedTreesCalculateBestFeatureSplit,"tf.raw_ops.BoostedTreesCalculateBestFeatureSplit(
    node_id_range,
    stats_summary,
    l1,
    l2,
    tree_complexity,
    min_node_weight,
    logits_dimension,
    split_type='inequality',
    name=None
)
",Calculates gains for each feature and returns the best possible split information for the feature.View aliases
tf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2,"tf.raw_ops.BoostedTreesCalculateBestFeatureSplitV2(
    node_id_range,
    stats_summaries_list,
    split_types,
    candidate_feature_ids,
    l1,
    l2,
    tree_complexity,
    min_node_weight,
    logits_dimension,
    name=None
)
","Calculates gains for each feature and returns the best possible split information for each node. However, if no split is found, then no split information is returned for that node.View aliases"
tf.raw_ops.BoostedTreesCalculateBestGainsPerFeature,"tf.raw_ops.BoostedTreesCalculateBestGainsPerFeature(
    node_id_range,
    stats_summary_list,
    l1,
    l2,
    tree_complexity,
    min_node_weight,
    max_splits,
    name=None
)
",Calculates gains for each feature and returns the best possible split information for the feature.View aliases
tf.raw_ops.BoostedTreesCenterBias,"tf.raw_ops.BoostedTreesCenterBias(
    tree_ensemble_handle, mean_gradients, mean_hessians, l1, l2, name=None
)
",Calculates the prior from the training data (the bias) and fills in the first node with the logits' prior. Returns a boolean indicating whether to continue centering.View aliases
tf.raw_ops.BoostedTreesCreateEnsemble,"tf.raw_ops.BoostedTreesCreateEnsemble(
    tree_ensemble_handle, stamp_token, tree_ensemble_serialized, name=None
)
",Creates a tree ensemble model and returns a handle to it.View aliases
tf.raw_ops.BoostedTreesCreateQuantileStreamResource,"tf.raw_ops.BoostedTreesCreateQuantileStreamResource(
    quantile_stream_resource_handle,
    epsilon,
    num_streams,
    max_elements=1099511627776,
    name=None
)
",Create the Resource for Quantile Streams.View aliases
tf.raw_ops.BoostedTreesDeserializeEnsemble,"tf.raw_ops.BoostedTreesDeserializeEnsemble(
    tree_ensemble_handle, stamp_token, tree_ensemble_serialized, name=None
)
",Deserializes a serialized tree ensemble config and replaces current treeView aliases
tf.raw_ops.BoostedTreesEnsembleResourceHandleOp,"tf.raw_ops.BoostedTreesEnsembleResourceHandleOp(
    container='', shared_name='', name=None
)
",Creates a handle to a BoostedTreesEnsembleResourceView aliases
tf.raw_ops.BoostedTreesExampleDebugOutputs,"tf.raw_ops.BoostedTreesExampleDebugOutputs(
    tree_ensemble_handle, bucketized_features, logits_dimension, name=None
)
",Debugging/model interpretability outputs for each example.View aliases
tf.raw_ops.BoostedTreesFlushQuantileSummaries,"tf.raw_ops.BoostedTreesFlushQuantileSummaries(
    quantile_stream_resource_handle, num_features, name=None
)
",Flush the quantile summaries from each quantile stream resource.View aliases
tf.raw_ops.BoostedTreesGetEnsembleStates,"tf.raw_ops.BoostedTreesGetEnsembleStates(
    tree_ensemble_handle, name=None
)
","Retrieves the tree ensemble resource stamp token, number of trees and growing statistics.View aliases"
tf.raw_ops.BoostedTreesMakeQuantileSummaries,"tf.raw_ops.BoostedTreesMakeQuantileSummaries(
    float_values, example_weights, epsilon, name=None
)
",Makes the summary of quantiles for the batch.View aliases
tf.raw_ops.BoostedTreesMakeStatsSummary,"tf.raw_ops.BoostedTreesMakeStatsSummary(
    node_ids,
    gradients,
    hessians,
    bucketized_features_list,
    max_splits,
    num_buckets,
    name=None
)
",Makes the summary of accumulated stats for the batch.View aliases
tf.raw_ops.BoostedTreesPredict,"tf.raw_ops.BoostedTreesPredict(
    tree_ensemble_handle, bucketized_features, logits_dimension, name=None
)
",Runs multiple additive regression ensemble predictors on input instances andView aliases
tf.raw_ops.BoostedTreesQuantileStreamResourceAddSummaries,"tf.raw_ops.BoostedTreesQuantileStreamResourceAddSummaries(
    quantile_stream_resource_handle, summaries, name=None
)
",Add the quantile summaries to each quantile stream resource.View aliases
tf.raw_ops.BoostedTreesQuantileStreamResourceDeserialize,"tf.raw_ops.BoostedTreesQuantileStreamResourceDeserialize(
    quantile_stream_resource_handle, bucket_boundaries, name=None
)
",Deserialize bucket boundaries and ready flag into current QuantileAccumulator.View aliases
tf.raw_ops.BoostedTreesQuantileStreamResourceFlush,"tf.raw_ops.BoostedTreesQuantileStreamResourceFlush(
    quantile_stream_resource_handle,
    num_buckets,
    generate_quantiles=False,
    name=None
)
",Flush the summaries for a quantile stream resource.View aliases
tf.raw_ops.BoostedTreesQuantileStreamResourceGetBucketBoundaries,"tf.raw_ops.BoostedTreesQuantileStreamResourceGetBucketBoundaries(
    quantile_stream_resource_handle, num_features, name=None
)
",Generate the bucket boundaries for each feature based on accumulated summaries.View aliases
tf.raw_ops.BoostedTreesQuantileStreamResourceHandleOp,"tf.raw_ops.BoostedTreesQuantileStreamResourceHandleOp(
    container='', shared_name='', name=None
)
",Creates a handle to a BoostedTreesQuantileStreamResource.View aliases
tf.raw_ops.BoostedTreesSerializeEnsemble,"tf.raw_ops.BoostedTreesSerializeEnsemble(
    tree_ensemble_handle, name=None
)
",Serializes the tree ensemble to a proto.View aliases
tf.raw_ops.BoostedTreesSparseAggregateStats,"tf.raw_ops.BoostedTreesSparseAggregateStats(
    node_ids,
    gradients,
    hessians,
    feature_indices,
    feature_values,
    feature_shape,
    max_splits,
    num_buckets,
    name=None
)
",Aggregates the summary of accumulated stats for the batch.View aliases
tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit,"tf.raw_ops.BoostedTreesSparseCalculateBestFeatureSplit(
    node_id_range,
    stats_summary_indices,
    stats_summary_values,
    stats_summary_shape,
    l1,
    l2,
    tree_complexity,
    min_node_weight,
    logits_dimension,
    split_type='inequality',
    name=None
)
",Calculates gains for each feature and returns the best possible split information for the feature.View aliases
tf.raw_ops.BoostedTreesTrainingPredict,"tf.raw_ops.BoostedTreesTrainingPredict(
    tree_ensemble_handle,
    cached_tree_ids,
    cached_node_ids,
    bucketized_features,
    logits_dimension,
    name=None
)
",Runs multiple additive regression ensemble predictors on input instances andView aliases
tf.raw_ops.BoostedTreesUpdateEnsemble,"tf.raw_ops.BoostedTreesUpdateEnsemble(
    tree_ensemble_handle,
    feature_ids,
    node_ids,
    gains,
    thresholds,
    left_node_contribs,
    right_node_contribs,
    max_depth,
    learning_rate,
    pruning_mode,
    name=None
)
",Updates the tree ensemble by either adding a layer to the last tree being grownView aliases
tf.raw_ops.BoostedTreesUpdateEnsembleV2,"tf.raw_ops.BoostedTreesUpdateEnsembleV2(
    tree_ensemble_handle,
    feature_ids,
    dimension_ids,
    node_ids,
    gains,
    thresholds,
    left_node_contribs,
    right_node_contribs,
    split_types,
    max_depth,
    learning_rate,
    pruning_mode,
    logits_dimension=1,
    name=None
)
",Updates the tree ensemble by adding a layer to the last tree being grownView aliases
tf.raw_ops.BroadcastArgs,"tf.raw_ops.BroadcastArgs(
    s0, s1, name=None
)
",Return the shape of s0 op s1 with broadcast.View aliases
tf.raw_ops.BroadcastGradientArgs,"tf.raw_ops.BroadcastGradientArgs(
    s0, s1, name=None
)
",Return the reduction indices for computing gradients of s0 op s1 with broadcast.View aliases
tf.raw_ops.BroadcastTo,"tf.raw_ops.BroadcastTo(
    input, shape, name=None
)
",Broadcast an array for a compatible shape.View aliases
tf.raw_ops.Bucketize,"tf.raw_ops.Bucketize(
    input, boundaries, name=None
)
",Bucketizes 'input' based on 'boundaries'.View aliases
tf.raw_ops.BytesProducedStatsDataset,"tf.raw_ops.BytesProducedStatsDataset(
    input_dataset, tag, output_types, output_shapes, name=None
)
",Records the bytes size of each element of input_dataset in a StatsAggregator.View aliases
tf.raw_ops.CSRSparseMatrixComponents,"tf.raw_ops.CSRSparseMatrixComponents(
    csr_sparse_matrix, index, type, name=None
)
",Reads out the CSR components at batch index.View aliases
tf.raw_ops.CSRSparseMatrixToDense,"tf.raw_ops.CSRSparseMatrixToDense(
    sparse_input, type, name=None
)
",Convert a (possibly batched) CSRSparseMatrix to dense.View aliases
tf.raw_ops.CSRSparseMatrixToSparseTensor,"tf.raw_ops.CSRSparseMatrixToSparseTensor(
    sparse_matrix, type, name=None
)
",Converts a (possibly batched) CSRSparesMatrix to a SparseTensor.View aliases
tf.raw_ops.CSVDataset,"tf.raw_ops.CSVDataset(
    filenames,
    compression_type,
    buffer_size,
    header,
    field_delim,
    use_quote_delim,
    na_value,
    select_cols,
    record_defaults,
    output_shapes,
    name=None
)
",View aliases
tf.raw_ops.CSVDatasetV2,"tf.raw_ops.CSVDatasetV2(
    filenames,
    compression_type,
    buffer_size,
    header,
    field_delim,
    use_quote_delim,
    na_value,
    select_cols,
    record_defaults,
    exclude_cols,
    output_shapes,
    name=None
)
",View aliases
tf.raw_ops.CTCBeamSearchDecoder,"tf.raw_ops.CTCBeamSearchDecoder(
    inputs,
    sequence_length,
    beam_width,
    top_paths,
    merge_repeated=True,
    name=None
)
",Performs beam search decoding on the logits given in input.View aliases
tf.raw_ops.CTCGreedyDecoder,"tf.raw_ops.CTCGreedyDecoder(
    inputs, sequence_length, merge_repeated=False, blank_index=-1, name=None
)
",Performs greedy decoding on the logits given in inputs.View aliases
tf.raw_ops.CTCLoss,"tf.raw_ops.CTCLoss(
    inputs,
    labels_indices,
    labels_values,
    sequence_length,
    preprocess_collapse_repeated=False,
    ctc_merge_repeated=True,
    ignore_longer_outputs_than_inputs=False,
    name=None
)
",Calculates the CTC Loss (log probability) for each batch entry.  Also calculatesView aliases
tf.raw_ops.CTCLossV2,"tf.raw_ops.CTCLossV2(
    inputs,
    labels_indices,
    labels_values,
    sequence_length,
    preprocess_collapse_repeated=False,
    ctc_merge_repeated=True,
    ignore_longer_outputs_than_inputs=False,
    name=None
)
",Calculates the CTC Loss (log probability) for each batch entry.  Also calculatesView aliases
tf.raw_ops.CacheDataset,"tf.raw_ops.CacheDataset(
    input_dataset,
    filename,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that caches elements from input_dataset.View aliases
tf.raw_ops.CacheDatasetV2,"tf.raw_ops.CacheDatasetV2(
    input_dataset,
    filename,
    cache,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",View aliases
tf.raw_ops.Case,"tf.raw_ops.Case(
    branch_index, input, Tout, branches, output_shapes=[], name=None
)
",An n-way switch statement which calls a single branch function.View aliases
tf.raw_ops.Cast,"tf.raw_ops.Cast(
    x, DstT, Truncate=False, name=None
)
",Cast x of type SrcT to y of DstT.View aliases
tf.raw_ops.Ceil,"tf.raw_ops.Ceil(
    x, name=None
)
",Returns element-wise smallest integer not less than x.View aliases
tf.raw_ops.CheckNumerics,"tf.raw_ops.CheckNumerics(
    tensor, message, name=None
)
",Checks a tensor for NaN and Inf values.View aliases
tf.raw_ops.CheckNumericsV2,"tf.raw_ops.CheckNumericsV2(
    tensor, message, name=None
)
","Checks a tensor for NaN, -Inf and +Inf values.View aliases"
tf.raw_ops.Cholesky,"tf.raw_ops.Cholesky(
    input, name=None
)
",Computes the Cholesky decomposition of one or more square matrices.View aliases
tf.raw_ops.CholeskyGrad,"tf.raw_ops.CholeskyGrad(
    l, grad, name=None
)
",Computes the reverse mode backpropagated gradient of the Cholesky algorithm.View aliases
tf.raw_ops.ChooseFastestBranchDataset,"tf.raw_ops.ChooseFastestBranchDataset(
    input_dataset,
    ratio_numerator,
    ratio_denominator,
    other_arguments,
    num_elements_per_branch,
    branches,
    other_arguments_lengths,
    output_types,
    output_shapes,
    name=None
)
",View aliases
tf.raw_ops.ChooseFastestDataset,"tf.raw_ops.ChooseFastestDataset(
    input_datasets, num_experiments, output_types, output_shapes, name=None
)
",View aliases
tf.raw_ops.ClipByValue,"tf.raw_ops.ClipByValue(
    t, clip_value_min, clip_value_max, name=None
)
",Clips tensor values to a specified min and max.View aliases
tf.raw_ops.CloseSummaryWriter,"tf.raw_ops.CloseSummaryWriter(
    writer, name=None
)
",View aliases
tf.raw_ops.CollectiveAllToAllV3,"tf.raw_ops.CollectiveAllToAllV3(
    input, communicator, group_assignment, timeout_seconds=0, name=None
)
",Mutually exchanges multiple tensors of identical type and shape.View aliases
tf.raw_ops.CollectiveAssignGroupV2,"tf.raw_ops.CollectiveAssignGroupV2(
    group_assignment, device_index, base_key, name=None
)
",Assign group keys based on group assignment.View aliases
tf.raw_ops.CollectiveBcastRecv,"tf.raw_ops.CollectiveBcastRecv(
    T,
    group_size,
    group_key,
    instance_key,
    shape,
    communication_hint='auto',
    timeout_seconds=0,
    name=None
)
",Receives a tensor value broadcast from another device.View aliases
tf.raw_ops.CollectiveBcastRecvV2,"tf.raw_ops.CollectiveBcastRecvV2(
    group_size,
    group_key,
    instance_key,
    shape,
    T,
    communication_hint='auto',
    timeout_seconds=0,
    name=None
)
",Receives a tensor value broadcast from another device.View aliases
tf.raw_ops.CollectiveBcastSend,"tf.raw_ops.CollectiveBcastSend(
    input,
    group_size,
    group_key,
    instance_key,
    shape,
    communication_hint='auto',
    timeout_seconds=0,
    name=None
)
",Broadcasts a tensor value to one or more other devices.View aliases
tf.raw_ops.CollectiveBcastSendV2,"tf.raw_ops.CollectiveBcastSendV2(
    input,
    group_size,
    group_key,
    instance_key,
    communication_hint='auto',
    timeout_seconds=0,
    name=None
)
",Broadcasts a tensor value to one or more other devices.View aliases
tf.raw_ops.CollectiveGather,"tf.raw_ops.CollectiveGather(
    input,
    group_size,
    group_key,
    instance_key,
    shape,
    communication_hint='auto',
    timeout_seconds=0,
    name=None
)
",Mutually accumulates multiple tensors of identical type and shape.View aliases
tf.raw_ops.CollectiveGatherV2,"tf.raw_ops.CollectiveGatherV2(
    input,
    group_size,
    group_key,
    instance_key,
    ordering_token,
    communication_hint='auto',
    timeout_seconds=0,
    name=None
)
",Mutually accumulates multiple tensors of identical type and shape.View aliases
tf.raw_ops.CollectiveInitializeCommunicator,"tf.raw_ops.CollectiveInitializeCommunicator(
    group_key,
    rank,
    group_size,
    communication_hint='auto',
    timeout_seconds=0,
    name=None
)
",Initializes a group for collective operations.View aliases
tf.raw_ops.CollectivePermute,"tf.raw_ops.CollectivePermute(
    input, source_target_pairs, name=None
)
",An Op to permute tensors across replicated TPU instances.View aliases
tf.raw_ops.CollectiveReduce,"tf.raw_ops.CollectiveReduce(
    input,
    group_size,
    group_key,
    instance_key,
    merge_op,
    final_op,
    subdiv_offsets,
    wait_for=[],
    communication_hint='auto',
    timeout_seconds=0,
    name=None
)
",Mutually reduces multiple tensors of identical type and shape.View aliases
tf.raw_ops.CollectiveReduceV2,"tf.raw_ops.CollectiveReduceV2(
    input,
    group_size,
    group_key,
    instance_key,
    ordering_token,
    merge_op,
    final_op,
    communication_hint='auto',
    timeout_seconds=0,
    max_subdivs_per_device=-1,
    name=None
)
",Mutually reduces multiple tensors of identical type and shape.View aliases
tf.raw_ops.CollectiveReduceV3,"tf.raw_ops.CollectiveReduceV3(
    input,
    communicator,
    group_assignment,
    reduction,
    timeout_seconds=0,
    name=None
)
",Mutually reduces multiple tensors of identical type and shape.View aliases
tf.raw_ops.CombinedNonMaxSuppression,"tf.raw_ops.CombinedNonMaxSuppression(
    boxes,
    scores,
    max_output_size_per_class,
    max_total_size,
    iou_threshold,
    score_threshold,
    pad_per_class=False,
    clip_boxes=True,
    name=None
)
","Greedily selects a subset of bounding boxes in descending order of score,View aliases"
tf.raw_ops.Complex,"tf.raw_ops.Complex(
    real,
    imag,
    Tout=tf.dtypes.complex64,
    name=None
)
",Converts two real numbers to a complex number.View aliases
tf.raw_ops.ComplexAbs,"tf.raw_ops.ComplexAbs(
    x,
    Tout=tf.dtypes.float32,
    name=None
)
",Computes the complex absolute value of a tensor.View aliases
tf.raw_ops.CompositeTensorVariantFromComponents,"tf.raw_ops.CompositeTensorVariantFromComponents(
    components, metadata, name=None
)
",Encodes an ExtensionType value into a variant scalar Tensor.View aliases
tf.raw_ops.CompositeTensorVariantToComponents,"tf.raw_ops.CompositeTensorVariantToComponents(
    encoded, metadata, Tcomponents, name=None
)
",Decodes a variant scalar Tensor into an ExtensionType value.View aliases
tf.raw_ops.CompressElement,"tf.raw_ops.CompressElement(
    components, name=None
)
",Compresses a dataset element.View aliases
tf.raw_ops.ComputeAccidentalHits,"tf.raw_ops.ComputeAccidentalHits(
    true_classes, sampled_candidates, num_true, seed=0, seed2=0, name=None
)
",Computes the ids of the positions in sampled_candidates that match true_labels.View aliases
tf.raw_ops.ComputeBatchSize,"tf.raw_ops.ComputeBatchSize(
    input_dataset, name=None
)
",Computes the static batch size of a dataset sans partial batches.View aliases
tf.raw_ops.Concat,"tf.raw_ops.Concat(
    concat_dim, values, name=None
)
",Concatenates tensors along one dimension.View aliases
tf.raw_ops.ConcatOffset,"tf.raw_ops.ConcatOffset(
    concat_dim, shape, name=None
)
",Computes offsets of concat inputs within its output.View aliases
tf.raw_ops.ConcatV2,"tf.raw_ops.ConcatV2(
    values, axis, name=None
)
",Concatenates tensors along one dimension.View aliases
tf.raw_ops.ConcatenateDataset,"tf.raw_ops.ConcatenateDataset(
    input_dataset,
    another_dataset,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that concatenates input_dataset with another_dataset.View aliases
tf.raw_ops.ConditionalAccumulator,"tf.raw_ops.ConditionalAccumulator(
    dtype,
    shape,
    container='',
    shared_name='',
    reduction_type='MEAN',
    name=None
)
",A conditional accumulator for aggregating gradients.View aliases
tf.raw_ops.ConfigureDistributedTPU,"tf.raw_ops.ConfigureDistributedTPU(
    embedding_config='',
    tpu_embedding_config='',
    is_global_init=False,
    enable_whole_mesh_compilations=False,
    compilation_failure_closes_chips=True,
    tpu_cancellation_closes_chips=0,
    name=None
)
",Sets up the centralized structures for a distributed TPU system.View aliases
tf.raw_ops.ConfigureTPUEmbedding,"tf.raw_ops.ConfigureTPUEmbedding(
    config, name=None
)
",Sets up TPUEmbedding in a distributed TPU system.View aliases
tf.raw_ops.Conj,"tf.raw_ops.Conj(
    input, name=None
)
",Returns the complex conjugate of a complex number.View aliases
tf.raw_ops.ConjugateTranspose,"tf.raw_ops.ConjugateTranspose(
    x, perm, name=None
)
",Shuffle dimensions of x according to a permutation and conjugate the result.View aliases
tf.raw_ops.Const,"tf.raw_ops.Const(
    value, dtype, name=None
)
",Returns a constant tensor.View aliases
tf.raw_ops.ConsumeMutexLock,"tf.raw_ops.ConsumeMutexLock(
    mutex_lock, name=None
)
",This op consumes a lock created by MutexLock.View aliases
tf.raw_ops.ControlTrigger,"tf.raw_ops.ControlTrigger(
    name=None
)
",Does nothing. Serves as a control trigger for scheduling.View aliases
tf.raw_ops.Conv2D,"tf.raw_ops.Conv2D(
    input,
    filter,
    strides,
    padding,
    use_cudnn_on_gpu=True,
    explicit_paddings=[],
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes a 2-D convolution given 4-D input and filter tensors.View aliases
tf.raw_ops.Conv2DBackpropFilter,"tf.raw_ops.Conv2DBackpropFilter(
    input,
    filter_sizes,
    out_backprop,
    strides,
    padding,
    use_cudnn_on_gpu=True,
    explicit_paddings=[],
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes the gradients of convolution with respect to the filter.View aliases
tf.raw_ops.Conv2DBackpropInput,"tf.raw_ops.Conv2DBackpropInput(
    input_sizes,
    filter,
    out_backprop,
    strides,
    padding,
    use_cudnn_on_gpu=True,
    explicit_paddings=[],
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes the gradients of convolution with respect to the input.View aliases
tf.raw_ops.Conv3D,"tf.raw_ops.Conv3D(
    input,
    filter,
    strides,
    padding,
    data_format='NDHWC',
    dilations=[1, 1, 1, 1, 1],
    name=None
)
",Computes a 3-D convolution given 5-D input and filter tensors.View aliases
tf.raw_ops.Conv3DBackpropFilter,"tf.raw_ops.Conv3DBackpropFilter(
    input,
    filter,
    out_backprop,
    strides,
    padding,
    dilations=[1, 1, 1, 1, 1],
    name=None
)
",Computes the gradients of 3-D convolution with respect to the filter.View aliases
tf.raw_ops.Conv3DBackpropFilterV2,"tf.raw_ops.Conv3DBackpropFilterV2(
    input,
    filter_sizes,
    out_backprop,
    strides,
    padding,
    data_format='NDHWC',
    dilations=[1, 1, 1, 1, 1],
    name=None
)
",Computes the gradients of 3-D convolution with respect to the filter.View aliases
tf.raw_ops.Conv3DBackpropInput,"tf.raw_ops.Conv3DBackpropInput(
    input,
    filter,
    out_backprop,
    strides,
    padding,
    dilations=[1, 1, 1, 1, 1],
    name=None
)
",Computes the gradients of 3-D convolution with respect to the input.View aliases
tf.raw_ops.Conv3DBackpropInputV2,"tf.raw_ops.Conv3DBackpropInputV2(
    input_sizes,
    filter,
    out_backprop,
    strides,
    padding,
    data_format='NDHWC',
    dilations=[1, 1, 1, 1, 1],
    name=None
)
",Computes the gradients of 3-D convolution with respect to the input.View aliases
tf.raw_ops.Copy,"tf.raw_ops.Copy(
    input, tensor_name='', debug_ops_spec=[], name=None
)
",Copy a tensor from CPU-to-CPU or GPU-to-GPU.View aliases
tf.raw_ops.CopyHost,"tf.raw_ops.CopyHost(
    input, tensor_name='', debug_ops_spec=[], name=None
)
",Copy a tensor to host.View aliases
tf.raw_ops.Cos,"tf.raw_ops.Cos(
    x, name=None
)
",Computes cos of x element-wise.View aliases
tf.raw_ops.Cosh,"tf.raw_ops.Cosh(
    x, name=None
)
",Computes hyperbolic cosine of x element-wise.View aliases
tf.raw_ops.CountUpTo,"tf.raw_ops.CountUpTo(
    ref, limit, name=None
)
",Increments 'ref' until it reaches 'limit'.View aliases
tf.raw_ops.CreateSummaryDbWriter,"tf.raw_ops.CreateSummaryDbWriter(
    writer, db_uri, experiment_name, run_name, user_name, name=None
)
",View aliases
tf.raw_ops.CreateSummaryFileWriter,"tf.raw_ops.CreateSummaryFileWriter(
    writer, logdir, max_queue, flush_millis, filename_suffix, name=None
)
",View aliases
tf.raw_ops.CropAndResize,"tf.raw_ops.CropAndResize(
    image,
    boxes,
    box_ind,
    crop_size,
    method='bilinear',
    extrapolation_value=0,
    name=None
)
",Extracts crops from the input image tensor and resizes them.View aliases
tf.raw_ops.CropAndResizeGradBoxes,"tf.raw_ops.CropAndResizeGradBoxes(
    grads, image, boxes, box_ind, method='bilinear', name=None
)
",Computes the gradient of the crop_and_resize op wrt the input boxes tensor.View aliases
tf.raw_ops.CropAndResizeGradImage,"tf.raw_ops.CropAndResizeGradImage(
    grads,
    boxes,
    box_ind,
    image_size,
    T,
    method='bilinear',
    name=None
)
",Computes the gradient of the crop_and_resize op wrt the input image tensor.View aliases
tf.raw_ops.Cross,"tf.raw_ops.Cross(
    a, b, name=None
)
",Compute the pairwise cross product.View aliases
tf.raw_ops.CrossReplicaSum,"tf.raw_ops.CrossReplicaSum(
    input, group_assignment, name=None
)
",An Op to sum inputs across replicated TPU instances.View aliases
tf.raw_ops.CudnnRNN,"tf.raw_ops.CudnnRNN(
    input,
    input_h,
    input_c,
    params,
    rnn_mode='lstm',
    input_mode='linear_input',
    direction='unidirectional',
    dropout=0,
    seed=0,
    seed2=0,
    is_training=True,
    name=None
)
",A RNN backed by cuDNN.View aliases
tf.raw_ops.CudnnRNNBackprop,"tf.raw_ops.CudnnRNNBackprop(
    input,
    input_h,
    input_c,
    params,
    output,
    output_h,
    output_c,
    output_backprop,
    output_h_backprop,
    output_c_backprop,
    reserve_space,
    rnn_mode='lstm',
    input_mode='linear_input',
    direction='unidirectional',
    dropout=0,
    seed=0,
    seed2=0,
    name=None
)
",Backprop step of CudnnRNN.View aliases
tf.raw_ops.CudnnRNNBackpropV2,"tf.raw_ops.CudnnRNNBackpropV2(
    input,
    input_h,
    input_c,
    params,
    output,
    output_h,
    output_c,
    output_backprop,
    output_h_backprop,
    output_c_backprop,
    reserve_space,
    host_reserved,
    rnn_mode='lstm',
    input_mode='linear_input',
    direction='unidirectional',
    dropout=0,
    seed=0,
    seed2=0,
    name=None
)
",Backprop step of CudnnRNN.View aliases
tf.raw_ops.CudnnRNNBackpropV3,"tf.raw_ops.CudnnRNNBackpropV3(
    input,
    input_h,
    input_c,
    params,
    sequence_lengths,
    output,
    output_h,
    output_c,
    output_backprop,
    output_h_backprop,
    output_c_backprop,
    reserve_space,
    host_reserved,
    rnn_mode='lstm',
    input_mode='linear_input',
    direction='unidirectional',
    dropout=0,
    seed=0,
    seed2=0,
    num_proj=0,
    time_major=True,
    name=None
)
",Backprop step of CudnnRNNV3.View aliases
tf.raw_ops.CudnnRNNCanonicalToParams,"tf.raw_ops.CudnnRNNCanonicalToParams(
    num_layers,
    num_units,
    input_size,
    weights,
    biases,
    rnn_mode='lstm',
    input_mode='linear_input',
    direction='unidirectional',
    dropout=0,
    seed=0,
    seed2=0,
    name=None
)
",Converts CudnnRNN params from canonical form to usable form.View aliases
tf.raw_ops.CudnnRNNCanonicalToParamsV2,"tf.raw_ops.CudnnRNNCanonicalToParamsV2(
    num_layers,
    num_units,
    input_size,
    weights,
    biases,
    rnn_mode='lstm',
    input_mode='linear_input',
    direction='unidirectional',
    dropout=0,
    seed=0,
    seed2=0,
    num_proj=0,
    name=None
)
",Converts CudnnRNN params from canonical form to usable form. It supports the projection in LSTM.View aliases
tf.raw_ops.CudnnRNNParamsSize,"tf.raw_ops.CudnnRNNParamsSize(
    num_layers,
    num_units,
    input_size,
    T,
    S,
    rnn_mode='lstm',
    input_mode='linear_input',
    direction='unidirectional',
    dropout=0,
    seed=0,
    seed2=0,
    num_proj=0,
    name=None
)
",Computes size of weights that can be used by a Cudnn RNN model.View aliases
tf.raw_ops.CudnnRNNParamsToCanonical,"tf.raw_ops.CudnnRNNParamsToCanonical(
    num_layers,
    num_units,
    input_size,
    params,
    num_params,
    rnn_mode='lstm',
    input_mode='linear_input',
    direction='unidirectional',
    dropout=0,
    seed=0,
    seed2=0,
    name=None
)
",Retrieves CudnnRNN params in canonical form.View aliases
tf.raw_ops.CudnnRNNParamsToCanonicalV2,"tf.raw_ops.CudnnRNNParamsToCanonicalV2(
    num_layers,
    num_units,
    input_size,
    params,
    num_params_weights,
    num_params_biases,
    rnn_mode='lstm',
    input_mode='linear_input',
    direction='unidirectional',
    dropout=0,
    seed=0,
    seed2=0,
    num_proj=0,
    name=None
)
",Retrieves CudnnRNN params in canonical form. It supports the projection in LSTM.View aliases
tf.raw_ops.CudnnRNNV2,"tf.raw_ops.CudnnRNNV2(
    input,
    input_h,
    input_c,
    params,
    rnn_mode='lstm',
    input_mode='linear_input',
    direction='unidirectional',
    dropout=0,
    seed=0,
    seed2=0,
    is_training=True,
    name=None
)
",A RNN backed by cuDNN.View aliases
tf.raw_ops.CudnnRNNV3,"tf.raw_ops.CudnnRNNV3(
    input,
    input_h,
    input_c,
    params,
    sequence_lengths,
    rnn_mode='lstm',
    input_mode='linear_input',
    direction='unidirectional',
    dropout=0,
    seed=0,
    seed2=0,
    num_proj=0,
    is_training=True,
    time_major=True,
    name=None
)
",A RNN backed by cuDNN.View aliases
tf.raw_ops.Cumprod,"tf.raw_ops.Cumprod(
    x, axis, exclusive=False, reverse=False, name=None
)
",Compute the cumulative product of the tensor x along axis.View aliases
tf.raw_ops.Cumsum,"tf.raw_ops.Cumsum(
    x, axis, exclusive=False, reverse=False, name=None
)
",Compute the cumulative sum of the tensor x along axis.View aliases
tf.raw_ops.CumulativeLogsumexp,"tf.raw_ops.CumulativeLogsumexp(
    x, axis, exclusive=False, reverse=False, name=None
)
",Compute the cumulative product of the tensor x along axis.View aliases
tf.raw_ops.DataFormatDimMap,"tf.raw_ops.DataFormatDimMap(
    x, src_format='NHWC', dst_format='NCHW', name=None
)
",Returns the dimension index in the destination data format given the one inView aliases
tf.raw_ops.DataFormatVecPermute,"tf.raw_ops.DataFormatVecPermute(
    x, src_format='NHWC', dst_format='NCHW', name=None
)
",Permute input tensor from src_format to dst_format.View aliases
tf.raw_ops.DataServiceDataset,"tf.raw_ops.DataServiceDataset(
    dataset_id,
    processing_mode,
    address,
    protocol,
    job_name,
    max_outstanding_requests,
    iteration_counter,
    output_types,
    output_shapes,
    task_refresh_interval_hint_ms=-1,
    data_transfer_protocol='',
    target_workers='AUTO',
    cross_trainer_cache_options='',
    name=None
)
",Creates a dataset that reads data from the tf.data service.View aliases
tf.raw_ops.DataServiceDatasetV2,"tf.raw_ops.DataServiceDatasetV2(
    dataset_id,
    processing_mode,
    address,
    protocol,
    job_name,
    consumer_index,
    num_consumers,
    max_outstanding_requests,
    iteration_counter,
    output_types,
    output_shapes,
    task_refresh_interval_hint_ms=-1,
    data_transfer_protocol='',
    target_workers='AUTO',
    cross_trainer_cache_options='',
    name=None
)
",Creates a dataset that reads data from the tf.data service.View aliases
tf.raw_ops.DataServiceDatasetV3,"tf.raw_ops.DataServiceDatasetV3(
    dataset_id,
    processing_mode,
    address,
    protocol,
    job_name,
    consumer_index,
    num_consumers,
    max_outstanding_requests,
    iteration_counter,
    output_types,
    output_shapes,
    uncompress_fn,
    task_refresh_interval_hint_ms=-1,
    data_transfer_protocol='',
    target_workers='AUTO',
    uncompress=False,
    cross_trainer_cache_options='',
    name=None
)
",Creates a dataset that reads data from the tf.data service.View aliases
tf.raw_ops.DataServiceDatasetV4,"tf.raw_ops.DataServiceDatasetV4(
    dataset_id,
    processing_mode,
    address,
    protocol,
    job_name,
    consumer_index,
    num_consumers,
    max_outstanding_requests,
    iteration_counter,
    output_types,
    output_shapes,
    uncompress_fn,
    task_refresh_interval_hint_ms=-1,
    data_transfer_protocol='',
    target_workers='AUTO',
    uncompress=False,
    cross_trainer_cache_options='',
    name=None
)
",Creates a dataset that reads data from the tf.data service.View aliases
tf.raw_ops.DatasetCardinality,"tf.raw_ops.DatasetCardinality(
    input_dataset, name=None
)
",Returns the cardinality of input_dataset.View aliases
tf.raw_ops.DatasetFromGraph,"tf.raw_ops.DatasetFromGraph(
    graph_def, name=None
)
",Creates a dataset from the given graph_def.View aliases
tf.raw_ops.DatasetToGraph,"tf.raw_ops.DatasetToGraph(
    input_dataset,
    stateful_whitelist=[],
    allow_stateful=False,
    strip_device_assignment=False,
    name=None
)
",Returns a serialized GraphDef representing input_dataset.View aliases
tf.raw_ops.DatasetToGraphV2,"tf.raw_ops.DatasetToGraphV2(
    input_dataset,
    external_state_policy=0,
    strip_device_assignment=False,
    name=None
)
",Returns a serialized GraphDef representing input_dataset.View aliases
tf.raw_ops.DatasetToSingleElement,"tf.raw_ops.DatasetToSingleElement(
    dataset, output_types, output_shapes, metadata='', name=None
)
",Outputs the single element from the given dataset.View aliases
tf.raw_ops.DatasetToTFRecord,"tf.raw_ops.DatasetToTFRecord(
    input_dataset, filename, compression_type, name=None
)
",Writes the given dataset to the given file using the TFRecord format.View aliases
tf.raw_ops.Dawsn,"tf.raw_ops.Dawsn(
    x, name=None
)
",View aliases
tf.raw_ops.DebugGradientIdentity,"tf.raw_ops.DebugGradientIdentity(
    input, name=None
)
",Identity op for gradient debugging.View aliases
tf.raw_ops.DebugGradientRefIdentity,"tf.raw_ops.DebugGradientRefIdentity(
    input, name=None
)
",Identity op for gradient debugging.View aliases
tf.raw_ops.DebugIdentity,"tf.raw_ops.DebugIdentity(
    input,
    device_name='',
    tensor_name='',
    debug_urls=[],
    gated_grpc=False,
    name=None
)
",Provides an identity mapping of the non-Ref type input tensor for debugging.View aliases
tf.raw_ops.DebugIdentityV2,"tf.raw_ops.DebugIdentityV2(
    input,
    tfdbg_context_id='',
    op_name='',
    output_slot=-1,
    tensor_debug_mode=-1,
    debug_urls=[],
    circular_buffer_size=1000,
    tfdbg_run_id='',
    name=None
)
",Debug Identity V2 Op.View aliases
tf.raw_ops.DebugNanCount,"tf.raw_ops.DebugNanCount(
    input,
    device_name='',
    tensor_name='',
    debug_urls=[],
    gated_grpc=False,
    name=None
)
",Debug NaN Value Counter Op.View aliases
tf.raw_ops.DebugNumericSummary,"tf.raw_ops.DebugNumericSummary(
    input,
    device_name='',
    tensor_name='',
    debug_urls=[],
    lower_bound=float('-inf'),
    upper_bound=float('inf'),
    mute_if_healthy=False,
    gated_grpc=False,
    name=None
)
",Debug Numeric Summary Op.View aliases
tf.raw_ops.DebugNumericSummaryV2,"tf.raw_ops.DebugNumericSummaryV2(
    input,
    output_dtype=tf.dtypes.float32,
    tensor_debug_mode=-1,
    tensor_id=-1,
    name=None
)
",Debug Numeric Summary V2 Op.View aliases
tf.raw_ops.DecodeAndCropJpeg,"tf.raw_ops.DecodeAndCropJpeg(
    contents,
    crop_window,
    channels=0,
    ratio=1,
    fancy_upscaling=True,
    try_recover_truncated=False,
    acceptable_fraction=1,
    dct_method='',
    name=None
)
",Decode and Crop a JPEG-encoded image to a uint8 tensor.View aliases
tf.raw_ops.DecodeBase64,"tf.raw_ops.DecodeBase64(
    input, name=None
)
",Decode web-safe base64-encoded strings.View aliases
tf.raw_ops.DecodeBmp,"tf.raw_ops.DecodeBmp(
    contents, channels=0, name=None
)
",Decode the first frame of a BMP-encoded image to a uint8 tensor.View aliases
tf.raw_ops.DecodeCSV,"tf.raw_ops.DecodeCSV(
    records,
    record_defaults,
    field_delim=',',
    use_quote_delim=True,
    na_value='',
    select_cols=[],
    name=None
)
",Convert CSV records to tensors. Each column maps to one tensor.View aliases
tf.raw_ops.DecodeCompressed,"tf.raw_ops.DecodeCompressed(
    bytes, compression_type='', name=None
)
",Decompress strings.View aliases
tf.raw_ops.DecodeGif,"tf.raw_ops.DecodeGif(
    contents, name=None
)
",Decode the frame(s) of a GIF-encoded image to a uint8 tensor.View aliases
tf.raw_ops.DecodeImage,"tf.raw_ops.DecodeImage(
    contents,
    channels=0,
    dtype=tf.dtypes.uint8,
    expand_animations=True,
    name=None
)
","Function for decode_bmp, decode_gif, decode_jpeg, and decode_png.View aliases"
tf.raw_ops.DecodeJSONExample,"tf.raw_ops.DecodeJSONExample(
    json_examples, name=None
)
",Convert JSON-encoded Example records to binary protocol buffer strings.View aliases
tf.raw_ops.DecodeJpeg,"tf.raw_ops.DecodeJpeg(
    contents,
    channels=0,
    ratio=1,
    fancy_upscaling=True,
    try_recover_truncated=False,
    acceptable_fraction=1,
    dct_method='',
    name=None
)
",Decode a JPEG-encoded image to a uint8 tensor.View aliases
tf.raw_ops.DecodePaddedRaw,"tf.raw_ops.DecodePaddedRaw(
    input_bytes, fixed_length, out_type, little_endian=True, name=None
)
",Reinterpret the bytes of a string as a vector of numbers.View aliases
tf.raw_ops.DecodePng,"tf.raw_ops.DecodePng(
    contents,
    channels=0,
    dtype=tf.dtypes.uint8,
    name=None
)
",Decode a PNG-encoded image to a uint8 or uint16 tensor.View aliases
tf.raw_ops.DecodeProtoV2,"tf.raw_ops.DecodeProtoV2(
    bytes,
    message_type,
    field_names,
    output_types,
    descriptor_source='local://',
    message_format='binary',
    sanitize=False,
    name=None
)
",The op extracts fields from a serialized protocol buffers message into tensors.View aliases
tf.raw_ops.DecodeRaw,"tf.raw_ops.DecodeRaw(
    bytes, out_type, little_endian=True, name=None
)
",Reinterpret the bytes of a string as a vector of numbers.View aliases
tf.raw_ops.DecodeWav,"tf.raw_ops.DecodeWav(
    contents, desired_channels=-1, desired_samples=-1, name=None
)
",Decode a 16-bit PCM WAV file to a float tensor.View aliases
tf.raw_ops.DeepCopy,"tf.raw_ops.DeepCopy(
    x, name=None
)
",Makes a copy of x.View aliases
tf.raw_ops.DeleteIterator,"tf.raw_ops.DeleteIterator(
    handle, deleter, name=None
)
",A container for an iterator resource.View aliases
tf.raw_ops.DeleteMemoryCache,"tf.raw_ops.DeleteMemoryCache(
    handle, deleter, name=None
)
",View aliases
tf.raw_ops.DeleteMultiDeviceIterator,"tf.raw_ops.DeleteMultiDeviceIterator(
    multi_device_iterator, iterators, deleter, name=None
)
",A container for an iterator resource.View aliases
tf.raw_ops.DeleteRandomSeedGenerator,"tf.raw_ops.DeleteRandomSeedGenerator(
    handle, deleter, name=None
)
",View aliases
tf.raw_ops.DeleteSeedGenerator,"tf.raw_ops.DeleteSeedGenerator(
    handle, deleter, name=None
)
",View aliases
tf.raw_ops.DeleteSessionTensor,"tf.raw_ops.DeleteSessionTensor(
    handle, name=None
)
",Delete the tensor specified by its handle in the session.View aliases
tf.raw_ops.DenseBincount,"tf.raw_ops.DenseBincount(
    input, size, weights, binary_output=False, name=None
)
",Counts the number of occurrences of each value in an integer array.View aliases
tf.raw_ops.DenseCountSparseOutput,"tf.raw_ops.DenseCountSparseOutput(
    values, weights, binary_output, minlength=-1, maxlength=-1, name=None
)
",Performs sparse-output bin counting for a tf.tensor input.View aliases
tf.raw_ops.DenseToCSRSparseMatrix,"tf.raw_ops.DenseToCSRSparseMatrix(
    dense_input, indices, name=None
)
",Converts a dense tensor to a (possibly batched) CSRSparseMatrix.View aliases
tf.raw_ops.DenseToDenseSetOperation,"tf.raw_ops.DenseToDenseSetOperation(
    set1, set2, set_operation, validate_indices=True, name=None
)
",Applies set operation along last dimension of 2 Tensor inputs.View aliases
tf.raw_ops.DenseToSparseBatchDataset,"tf.raw_ops.DenseToSparseBatchDataset(
    input_dataset,
    batch_size,
    row_shape,
    output_types,
    output_shapes,
    name=None
)
",Creates a dataset that batches input elements into a SparseTensor.View aliases
tf.raw_ops.DenseToSparseSetOperation,"tf.raw_ops.DenseToSparseSetOperation(
    set1,
    set2_indices,
    set2_values,
    set2_shape,
    set_operation,
    validate_indices=True,
    name=None
)
",Applies set operation along last dimension of Tensor and SparseTensor.View aliases
tf.raw_ops.DepthToSpace,"tf.raw_ops.DepthToSpace(
    input, block_size, data_format='NHWC', name=None
)
",DepthToSpace for tensors of type T.View aliases
tf.raw_ops.DepthwiseConv2dNative,"tf.raw_ops.DepthwiseConv2dNative(
    input,
    filter,
    strides,
    padding,
    explicit_paddings=[],
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes a 2-D depthwise convolution given 4-D input and filter tensors.View aliases
tf.raw_ops.DepthwiseConv2dNativeBackpropFilter,"tf.raw_ops.DepthwiseConv2dNativeBackpropFilter(
    input,
    filter_sizes,
    out_backprop,
    strides,
    padding,
    explicit_paddings=[],
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes the gradients of depthwise convolution with respect to the filter.View aliases
tf.raw_ops.DepthwiseConv2dNativeBackpropInput,"tf.raw_ops.DepthwiseConv2dNativeBackpropInput(
    input_sizes,
    filter,
    out_backprop,
    strides,
    padding,
    explicit_paddings=[],
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes the gradients of depthwise convolution with respect to the input.View aliases
tf.raw_ops.Dequantize,"tf.raw_ops.Dequantize(
    input,
    min_range,
    max_range,
    mode='MIN_COMBINED',
    narrow_range=False,
    axis=-1,
    dtype=tf.dtypes.float32,
    name=None
)
",Dequantize the 'input' tensor into a float or bfloat16 Tensor.View aliases
tf.raw_ops.DeserializeIterator,"tf.raw_ops.DeserializeIterator(
    resource_handle, serialized, name=None
)
",Converts the given variant tensor to an iterator and stores it in the given resource.View aliases
tf.raw_ops.DeserializeManySparse,"tf.raw_ops.DeserializeManySparse(
    serialized_sparse, dtype, name=None
)
",Deserialize and concatenate SparseTensors from a serialized minibatch.View aliases
tf.raw_ops.DeserializeSparse,"tf.raw_ops.DeserializeSparse(
    serialized_sparse, dtype, name=None
)
",Deserialize SparseTensor objects.View aliases
tf.raw_ops.DestroyResourceOp,"tf.raw_ops.DestroyResourceOp(
    resource, ignore_lookup_error=True, name=None
)
",Deletes the resource specified by the handle.View aliases
tf.raw_ops.DestroyTemporaryVariable,"tf.raw_ops.DestroyTemporaryVariable(
    ref, var_name, name=None
)
",Destroys the temporary variable and returns its final value.View aliases
tf.raw_ops.DeviceIndex,"tf.raw_ops.DeviceIndex(
    device_names, name=None
)
",Return the index of device the op runs.View aliases
tf.raw_ops.Diag,"tf.raw_ops.Diag(
    diagonal, name=None
)
",Returns a diagonal tensor with a given diagonal values.View aliases
tf.raw_ops.DiagPart,"tf.raw_ops.DiagPart(
    input, name=None
)
",Returns the diagonal part of the tensor.View aliases
tf.raw_ops.Digamma,"tf.raw_ops.Digamma(
    x, name=None
)
","Computes Psi, the derivative of Lgamma (the log of the absolute value ofView aliases"
tf.raw_ops.Dilation2D,"tf.raw_ops.Dilation2D(
    input, filter, strides, rates, padding, name=None
)
",Computes the grayscale dilation of 4-D input and 3-D filter tensors.View aliases
tf.raw_ops.Dilation2DBackpropFilter,"tf.raw_ops.Dilation2DBackpropFilter(
    input, filter, out_backprop, strides, rates, padding, name=None
)
",Computes the gradient of morphological 2-D dilation with respect to the filter.View aliases
tf.raw_ops.Dilation2DBackpropInput,"tf.raw_ops.Dilation2DBackpropInput(
    input, filter, out_backprop, strides, rates, padding, name=None
)
",Computes the gradient of morphological 2-D dilation with respect to the input.View aliases
tf.raw_ops.DirectedInterleaveDataset,"tf.raw_ops.DirectedInterleaveDataset(
    selector_input_dataset,
    data_input_datasets,
    output_types,
    output_shapes,
    stop_on_empty_dataset=False,
    name=None
)
",A substitute for InterleaveDataset on a fixed list of N datasets.View aliases
tf.raw_ops.DisableCopyOnRead,"tf.raw_ops.DisableCopyOnRead(
    resource, name=None
)
",Turns off the copy-on-read mode.View aliases
tf.raw_ops.Div,"tf.raw_ops.Div(
    x, y, name=None
)
",Returns x / y element-wise.View aliases
tf.raw_ops.DivNoNan,"tf.raw_ops.DivNoNan(
    x, y, name=None
)
",Returns 0 if the denominator is zero.View aliases
tf.raw_ops.DrawBoundingBoxes,"tf.raw_ops.DrawBoundingBoxes(
    images, boxes, name=None
)
",Draw bounding boxes on a batch of images.View aliases
tf.raw_ops.DrawBoundingBoxesV2,"tf.raw_ops.DrawBoundingBoxesV2(
    images, boxes, colors, name=None
)
",Draw bounding boxes on a batch of images.View aliases
tf.raw_ops.DummyIterationCounter,"tf.raw_ops.DummyIterationCounter(
    name=None
)
",View aliases
tf.raw_ops.DummyMemoryCache,"tf.raw_ops.DummyMemoryCache(
    name=None
)
",View aliases
tf.raw_ops.DummySeedGenerator,"tf.raw_ops.DummySeedGenerator(
    name=None
)
",View aliases
tf.raw_ops.DynamicEnqueueTPUEmbeddingArbitraryTensorBatch,"tf.raw_ops.DynamicEnqueueTPUEmbeddingArbitraryTensorBatch(
    sample_indices_or_row_splits,
    embedding_indices,
    aggregation_weights,
    mode_override,
    device_ordinal,
    combiners=[],
    name=None
)
",Eases the porting of code that uses tf.nn.embedding_lookup_sparse().View aliases
tf.raw_ops.DynamicPartition,"tf.raw_ops.DynamicPartition(
    data, partitions, num_partitions, name=None
)
",Partitions data into num_partitions tensors using indices from partitions.View aliases
tf.raw_ops.DynamicStitch,"tf.raw_ops.DynamicStitch(
    indices, data, name=None
)
",Interleave the values from the data tensors into a single tensor.View aliases
tf.raw_ops.EagerPyFunc,"tf.raw_ops.EagerPyFunc(
    input, token, Tout, is_async=False, name=None
)
",Eagerly executes a python function to compute func(input)->output. TheView aliases
tf.raw_ops.EditDistance,"tf.raw_ops.EditDistance(
    hypothesis_indices,
    hypothesis_values,
    hypothesis_shape,
    truth_indices,
    truth_values,
    truth_shape,
    normalize=True,
    name=None
)
",Computes the (possibly normalized) Levenshtein Edit Distance.View aliases
tf.raw_ops.Eig,"tf.raw_ops.Eig(
    input, Tout, compute_v=True, name=None
)
",Computes the eigen decomposition of one or more square matrices.View aliases
tf.raw_ops.Einsum,"tf.raw_ops.Einsum(
    inputs, equation, name=None
)
",Tensor contraction according to Einstein summation convention.View aliases
tf.raw_ops.Elu,"tf.raw_ops.Elu(
    features, name=None
)
",Computes the exponential linear function.View aliases
tf.raw_ops.EluGrad,"tf.raw_ops.EluGrad(
    gradients, outputs, name=None
)
",Computes gradients for the exponential linear (Elu) operation.View aliases
tf.raw_ops.Empty,"tf.raw_ops.Empty(
    shape, dtype, init=False, name=None
)
",Creates a tensor with the given shape.View aliases
tf.raw_ops.EmptyTensorList,"tf.raw_ops.EmptyTensorList(
    element_shape, max_num_elements, element_dtype, name=None
)
",Creates and returns an empty tensor list.View aliases
tf.raw_ops.EncodeBase64,"tf.raw_ops.EncodeBase64(
    input, pad=False, name=None
)
",Encode strings into web-safe base64 format.View aliases
tf.raw_ops.EncodeJpeg,"tf.raw_ops.EncodeJpeg(
    image,
    format='',
    quality=95,
    progressive=False,
    optimize_size=False,
    chroma_downsampling=True,
    density_unit='in',
    x_density=300,
    y_density=300,
    xmp_metadata='',
    name=None
)
",JPEG-encode an image.View aliases
tf.raw_ops.EncodeJpegVariableQuality,"tf.raw_ops.EncodeJpegVariableQuality(
    images, quality, name=None
)
",JPEG encode input image with provided compression quality.View aliases
tf.raw_ops.EncodePng,"tf.raw_ops.EncodePng(
    image, compression=-1, name=None
)
",PNG-encode an image.View aliases
tf.raw_ops.EncodeProto,"tf.raw_ops.EncodeProto(
    sizes,
    values,
    field_names,
    message_type,
    descriptor_source='local://',
    name=None
)
",The op serializes protobuf messages provided in the input tensors.View aliases
tf.raw_ops.EncodeWav,"tf.raw_ops.EncodeWav(
    audio, sample_rate, name=None
)
",Encode audio data using the WAV file format.View aliases
tf.raw_ops.EnqueueTPUEmbeddingArbitraryTensorBatch,"tf.raw_ops.EnqueueTPUEmbeddingArbitraryTensorBatch(
    sample_indices_or_row_splits,
    embedding_indices,
    aggregation_weights,
    mode_override,
    device_ordinal=-1,
    combiners=[],
    name=None
)
",Eases the porting of code that uses tf.nn.embedding_lookup_sparse().View aliases
tf.raw_ops.EnqueueTPUEmbeddingIntegerBatch,"tf.raw_ops.EnqueueTPUEmbeddingIntegerBatch(
    batch, mode_override, device_ordinal=-1, name=None
)
",An op that enqueues a list of input batch tensors to TPUEmbedding.View aliases
tf.raw_ops.EnqueueTPUEmbeddingRaggedTensorBatch,"tf.raw_ops.EnqueueTPUEmbeddingRaggedTensorBatch(
    sample_splits,
    embedding_indices,
    aggregation_weights,
    mode_override,
    table_ids,
    device_ordinal=-1,
    combiners=[],
    max_sequence_lengths=[],
    num_features=[],
    name=None
)
",Eases the porting of code that uses tf.nn.embedding_lookup().View aliases
tf.raw_ops.EnqueueTPUEmbeddingSparseBatch,"tf.raw_ops.EnqueueTPUEmbeddingSparseBatch(
    sample_indices,
    embedding_indices,
    aggregation_weights,
    mode_override,
    device_ordinal=-1,
    combiners=[],
    name=None
)
",An op that enqueues TPUEmbedding input indices from a SparseTensor.View aliases
tf.raw_ops.EnqueueTPUEmbeddingSparseTensorBatch,"tf.raw_ops.EnqueueTPUEmbeddingSparseTensorBatch(
    sample_indices,
    embedding_indices,
    aggregation_weights,
    mode_override,
    table_ids,
    device_ordinal=-1,
    combiners=[],
    max_sequence_lengths=[],
    num_features=[],
    name=None
)
",Eases the porting of code that uses tf.nn.embedding_lookup_sparse().View aliases
tf.raw_ops.EnsureShape,"tf.raw_ops.EnsureShape(
    input, shape, name=None
)
",Ensures that the tensor's shape matches the expected shape.View aliases
tf.raw_ops.Enter,"tf.raw_ops.Enter(
    data, frame_name, is_constant=False, parallel_iterations=10, name=None
)
","Creates or finds a child frame, and makes data available to the child frame.View aliases"
tf.raw_ops.Equal,"tf.raw_ops.Equal(
    x, y, incompatible_shape_error=True, name=None
)
",Returns the truth value of (x == y) element-wise.View aliases
tf.raw_ops.Erf,"tf.raw_ops.Erf(
    x, name=None
)
","Computes the Gauss error function of x element-wise. In statistics, for non-negative values of \(x\), the error function has the following interpretation: for a random variable \(Y\) that is normally distributed with mean 0 and variance \(1/\sqrt{2}\), \(erf(x)\) is the probability that \(Y\) falls in the range \([x, x]\).View aliases"
tf.raw_ops.Erfc,"tf.raw_ops.Erfc(
    x, name=None
)
",Computes the complementary error function of x element-wise.View aliases
tf.raw_ops.Erfinv,"tf.raw_ops.Erfinv(
    x, name=None
)
",View aliases
tf.raw_ops.EuclideanNorm,"tf.raw_ops.EuclideanNorm(
    input, axis, keep_dims=False, name=None
)
",Computes the euclidean norm of elements across dimensions of a tensor.View aliases
tf.raw_ops.Exit,"tf.raw_ops.Exit(
    data, name=None
)
",Exits the current frame to its parent frame.View aliases
tf.raw_ops.Exp,"tf.raw_ops.Exp(
    x, name=None
)
",Computes exponential of x element-wise.  \(y = e^x\).View aliases
tf.raw_ops.ExpandDims,"tf.raw_ops.ExpandDims(
    input, axis, name=None
)
",Inserts a dimension of 1 into a tensor's shape.View aliases
tf.raw_ops.ExperimentalAssertNextDataset,"tf.raw_ops.ExperimentalAssertNextDataset(
    input_dataset, transformations, output_types, output_shapes, name=None
)
",View aliases
tf.raw_ops.ExperimentalAutoShardDataset,"tf.raw_ops.ExperimentalAutoShardDataset(
    input_dataset,
    num_workers,
    index,
    output_types,
    output_shapes,
    auto_shard_policy=0,
    name=None
)
",Creates a dataset that shards the input dataset.View aliases
tf.raw_ops.ExperimentalBytesProducedStatsDataset,"tf.raw_ops.ExperimentalBytesProducedStatsDataset(
    input_dataset, tag, output_types, output_shapes, name=None
)
",Records the bytes size of each element of input_dataset in a StatsAggregator.View aliases
tf.raw_ops.ExperimentalCSVDataset,"tf.raw_ops.ExperimentalCSVDataset(
    filenames,
    compression_type,
    buffer_size,
    header,
    field_delim,
    use_quote_delim,
    na_value,
    select_cols,
    record_defaults,
    output_shapes,
    name=None
)
",View aliases
tf.raw_ops.ExperimentalChooseFastestDataset,"tf.raw_ops.ExperimentalChooseFastestDataset(
    input_datasets, num_experiments, output_types, output_shapes, name=None
)
",View aliases
tf.raw_ops.ExperimentalDatasetCardinality,"tf.raw_ops.ExperimentalDatasetCardinality(
    input_dataset, name=None
)
",Returns the cardinality of input_dataset.View aliases
tf.raw_ops.ExperimentalDatasetToTFRecord,"tf.raw_ops.ExperimentalDatasetToTFRecord(
    input_dataset, filename, compression_type, name=None
)
",Writes the given dataset to the given file using the TFRecord format.View aliases
tf.raw_ops.ExperimentalDenseToSparseBatchDataset,"tf.raw_ops.ExperimentalDenseToSparseBatchDataset(
    input_dataset,
    batch_size,
    row_shape,
    output_types,
    output_shapes,
    name=None
)
",Creates a dataset that batches input elements into a SparseTensor.View aliases
tf.raw_ops.ExperimentalDirectedInterleaveDataset,"tf.raw_ops.ExperimentalDirectedInterleaveDataset(
    selector_input_dataset,
    data_input_datasets,
    output_types,
    output_shapes,
    name=None
)
",A substitute for InterleaveDataset on a fixed list of N datasets.View aliases
tf.raw_ops.ExperimentalGroupByReducerDataset,"tf.raw_ops.ExperimentalGroupByReducerDataset(
    input_dataset,
    key_func_other_arguments,
    init_func_other_arguments,
    reduce_func_other_arguments,
    finalize_func_other_arguments,
    key_func,
    init_func,
    reduce_func,
    finalize_func,
    output_types,
    output_shapes,
    name=None
)
",Creates a dataset that computes a group-by on input_dataset.View aliases
tf.raw_ops.ExperimentalGroupByWindowDataset,"tf.raw_ops.ExperimentalGroupByWindowDataset(
    input_dataset,
    key_func_other_arguments,
    reduce_func_other_arguments,
    window_size_func_other_arguments,
    key_func,
    reduce_func,
    window_size_func,
    output_types,
    output_shapes,
    name=None
)
",Creates a dataset that computes a windowed group-by on input_dataset.View aliases
tf.raw_ops.ExperimentalIgnoreErrorsDataset,"tf.raw_ops.ExperimentalIgnoreErrorsDataset(
    input_dataset, output_types, output_shapes, log_warning=False, name=None
)
",Creates a dataset that contains the elements of input_dataset ignoring errors.View aliases
tf.raw_ops.ExperimentalIteratorGetDevice,"tf.raw_ops.ExperimentalIteratorGetDevice(
    resource, name=None
)
",Returns the name of the device on which resource has been placed.View aliases
tf.raw_ops.ExperimentalLMDBDataset,"tf.raw_ops.ExperimentalLMDBDataset(
    filenames, output_types, output_shapes, name=None
)
",View aliases
tf.raw_ops.ExperimentalLatencyStatsDataset,"tf.raw_ops.ExperimentalLatencyStatsDataset(
    input_dataset, tag, output_types, output_shapes, name=None
)
",Records the latency of producing input_dataset elements in a StatsAggregator.View aliases
tf.raw_ops.ExperimentalMapAndBatchDataset,"tf.raw_ops.ExperimentalMapAndBatchDataset(
    input_dataset,
    other_arguments,
    batch_size,
    num_parallel_calls,
    drop_remainder,
    f,
    output_types,
    output_shapes,
    preserve_cardinality=False,
    name=None
)
",Creates a dataset that fuses mapping with batching.View aliases
tf.raw_ops.ExperimentalMapDataset,"tf.raw_ops.ExperimentalMapDataset(
    input_dataset,
    other_arguments,
    f,
    output_types,
    output_shapes,
    use_inter_op_parallelism=True,
    preserve_cardinality=False,
    name=None
)
",Creates a dataset that applies f to the outputs of input_dataset.View aliases
tf.raw_ops.ExperimentalMatchingFilesDataset,"tf.raw_ops.ExperimentalMatchingFilesDataset(
    patterns, name=None
)
",View aliases
tf.raw_ops.ExperimentalMaxIntraOpParallelismDataset,"tf.raw_ops.ExperimentalMaxIntraOpParallelismDataset(
    input_dataset,
    max_intra_op_parallelism,
    output_types,
    output_shapes,
    name=None
)
",Creates a dataset that overrides the maximum intra-op parallelism.View aliases
tf.raw_ops.ExperimentalNonSerializableDataset,"tf.raw_ops.ExperimentalNonSerializableDataset(
    input_dataset, output_types, output_shapes, name=None
)
",View aliases
tf.raw_ops.ExperimentalParallelInterleaveDataset,"tf.raw_ops.ExperimentalParallelInterleaveDataset(
    input_dataset,
    other_arguments,
    cycle_length,
    block_length,
    sloppy,
    buffer_output_elements,
    prefetch_input_elements,
    f,
    output_types,
    output_shapes,
    name=None
)
",Creates a dataset that applies f to the outputs of input_dataset.View aliases
tf.raw_ops.ExperimentalParseExampleDataset,"tf.raw_ops.ExperimentalParseExampleDataset(
    input_dataset,
    num_parallel_calls,
    dense_defaults,
    sparse_keys,
    dense_keys,
    sparse_types,
    dense_shapes,
    output_types,
    output_shapes,
    sloppy=False,
    name=None
)
",Transforms input_dataset containing Example protos as vectors of DT_STRING into a dataset of Tensor or SparseTensor objects representing the parsed features.View aliases
tf.raw_ops.ExperimentalPrivateThreadPoolDataset,"tf.raw_ops.ExperimentalPrivateThreadPoolDataset(
    input_dataset, num_threads, output_types, output_shapes, name=None
)
",Creates a dataset that uses a custom thread pool to compute input_dataset.View aliases
tf.raw_ops.ExperimentalRandomDataset,"tf.raw_ops.ExperimentalRandomDataset(
    seed, seed2, output_types, output_shapes, name=None
)
",Creates a Dataset that returns pseudorandom numbers.View aliases
tf.raw_ops.ExperimentalRebatchDataset,"tf.raw_ops.ExperimentalRebatchDataset(
    input_dataset,
    num_replicas,
    output_types,
    output_shapes,
    use_fallback=True,
    name=None
)
",Creates a dataset that changes the batch size.View aliases
tf.raw_ops.ExperimentalScanDataset,"tf.raw_ops.ExperimentalScanDataset(
    input_dataset,
    initial_state,
    other_arguments,
    f,
    output_types,
    output_shapes,
    preserve_cardinality=False,
    name=None
)
",Creates a dataset successively reduces f over the elements of input_dataset.View aliases
tf.raw_ops.ExperimentalSetStatsAggregatorDataset,"tf.raw_ops.ExperimentalSetStatsAggregatorDataset(
    input_dataset,
    stats_aggregator,
    tag,
    counter_prefix,
    output_types,
    output_shapes,
    name=None
)
",View aliases
tf.raw_ops.ExperimentalSleepDataset,"tf.raw_ops.ExperimentalSleepDataset(
    input_dataset, sleep_microseconds, output_types, output_shapes, name=None
)
",View aliases
tf.raw_ops.ExperimentalSlidingWindowDataset,"tf.raw_ops.ExperimentalSlidingWindowDataset(
    input_dataset,
    window_size,
    window_shift,
    window_stride,
    output_types,
    output_shapes,
    name=None
)
",Creates a dataset that passes a sliding window over input_dataset.View aliases
tf.raw_ops.ExperimentalSqlDataset,"tf.raw_ops.ExperimentalSqlDataset(
    driver_name,
    data_source_name,
    query,
    output_types,
    output_shapes,
    name=None
)
",Creates a dataset that executes a SQL query and emits rows of the result set.View aliases
tf.raw_ops.ExperimentalStatsAggregatorHandle,"tf.raw_ops.ExperimentalStatsAggregatorHandle(
    container='', shared_name='', name=None
)
",Creates a statistics manager resource.View aliases
tf.raw_ops.ExperimentalStatsAggregatorSummary,"tf.raw_ops.ExperimentalStatsAggregatorSummary(
    iterator, name=None
)
",Produces a summary of any statistics recorded by the given statistics manager.View aliases
tf.raw_ops.ExperimentalTakeWhileDataset,"tf.raw_ops.ExperimentalTakeWhileDataset(
    input_dataset,
    other_arguments,
    predicate,
    output_types,
    output_shapes,
    name=None
)
",Creates a dataset that stops iteration when predicate` is false.View aliases
tf.raw_ops.ExperimentalThreadPoolDataset,"tf.raw_ops.ExperimentalThreadPoolDataset(
    input_dataset, thread_pool, output_types, output_shapes, name=None
)
",Creates a dataset that uses a custom thread pool to compute input_dataset.View aliases
tf.raw_ops.ExperimentalThreadPoolHandle,"tf.raw_ops.ExperimentalThreadPoolHandle(
    num_threads,
    display_name,
    max_intra_op_parallelism=1,
    container='',
    shared_name='',
    name=None
)
",Creates a dataset that uses a custom thread pool to compute input_dataset.View aliases
tf.raw_ops.ExperimentalUnbatchDataset,"tf.raw_ops.ExperimentalUnbatchDataset(
    input_dataset, output_types, output_shapes, name=None
)
",A dataset that splits the elements of its input into multiple elements.View aliases
tf.raw_ops.ExperimentalUniqueDataset,"tf.raw_ops.ExperimentalUniqueDataset(
    input_dataset, output_types, output_shapes, name=None
)
",Creates a dataset that contains the unique elements of input_dataset.View aliases
tf.raw_ops.Expint,"tf.raw_ops.Expint(
    x, name=None
)
",View aliases
tf.raw_ops.Expm1,"tf.raw_ops.Expm1(
    x, name=None
)
",Computes exp(x) - 1 element-wise.View aliases
tf.raw_ops.ExtractGlimpse,"tf.raw_ops.ExtractGlimpse(
    input,
    size,
    offsets,
    centered=True,
    normalized=True,
    uniform_noise=True,
    noise='uniform',
    name=None
)
",Extracts a glimpse from the input tensor.View aliases
tf.raw_ops.ExtractGlimpseV2,"tf.raw_ops.ExtractGlimpseV2(
    input,
    size,
    offsets,
    centered=True,
    normalized=True,
    uniform_noise=True,
    noise='uniform',
    name=None
)
",Extracts a glimpse from the input tensor.View aliases
tf.raw_ops.ExtractImagePatches,"tf.raw_ops.ExtractImagePatches(
    images, ksizes, strides, rates, padding, name=None
)
","Extract patches from images and put them in the ""depth"" output dimension.View aliases"
tf.raw_ops.ExtractJpegShape,"tf.raw_ops.ExtractJpegShape(
    contents,
    output_type=tf.dtypes.int32,
    name=None
)
",Extract the shape information of a JPEG-encoded image.View aliases
tf.raw_ops.ExtractVolumePatches,"tf.raw_ops.ExtractVolumePatches(
    input, ksizes, strides, padding, name=None
)
","Extract patches from input and put them in the ""depth"" output dimension. 3D extension of extract_image_patches.View aliases"
tf.raw_ops.FFT,"tf.raw_ops.FFT(
    input, name=None
)
",Fast Fourier transform.View aliases
tf.raw_ops.FFT2D,"tf.raw_ops.FFT2D(
    input, name=None
)
",2D fast Fourier transform.View aliases
tf.raw_ops.FFT3D,"tf.raw_ops.FFT3D(
    input, name=None
)
",3D fast Fourier transform.View aliases
tf.raw_ops.FIFOQueue,"tf.raw_ops.FIFOQueue(
    component_types,
    shapes=[],
    capacity=-1,
    container='',
    shared_name='',
    name=None
)
",A queue that produces elements in first-in first-out order.View aliases
tf.raw_ops.FIFOQueueV2,"tf.raw_ops.FIFOQueueV2(
    component_types,
    shapes=[],
    capacity=-1,
    container='',
    shared_name='',
    name=None
)
",A queue that produces elements in first-in first-out order.View aliases
tf.raw_ops.Fact,"tf.raw_ops.Fact(
    name=None
)
",Output a fact about factorials.View aliases
tf.raw_ops.FakeParam,"tf.raw_ops.FakeParam(
    dtype, shape, name=None
)
",This op is used as a placeholder in If branch functions. It doesn't provide aView aliases
tf.raw_ops.FakeQuantWithMinMaxArgs,"tf.raw_ops.FakeQuantWithMinMaxArgs(
    inputs, min=-6, max=6, num_bits=8, narrow_range=False, name=None
)
","Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.View aliases"
tf.raw_ops.FakeQuantWithMinMaxArgsGradient,"tf.raw_ops.FakeQuantWithMinMaxArgsGradient(
    gradients, inputs, min=-6, max=6, num_bits=8, narrow_range=False, name=None
)
",Compute gradients for a FakeQuantWithMinMaxArgs operation.View aliases
tf.raw_ops.FakeQuantWithMinMaxVars,"tf.raw_ops.FakeQuantWithMinMaxVars(
    inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Fake-quantize the 'inputs' tensor of type float via global float scalarsView aliases
tf.raw_ops.FakeQuantWithMinMaxVarsGradient,"tf.raw_ops.FakeQuantWithMinMaxVarsGradient(
    gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Compute gradients for a FakeQuantWithMinMaxVars operation.View aliases
tf.raw_ops.FakeQuantWithMinMaxVarsPerChannel,"tf.raw_ops.FakeQuantWithMinMaxVarsPerChannel(
    inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Fake-quantize the 'inputs' tensor of type float via per-channel floatsView aliases
tf.raw_ops.FakeQuantWithMinMaxVarsPerChannelGradient,"tf.raw_ops.FakeQuantWithMinMaxVarsPerChannelGradient(
    gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.View aliases
tf.raw_ops.FakeQueue,"tf.raw_ops.FakeQueue(
    resource, name=None
)
",Deprecated. Do not use.View aliases
tf.raw_ops.Fill,"tf.raw_ops.Fill(
    dims, value, name=None
)
",Creates a tensor filled with a scalar value.View aliases
tf.raw_ops.FilterByLastComponentDataset,"tf.raw_ops.FilterByLastComponentDataset(
    input_dataset, output_types, output_shapes, name=None
)
",Creates a dataset containing elements of first component of input_dataset having true in the last component.View aliases
tf.raw_ops.FilterDataset,"tf.raw_ops.FilterDataset(
    input_dataset,
    other_arguments,
    predicate,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset containing elements of input_dataset matching predicate.View aliases
tf.raw_ops.FinalizeDataset,"tf.raw_ops.FinalizeDataset(
    input_dataset,
    output_types,
    output_shapes,
    has_captured_ref=False,
    name=None
)
",Creates a dataset by applying tf.data.Options to input_dataset.View aliases
tf.raw_ops.Fingerprint,"tf.raw_ops.Fingerprint(
    data, method, name=None
)
",Generates fingerprint values.View aliases
tf.raw_ops.FixedLengthRecordDataset,"tf.raw_ops.FixedLengthRecordDataset(
    filenames,
    header_bytes,
    record_bytes,
    footer_bytes,
    buffer_size,
    metadata='',
    name=None
)
",Creates a dataset that emits the records from one or more binary files.View aliases
tf.raw_ops.FixedLengthRecordDatasetV2,"tf.raw_ops.FixedLengthRecordDatasetV2(
    filenames,
    header_bytes,
    record_bytes,
    footer_bytes,
    buffer_size,
    compression_type,
    metadata='',
    name=None
)
",View aliases
tf.raw_ops.FixedLengthRecordReader,"tf.raw_ops.FixedLengthRecordReader(
    record_bytes,
    header_bytes=0,
    footer_bytes=0,
    hop_bytes=0,
    container='',
    shared_name='',
    name=None
)
",A Reader that outputs fixed-length records from a file.View aliases
tf.raw_ops.FixedLengthRecordReaderV2,"tf.raw_ops.FixedLengthRecordReaderV2(
    record_bytes,
    header_bytes=0,
    footer_bytes=0,
    hop_bytes=0,
    container='',
    shared_name='',
    encoding='',
    name=None
)
",A Reader that outputs fixed-length records from a file.View aliases
tf.raw_ops.FixedUnigramCandidateSampler,"tf.raw_ops.FixedUnigramCandidateSampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    vocab_file='',
    distortion=1,
    num_reserved_ids=0,
    num_shards=1,
    shard=0,
    unigrams=[],
    seed=0,
    seed2=0,
    name=None
)
",Generates labels for candidate sampling with a learned unigram distribution.View aliases
tf.raw_ops.FlatMapDataset,"tf.raw_ops.FlatMapDataset(
    input_dataset,
    other_arguments,
    f,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that applies f to the outputs of input_dataset.View aliases
tf.raw_ops.Floor,"tf.raw_ops.Floor(
    x, name=None
)
",Returns element-wise largest integer not greater than x.View aliases
tf.raw_ops.FloorDiv,"tf.raw_ops.FloorDiv(
    x, y, name=None
)
",Returns x // y element-wise.View aliases
tf.raw_ops.FloorMod,"tf.raw_ops.FloorMod(
    x, y, name=None
)
",Returns element-wise remainder of division. When x < 0 xor y < 0 isView aliases
tf.raw_ops.FlushSummaryWriter,"tf.raw_ops.FlushSummaryWriter(
    writer, name=None
)
",View aliases
tf.raw_ops.For,"tf.raw_ops.For(
    start, limit, delta, input, body, name=None
)
",Applies a for loop.View aliases
tf.raw_ops.FractionalAvgPool,"tf.raw_ops.FractionalAvgPool(
    value,
    pooling_ratio,
    pseudo_random=False,
    overlapping=False,
    deterministic=False,
    seed=0,
    seed2=0,
    name=None
)
",Performs fractional average pooling on the input.View aliases
tf.raw_ops.FractionalAvgPoolGrad,"tf.raw_ops.FractionalAvgPoolGrad(
    orig_input_tensor_shape,
    out_backprop,
    row_pooling_sequence,
    col_pooling_sequence,
    overlapping=False,
    name=None
)
",Computes gradient of the FractionalAvgPool function.View aliases
tf.raw_ops.FractionalMaxPool,"tf.raw_ops.FractionalMaxPool(
    value,
    pooling_ratio,
    pseudo_random=False,
    overlapping=False,
    deterministic=False,
    seed=0,
    seed2=0,
    name=None
)
",Performs fractional max pooling on the input.View aliases
tf.raw_ops.FractionalMaxPoolGrad,"tf.raw_ops.FractionalMaxPoolGrad(
    orig_input,
    orig_output,
    out_backprop,
    row_pooling_sequence,
    col_pooling_sequence,
    overlapping=False,
    name=None
)
",Computes gradient of the FractionalMaxPool function.View aliases
tf.raw_ops.FresnelCos,"tf.raw_ops.FresnelCos(
    x, name=None
)
",View aliases
tf.raw_ops.FresnelSin,"tf.raw_ops.FresnelSin(
    x, name=None
)
",View aliases
tf.raw_ops.FusedBatchNorm,"tf.raw_ops.FusedBatchNorm(
    x,
    scale,
    offset,
    mean,
    variance,
    epsilon=0.0001,
    exponential_avg_factor=1,
    data_format='NHWC',
    is_training=True,
    name=None
)
",Batch normalization.View aliases
tf.raw_ops.FusedBatchNormGrad,"tf.raw_ops.FusedBatchNormGrad(
    y_backprop,
    x,
    scale,
    reserve_space_1,
    reserve_space_2,
    epsilon=0.0001,
    data_format='NHWC',
    is_training=True,
    name=None
)
",Gradient for batch normalization.View aliases
tf.raw_ops.FusedBatchNormGradV2,"tf.raw_ops.FusedBatchNormGradV2(
    y_backprop,
    x,
    scale,
    reserve_space_1,
    reserve_space_2,
    epsilon=0.0001,
    data_format='NHWC',
    is_training=True,
    name=None
)
",Gradient for batch normalization.View aliases
tf.raw_ops.FusedBatchNormGradV3,"tf.raw_ops.FusedBatchNormGradV3(
    y_backprop,
    x,
    scale,
    reserve_space_1,
    reserve_space_2,
    reserve_space_3,
    epsilon=0.0001,
    data_format='NHWC',
    is_training=True,
    name=None
)
",Gradient for batch normalization.View aliases
tf.raw_ops.FusedBatchNormV2,"tf.raw_ops.FusedBatchNormV2(
    x,
    scale,
    offset,
    mean,
    variance,
    epsilon=0.0001,
    exponential_avg_factor=1,
    data_format='NHWC',
    is_training=True,
    name=None
)
",Batch normalization.View aliases
tf.raw_ops.FusedBatchNormV3,"tf.raw_ops.FusedBatchNormV3(
    x,
    scale,
    offset,
    mean,
    variance,
    epsilon=0.0001,
    exponential_avg_factor=1,
    data_format='NHWC',
    is_training=True,
    name=None
)
",Batch normalization.View aliases
tf.raw_ops.FusedPadConv2D,"tf.raw_ops.FusedPadConv2D(
    input, paddings, filter, mode, strides, padding, name=None
)
",Performs a padding as a preprocess during a convolution.View aliases
tf.raw_ops.FusedResizeAndPadConv2D,"tf.raw_ops.FusedResizeAndPadConv2D(
    input,
    size,
    paddings,
    filter,
    mode,
    strides,
    padding,
    resize_align_corners=False,
    name=None
)
",Performs a resize and padding as a preprocess during a convolution.View aliases
tf.raw_ops.GRUBlockCell,"tf.raw_ops.GRUBlockCell(
    x, h_prev, w_ru, w_c, b_ru, b_c, name=None
)
",Computes the GRU cell forward propagation for 1 time step.View aliases
tf.raw_ops.GRUBlockCellGrad,"tf.raw_ops.GRUBlockCellGrad(
    x, h_prev, w_ru, w_c, b_ru, b_c, r, u, c, d_h, name=None
)
",Computes the GRU cell back-propagation for 1 time step.View aliases
tf.raw_ops.Gather,"tf.raw_ops.Gather(
    params, indices, validate_indices=True, name=None
)
",Gather slices from params according to indices.View aliases
tf.raw_ops.GatherNd,"tf.raw_ops.GatherNd(
    params, indices, name=None
)
",Gather slices from params into a Tensor with shape specified by indices.View aliases
tf.raw_ops.GatherV2,"tf.raw_ops.GatherV2(
    params, indices, axis, batch_dims=0, name=None
)
",Gather slices from params axis axis according to indices.View aliases
tf.raw_ops.GenerateBoundingBoxProposals,"tf.raw_ops.GenerateBoundingBoxProposals(
    scores,
    bbox_deltas,
    image_info,
    anchors,
    nms_threshold,
    pre_nms_topn,
    min_size,
    post_nms_topn=300,
    name=None
)
",This op produces Region of Interests from given bounding boxes(bbox_deltas) encoded wrt anchors according to eq.2 in arXiv:1506.01497View aliases
tf.raw_ops.GenerateVocabRemapping,"tf.raw_ops.GenerateVocabRemapping(
    new_vocab_file,
    old_vocab_file,
    new_vocab_offset,
    num_new_vocab,
    old_vocab_size=-1,
    name=None
)
","Given a path to new and old vocabulary files, returns a remapping Tensor ofView aliases"
tf.raw_ops.GeneratorDataset,"tf.raw_ops.GeneratorDataset(
    init_func_other_args,
    next_func_other_args,
    finalize_func_other_args,
    init_func,
    next_func,
    finalize_func,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that invokes a function to generate elements.View aliases
tf.raw_ops.GetElementAtIndex,"tf.raw_ops.GetElementAtIndex(
    dataset, index, output_types, output_shapes, name=None
)
",Gets the element at the specified index in a dataset.View aliases
tf.raw_ops.GetOptions,"tf.raw_ops.GetOptions(
    input_dataset, name=None
)
",Returns the tf.data.Options attached to input_dataset.View aliases
tf.raw_ops.GetSessionHandle,"tf.raw_ops.GetSessionHandle(
    value, name=None
)
",Store the input tensor in the state of the current session.View aliases
tf.raw_ops.GetSessionHandleV2,"tf.raw_ops.GetSessionHandleV2(
    value, name=None
)
",Store the input tensor in the state of the current session.View aliases
tf.raw_ops.GetSessionTensor,"tf.raw_ops.GetSessionTensor(
    handle, dtype, name=None
)
",Get the value of the tensor specified by its handle.View aliases
tf.raw_ops.Greater,"tf.raw_ops.Greater(
    x, y, name=None
)
",Returns the truth value of (x > y) element-wise.View aliases
tf.raw_ops.GreaterEqual,"tf.raw_ops.GreaterEqual(
    x, y, name=None
)
",Returns the truth value of (x >= y) element-wise.View aliases
tf.raw_ops.GroupByReducerDataset,"tf.raw_ops.GroupByReducerDataset(
    input_dataset,
    key_func_other_arguments,
    init_func_other_arguments,
    reduce_func_other_arguments,
    finalize_func_other_arguments,
    key_func,
    init_func,
    reduce_func,
    finalize_func,
    output_types,
    output_shapes,
    name=None
)
",Creates a dataset that computes a group-by on input_dataset.View aliases
tf.raw_ops.GroupByWindowDataset,"tf.raw_ops.GroupByWindowDataset(
    input_dataset,
    key_func_other_arguments,
    reduce_func_other_arguments,
    window_size_func_other_arguments,
    key_func,
    reduce_func,
    window_size_func,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that computes a windowed group-by on input_dataset.View aliases
tf.raw_ops.GuaranteeConst,"tf.raw_ops.GuaranteeConst(
    input, name=None
)
",Gives a guarantee to the TF runtime that the input tensor is a constant.View aliases
tf.raw_ops.HSVToRGB,"tf.raw_ops.HSVToRGB(
    images, name=None
)
",Convert one or more images from HSV to RGB.View aliases
tf.raw_ops.HashTable,"tf.raw_ops.HashTable(
    key_dtype,
    value_dtype,
    container='',
    shared_name='',
    use_node_name_sharing=False,
    name=None
)
",Creates a non-initialized hash table.View aliases
tf.raw_ops.HashTableV2,"tf.raw_ops.HashTableV2(
    key_dtype,
    value_dtype,
    container='',
    shared_name='',
    use_node_name_sharing=False,
    name=None
)
",Creates a non-initialized hash table.View aliases
tf.raw_ops.HistogramFixedWidth,"tf.raw_ops.HistogramFixedWidth(
    values,
    value_range,
    nbins,
    dtype=tf.dtypes.int32,
    name=None
)
",Return histogram of values.View aliases
tf.raw_ops.HistogramSummary,"tf.raw_ops.HistogramSummary(
    tag, values, name=None
)
",Outputs a Summary protocol buffer with a histogram.View aliases
tf.raw_ops.IFFT,"tf.raw_ops.IFFT(
    input, name=None
)
",Inverse fast Fourier transform.View aliases
tf.raw_ops.IFFT2D,"tf.raw_ops.IFFT2D(
    input, name=None
)
",Inverse 2D fast Fourier transform.View aliases
tf.raw_ops.IFFT3D,"tf.raw_ops.IFFT3D(
    input, name=None
)
",Inverse 3D fast Fourier transform.View aliases
tf.raw_ops.IRFFT,"tf.raw_ops.IRFFT(
    input,
    fft_length,
    Treal=tf.dtypes.float32,
    name=None
)
",Inverse real-valued fast Fourier transform.View aliases
tf.raw_ops.IRFFT2D,"tf.raw_ops.IRFFT2D(
    input,
    fft_length,
    Treal=tf.dtypes.float32,
    name=None
)
",Inverse 2D real-valued fast Fourier transform.View aliases
tf.raw_ops.IRFFT3D,"tf.raw_ops.IRFFT3D(
    input,
    fft_length,
    Treal=tf.dtypes.float32,
    name=None
)
",Inverse 3D real-valued fast Fourier transform.View aliases
tf.raw_ops.Identity,"tf.raw_ops.Identity(
    input, name=None
)
",Return a tensor with the same shape and contents as the input tensor or value.View aliases
tf.raw_ops.IdentityN,"tf.raw_ops.IdentityN(
    input, name=None
)
",Returns a list of tensors with the same shapes and contents as the inputView aliases
tf.raw_ops.IdentityReader,"tf.raw_ops.IdentityReader(
    container='', shared_name='', name=None
)
",A Reader that outputs the queued work as both the key and value.View aliases
tf.raw_ops.IdentityReaderV2,"tf.raw_ops.IdentityReaderV2(
    container='', shared_name='', name=None
)
",A Reader that outputs the queued work as both the key and value.View aliases
tf.raw_ops.If,"tf.raw_ops.If(
    cond, input, Tout, then_branch, else_branch, output_shapes=[], name=None
)
",output = cond ? then_branch(input) : else_branch(input)View aliases
tf.raw_ops.Igamma,"tf.raw_ops.Igamma(
    a, x, name=None
)
","Compute the lower regularized incomplete Gamma function P(a, x).View aliases"
tf.raw_ops.IgammaGradA,"tf.raw_ops.IgammaGradA(
    a, x, name=None
)
","Computes the gradient of igamma(a, x) wrt a.View aliases"
tf.raw_ops.Igammac,"tf.raw_ops.Igammac(
    a, x, name=None
)
","Compute the upper regularized incomplete Gamma function Q(a, x).View aliases"
tf.raw_ops.IgnoreErrorsDataset,"tf.raw_ops.IgnoreErrorsDataset(
    input_dataset, output_types, output_shapes, log_warning=False, name=None
)
",Creates a dataset that contains the elements of input_dataset ignoring errors.View aliases
tf.raw_ops.Imag,"tf.raw_ops.Imag(
    input,
    Tout=tf.dtypes.float32,
    name=None
)
",Returns the imaginary part of a complex number.View aliases
tf.raw_ops.ImageProjectiveTransformV2,"tf.raw_ops.ImageProjectiveTransformV2(
    images,
    transforms,
    output_shape,
    interpolation,
    fill_mode='CONSTANT',
    name=None
)
",Applies the given transform to each of the images.View aliases
tf.raw_ops.ImageProjectiveTransformV3,"tf.raw_ops.ImageProjectiveTransformV3(
    images,
    transforms,
    output_shape,
    fill_value,
    interpolation,
    fill_mode='CONSTANT',
    name=None
)
",Applies the given transform to each of the images.View aliases
tf.raw_ops.ImageSummary,"tf.raw_ops.ImageSummary(
    tag,
    tensor,
    max_images=3,
    bad_color=_execute.make_tensor(\n    'dtype: DT_UINT8 tensor_shape { dim { size: 4 } } int_val: 255 int_val: 0 int_val: 0 int_val: 255'\n    , 'bad_color'),
    name=None
)
",Outputs a Summary protocol buffer with images.View aliases
tf.raw_ops.ImmutableConst,"tf.raw_ops.ImmutableConst(
    dtype, shape, memory_region_name, name=None
)
",Returns immutable tensor from memory region.View aliases
tf.raw_ops.ImportEvent,"tf.raw_ops.ImportEvent(
    writer, event, name=None
)
",View aliases
tf.raw_ops.InTopK,"tf.raw_ops.InTopK(
    predictions, targets, k, name=None
)
",Says whether the targets are in the top K predictions.View aliases
tf.raw_ops.InTopKV2,"tf.raw_ops.InTopKV2(
    predictions, targets, k, name=None
)
",Says whether the targets are in the top K predictions.View aliases
tf.raw_ops.InfeedDequeue,"tf.raw_ops.InfeedDequeue(
    dtype, shape, name=None
)
",A placeholder op for a value that will be fed into the computation.View aliases
tf.raw_ops.InfeedDequeueTuple,"tf.raw_ops.InfeedDequeueTuple(
    dtypes, shapes, name=None
)
",Fetches multiple values from infeed as an XLA tuple.View aliases
tf.raw_ops.InfeedEnqueue,"tf.raw_ops.InfeedEnqueue(
    input, shape=[], layout=[], device_ordinal=-1, name=None
)
",An op which feeds a single Tensor value into the computation.View aliases
tf.raw_ops.InfeedEnqueuePrelinearizedBuffer,"tf.raw_ops.InfeedEnqueuePrelinearizedBuffer(
    input, device_ordinal=-1, name=None
)
",An op which enqueues prelinearized buffer into TPU infeed.View aliases
tf.raw_ops.InfeedEnqueueTuple,"tf.raw_ops.InfeedEnqueueTuple(
    inputs, shapes, layouts=[], device_ordinal=-1, name=None
)
",Feeds multiple Tensor values into the computation as an XLA tuple.View aliases
tf.raw_ops.InitializeTable,"tf.raw_ops.InitializeTable(
    table_handle, keys, values, name=None
)
",Table initializer that takes two tensors for keys and values respectively.View aliases
tf.raw_ops.InitializeTableFromDataset,"tf.raw_ops.InitializeTableFromDataset(
    table_handle, dataset, name=None
)
",View aliases
tf.raw_ops.InitializeTableFromTextFile,"tf.raw_ops.InitializeTableFromTextFile(
    table_handle,
    filename,
    key_index,
    value_index,
    vocab_size=-1,
    delimiter='\t',
    offset=0,
    name=None
)
",Initializes a table from a text file.View aliases
tf.raw_ops.InitializeTableFromTextFileV2,"tf.raw_ops.InitializeTableFromTextFileV2(
    table_handle,
    filename,
    key_index,
    value_index,
    vocab_size=-1,
    delimiter='\t',
    offset=0,
    name=None
)
",Initializes a table from a text file.View aliases
tf.raw_ops.InitializeTableV2,"tf.raw_ops.InitializeTableV2(
    table_handle, keys, values, name=None
)
",Table initializer that takes two tensors for keys and values respectively.View aliases
tf.raw_ops.InplaceAdd,"tf.raw_ops.InplaceAdd(
    x, i, v, name=None
)
",Adds v into specified rows of x.View aliases
tf.raw_ops.InplaceSub,"tf.raw_ops.InplaceSub(
    x, i, v, name=None
)
",Subtracts v into specified rows of x.View aliases
tf.raw_ops.InplaceUpdate,"tf.raw_ops.InplaceUpdate(
    x, i, v, name=None
)
",Updates specified rows 'i' with values 'v'.View aliases
tf.raw_ops.InterleaveDataset,"tf.raw_ops.InterleaveDataset(
    input_dataset,
    other_arguments,
    cycle_length,
    block_length,
    f,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that applies f to the outputs of input_dataset.View aliases
tf.raw_ops.Inv,"tf.raw_ops.Inv(
    x, name=None
)
",Computes the reciprocal of x element-wise.View aliases
tf.raw_ops.InvGrad,"tf.raw_ops.InvGrad(
    y, dy, name=None
)
",Computes the gradient for the inverse of x wrt its input.View aliases
tf.raw_ops.Invert,"tf.raw_ops.Invert(
    x, name=None
)
","Invert (flip) each bit of supported types; for example, type uint8 value 01010101 becomes 10101010.View aliases"
tf.raw_ops.InvertPermutation,"tf.raw_ops.InvertPermutation(
    x, name=None
)
",Computes the inverse permutation of a tensor.View aliases
tf.raw_ops.IsBoostedTreesEnsembleInitialized,"tf.raw_ops.IsBoostedTreesEnsembleInitialized(
    tree_ensemble_handle, name=None
)
",Checks whether a tree ensemble has been initialized.View aliases
tf.raw_ops.IsBoostedTreesQuantileStreamResourceInitialized,"tf.raw_ops.IsBoostedTreesQuantileStreamResourceInitialized(
    quantile_stream_resource_handle, name=None
)
",Checks whether a quantile stream has been initialized.View aliases
tf.raw_ops.IsFinite,"tf.raw_ops.IsFinite(
    x, name=None
)
",Returns which elements of x are finite.View aliases
tf.raw_ops.IsInf,"tf.raw_ops.IsInf(
    x, name=None
)
",Returns which elements of x are Inf.View aliases
tf.raw_ops.IsNan,"tf.raw_ops.IsNan(
    x, name=None
)
",Returns which elements of x are NaN.View aliases
tf.raw_ops.IsTPUEmbeddingInitialized,"tf.raw_ops.IsTPUEmbeddingInitialized(
    config='', name=None
)
",Whether TPU Embedding is initialized in a distributed TPU system.View aliases
tf.raw_ops.IsVariableInitialized,"tf.raw_ops.IsVariableInitialized(
    ref, name=None
)
",Checks whether a tensor has been initialized.View aliases
tf.raw_ops.IsotonicRegression,"tf.raw_ops.IsotonicRegression(
    input,
    output_dtype=tf.dtypes.float32,
    name=None
)
",Solves a batch of isotonic regression problems.View aliases
tf.raw_ops.Iterator,"tf.raw_ops.Iterator(
    shared_name, container, output_types, output_shapes, name=None
)
",A container for an iterator resource.View aliases
tf.raw_ops.IteratorFromStringHandle,"tf.raw_ops.IteratorFromStringHandle(
    string_handle, output_types=[], output_shapes=[], name=None
)
",Converts the given string representing a handle to an iterator to a resource.View aliases
tf.raw_ops.IteratorFromStringHandleV2,"tf.raw_ops.IteratorFromStringHandleV2(
    string_handle, output_types=[], output_shapes=[], name=None
)
",View aliases
tf.raw_ops.IteratorGetDevice,"tf.raw_ops.IteratorGetDevice(
    resource, name=None
)
",Returns the name of the device on which resource has been placed.View aliases
tf.raw_ops.IteratorGetNext,"tf.raw_ops.IteratorGetNext(
    iterator, output_types, output_shapes, name=None
)
",Gets the next output from the given iterator .View aliases
tf.raw_ops.IteratorGetNextAsOptional,"tf.raw_ops.IteratorGetNextAsOptional(
    iterator, output_types, output_shapes, name=None
)
",Gets the next output from the given iterator as an Optional variant.View aliases
tf.raw_ops.IteratorGetNextSync,"tf.raw_ops.IteratorGetNextSync(
    iterator, output_types, output_shapes, name=None
)
",Gets the next output from the given iterator.View aliases
tf.raw_ops.IteratorToStringHandle,"tf.raw_ops.IteratorToStringHandle(
    resource_handle, name=None
)
",Converts the given resource_handle representing an iterator to a string.View aliases
tf.raw_ops.IteratorV2,"tf.raw_ops.IteratorV2(
    shared_name, container, output_types, output_shapes, name=None
)
",View aliases
tf.raw_ops.L2Loss,"tf.raw_ops.L2Loss(
    t, name=None
)
",L2 Loss.View aliases
tf.raw_ops.LMDBDataset,"tf.raw_ops.LMDBDataset(
    filenames, output_types, output_shapes, name=None
)
",Creates a dataset that emits the key-value pairs in one or more LMDB files.View aliases
tf.raw_ops.LMDBReader,"tf.raw_ops.LMDBReader(
    container='', shared_name='', name=None
)
",A Reader that outputs the records from a LMDB file.View aliases
tf.raw_ops.LRN,"tf.raw_ops.LRN(
    input, depth_radius=5, bias=1, alpha=1, beta=0.5, name=None
)
",Local Response Normalization.View aliases
tf.raw_ops.LRNGrad,"tf.raw_ops.LRNGrad(
    input_grads,
    input_image,
    output_image,
    depth_radius=5,
    bias=1,
    alpha=1,
    beta=0.5,
    name=None
)
",Gradients for Local Response Normalization.View aliases
tf.raw_ops.LSTMBlockCell,"tf.raw_ops.LSTMBlockCell(
    x,
    cs_prev,
    h_prev,
    w,
    wci,
    wcf,
    wco,
    b,
    forget_bias=1,
    cell_clip=3,
    use_peephole=False,
    name=None
)
",Computes the LSTM cell forward propagation for 1 time step.View aliases
tf.raw_ops.LSTMBlockCellGrad,"tf.raw_ops.LSTMBlockCellGrad(
    x,
    cs_prev,
    h_prev,
    w,
    wci,
    wcf,
    wco,
    b,
    i,
    cs,
    f,
    o,
    ci,
    co,
    cs_grad,
    h_grad,
    use_peephole,
    name=None
)
",Computes the LSTM cell backward propagation for 1 timestep.View aliases
tf.raw_ops.LatencyStatsDataset,"tf.raw_ops.LatencyStatsDataset(
    input_dataset, tag, output_types, output_shapes, name=None
)
",Records the latency of producing input_dataset elements in a StatsAggregator.View aliases
tf.raw_ops.LeakyRelu,"tf.raw_ops.LeakyRelu(
    features, alpha=0.2, name=None
)
","Computes rectified linear: max(features, features * alpha).View aliases"
tf.raw_ops.LeakyReluGrad,"tf.raw_ops.LeakyReluGrad(
    gradients, features, alpha=0.2, name=None
)
",Computes rectified linear gradients for a LeakyRelu operation.View aliases
tf.raw_ops.LearnedUnigramCandidateSampler,"tf.raw_ops.LearnedUnigramCandidateSampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=0,
    seed2=0,
    name=None
)
",Generates labels for candidate sampling with a learned unigram distribution.View aliases
tf.raw_ops.LeftShift,"tf.raw_ops.LeftShift(
    x, y, name=None
)
",Elementwise computes the bitwise left-shift of x and y.View aliases
tf.raw_ops.LegacyParallelInterleaveDatasetV2,"tf.raw_ops.LegacyParallelInterleaveDatasetV2(
    input_dataset,
    other_arguments,
    cycle_length,
    block_length,
    buffer_output_elements,
    prefetch_input_elements,
    f,
    output_types,
    output_shapes,
    deterministic='default',
    metadata='',
    name=None
)
",Creates a dataset that applies f to the outputs of input_dataset.View aliases
tf.raw_ops.Less,"tf.raw_ops.Less(
    x, y, name=None
)
",Returns the truth value of (x < y) element-wise.View aliases
tf.raw_ops.LessEqual,"tf.raw_ops.LessEqual(
    x, y, name=None
)
",Returns the truth value of (x <= y) element-wise.View aliases
tf.raw_ops.Lgamma,"tf.raw_ops.Lgamma(
    x, name=None
)
",Computes the log of the absolute value of Gamma(x) element-wise.View aliases
tf.raw_ops.LinSpace,"tf.raw_ops.LinSpace(
    start, stop, num, name=None
)
",Generates values in an interval.View aliases
tf.raw_ops.ListDataset,"tf.raw_ops.ListDataset(
    tensors, output_types, output_shapes, metadata='', name=None
)
",Creates a dataset that emits each of tensors once.View aliases
tf.raw_ops.ListDiff,"tf.raw_ops.ListDiff(
    x,
    y,
    out_idx=tf.dtypes.int32,
    name=None
)
",Computes the difference between two lists of numbers or strings.View aliases
tf.raw_ops.LoadAndRemapMatrix,"tf.raw_ops.LoadAndRemapMatrix(
    ckpt_path,
    old_tensor_name,
    row_remapping,
    col_remapping,
    initializing_values,
    num_rows,
    num_cols,
    max_rows_in_memory=-1,
    name=None
)
",Loads a 2-D (matrix) Tensor with name old_tensor_name from the checkpointView aliases
tf.raw_ops.LoadDataset,"tf.raw_ops.LoadDataset(
    path,
    reader_func_other_args,
    output_types,
    output_shapes,
    reader_func,
    compression='',
    name=None
)
",View aliases
tf.raw_ops.LoadTPUEmbeddingADAMParameters,"tf.raw_ops.LoadTPUEmbeddingADAMParameters(
    parameters,
    momenta,
    velocities,
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Load ADAM embedding parameters.View aliases
tf.raw_ops.LoadTPUEmbeddingAdadeltaParameters,"tf.raw_ops.LoadTPUEmbeddingAdadeltaParameters(
    parameters,
    accumulators,
    updates,
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Load Adadelta embedding parameters.View aliases
tf.raw_ops.LoadTPUEmbeddingAdagradMomentumParameters,"tf.raw_ops.LoadTPUEmbeddingAdagradMomentumParameters(
    parameters,
    accumulators,
    momenta,
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Load Adagrad Momentum embedding parameters.View aliases
tf.raw_ops.LoadTPUEmbeddingAdagradParameters,"tf.raw_ops.LoadTPUEmbeddingAdagradParameters(
    parameters,
    accumulators,
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Load Adagrad embedding parameters.View aliases
tf.raw_ops.LoadTPUEmbeddingCenteredRMSPropParameters,"tf.raw_ops.LoadTPUEmbeddingCenteredRMSPropParameters(
    parameters,
    ms,
    mom,
    mg,
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Load centered RMSProp embedding parameters.View aliases
tf.raw_ops.LoadTPUEmbeddingFTRLParameters,"tf.raw_ops.LoadTPUEmbeddingFTRLParameters(
    parameters,
    accumulators,
    linears,
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Load FTRL embedding parameters.View aliases
tf.raw_ops.LoadTPUEmbeddingFrequencyEstimatorParameters,"tf.raw_ops.LoadTPUEmbeddingFrequencyEstimatorParameters(
    parameters,
    last_hit_step,
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Load frequency estimator embedding parameters.View aliases
tf.raw_ops.LoadTPUEmbeddingMDLAdagradLightParameters,"tf.raw_ops.LoadTPUEmbeddingMDLAdagradLightParameters(
    parameters,
    accumulators,
    weights,
    benefits,
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Load MDL Adagrad Light embedding parameters.View aliases
tf.raw_ops.LoadTPUEmbeddingMomentumParameters,"tf.raw_ops.LoadTPUEmbeddingMomentumParameters(
    parameters,
    momenta,
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Load Momentum embedding parameters.View aliases
tf.raw_ops.LoadTPUEmbeddingProximalAdagradParameters,"tf.raw_ops.LoadTPUEmbeddingProximalAdagradParameters(
    parameters,
    accumulators,
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Load proximal Adagrad embedding parameters.View aliases
tf.raw_ops.LoadTPUEmbeddingProximalYogiParameters,"tf.raw_ops.LoadTPUEmbeddingProximalYogiParameters(
    parameters,
    v,
    m,
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",View aliases
tf.raw_ops.LoadTPUEmbeddingRMSPropParameters,"tf.raw_ops.LoadTPUEmbeddingRMSPropParameters(
    parameters,
    ms,
    mom,
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Load RMSProp embedding parameters.View aliases
tf.raw_ops.LoadTPUEmbeddingStochasticGradientDescentParameters,"tf.raw_ops.LoadTPUEmbeddingStochasticGradientDescentParameters(
    parameters,
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Load SGD embedding parameters.View aliases
tf.raw_ops.Log,"tf.raw_ops.Log(
    x, name=None
)
",Computes natural logarithm of x element-wise.View aliases
tf.raw_ops.Log1p,"tf.raw_ops.Log1p(
    x, name=None
)
",Computes natural logarithm of (1 + x) element-wise.View aliases
tf.raw_ops.LogMatrixDeterminant,"tf.raw_ops.LogMatrixDeterminant(
    input, name=None
)
",Computes the sign and the log of the absolute value of the determinant ofView aliases
tf.raw_ops.LogSoftmax,"tf.raw_ops.LogSoftmax(
    logits, name=None
)
",Computes log softmax activations.View aliases
tf.raw_ops.LogUniformCandidateSampler,"tf.raw_ops.LogUniformCandidateSampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=0,
    seed2=0,
    name=None
)
",Generates labels for candidate sampling with a log-uniform distribution.View aliases
tf.raw_ops.LogicalAnd,"tf.raw_ops.LogicalAnd(
    x, y, name=None
)
",Returns the truth value of x AND y element-wise.View aliases
tf.raw_ops.LogicalNot,"tf.raw_ops.LogicalNot(
    x, name=None
)
",Returns the truth value of NOT x element-wise.View aliases
tf.raw_ops.LogicalOr,"tf.raw_ops.LogicalOr(
    x, y, name=None
)
",Returns the truth value of x OR y element-wise.View aliases
tf.raw_ops.LookupTableExport,"tf.raw_ops.LookupTableExport(
    table_handle, Tkeys, Tvalues, name=None
)
",Outputs all keys and values in the table.View aliases
tf.raw_ops.LookupTableExportV2,"tf.raw_ops.LookupTableExportV2(
    table_handle, Tkeys, Tvalues, name=None
)
",Outputs all keys and values in the table.View aliases
tf.raw_ops.LookupTableFind,"tf.raw_ops.LookupTableFind(
    table_handle, keys, default_value, name=None
)
","Looks up keys in a table, outputs the corresponding values.View aliases"
tf.raw_ops.LookupTableFindV2,"tf.raw_ops.LookupTableFindV2(
    table_handle, keys, default_value, name=None
)
","Looks up keys in a table, outputs the corresponding values.View aliases"
tf.raw_ops.LookupTableImport,"tf.raw_ops.LookupTableImport(
    table_handle, keys, values, name=None
)
",Replaces the contents of the table with the specified keys and values.View aliases
tf.raw_ops.LookupTableImportV2,"tf.raw_ops.LookupTableImportV2(
    table_handle, keys, values, name=None
)
",Replaces the contents of the table with the specified keys and values.View aliases
tf.raw_ops.LookupTableInsert,"tf.raw_ops.LookupTableInsert(
    table_handle, keys, values, name=None
)
",Updates the table to associates keys with values.View aliases
tf.raw_ops.LookupTableInsertV2,"tf.raw_ops.LookupTableInsertV2(
    table_handle, keys, values, name=None
)
",Updates the table to associates keys with values.View aliases
tf.raw_ops.LookupTableRemoveV2,"tf.raw_ops.LookupTableRemoveV2(
    table_handle, keys, name=None
)
",Removes keys and its associated values from a table.View aliases
tf.raw_ops.LookupTableSize,"tf.raw_ops.LookupTableSize(
    table_handle, name=None
)
",Computes the number of elements in the given table.View aliases
tf.raw_ops.LookupTableSizeV2,"tf.raw_ops.LookupTableSizeV2(
    table_handle, name=None
)
",Computes the number of elements in the given table.View aliases
tf.raw_ops.LoopCond,"tf.raw_ops.LoopCond(
    input, name=None
)
",Forwards the input to the output.View aliases
tf.raw_ops.LowerBound,"tf.raw_ops.LowerBound(
    sorted_inputs,
    values,
    out_type=tf.dtypes.int32,
    name=None
)
","Applies lower_bound(sorted_search_values, values) along each row.View aliases"
tf.raw_ops.Lu,"tf.raw_ops.Lu(
    input,
    output_idx_type=tf.dtypes.int32,
    name=None
)
",Computes the LU decomposition of one or more square matrices.View aliases
tf.raw_ops.MakeIterator,"tf.raw_ops.MakeIterator(
    dataset, iterator, name=None
)
",Makes a new iterator from the given dataset and stores it in iterator.View aliases
tf.raw_ops.MapAndBatchDataset,"tf.raw_ops.MapAndBatchDataset(
    input_dataset,
    other_arguments,
    batch_size,
    num_parallel_calls,
    drop_remainder,
    f,
    output_types,
    output_shapes,
    preserve_cardinality=False,
    metadata='',
    name=None
)
",Creates a dataset that fuses mapping with batching.View aliases
tf.raw_ops.MapClear,"tf.raw_ops.MapClear(
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op removes all elements in the underlying container.View aliases
tf.raw_ops.MapDataset,"tf.raw_ops.MapDataset(
    input_dataset,
    other_arguments,
    f,
    output_types,
    output_shapes,
    use_inter_op_parallelism=True,
    preserve_cardinality=False,
    metadata='',
    name=None
)
",Creates a dataset that applies f to the outputs of input_dataset.View aliases
tf.raw_ops.MapDefun,"tf.raw_ops.MapDefun(
    arguments,
    captured_inputs,
    output_types,
    output_shapes,
    f,
    max_intra_op_parallelism=1,
    name=None
)
",Maps a function on the list of tensors unpacked from arguments on dimension 0.View aliases
tf.raw_ops.MapIncompleteSize,"tf.raw_ops.MapIncompleteSize(
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op returns the number of incomplete elements in the underlying container.View aliases
tf.raw_ops.MapPeek,"tf.raw_ops.MapPeek(
    key,
    indices,
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op peeks at the values at the specified key.  If theView aliases
tf.raw_ops.MapSize,"tf.raw_ops.MapSize(
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op returns the number of elements in the underlying container.View aliases
tf.raw_ops.MapStage,"tf.raw_ops.MapStage(
    key,
    indices,
    values,
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
","Stage (key, values) in the underlying container which behaves like a hashtable.View aliases"
tf.raw_ops.MapUnstage,"tf.raw_ops.MapUnstage(
    key,
    indices,
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op removes and returns the values associated with the keyView aliases
tf.raw_ops.MapUnstageNoKey,"tf.raw_ops.MapUnstageNoKey(
    indices,
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
","Op removes and returns a random (key, value)View aliases"
tf.raw_ops.MatMul,"tf.raw_ops.MatMul(
    a, b, transpose_a=False, transpose_b=False, name=None
)
","Multiply the matrix ""a"" by the matrix ""b"".View aliases"
tf.raw_ops.MatchingFiles,"tf.raw_ops.MatchingFiles(
    pattern, name=None
)
",Returns the set of files matching one or more glob patterns.View aliases
tf.raw_ops.MatchingFilesDataset,"tf.raw_ops.MatchingFilesDataset(
    patterns, name=None
)
",View aliases
tf.raw_ops.MatrixBandPart,"tf.raw_ops.MatrixBandPart(
    input, num_lower, num_upper, name=None
)
",Copy a tensor setting everything outside a central band in each innermost matrix to zero.View aliases
tf.raw_ops.MatrixDeterminant,"tf.raw_ops.MatrixDeterminant(
    input, name=None
)
",Computes the determinant of one or more square matrices.View aliases
tf.raw_ops.MatrixDiag,"tf.raw_ops.MatrixDiag(
    diagonal, name=None
)
",Returns a batched diagonal tensor with a given batched diagonal values.View aliases
tf.raw_ops.MatrixDiagPart,"tf.raw_ops.MatrixDiagPart(
    input, name=None
)
",Returns the batched diagonal part of a batched tensor.View aliases
tf.raw_ops.MatrixDiagPartV2,"tf.raw_ops.MatrixDiagPartV2(
    input, k, padding_value, name=None
)
",Returns the batched diagonal part of a batched tensor.View aliases
tf.raw_ops.MatrixDiagPartV3,"tf.raw_ops.MatrixDiagPartV3(
    input, k, padding_value, align='RIGHT_LEFT', name=None
)
",Returns the batched diagonal part of a batched tensor.View aliases
tf.raw_ops.MatrixDiagV2,"tf.raw_ops.MatrixDiagV2(
    diagonal, k, num_rows, num_cols, padding_value, name=None
)
",Returns a batched diagonal tensor with given batched diagonal values.View aliases
tf.raw_ops.MatrixDiagV3,"tf.raw_ops.MatrixDiagV3(
    diagonal,
    k,
    num_rows,
    num_cols,
    padding_value,
    align='RIGHT_LEFT',
    name=None
)
",Returns a batched diagonal tensor with given batched diagonal values.View aliases
tf.raw_ops.MatrixExponential,"tf.raw_ops.MatrixExponential(
    input, name=None
)
","Deprecated, use python implementation tf.linalg.matrix_exponential.View aliases"
tf.raw_ops.MatrixInverse,"tf.raw_ops.MatrixInverse(
    input, adjoint=False, name=None
)
",Computes the inverse of one or more square invertible matrices or their adjoints (conjugate transposes).View aliases
tf.raw_ops.MatrixLogarithm,"tf.raw_ops.MatrixLogarithm(
    input, name=None
)
",Computes the matrix logarithm of one or more square matrices:View aliases
tf.raw_ops.MatrixSetDiag,"tf.raw_ops.MatrixSetDiag(
    input, diagonal, name=None
)
",Returns a batched matrix tensor with new batched diagonal values.View aliases
tf.raw_ops.MatrixSetDiagV2,"tf.raw_ops.MatrixSetDiagV2(
    input, diagonal, k, name=None
)
",Returns a batched matrix tensor with new batched diagonal values.View aliases
tf.raw_ops.MatrixSetDiagV3,"tf.raw_ops.MatrixSetDiagV3(
    input, diagonal, k, align='RIGHT_LEFT', name=None
)
",Returns a batched matrix tensor with new batched diagonal values.View aliases
tf.raw_ops.MatrixSolve,"tf.raw_ops.MatrixSolve(
    matrix, rhs, adjoint=False, name=None
)
",Solves systems of linear equations.View aliases
tf.raw_ops.MatrixSolveLs,"tf.raw_ops.MatrixSolveLs(
    matrix, rhs, l2_regularizer, fast=True, name=None
)
",Solves one or more linear least-squares problems.View aliases
tf.raw_ops.MatrixSquareRoot,"tf.raw_ops.MatrixSquareRoot(
    input, name=None
)
",Computes the matrix square root of one or more square matrices:View aliases
tf.raw_ops.MatrixTriangularSolve,"tf.raw_ops.MatrixTriangularSolve(
    matrix, rhs, lower=True, adjoint=False, name=None
)
",Solves systems of linear equations with upper or lower triangular matrices by backsubstitution.View aliases
tf.raw_ops.Max,"tf.raw_ops.Max(
    input, axis, keep_dims=False, name=None
)
",Computes the maximum of elements across dimensions of a tensor.View aliases
tf.raw_ops.MaxIntraOpParallelismDataset,"tf.raw_ops.MaxIntraOpParallelismDataset(
    input_dataset,
    max_intra_op_parallelism,
    output_types,
    output_shapes,
    name=None
)
",Creates a dataset that overrides the maximum intra-op parallelism.View aliases
tf.raw_ops.MaxPool,"tf.raw_ops.MaxPool(
    input,
    ksize,
    strides,
    padding,
    explicit_paddings=[],
    data_format='NHWC',
    name=None
)
",Performs max pooling on the input.View aliases
tf.raw_ops.MaxPool3D,"tf.raw_ops.MaxPool3D(
    input, ksize, strides, padding, data_format='NDHWC', name=None
)
",Performs 3D max pooling on the input.View aliases
tf.raw_ops.MaxPool3DGrad,"tf.raw_ops.MaxPool3DGrad(
    orig_input,
    orig_output,
    grad,
    ksize,
    strides,
    padding,
    data_format='NDHWC',
    name=None
)
",Computes gradients of 3D max pooling function.View aliases
tf.raw_ops.MaxPool3DGradGrad,"tf.raw_ops.MaxPool3DGradGrad(
    orig_input,
    orig_output,
    grad,
    ksize,
    strides,
    padding,
    data_format='NDHWC',
    name=None
)
",Computes second-order gradients of the maxpooling function.View aliases
tf.raw_ops.MaxPoolGrad,"tf.raw_ops.MaxPoolGrad(
    orig_input,
    orig_output,
    grad,
    ksize,
    strides,
    padding,
    explicit_paddings=[],
    data_format='NHWC',
    name=None
)
",Computes gradients of the maxpooling function.View aliases
tf.raw_ops.MaxPoolGradGrad,"tf.raw_ops.MaxPoolGradGrad(
    orig_input,
    orig_output,
    grad,
    ksize,
    strides,
    padding,
    data_format='NHWC',
    name=None
)
",Computes second-order gradients of the maxpooling function.View aliases
tf.raw_ops.MaxPoolGradGradV2,"tf.raw_ops.MaxPoolGradGradV2(
    orig_input,
    orig_output,
    grad,
    ksize,
    strides,
    padding,
    data_format='NHWC',
    name=None
)
",Computes second-order gradients of the maxpooling function.View aliases
tf.raw_ops.MaxPoolGradGradWithArgmax,"tf.raw_ops.MaxPoolGradGradWithArgmax(
    input,
    grad,
    argmax,
    ksize,
    strides,
    padding,
    include_batch_in_index=False,
    name=None
)
",Computes second-order gradients of the maxpooling function.View aliases
tf.raw_ops.MaxPoolGradV2,"tf.raw_ops.MaxPoolGradV2(
    orig_input,
    orig_output,
    grad,
    ksize,
    strides,
    padding,
    data_format='NHWC',
    name=None
)
",Computes gradients of the maxpooling function.View aliases
tf.raw_ops.MaxPoolGradWithArgmax,"tf.raw_ops.MaxPoolGradWithArgmax(
    input,
    grad,
    argmax,
    ksize,
    strides,
    padding,
    include_batch_in_index=False,
    name=None
)
",Computes gradients of the maxpooling function.View aliases
tf.raw_ops.MaxPoolV2,"tf.raw_ops.MaxPoolV2(
    input, ksize, strides, padding, data_format='NHWC', name=None
)
",Performs max pooling on the input.View aliases
tf.raw_ops.MaxPoolWithArgmax,"tf.raw_ops.MaxPoolWithArgmax(
    input,
    ksize,
    strides,
    padding,
    Targmax=tf.dtypes.int64,
    include_batch_in_index=False,
    name=None
)
",Performs max pooling on the input and outputs both max values and indices.View aliases
tf.raw_ops.Maximum,"tf.raw_ops.Maximum(
    x, y, name=None
)
",Returns the max of x and y (i.e. x > y ? x : y) element-wise.View aliases
tf.raw_ops.Mean,"tf.raw_ops.Mean(
    input, axis, keep_dims=False, name=None
)
",Computes the mean of elements across dimensions of a tensor.View aliases
tf.raw_ops.Merge,"tf.raw_ops.Merge(
    inputs, name=None
)
",Forwards the value of an available tensor from inputs to output.View aliases
tf.raw_ops.MergeSummary,"tf.raw_ops.MergeSummary(
    inputs, name=None
)
",Merges summaries.View aliases
tf.raw_ops.MergeV2Checkpoints,"tf.raw_ops.MergeV2Checkpoints(
    checkpoint_prefixes,
    destination_prefix,
    delete_old_dirs=True,
    allow_missing_files=False,
    name=None
)
",V2 format specific: merges the metadata files of sharded checkpoints.  TheView aliases
tf.raw_ops.Mfcc,"tf.raw_ops.Mfcc(
    spectrogram,
    sample_rate,
    upper_frequency_limit=4000,
    lower_frequency_limit=20,
    filterbank_channel_count=40,
    dct_coefficient_count=13,
    name=None
)
",Transforms a spectrogram into a form that's useful for speech recognition.View aliases
tf.raw_ops.Min,"tf.raw_ops.Min(
    input, axis, keep_dims=False, name=None
)
",Computes the minimum of elements across dimensions of a tensor.View aliases
tf.raw_ops.Minimum,"tf.raw_ops.Minimum(
    x, y, name=None
)
",Returns the min of x and y (i.e. x < y ? x : y) element-wise.View aliases
tf.raw_ops.MirrorPad,"tf.raw_ops.MirrorPad(
    input, paddings, mode, name=None
)
",Pads a tensor with mirrored values.View aliases
tf.raw_ops.MirrorPadGrad,"tf.raw_ops.MirrorPadGrad(
    input, paddings, mode, name=None
)
",Gradient op for MirrorPad op. This op folds a mirror-padded tensor.View aliases
tf.raw_ops.Mod,"tf.raw_ops.Mod(
    x, y, name=None
)
",Returns element-wise remainder of division. This emulates C semantics in thatView aliases
tf.raw_ops.ModelDataset,"tf.raw_ops.ModelDataset(
    input_dataset,
    output_types,
    output_shapes,
    algorithm=0,
    cpu_budget=0,
    ram_budget=0,
    name=None
)
",Identity transformation that models performance.View aliases
tf.raw_ops.Mul,"tf.raw_ops.Mul(
    x, y, name=None
)
",Returns x * y element-wise.View aliases
tf.raw_ops.MulNoNan,"tf.raw_ops.MulNoNan(
    x, y, name=None
)
","Returns x * y element-wise. Returns zero if y is zero, even if x if infinite or NaN.View aliases"
tf.raw_ops.MultiDeviceIterator,"tf.raw_ops.MultiDeviceIterator(
    devices, shared_name, container, output_types, output_shapes, name=None
)
",Creates a MultiDeviceIterator resource.View aliases
tf.raw_ops.MultiDeviceIteratorFromStringHandle,"tf.raw_ops.MultiDeviceIteratorFromStringHandle(
    string_handle, output_types=[], output_shapes=[], name=None
)
",Generates a MultiDeviceIterator resource from its provided string handle.View aliases
tf.raw_ops.MultiDeviceIteratorGetNextFromShard,"tf.raw_ops.MultiDeviceIteratorGetNextFromShard(
    multi_device_iterator,
    shard_num,
    incarnation_id,
    output_types,
    output_shapes,
    name=None
)
",Gets next element for the provided shard number.View aliases
tf.raw_ops.MultiDeviceIteratorInit,"tf.raw_ops.MultiDeviceIteratorInit(
    dataset, multi_device_iterator, max_buffer_size, name=None
)
",Initializes the multi device iterator with the given dataset.View aliases
tf.raw_ops.MultiDeviceIteratorToStringHandle,"tf.raw_ops.MultiDeviceIteratorToStringHandle(
    multi_device_iterator, name=None
)
",Produces a string handle for the given MultiDeviceIterator.View aliases
tf.raw_ops.Multinomial,"tf.raw_ops.Multinomial(
    logits,
    num_samples,
    seed=0,
    seed2=0,
    output_dtype=tf.dtypes.int64,
    name=None
)
",Draws samples from a multinomial distribution.View aliases
tf.raw_ops.MutableDenseHashTable,"tf.raw_ops.MutableDenseHashTable(
    empty_key,
    value_dtype,
    container='',
    shared_name='',
    use_node_name_sharing=False,
    value_shape=[],
    initial_num_buckets=131072,
    max_load_factor=0.8,
    name=None
)
",Creates an empty hash table that uses tensors as the backing store.View aliases
tf.raw_ops.MutableDenseHashTableV2,"tf.raw_ops.MutableDenseHashTableV2(
    empty_key,
    deleted_key,
    value_dtype,
    container='',
    shared_name='',
    use_node_name_sharing=False,
    value_shape=[],
    initial_num_buckets=131072,
    max_load_factor=0.8,
    name=None
)
",Creates an empty hash table that uses tensors as the backing store.View aliases
tf.raw_ops.MutableHashTable,"tf.raw_ops.MutableHashTable(
    key_dtype,
    value_dtype,
    container='',
    shared_name='',
    use_node_name_sharing=False,
    name=None
)
",Creates an empty hash table.View aliases
tf.raw_ops.MutableHashTableOfTensors,"tf.raw_ops.MutableHashTableOfTensors(
    key_dtype,
    value_dtype,
    container='',
    shared_name='',
    use_node_name_sharing=False,
    value_shape=[],
    name=None
)
",Creates an empty hash table.View aliases
tf.raw_ops.MutableHashTableOfTensorsV2,"tf.raw_ops.MutableHashTableOfTensorsV2(
    key_dtype,
    value_dtype,
    container='',
    shared_name='',
    use_node_name_sharing=False,
    value_shape=[],
    name=None
)
",Creates an empty hash table.View aliases
tf.raw_ops.MutableHashTableV2,"tf.raw_ops.MutableHashTableV2(
    key_dtype,
    value_dtype,
    container='',
    shared_name='',
    use_node_name_sharing=False,
    name=None
)
",Creates an empty hash table.View aliases
tf.raw_ops.MutexLock,"tf.raw_ops.MutexLock(
    mutex, name=None
)
",Locks a mutex resource.  The output is the lock.  So long as the lock tensorView aliases
tf.raw_ops.MutexV2,"tf.raw_ops.MutexV2(
    container='', shared_name='', name=None
)
",Creates a Mutex resource that can be locked by MutexLock.View aliases
tf.raw_ops.NcclAllReduce,"tf.raw_ops.NcclAllReduce(
    input, reduction, num_devices, shared_name, name=None
)
",Outputs a tensor containing the reduction across all input tensors.View aliases
tf.raw_ops.NcclBroadcast,"tf.raw_ops.NcclBroadcast(
    input, shape, name=None
)
",Sends input to all devices that are connected to the output.View aliases
tf.raw_ops.NcclReduce,"tf.raw_ops.NcclReduce(
    input, reduction, name=None
)
",Reduces input from num_devices using reduction to a single device.View aliases
tf.raw_ops.Ndtri,"tf.raw_ops.Ndtri(
    x, name=None
)
",View aliases
tf.raw_ops.Neg,"tf.raw_ops.Neg(
    x, name=None
)
",Computes numerical negative value element-wise.View aliases
tf.raw_ops.NextAfter,"tf.raw_ops.NextAfter(
    x1, x2, name=None
)
","Returns the next representable value of x1 in the direction of x2, element-wise.View aliases"
tf.raw_ops.NextIteration,"tf.raw_ops.NextIteration(
    data, name=None
)
",Makes its input available to the next iteration.View aliases
tf.raw_ops.NoOp,"tf.raw_ops.NoOp(
    name=None
)
",Does nothing. Only useful as a placeholder for control edges.View aliases
tf.raw_ops.NonDeterministicInts,"tf.raw_ops.NonDeterministicInts(
    shape,
    dtype=tf.dtypes.int64,
    name=None
)
",Non-deterministically generates some integers.View aliases
tf.raw_ops.NonMaxSuppression,"tf.raw_ops.NonMaxSuppression(
    boxes, scores, max_output_size, iou_threshold=0.5, name=None
)
","Greedily selects a subset of bounding boxes in descending order of score,View aliases"
tf.raw_ops.NonMaxSuppressionV2,"tf.raw_ops.NonMaxSuppressionV2(
    boxes, scores, max_output_size, iou_threshold, name=None
)
","Greedily selects a subset of bounding boxes in descending order of score,View aliases"
tf.raw_ops.NonMaxSuppressionV3,"tf.raw_ops.NonMaxSuppressionV3(
    boxes, scores, max_output_size, iou_threshold, score_threshold, name=None
)
","Greedily selects a subset of bounding boxes in descending order of score,View aliases"
tf.raw_ops.NonMaxSuppressionV4,"tf.raw_ops.NonMaxSuppressionV4(
    boxes,
    scores,
    max_output_size,
    iou_threshold,
    score_threshold,
    pad_to_max_output_size=False,
    name=None
)
","Greedily selects a subset of bounding boxes in descending order of score,View aliases"
tf.raw_ops.NonMaxSuppressionV5,"tf.raw_ops.NonMaxSuppressionV5(
    boxes,
    scores,
    max_output_size,
    iou_threshold,
    score_threshold,
    soft_nms_sigma,
    pad_to_max_output_size=False,
    name=None
)
","Greedily selects a subset of bounding boxes in descending order of score,View aliases"
tf.raw_ops.NonMaxSuppressionWithOverlaps,"tf.raw_ops.NonMaxSuppressionWithOverlaps(
    overlaps,
    scores,
    max_output_size,
    overlap_threshold,
    score_threshold,
    name=None
)
","Greedily selects a subset of bounding boxes in descending order of score,View aliases"
tf.raw_ops.NonSerializableDataset,"tf.raw_ops.NonSerializableDataset(
    input_dataset, output_types, output_shapes, name=None
)
",View aliases
tf.raw_ops.NotEqual,"tf.raw_ops.NotEqual(
    x, y, incompatible_shape_error=True, name=None
)
",Returns the truth value of (x != y) element-wise.View aliases
tf.raw_ops.NthElement,"tf.raw_ops.NthElement(
    input, n, reverse=False, name=None
)
",Finds values of the n-th order statistic for the last dimension.View aliases
tf.raw_ops.OneHot,"tf.raw_ops.OneHot(
    indices, depth, on_value, off_value, axis=-1, name=None
)
",Returns a one-hot tensor.View aliases
tf.raw_ops.OneShotIterator,"tf.raw_ops.OneShotIterator(
    dataset_factory,
    output_types,
    output_shapes,
    container='',
    shared_name='',
    name=None
)
","Makes a ""one-shot"" iterator that can be iterated only once.View aliases"
tf.raw_ops.OnesLike,"tf.raw_ops.OnesLike(
    x, name=None
)
",Returns a tensor of ones with the same shape and type as x.View aliases
tf.raw_ops.OptimizeDataset,"tf.raw_ops.OptimizeDataset(
    input_dataset,
    optimizations,
    output_types,
    output_shapes,
    optimization_configs=[],
    name=None
)
",Creates a dataset by applying optimizations to input_dataset.View aliases
tf.raw_ops.OptimizeDatasetV2,"tf.raw_ops.OptimizeDatasetV2(
    input_dataset,
    optimizations_enabled,
    optimizations_disabled,
    optimizations_default,
    output_types,
    output_shapes,
    optimization_configs=[],
    name=None
)
",Creates a dataset by applying related optimizations to input_dataset.View aliases
tf.raw_ops.OptionalFromValue,"tf.raw_ops.OptionalFromValue(
    components, name=None
)
",Constructs an Optional variant from a tuple of tensors.View aliases
tf.raw_ops.OptionalGetValue,"tf.raw_ops.OptionalGetValue(
    optional, output_types, output_shapes, name=None
)
",Returns the value stored in an Optional variant or raises an error if none exists.View aliases
tf.raw_ops.OptionalHasValue,"tf.raw_ops.OptionalHasValue(
    optional, name=None
)
",Returns true if and only if the given Optional variant has a value.View aliases
tf.raw_ops.OptionalNone,"tf.raw_ops.OptionalNone(
    name=None
)
",Creates an Optional variant with no value.View aliases
tf.raw_ops.OptionsDataset,"tf.raw_ops.OptionsDataset(
    input_dataset,
    serialized_options,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset by attaching tf.data.Options to input_dataset.View aliases
tf.raw_ops.OrderedMapClear,"tf.raw_ops.OrderedMapClear(
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op removes all elements in the underlying container.View aliases
tf.raw_ops.OrderedMapIncompleteSize,"tf.raw_ops.OrderedMapIncompleteSize(
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op returns the number of incomplete elements in the underlying container.View aliases
tf.raw_ops.OrderedMapPeek,"tf.raw_ops.OrderedMapPeek(
    key,
    indices,
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op peeks at the values at the specified key.  If theView aliases
tf.raw_ops.OrderedMapSize,"tf.raw_ops.OrderedMapSize(
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op returns the number of elements in the underlying container.View aliases
tf.raw_ops.OrderedMapStage,"tf.raw_ops.OrderedMapStage(
    key,
    indices,
    values,
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
","Stage (key, values) in the underlying container which behaves like a orderedView aliases"
tf.raw_ops.OrderedMapUnstage,"tf.raw_ops.OrderedMapUnstage(
    key,
    indices,
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op removes and returns the values associated with the keyView aliases
tf.raw_ops.OrderedMapUnstageNoKey,"tf.raw_ops.OrderedMapUnstageNoKey(
    indices,
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
","Op removes and returns the (key, value) element with the smallestView aliases"
tf.raw_ops.OutfeedDequeue,"tf.raw_ops.OutfeedDequeue(
    dtype, shape, device_ordinal=-1, name=None
)
",Retrieves a single tensor from the computation outfeed.View aliases
tf.raw_ops.OutfeedDequeueTuple,"tf.raw_ops.OutfeedDequeueTuple(
    dtypes, shapes, device_ordinal=-1, name=None
)
",Retrieve multiple values from the computation outfeed.View aliases
tf.raw_ops.OutfeedDequeueTupleV2,"tf.raw_ops.OutfeedDequeueTupleV2(
    device_ordinal, dtypes, shapes, name=None
)
",Retrieve multiple values from the computation outfeed. Device ordinal is aView aliases
tf.raw_ops.OutfeedDequeueV2,"tf.raw_ops.OutfeedDequeueV2(
    device_ordinal, dtype, shape, name=None
)
",Retrieves a single tensor from the computation outfeed. Device ordinal is aView aliases
tf.raw_ops.OutfeedEnqueue,"tf.raw_ops.OutfeedEnqueue(
    input, name=None
)
",Enqueue a Tensor on the computation outfeed.View aliases
tf.raw_ops.OutfeedEnqueueTuple,"tf.raw_ops.OutfeedEnqueueTuple(
    inputs, name=None
)
",Enqueue multiple Tensor values on the computation outfeed.View aliases
tf.raw_ops.Pack,"tf.raw_ops.Pack(
    values, axis=0, name=None
)
",Packs a list of N rank-R tensors into one rank-(R+1) tensor.View aliases
tf.raw_ops.Pad,"tf.raw_ops.Pad(
    input, paddings, name=None
)
",Pads a tensor with zeros.View aliases
tf.raw_ops.PadV2,"tf.raw_ops.PadV2(
    input, paddings, constant_values, name=None
)
",Pads a tensor.View aliases
tf.raw_ops.PaddedBatchDataset,"tf.raw_ops.PaddedBatchDataset(
    input_dataset,
    batch_size,
    padded_shapes,
    padding_values,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that batches and pads batch_size elements from the input.View aliases
tf.raw_ops.PaddedBatchDatasetV2,"tf.raw_ops.PaddedBatchDatasetV2(
    input_dataset,
    batch_size,
    padded_shapes,
    padding_values,
    drop_remainder,
    output_shapes,
    parallel_copy=False,
    metadata='',
    name=None
)
",Creates a dataset that batches and pads batch_size elements from the input.View aliases
tf.raw_ops.PaddingFIFOQueue,"tf.raw_ops.PaddingFIFOQueue(
    component_types,
    shapes=[],
    capacity=-1,
    container='',
    shared_name='',
    name=None
)
",A queue that produces elements in first-in first-out order.View aliases
tf.raw_ops.PaddingFIFOQueueV2,"tf.raw_ops.PaddingFIFOQueueV2(
    component_types,
    shapes=[],
    capacity=-1,
    container='',
    shared_name='',
    name=None
)
",A queue that produces elements in first-in first-out order.View aliases
tf.raw_ops.ParallelBatchDataset,"tf.raw_ops.ParallelBatchDataset(
    input_dataset,
    batch_size,
    num_parallel_calls,
    drop_remainder,
    output_types,
    output_shapes,
    parallel_copy=False,
    deterministic='default',
    metadata='',
    name=None
)
",View aliases
tf.raw_ops.ParallelConcat,"tf.raw_ops.ParallelConcat(
    values, shape, name=None
)
",Concatenates a list of N tensors along the first dimension.View aliases
tf.raw_ops.ParallelDynamicStitch,"tf.raw_ops.ParallelDynamicStitch(
    indices, data, name=None
)
",Interleave the values from the data tensors into a single tensor.View aliases
tf.raw_ops.ParallelFilterDataset,"tf.raw_ops.ParallelFilterDataset(
    input_dataset,
    other_arguments,
    num_parallel_calls,
    predicate,
    output_types,
    output_shapes,
    deterministic='default',
    metadata='',
    name=None
)
",Creates a dataset containing elements of input_dataset matching predicate.View aliases
tf.raw_ops.ParallelInterleaveDataset,"tf.raw_ops.ParallelInterleaveDataset(
    input_dataset,
    other_arguments,
    cycle_length,
    block_length,
    sloppy,
    buffer_output_elements,
    prefetch_input_elements,
    f,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that applies f to the outputs of input_dataset.View aliases
tf.raw_ops.ParallelInterleaveDatasetV2,"tf.raw_ops.ParallelInterleaveDatasetV2(
    input_dataset,
    other_arguments,
    cycle_length,
    block_length,
    num_parallel_calls,
    f,
    output_types,
    output_shapes,
    sloppy=False,
    metadata='',
    name=None
)
",Creates a dataset that applies f to the outputs of input_dataset.View aliases
tf.raw_ops.ParallelInterleaveDatasetV3,"tf.raw_ops.ParallelInterleaveDatasetV3(
    input_dataset,
    other_arguments,
    cycle_length,
    block_length,
    num_parallel_calls,
    f,
    output_types,
    output_shapes,
    deterministic='default',
    metadata='',
    name=None
)
",Creates a dataset that applies f to the outputs of input_dataset.View aliases
tf.raw_ops.ParallelInterleaveDatasetV4,"tf.raw_ops.ParallelInterleaveDatasetV4(
    input_dataset,
    other_arguments,
    cycle_length,
    block_length,
    buffer_output_elements,
    prefetch_input_elements,
    num_parallel_calls,
    f,
    output_types,
    output_shapes,
    deterministic='default',
    metadata='',
    name=None
)
",Creates a dataset that applies f to the outputs of input_dataset.View aliases
tf.raw_ops.ParallelMapDataset,"tf.raw_ops.ParallelMapDataset(
    input_dataset,
    other_arguments,
    num_parallel_calls,
    f,
    output_types,
    output_shapes,
    use_inter_op_parallelism=True,
    sloppy=False,
    preserve_cardinality=False,
    metadata='',
    name=None
)
",Creates a dataset that applies f to the outputs of input_dataset.View aliases
tf.raw_ops.ParallelMapDatasetV2,"tf.raw_ops.ParallelMapDatasetV2(
    input_dataset,
    other_arguments,
    num_parallel_calls,
    f,
    output_types,
    output_shapes,
    use_inter_op_parallelism=True,
    deterministic='default',
    preserve_cardinality=False,
    metadata='',
    name=None
)
",Creates a dataset that applies f to the outputs of input_dataset.View aliases
tf.raw_ops.ParameterizedTruncatedNormal,"tf.raw_ops.ParameterizedTruncatedNormal(
    shape, means, stdevs, minvals, maxvals, seed=0, seed2=0, name=None
)
",Outputs random values from a normal distribution. The parameters may each be aView aliases
tf.raw_ops.ParseExample,"tf.raw_ops.ParseExample(
    serialized,
    names,
    sparse_keys,
    dense_keys,
    dense_defaults,
    sparse_types,
    dense_shapes,
    name=None
)
",Transforms a vector of brain.Example protos (as strings) into typed tensors.View aliases
tf.raw_ops.ParseExampleDataset,"tf.raw_ops.ParseExampleDataset(
    input_dataset,
    num_parallel_calls,
    dense_defaults,
    sparse_keys,
    dense_keys,
    sparse_types,
    dense_shapes,
    output_types,
    output_shapes,
    sloppy=False,
    ragged_keys=[],
    ragged_value_types=[],
    ragged_split_types=[],
    name=None
)
",Transforms input_dataset containing Example protos as vectors of DT_STRING into a dataset of Tensor or SparseTensor objects representing the parsed features.View aliases
tf.raw_ops.ParseExampleDatasetV2,"tf.raw_ops.ParseExampleDatasetV2(
    input_dataset,
    num_parallel_calls,
    dense_defaults,
    sparse_keys,
    dense_keys,
    sparse_types,
    dense_shapes,
    output_types,
    output_shapes,
    deterministic='default',
    ragged_keys=[],
    ragged_value_types=[],
    ragged_split_types=[],
    name=None
)
",Transforms input_dataset containing Example protos as vectors of DT_STRING into a dataset of Tensor or SparseTensor objects representing the parsed features.View aliases
tf.raw_ops.ParseExampleV2,"tf.raw_ops.ParseExampleV2(
    serialized,
    names,
    sparse_keys,
    dense_keys,
    ragged_keys,
    dense_defaults,
    num_sparse,
    sparse_types,
    ragged_value_types,
    ragged_split_types,
    dense_shapes,
    name=None
)
",Transforms a vector of tf.Example protos (as strings) into typed tensors.View aliases
tf.raw_ops.ParseSequenceExample,"tf.raw_ops.ParseSequenceExample(
    serialized,
    debug_name,
    context_dense_defaults,
    feature_list_dense_missing_assumed_empty,
    context_sparse_keys,
    context_dense_keys,
    feature_list_sparse_keys,
    feature_list_dense_keys,
    Ncontext_sparse=0,
    Ncontext_dense=0,
    Nfeature_list_sparse=0,
    Nfeature_list_dense=0,
    context_sparse_types=[],
    feature_list_dense_types=[],
    context_dense_shapes=[],
    feature_list_sparse_types=[],
    feature_list_dense_shapes=[],
    name=None
)
",Transforms a vector of brain.SequenceExample protos (as strings) into typed tensors.View aliases
tf.raw_ops.ParseSequenceExampleV2,"tf.raw_ops.ParseSequenceExampleV2(
    serialized,
    debug_name,
    context_sparse_keys,
    context_dense_keys,
    context_ragged_keys,
    feature_list_sparse_keys,
    feature_list_dense_keys,
    feature_list_ragged_keys,
    feature_list_dense_missing_assumed_empty,
    context_dense_defaults,
    Ncontext_sparse=0,
    context_sparse_types=[],
    context_ragged_value_types=[],
    context_ragged_split_types=[],
    context_dense_shapes=[],
    Nfeature_list_sparse=0,
    Nfeature_list_dense=0,
    feature_list_dense_types=[],
    feature_list_sparse_types=[],
    feature_list_ragged_value_types=[],
    feature_list_ragged_split_types=[],
    feature_list_dense_shapes=[],
    name=None
)
",Transforms a vector of tf.io.SequenceExample protos (as strings) intoView aliases
tf.raw_ops.ParseSingleExample,"tf.raw_ops.ParseSingleExample(
    serialized,
    dense_defaults,
    num_sparse,
    sparse_keys,
    dense_keys,
    sparse_types,
    dense_shapes,
    name=None
)
",Transforms a tf.Example proto (as a string) into typed tensors.View aliases
tf.raw_ops.ParseSingleSequenceExample,"tf.raw_ops.ParseSingleSequenceExample(
    serialized,
    feature_list_dense_missing_assumed_empty,
    context_sparse_keys,
    context_dense_keys,
    feature_list_sparse_keys,
    feature_list_dense_keys,
    context_dense_defaults,
    debug_name,
    context_sparse_types=[],
    feature_list_dense_types=[],
    context_dense_shapes=[],
    feature_list_sparse_types=[],
    feature_list_dense_shapes=[],
    name=None
)
",Transforms a scalar brain.SequenceExample proto (as strings) into typed tensors.View aliases
tf.raw_ops.ParseTensor,"tf.raw_ops.ParseTensor(
    serialized, out_type, name=None
)
",Transforms a serialized tensorflow.TensorProto proto into a Tensor.View aliases
tf.raw_ops.PartitionedCall,"tf.raw_ops.PartitionedCall(
    args,
    Tout,
    f,
    config='',
    config_proto='',
    executor_type='',
    name=None
)
","returns f(inputs), where f's body is placed and partitioned.View aliases"
tf.raw_ops.Placeholder,"tf.raw_ops.Placeholder(
    dtype, shape=None, name=None
)
",A placeholder op for a value that will be fed into the computation.View aliases
tf.raw_ops.PlaceholderV2,"tf.raw_ops.PlaceholderV2(
    dtype, shape, name=None
)
",A placeholder op for a value that will be fed into the computation.View aliases
tf.raw_ops.PlaceholderWithDefault,"tf.raw_ops.PlaceholderWithDefault(
    input, shape, name=None
)
",A placeholder op that passes through input when its output is not fed.View aliases
tf.raw_ops.Polygamma,"tf.raw_ops.Polygamma(
    a, x, name=None
)
",Compute the polygamma function \(\psi^{(n)}(x)\).View aliases
tf.raw_ops.PopulationCount,"tf.raw_ops.PopulationCount(
    x, name=None
)
","Computes element-wise population count (a.k.a. popcount, bitsum, bitcount).View aliases"
tf.raw_ops.Pow,"tf.raw_ops.Pow(
    x, y, name=None
)
",Computes the power of one value to another.View aliases
tf.raw_ops.PrefetchDataset,"tf.raw_ops.PrefetchDataset(
    input_dataset,
    buffer_size,
    output_types,
    output_shapes,
    slack_period=0,
    legacy_autotune=True,
    buffer_size_min=0,
    metadata='',
    name=None
)
",Creates a dataset that asynchronously prefetches elements from input_dataset.View aliases
tf.raw_ops.Prelinearize,"tf.raw_ops.Prelinearize(
    input, shape=[], layout=[], name=None
)
",An op which linearizes one Tensor value to an opaque variant tensor.View aliases
tf.raw_ops.PrelinearizeTuple,"tf.raw_ops.PrelinearizeTuple(
    inputs, shapes, layouts=[], name=None
)
",An op which linearizes multiple Tensor values to an opaque variant tensor.View aliases
tf.raw_ops.PreventGradient,"tf.raw_ops.PreventGradient(
    input, message='', name=None
)
",An identity op that triggers an error if a gradient is requested.View aliases
tf.raw_ops.Print,"tf.raw_ops.Print(
    input, data, message='', first_n=-1, summarize=3, name=None
)
",Prints a list of tensors.View aliases
tf.raw_ops.PrintV2,"tf.raw_ops.PrintV2(
    input, output_stream='stderr', end='\n', name=None
)
",Prints a string scalar.View aliases
tf.raw_ops.PriorityQueue,"tf.raw_ops.PriorityQueue(
    shapes,
    component_types=[],
    capacity=-1,
    container='',
    shared_name='',
    name=None
)
",A queue that produces elements sorted by the first component value.View aliases
tf.raw_ops.PriorityQueueV2,"tf.raw_ops.PriorityQueueV2(
    shapes,
    component_types=[],
    capacity=-1,
    container='',
    shared_name='',
    name=None
)
",A queue that produces elements sorted by the first component value.View aliases
tf.raw_ops.PrivateThreadPoolDataset,"tf.raw_ops.PrivateThreadPoolDataset(
    input_dataset, num_threads, output_types, output_shapes, name=None
)
",Creates a dataset that uses a custom thread pool to compute input_dataset.View aliases
tf.raw_ops.Prod,"tf.raw_ops.Prod(
    input, axis, keep_dims=False, name=None
)
",Computes the product of elements across dimensions of a tensor.View aliases
tf.raw_ops.PyFunc,"tf.raw_ops.PyFunc(
    input, token, Tout, name=None
)
",Invokes a python function to compute func(input)->output.View aliases
tf.raw_ops.PyFuncStateless,"tf.raw_ops.PyFuncStateless(
    input, token, Tout, name=None
)
",A stateless version of PyFunc.View aliases
tf.raw_ops.Qr,"tf.raw_ops.Qr(
    input, full_matrices=False, name=None
)
",Computes the QR decompositions of one or more matrices.View aliases
tf.raw_ops.QuantizeAndDequantize,"tf.raw_ops.QuantizeAndDequantize(
    input,
    signed_input=True,
    num_bits=8,
    range_given=False,
    input_min=0,
    input_max=0,
    name=None
)
",Use QuantizeAndDequantizeV2 instead.View aliases
tf.raw_ops.QuantizeAndDequantizeV2,"tf.raw_ops.QuantizeAndDequantizeV2(
    input,
    input_min,
    input_max,
    signed_input=True,
    num_bits=8,
    range_given=False,
    round_mode='HALF_TO_EVEN',
    narrow_range=False,
    axis=-1,
    name=None
)
",Quantizes then dequantizes a tensor.View aliases
tf.raw_ops.QuantizeAndDequantizeV3,"tf.raw_ops.QuantizeAndDequantizeV3(
    input,
    input_min,
    input_max,
    num_bits,
    signed_input=True,
    range_given=True,
    narrow_range=False,
    axis=-1,
    name=None
)
",Quantizes then dequantizes a tensor.View aliases
tf.raw_ops.QuantizeAndDequantizeV4,"tf.raw_ops.QuantizeAndDequantizeV4(
    input,
    input_min,
    input_max,
    signed_input=True,
    num_bits=8,
    range_given=False,
    round_mode='HALF_TO_EVEN',
    narrow_range=False,
    axis=-1,
    name=None
)
",Quantizes then dequantizes a tensor.View aliases
tf.raw_ops.QuantizeAndDequantizeV4Grad,"tf.raw_ops.QuantizeAndDequantizeV4Grad(
    gradients, input, input_min, input_max, axis=-1, name=None
)
",Returns the gradient of QuantizeAndDequantizeV4.View aliases
tf.raw_ops.QuantizeDownAndShrinkRange,"tf.raw_ops.QuantizeDownAndShrinkRange(
    input, input_min, input_max, out_type, name=None
)
","Convert the quantized 'input' tensor into a lower-precision 'output', using theView aliases"
tf.raw_ops.QuantizeV2,"tf.raw_ops.QuantizeV2(
    input,
    min_range,
    max_range,
    T,
    mode='MIN_COMBINED',
    round_mode='HALF_AWAY_FROM_ZERO',
    narrow_range=False,
    axis=-1,
    ensure_minimum_range=0.01,
    name=None
)
",Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.View aliases
tf.raw_ops.QuantizedAdd,"tf.raw_ops.QuantizedAdd(
    x,
    y,
    min_x,
    max_x,
    min_y,
    max_y,
    Toutput=tf.dtypes.qint32,
    name=None
)
","Returns x + y element-wise, working on quantized buffers.View aliases"
tf.raw_ops.QuantizedAvgPool,"tf.raw_ops.QuantizedAvgPool(
    input, min_input, max_input, ksize, strides, padding, name=None
)
",Produces the average pool of the input tensor for quantized types.View aliases
tf.raw_ops.QuantizedBatchNormWithGlobalNormalization,"tf.raw_ops.QuantizedBatchNormWithGlobalNormalization(
    t,
    t_min,
    t_max,
    m,
    m_min,
    m_max,
    v,
    v_min,
    v_max,
    beta,
    beta_min,
    beta_max,
    gamma,
    gamma_min,
    gamma_max,
    out_type,
    variance_epsilon,
    scale_after_normalization,
    name=None
)
",Quantized Batch normalization.View aliases
tf.raw_ops.QuantizedBiasAdd,"tf.raw_ops.QuantizedBiasAdd(
    input, bias, min_input, max_input, min_bias, max_bias, out_type, name=None
)
",Adds Tensor 'bias' to Tensor 'input' for Quantized types.View aliases
tf.raw_ops.QuantizedConcat,"tf.raw_ops.QuantizedConcat(
    concat_dim, values, input_mins, input_maxes, name=None
)
",Concatenates quantized tensors along one dimension.View aliases
tf.raw_ops.QuantizedConv2D,"tf.raw_ops.QuantizedConv2D(
    input,
    filter,
    min_input,
    max_input,
    min_filter,
    max_filter,
    strides,
    padding,
    out_type=tf.dtypes.qint32,
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes a 2D convolution given quantized 4D input and filter tensors.View aliases
tf.raw_ops.QuantizedConv2DAndRelu,"tf.raw_ops.QuantizedConv2DAndRelu(
    input,
    filter,
    min_input,
    max_input,
    min_filter,
    max_filter,
    strides,
    padding,
    out_type=tf.dtypes.qint32,
    dilations=[1, 1, 1, 1],
    padding_list=[],
    name=None
)
",View aliases
tf.raw_ops.QuantizedConv2DAndReluAndRequantize,"tf.raw_ops.QuantizedConv2DAndReluAndRequantize(
    input,
    filter,
    min_input,
    max_input,
    min_filter,
    max_filter,
    min_freezed_output,
    max_freezed_output,
    strides,
    padding,
    out_type=tf.dtypes.quint8,
    dilations=[1, 1, 1, 1],
    padding_list=[],
    name=None
)
",View aliases
tf.raw_ops.QuantizedConv2DAndRequantize,"tf.raw_ops.QuantizedConv2DAndRequantize(
    input,
    filter,
    min_input,
    max_input,
    min_filter,
    max_filter,
    min_freezed_output,
    max_freezed_output,
    strides,
    padding,
    out_type=tf.dtypes.qint8,
    dilations=[1, 1, 1, 1],
    padding_list=[],
    name=None
)
",View aliases
tf.raw_ops.QuantizedConv2DPerChannel,"tf.raw_ops.QuantizedConv2DPerChannel(
    input,
    filter,
    min_input,
    max_input,
    min_filter,
    max_filter,
    strides,
    padding,
    out_type=tf.dtypes.qint32,
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes QuantizedConv2D per channel.View aliases
tf.raw_ops.QuantizedConv2DWithBias,"tf.raw_ops.QuantizedConv2DWithBias(
    input,
    filter,
    bias,
    min_input,
    max_input,
    min_filter,
    max_filter,
    strides,
    padding,
    out_type=tf.dtypes.qint32,
    dilations=[1, 1, 1, 1],
    padding_list=[],
    name=None
)
",View aliases
tf.raw_ops.QuantizedConv2DWithBiasAndRelu,"tf.raw_ops.QuantizedConv2DWithBiasAndRelu(
    input,
    filter,
    bias,
    min_input,
    max_input,
    min_filter,
    max_filter,
    strides,
    padding,
    out_type=tf.dtypes.qint32,
    dilations=[1, 1, 1, 1],
    padding_list=[],
    name=None
)
",View aliases
tf.raw_ops.QuantizedConv2DWithBiasAndReluAndRequantize,"tf.raw_ops.QuantizedConv2DWithBiasAndReluAndRequantize(
    input,
    filter,
    bias,
    min_input,
    max_input,
    min_filter,
    max_filter,
    min_freezed_output,
    max_freezed_output,
    strides,
    padding,
    out_type=tf.dtypes.quint8,
    dilations=[1, 1, 1, 1],
    padding_list=[],
    name=None
)
",View aliases
tf.raw_ops.QuantizedConv2DWithBiasAndRequantize,"tf.raw_ops.QuantizedConv2DWithBiasAndRequantize(
    input,
    filter,
    bias,
    min_input,
    max_input,
    min_filter,
    max_filter,
    min_freezed_output,
    max_freezed_output,
    strides,
    padding,
    out_type=tf.dtypes.qint8,
    dilations=[1, 1, 1, 1],
    padding_list=[],
    name=None
)
",View aliases
tf.raw_ops.QuantizedConv2DWithBiasSignedSumAndReluAndRequantize,"tf.raw_ops.QuantizedConv2DWithBiasSignedSumAndReluAndRequantize(
    input,
    filter,
    bias,
    min_input,
    max_input,
    min_filter,
    max_filter,
    min_freezed_output,
    max_freezed_output,
    summand,
    min_summand,
    max_summand,
    strides,
    padding,
    out_type=tf.dtypes.quint8,
    dilations=[1, 1, 1, 1],
    padding_list=[],
    name=None
)
",View aliases
tf.raw_ops.QuantizedConv2DWithBiasSumAndRelu,"tf.raw_ops.QuantizedConv2DWithBiasSumAndRelu(
    input,
    filter,
    bias,
    min_input,
    max_input,
    min_filter,
    max_filter,
    summand,
    strides,
    padding,
    out_type=tf.dtypes.qint32,
    dilations=[1, 1, 1, 1],
    padding_list=[],
    name=None
)
",View aliases
tf.raw_ops.QuantizedConv2DWithBiasSumAndReluAndRequantize,"tf.raw_ops.QuantizedConv2DWithBiasSumAndReluAndRequantize(
    input,
    filter,
    bias,
    min_input,
    max_input,
    min_filter,
    max_filter,
    min_freezed_output,
    max_freezed_output,
    summand,
    min_summand,
    max_summand,
    strides,
    padding,
    out_type=tf.dtypes.quint8,
    dilations=[1, 1, 1, 1],
    padding_list=[],
    name=None
)
",View aliases
tf.raw_ops.QuantizedDepthwiseConv2D,"tf.raw_ops.QuantizedDepthwiseConv2D(
    input,
    filter,
    min_input,
    max_input,
    min_filter,
    max_filter,
    strides,
    padding,
    out_type=tf.dtypes.qint32,
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes quantized depthwise Conv2D.View aliases
tf.raw_ops.QuantizedDepthwiseConv2DWithBias,"tf.raw_ops.QuantizedDepthwiseConv2DWithBias(
    input,
    filter,
    bias,
    min_input,
    max_input,
    min_filter,
    max_filter,
    strides,
    padding,
    out_type=tf.dtypes.qint32,
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes quantized depthwise Conv2D with Bias.View aliases
tf.raw_ops.QuantizedDepthwiseConv2DWithBiasAndRelu,"tf.raw_ops.QuantizedDepthwiseConv2DWithBiasAndRelu(
    input,
    filter,
    bias,
    min_input,
    max_input,
    min_filter,
    max_filter,
    strides,
    padding,
    out_type=tf.dtypes.qint32,
    dilations=[1, 1, 1, 1],
    padding_list=[],
    name=None
)
",Computes quantized depthwise Conv2D with Bias and Relu.View aliases
tf.raw_ops.QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize,"tf.raw_ops.QuantizedDepthwiseConv2DWithBiasAndReluAndRequantize(
    input,
    filter,
    bias,
    min_input,
    max_input,
    min_filter,
    max_filter,
    min_freezed_output,
    max_freezed_output,
    strides,
    padding,
    out_type=tf.dtypes.quint8,
    dilations=[1, 1, 1, 1],
    padding_list=[],
    name=None
)
","Computes quantized depthwise Conv2D with Bias, Relu and Requantize.View aliases"
tf.raw_ops.QuantizedInstanceNorm,"tf.raw_ops.QuantizedInstanceNorm(
    x,
    x_min,
    x_max,
    output_range_given=False,
    given_y_min=0,
    given_y_max=0,
    variance_epsilon=1e-05,
    min_separation=0.001,
    name=None
)
",Quantized Instance normalization.View aliases
tf.raw_ops.QuantizedMatMul,"tf.raw_ops.QuantizedMatMul(
    a,
    b,
    min_a,
    max_a,
    min_b,
    max_b,
    Toutput=tf.dtypes.qint32,
    transpose_a=False,
    transpose_b=False,
    Tactivation=tf.dtypes.quint8,
    name=None
)
",Perform a quantized matrix multiplication of  a by the matrix b.View aliases
tf.raw_ops.QuantizedMatMulWithBias,"tf.raw_ops.QuantizedMatMulWithBias(
    a,
    b,
    bias,
    min_a,
    max_a,
    min_b,
    max_b,
    Toutput=tf.dtypes.qint32,
    transpose_a=False,
    transpose_b=False,
    input_quant_mode='MIN_FIRST',
    name=None
)
",Performs a quantized matrix multiplication of a by the matrix b with biasView aliases
tf.raw_ops.QuantizedMatMulWithBiasAndDequantize,"tf.raw_ops.QuantizedMatMulWithBiasAndDequantize(
    a,
    b,
    bias,
    min_a,
    max_a,
    min_b,
    max_b,
    min_freezed_output,
    max_freezed_output,
    Toutput,
    transpose_a=False,
    transpose_b=False,
    input_quant_mode='MIN_FIRST',
    name=None
)
",View aliases
tf.raw_ops.QuantizedMatMulWithBiasAndRelu,"tf.raw_ops.QuantizedMatMulWithBiasAndRelu(
    a,
    b,
    bias,
    min_a,
    max_a,
    min_b,
    max_b,
    Toutput=tf.dtypes.qint32,
    transpose_a=False,
    transpose_b=False,
    input_quant_mode='MIN_FIRST',
    name=None
)
",Perform a quantized matrix multiplication of  a by the matrix b with biasView aliases
tf.raw_ops.QuantizedMatMulWithBiasAndReluAndRequantize,"tf.raw_ops.QuantizedMatMulWithBiasAndReluAndRequantize(
    a,
    b,
    bias,
    min_a,
    max_a,
    min_b,
    max_b,
    min_freezed_output,
    max_freezed_output,
    Toutput=tf.dtypes.quint8,
    transpose_a=False,
    transpose_b=False,
    input_quant_mode='MIN_FIRST',
    name=None
)
",Perform a quantized matrix multiplication of  a by the matrix b with biasView aliases
tf.raw_ops.QuantizedMatMulWithBiasAndRequantize,"tf.raw_ops.QuantizedMatMulWithBiasAndRequantize(
    a,
    b,
    bias,
    min_a,
    max_a,
    min_b,
    max_b,
    min_freezed_output,
    max_freezed_output,
    Toutput=tf.dtypes.quint8,
    transpose_a=False,
    transpose_b=False,
    input_quant_mode='MIN_FIRST',
    name=None
)
",View aliases
tf.raw_ops.QuantizedMaxPool,"tf.raw_ops.QuantizedMaxPool(
    input, min_input, max_input, ksize, strides, padding, name=None
)
",Produces the max pool of the input tensor for quantized types.View aliases
tf.raw_ops.QuantizedMul,"tf.raw_ops.QuantizedMul(
    x,
    y,
    min_x,
    max_x,
    min_y,
    max_y,
    Toutput=tf.dtypes.qint32,
    name=None
)
","Returns x * y element-wise, working on quantized buffers.View aliases"
tf.raw_ops.QuantizedRelu,"tf.raw_ops.QuantizedRelu(
    features,
    min_features,
    max_features,
    out_type=tf.dtypes.quint8,
    name=None
)
","Computes Quantized Rectified Linear: max(features, 0)View aliases"
tf.raw_ops.QuantizedRelu6,"tf.raw_ops.QuantizedRelu6(
    features,
    min_features,
    max_features,
    out_type=tf.dtypes.quint8,
    name=None
)
","Computes Quantized Rectified Linear 6: min(max(features, 0), 6)View aliases"
tf.raw_ops.QuantizedReluX,"tf.raw_ops.QuantizedReluX(
    features,
    max_value,
    min_features,
    max_features,
    out_type=tf.dtypes.quint8,
    name=None
)
","Computes Quantized Rectified Linear X: min(max(features, 0), max_value)View aliases"
tf.raw_ops.QuantizedReshape,"tf.raw_ops.QuantizedReshape(
    tensor, shape, input_min, input_max, name=None
)
",Reshapes a quantized tensor as per the Reshape op.View aliases
tf.raw_ops.QuantizedResizeBilinear,"tf.raw_ops.QuantizedResizeBilinear(
    images,
    size,
    min,
    max,
    align_corners=False,
    half_pixel_centers=False,
    name=None
)
",Resize quantized images to size using quantized bilinear interpolation.View aliases
tf.raw_ops.QueueClose,"tf.raw_ops.QueueClose(
    handle, cancel_pending_enqueues=False, name=None
)
",Closes the given queue.View aliases
tf.raw_ops.QueueCloseV2,"tf.raw_ops.QueueCloseV2(
    handle, cancel_pending_enqueues=False, name=None
)
",Closes the given queue.View aliases
tf.raw_ops.QueueDequeue,"tf.raw_ops.QueueDequeue(
    handle, component_types, timeout_ms=-1, name=None
)
",Dequeues a tuple of one or more tensors from the given queue.View aliases
tf.raw_ops.QueueDequeueMany,"tf.raw_ops.QueueDequeueMany(
    handle, n, component_types, timeout_ms=-1, name=None
)
",Dequeues n tuples of one or more tensors from the given queue.View aliases
tf.raw_ops.QueueDequeueManyV2,"tf.raw_ops.QueueDequeueManyV2(
    handle, n, component_types, timeout_ms=-1, name=None
)
",Dequeues n tuples of one or more tensors from the given queue.View aliases
tf.raw_ops.QueueDequeueUpTo,"tf.raw_ops.QueueDequeueUpTo(
    handle, n, component_types, timeout_ms=-1, name=None
)
",Dequeues n tuples of one or more tensors from the given queue.View aliases
tf.raw_ops.QueueDequeueUpToV2,"tf.raw_ops.QueueDequeueUpToV2(
    handle, n, component_types, timeout_ms=-1, name=None
)
",Dequeues n tuples of one or more tensors from the given queue.View aliases
tf.raw_ops.QueueDequeueV2,"tf.raw_ops.QueueDequeueV2(
    handle, component_types, timeout_ms=-1, name=None
)
",Dequeues a tuple of one or more tensors from the given queue.View aliases
tf.raw_ops.QueueEnqueue,"tf.raw_ops.QueueEnqueue(
    handle, components, timeout_ms=-1, name=None
)
",Enqueues a tuple of one or more tensors in the given queue.View aliases
tf.raw_ops.QueueEnqueueMany,"tf.raw_ops.QueueEnqueueMany(
    handle, components, timeout_ms=-1, name=None
)
",Enqueues zero or more tuples of one or more tensors in the given queue.View aliases
tf.raw_ops.QueueEnqueueManyV2,"tf.raw_ops.QueueEnqueueManyV2(
    handle, components, timeout_ms=-1, name=None
)
",Enqueues zero or more tuples of one or more tensors in the given queue.View aliases
tf.raw_ops.QueueEnqueueV2,"tf.raw_ops.QueueEnqueueV2(
    handle, components, timeout_ms=-1, name=None
)
",Enqueues a tuple of one or more tensors in the given queue.View aliases
tf.raw_ops.QueueIsClosed,"tf.raw_ops.QueueIsClosed(
    handle, name=None
)
",Returns true if queue is closed.View aliases
tf.raw_ops.QueueIsClosedV2,"tf.raw_ops.QueueIsClosedV2(
    handle, name=None
)
",Returns true if queue is closed.View aliases
tf.raw_ops.QueueSize,"tf.raw_ops.QueueSize(
    handle, name=None
)
",Computes the number of elements in the given queue.View aliases
tf.raw_ops.QueueSizeV2,"tf.raw_ops.QueueSizeV2(
    handle, name=None
)
",Computes the number of elements in the given queue.View aliases
tf.raw_ops.RFFT,"tf.raw_ops.RFFT(
    input,
    fft_length,
    Tcomplex=tf.dtypes.complex64,
    name=None
)
",Real-valued fast Fourier transform.View aliases
tf.raw_ops.RFFT2D,"tf.raw_ops.RFFT2D(
    input,
    fft_length,
    Tcomplex=tf.dtypes.complex64,
    name=None
)
",2D real-valued fast Fourier transform.View aliases
tf.raw_ops.RFFT3D,"tf.raw_ops.RFFT3D(
    input,
    fft_length,
    Tcomplex=tf.dtypes.complex64,
    name=None
)
",3D real-valued fast Fourier transform.View aliases
tf.raw_ops.RGBToHSV,"tf.raw_ops.RGBToHSV(
    images, name=None
)
",Converts one or more images from RGB to HSV.View aliases
tf.raw_ops.RaggedBincount,"tf.raw_ops.RaggedBincount(
    splits, values, size, weights, binary_output=False, name=None
)
",Counts the number of occurrences of each value in an integer array.View aliases
tf.raw_ops.RaggedCountSparseOutput,"tf.raw_ops.RaggedCountSparseOutput(
    splits,
    values,
    weights,
    binary_output,
    minlength=-1,
    maxlength=-1,
    name=None
)
",Performs sparse-output bin counting for a ragged tensor input.View aliases
tf.raw_ops.RaggedCross,"tf.raw_ops.RaggedCross(
    ragged_values,
    ragged_row_splits,
    sparse_indices,
    sparse_values,
    sparse_shape,
    dense_inputs,
    input_order,
    hashed_output,
    num_buckets,
    hash_key,
    out_values_type,
    out_row_splits_type,
    name=None
)
","Generates a feature cross from a list of tensors, and returns it as aView aliases"
tf.raw_ops.RaggedGather,"tf.raw_ops.RaggedGather(
    params_nested_splits,
    params_dense_values,
    indices,
    OUTPUT_RAGGED_RANK,
    name=None
)
",Gather ragged slices from params axis 0 according to indices.View aliases
tf.raw_ops.RaggedRange,"tf.raw_ops.RaggedRange(
    starts,
    limits,
    deltas,
    Tsplits=tf.dtypes.int64,
    name=None
)
",Returns a RaggedTensor containing the specified sequences of numbers.View aliases
tf.raw_ops.RaggedTensorFromVariant,"tf.raw_ops.RaggedTensorFromVariant(
    encoded_ragged,
    input_ragged_rank,
    output_ragged_rank,
    Tvalues,
    Tsplits=tf.dtypes.int64,
    name=None
)
",Decodes a variant Tensor into a RaggedTensor.View aliases
tf.raw_ops.RaggedTensorToSparse,"tf.raw_ops.RaggedTensorToSparse(
    rt_nested_splits, rt_dense_values, name=None
)
",Converts a RaggedTensor into a SparseTensor with the same values.View aliases
tf.raw_ops.RaggedTensorToTensor,"tf.raw_ops.RaggedTensorToTensor(
    shape,
    values,
    default_value,
    row_partition_tensors,
    row_partition_types,
    name=None
)
","Create a dense tensor from a ragged tensor, possibly altering its shape.View aliases"
tf.raw_ops.RaggedTensorToVariant,"tf.raw_ops.RaggedTensorToVariant(
    rt_nested_splits, rt_dense_values, batched_input, name=None
)
",Encodes a RaggedTensor into a variant Tensor.View aliases
tf.raw_ops.RaggedTensorToVariantGradient,"tf.raw_ops.RaggedTensorToVariantGradient(
    encoded_ragged_grad, row_splits, dense_values_shape, Tvalues, name=None
)
",Helper used to compute the gradient for RaggedTensorToVariant.View aliases
tf.raw_ops.RandomCrop,"tf.raw_ops.RandomCrop(
    image, size, seed=0, seed2=0, name=None
)
",Randomly crop image.View aliases
tf.raw_ops.RandomDataset,"tf.raw_ops.RandomDataset(
    seed, seed2, output_types, output_shapes, metadata='', name=None
)
",Creates a Dataset that returns pseudorandom numbers.View aliases
tf.raw_ops.RandomGamma,"tf.raw_ops.RandomGamma(
    shape, alpha, seed=0, seed2=0, name=None
)
",Outputs random values from the Gamma distribution(s) described by alpha.View aliases
tf.raw_ops.RandomGammaGrad,"tf.raw_ops.RandomGammaGrad(
    alpha, sample, name=None
)
",Computes the derivative of a Gamma random sample w.r.t. alpha.View aliases
tf.raw_ops.RandomIndexShuffle,"tf.raw_ops.RandomIndexShuffle(
    index, seed, max_index, name=None
)
","Outputs the position of value in a permutation of [0, ..., max_index].View aliases"
tf.raw_ops.RandomPoisson,"tf.raw_ops.RandomPoisson(
    shape, rate, seed=0, seed2=0, name=None
)
",Use RandomPoissonV2 instead.View aliases
tf.raw_ops.RandomPoissonV2,"tf.raw_ops.RandomPoissonV2(
    shape,
    rate,
    seed=0,
    seed2=0,
    dtype=tf.dtypes.int64,
    name=None
)
",Outputs random values from the Poisson distribution(s) described by rate.View aliases
tf.raw_ops.RandomShuffle,"tf.raw_ops.RandomShuffle(
    value, seed=0, seed2=0, name=None
)
",Randomly shuffles a tensor along its first dimension.View aliases
tf.raw_ops.RandomShuffleQueue,"tf.raw_ops.RandomShuffleQueue(
    component_types,
    shapes=[],
    capacity=-1,
    min_after_dequeue=0,
    seed=0,
    seed2=0,
    container='',
    shared_name='',
    name=None
)
",A queue that randomizes the order of elements.View aliases
tf.raw_ops.RandomShuffleQueueV2,"tf.raw_ops.RandomShuffleQueueV2(
    component_types,
    shapes=[],
    capacity=-1,
    min_after_dequeue=0,
    seed=0,
    seed2=0,
    container='',
    shared_name='',
    name=None
)
",A queue that randomizes the order of elements.View aliases
tf.raw_ops.RandomStandardNormal,"tf.raw_ops.RandomStandardNormal(
    shape, dtype, seed=0, seed2=0, name=None
)
",Outputs random values from a normal distribution.View aliases
tf.raw_ops.RandomUniform,"tf.raw_ops.RandomUniform(
    shape, dtype, seed=0, seed2=0, name=None
)
",Outputs random values from a uniform distribution.View aliases
tf.raw_ops.RandomUniformInt,"tf.raw_ops.RandomUniformInt(
    shape, minval, maxval, seed=0, seed2=0, name=None
)
",Outputs random integers from a uniform distribution.View aliases
tf.raw_ops.Range,"tf.raw_ops.Range(
    start, limit, delta, name=None
)
",Creates a sequence of numbers.View aliases
tf.raw_ops.RangeDataset,"tf.raw_ops.RangeDataset(
    start,
    stop,
    step,
    output_types,
    output_shapes,
    metadata='',
    replicate_on_split=False,
    name=None
)
",Creates a dataset with a range of values. Corresponds to python's xrange.View aliases
tf.raw_ops.Rank,"tf.raw_ops.Rank(
    input, name=None
)
",Returns the rank of a tensor.View aliases
tf.raw_ops.ReadFile,"tf.raw_ops.ReadFile(
    filename, name=None
)
",Reads and outputs the entire contents of the input filename.View aliases
tf.raw_ops.ReadVariableOp,"tf.raw_ops.ReadVariableOp(
    resource, dtype, name=None
)
",Reads the value of a variable.View aliases
tf.raw_ops.ReadVariableXlaSplitND,"tf.raw_ops.ReadVariableXlaSplitND(
    resource, T, N, num_splits, paddings=[], name=None
)
",Splits resource variable input tensor across all dimensions.View aliases
tf.raw_ops.ReaderNumRecordsProduced,"tf.raw_ops.ReaderNumRecordsProduced(
    reader_handle, name=None
)
",Returns the number of records this Reader has produced.View aliases
tf.raw_ops.ReaderNumRecordsProducedV2,"tf.raw_ops.ReaderNumRecordsProducedV2(
    reader_handle, name=None
)
",Returns the number of records this Reader has produced.View aliases
tf.raw_ops.ReaderNumWorkUnitsCompleted,"tf.raw_ops.ReaderNumWorkUnitsCompleted(
    reader_handle, name=None
)
",Returns the number of work units this Reader has finished processing.View aliases
tf.raw_ops.ReaderNumWorkUnitsCompletedV2,"tf.raw_ops.ReaderNumWorkUnitsCompletedV2(
    reader_handle, name=None
)
",Returns the number of work units this Reader has finished processing.View aliases
tf.raw_ops.ReaderRead,"tf.raw_ops.ReaderRead(
    reader_handle, queue_handle, name=None
)
","Returns the next record (key, value pair) produced by a Reader.View aliases"
tf.raw_ops.ReaderReadUpTo,"tf.raw_ops.ReaderReadUpTo(
    reader_handle, queue_handle, num_records, name=None
)
","Returns up to num_records (key, value) pairs produced by a Reader.View aliases"
tf.raw_ops.ReaderReadUpToV2,"tf.raw_ops.ReaderReadUpToV2(
    reader_handle, queue_handle, num_records, name=None
)
","Returns up to num_records (key, value) pairs produced by a Reader.View aliases"
tf.raw_ops.ReaderReadV2,"tf.raw_ops.ReaderReadV2(
    reader_handle, queue_handle, name=None
)
","Returns the next record (key, value pair) produced by a Reader.View aliases"
tf.raw_ops.ReaderReset,"tf.raw_ops.ReaderReset(
    reader_handle, name=None
)
",Restore a Reader to its initial clean state.View aliases
tf.raw_ops.ReaderResetV2,"tf.raw_ops.ReaderResetV2(
    reader_handle, name=None
)
",Restore a Reader to its initial clean state.View aliases
tf.raw_ops.ReaderRestoreState,"tf.raw_ops.ReaderRestoreState(
    reader_handle, state, name=None
)
",Restore a reader to a previously saved state.View aliases
tf.raw_ops.ReaderRestoreStateV2,"tf.raw_ops.ReaderRestoreStateV2(
    reader_handle, state, name=None
)
",Restore a reader to a previously saved state.View aliases
tf.raw_ops.ReaderSerializeState,"tf.raw_ops.ReaderSerializeState(
    reader_handle, name=None
)
",Produce a string tensor that encodes the state of a Reader.View aliases
tf.raw_ops.ReaderSerializeStateV2,"tf.raw_ops.ReaderSerializeStateV2(
    reader_handle, name=None
)
",Produce a string tensor that encodes the state of a Reader.View aliases
tf.raw_ops.Real,"tf.raw_ops.Real(
    input,
    Tout=tf.dtypes.float32,
    name=None
)
",Returns the real part of a complex number.View aliases
tf.raw_ops.RealDiv,"tf.raw_ops.RealDiv(
    x, y, name=None
)
",Returns x / y element-wise for real types.View aliases
tf.raw_ops.RebatchDataset,"tf.raw_ops.RebatchDataset(
    input_dataset,
    num_replicas,
    output_types,
    output_shapes,
    use_fallback=True,
    name=None
)
",Creates a dataset that changes the batch size.View aliases
tf.raw_ops.RebatchDatasetV2,"tf.raw_ops.RebatchDatasetV2(
    input_dataset,
    batch_sizes,
    drop_remainder,
    output_types,
    output_shapes,
    name=None
)
",Creates a dataset that changes the batch size.View aliases
tf.raw_ops.Reciprocal,"tf.raw_ops.Reciprocal(
    x, name=None
)
",Computes the reciprocal of x element-wise.View aliases
tf.raw_ops.ReciprocalGrad,"tf.raw_ops.ReciprocalGrad(
    y, dy, name=None
)
",Computes the gradient for the inverse of x wrt its input.View aliases
tf.raw_ops.RecordInput,"tf.raw_ops.RecordInput(
    file_pattern,
    file_random_seed=301,
    file_shuffle_shift_ratio=0,
    file_buffer_size=10000,
    file_parallelism=16,
    batch_size=32,
    compression_type='',
    name=None
)
",Emits randomized records.View aliases
tf.raw_ops.Recv,"tf.raw_ops.Recv(
    tensor_type,
    tensor_name,
    send_device,
    send_device_incarnation,
    recv_device,
    client_terminated=False,
    name=None
)
",Receives the named tensor from send_device on recv_device.View aliases
tf.raw_ops.RecvTPUEmbeddingActivations,"tf.raw_ops.RecvTPUEmbeddingActivations(
    num_outputs, config, name=None
)
",An op that receives embedding activations on the TPU.View aliases
tf.raw_ops.ReduceDataset,"tf.raw_ops.ReduceDataset(
    input_dataset,
    initial_state,
    other_arguments,
    f,
    output_types,
    output_shapes,
    use_inter_op_parallelism=True,
    metadata='',
    name=None
)
",Reduces the input dataset to a singleton using a reduce function.View aliases
tf.raw_ops.ReduceJoin,"tf.raw_ops.ReduceJoin(
    inputs,
    reduction_indices,
    keep_dims=False,
    separator='',
    name=None
)
",Joins a string Tensor across the given dimensions.View aliases
tf.raw_ops.RefEnter,"tf.raw_ops.RefEnter(
    data, frame_name, is_constant=False, parallel_iterations=10, name=None
)
","Creates or finds a child frame, and makes data available to the child frame.View aliases"
tf.raw_ops.RefExit,"tf.raw_ops.RefExit(
    data, name=None
)
",Exits the current frame to its parent frame.View aliases
tf.raw_ops.RefIdentity,"tf.raw_ops.RefIdentity(
    input, name=None
)
",Return the same ref tensor as the input ref tensor.View aliases
tf.raw_ops.RefMerge,"tf.raw_ops.RefMerge(
    inputs, name=None
)
",Forwards the value of an available tensor from inputs to output.View aliases
tf.raw_ops.RefNextIteration,"tf.raw_ops.RefNextIteration(
    data, name=None
)
",Makes its input available to the next iteration.View aliases
tf.raw_ops.RefSelect,"tf.raw_ops.RefSelect(
    index, inputs, name=None
)
",Forwards the indexth element of inputs to output.View aliases
tf.raw_ops.RefSwitch,"tf.raw_ops.RefSwitch(
    data, pred, name=None
)
",Forwards the ref tensor data to the output port determined by pred.View aliases
tf.raw_ops.RegexFullMatch,"tf.raw_ops.RegexFullMatch(
    input, pattern, name=None
)
",Check if the input matches the regex pattern.View aliases
tf.raw_ops.RegexReplace,"tf.raw_ops.RegexReplace(
    input, pattern, rewrite, replace_global=True, name=None
)
",Replaces matches of the pattern regular expression in input with theView aliases
tf.raw_ops.RegisterDataset,"tf.raw_ops.RegisterDataset(
    dataset,
    address,
    protocol,
    external_state_policy,
    element_spec='',
    metadata='',
    name=None
)
",Registers a dataset with the tf.data service.View aliases
tf.raw_ops.RegisterDatasetV2,"tf.raw_ops.RegisterDatasetV2(
    dataset,
    address,
    protocol,
    external_state_policy,
    element_spec='',
    requested_dataset_id='',
    metadata='',
    name=None
)
",Registers a dataset with the tf.data service.View aliases
tf.raw_ops.Relu,"tf.raw_ops.Relu(
    features, name=None
)
","Computes rectified linear: max(features, 0).View aliases"
tf.raw_ops.Relu6,"tf.raw_ops.Relu6(
    features, name=None
)
","Computes rectified linear 6: min(max(features, 0), 6).View aliases"
tf.raw_ops.Relu6Grad,"tf.raw_ops.Relu6Grad(
    gradients, features, name=None
)
",Computes rectified linear 6 gradients for a Relu6 operation.View aliases
tf.raw_ops.ReluGrad,"tf.raw_ops.ReluGrad(
    gradients, features, name=None
)
",Computes rectified linear gradients for a Relu operation.View aliases
tf.raw_ops.RemoteCall,"tf.raw_ops.RemoteCall(
    target, args, Tout, f, name=None
)
",Runs function f on a remote device indicated by target.View aliases
tf.raw_ops.RepeatDataset,"tf.raw_ops.RepeatDataset(
    input_dataset,
    count,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that emits the outputs of input_dataset count times.View aliases
tf.raw_ops.RequantizationRange,"tf.raw_ops.RequantizationRange(
    input, input_min, input_max, name=None
)
",Computes a range that covers the actual values present in a quantized tensor.View aliases
tf.raw_ops.RequantizationRangePerChannel,"tf.raw_ops.RequantizationRangePerChannel(
    input, input_min, input_max, clip_value_max, name=None
)
",Computes requantization range per channel.View aliases
tf.raw_ops.Requantize,"tf.raw_ops.Requantize(
    input,
    input_min,
    input_max,
    requested_output_min,
    requested_output_max,
    out_type,
    name=None
)
",Converts the quantized input tensor into a lower-precision output.View aliases
tf.raw_ops.RequantizePerChannel,"tf.raw_ops.RequantizePerChannel(
    input,
    input_min,
    input_max,
    requested_output_min,
    requested_output_max,
    out_type=tf.dtypes.quint8,
    name=None
)
",Requantizes input with min and max values known per channel.View aliases
tf.raw_ops.Reshape,"tf.raw_ops.Reshape(
    tensor, shape, name=None
)
",Reshapes a tensor.View aliases
tf.raw_ops.ResizeArea,"tf.raw_ops.ResizeArea(
    images, size, align_corners=False, name=None
)
",Resize images to size using area interpolation.View aliases
tf.raw_ops.ResizeBicubic,"tf.raw_ops.ResizeBicubic(
    images, size, align_corners=False, half_pixel_centers=False, name=None
)
",Resize images to size using bicubic interpolation.View aliases
tf.raw_ops.ResizeBicubicGrad,"tf.raw_ops.ResizeBicubicGrad(
    grads,
    original_image,
    align_corners=False,
    half_pixel_centers=False,
    name=None
)
",Computes the gradient of bicubic interpolation.View aliases
tf.raw_ops.ResizeBilinear,"tf.raw_ops.ResizeBilinear(
    images, size, align_corners=False, half_pixel_centers=False, name=None
)
",Resize images to size using bilinear interpolation.View aliases
tf.raw_ops.ResizeBilinearGrad,"tf.raw_ops.ResizeBilinearGrad(
    grads,
    original_image,
    align_corners=False,
    half_pixel_centers=False,
    name=None
)
",Computes the gradient of bilinear interpolation.View aliases
tf.raw_ops.ResizeNearestNeighbor,"tf.raw_ops.ResizeNearestNeighbor(
    images, size, align_corners=False, half_pixel_centers=False, name=None
)
",Resize images to size using nearest neighbor interpolation.View aliases
tf.raw_ops.ResizeNearestNeighborGrad,"tf.raw_ops.ResizeNearestNeighborGrad(
    grads, size, align_corners=False, half_pixel_centers=False, name=None
)
",Computes the gradient of nearest neighbor interpolation.View aliases
tf.raw_ops.ResourceAccumulatorApplyGradient,"tf.raw_ops.ResourceAccumulatorApplyGradient(
    handle, local_step, gradient, name=None
)
",Applies a gradient to a given accumulator.View aliases
tf.raw_ops.ResourceAccumulatorNumAccumulated,"tf.raw_ops.ResourceAccumulatorNumAccumulated(
    handle, name=None
)
",Returns the number of gradients aggregated in the given accumulators.View aliases
tf.raw_ops.ResourceAccumulatorSetGlobalStep,"tf.raw_ops.ResourceAccumulatorSetGlobalStep(
    handle, new_global_step, name=None
)
",Updates the accumulator with a new value for global_step.View aliases
tf.raw_ops.ResourceAccumulatorTakeGradient,"tf.raw_ops.ResourceAccumulatorTakeGradient(
    handle, num_required, dtype, name=None
)
",Extracts the average gradient in the given ConditionalAccumulator.View aliases
tf.raw_ops.ResourceApplyAdaMax,"tf.raw_ops.ResourceApplyAdaMax(
    var,
    m,
    v,
    beta1_power,
    lr,
    beta1,
    beta2,
    epsilon,
    grad,
    use_locking=False,
    name=None
)
",Update '*var' according to the AdaMax algorithm.View aliases
tf.raw_ops.ResourceApplyAdadelta,"tf.raw_ops.ResourceApplyAdadelta(
    var,
    accum,
    accum_update,
    lr,
    rho,
    epsilon,
    grad,
    use_locking=False,
    name=None
)
",Update '*var' according to the adadelta scheme.View aliases
tf.raw_ops.ResourceApplyAdagrad,"tf.raw_ops.ResourceApplyAdagrad(
    var, accum, lr, grad, use_locking=False, update_slots=True, name=None
)
",Update '*var' according to the adagrad scheme.View aliases
tf.raw_ops.ResourceApplyAdagradDA,"tf.raw_ops.ResourceApplyAdagradDA(
    var,
    gradient_accumulator,
    gradient_squared_accumulator,
    grad,
    lr,
    l1,
    l2,
    global_step,
    use_locking=False,
    name=None
)
",Update '*var' according to the proximal adagrad scheme.View aliases
tf.raw_ops.ResourceApplyAdagradV2,"tf.raw_ops.ResourceApplyAdagradV2(
    var,
    accum,
    lr,
    epsilon,
    grad,
    use_locking=False,
    update_slots=True,
    name=None
)
",Update '*var' according to the adagrad scheme.View aliases
tf.raw_ops.ResourceApplyAdam,"tf.raw_ops.ResourceApplyAdam(
    var,
    m,
    v,
    beta1_power,
    beta2_power,
    lr,
    beta1,
    beta2,
    epsilon,
    grad,
    use_locking=False,
    use_nesterov=False,
    name=None
)
",Update '*var' according to the Adam algorithm.View aliases
tf.raw_ops.ResourceApplyAdamWithAmsgrad,"tf.raw_ops.ResourceApplyAdamWithAmsgrad(
    var,
    m,
    v,
    vhat,
    beta1_power,
    beta2_power,
    lr,
    beta1,
    beta2,
    epsilon,
    grad,
    use_locking=False,
    name=None
)
",Update '*var' according to the Adam algorithm.View aliases
tf.raw_ops.ResourceApplyAddSign,"tf.raw_ops.ResourceApplyAddSign(
    var, m, lr, alpha, sign_decay, beta, grad, use_locking=False, name=None
)
",Update '*var' according to the AddSign update.View aliases
tf.raw_ops.ResourceApplyCenteredRMSProp,"tf.raw_ops.ResourceApplyCenteredRMSProp(
    var,
    mg,
    ms,
    mom,
    lr,
    rho,
    momentum,
    epsilon,
    grad,
    use_locking=False,
    name=None
)
",Update '*var' according to the centered RMSProp algorithm.View aliases
tf.raw_ops.ResourceApplyFtrl,"tf.raw_ops.ResourceApplyFtrl(
    var,
    accum,
    linear,
    grad,
    lr,
    l1,
    l2,
    lr_power,
    use_locking=False,
    multiply_linear_by_lr=False,
    name=None
)
",Update '*var' according to the Ftrl-proximal scheme.View aliases
tf.raw_ops.ResourceApplyFtrlV2,"tf.raw_ops.ResourceApplyFtrlV2(
    var,
    accum,
    linear,
    grad,
    lr,
    l1,
    l2,
    l2_shrinkage,
    lr_power,
    use_locking=False,
    multiply_linear_by_lr=False,
    name=None
)
",Update '*var' according to the Ftrl-proximal scheme.View aliases
tf.raw_ops.ResourceApplyGradientDescent,"tf.raw_ops.ResourceApplyGradientDescent(
    var, alpha, delta, use_locking=False, name=None
)
",Update '*var' by subtracting 'alpha' * 'delta' from it.View aliases
tf.raw_ops.ResourceApplyKerasMomentum,"tf.raw_ops.ResourceApplyKerasMomentum(
    var,
    accum,
    lr,
    grad,
    momentum,
    use_locking=False,
    use_nesterov=False,
    name=None
)
",Update '*var' according to the momentum scheme.View aliases
tf.raw_ops.ResourceApplyMomentum,"tf.raw_ops.ResourceApplyMomentum(
    var,
    accum,
    lr,
    grad,
    momentum,
    use_locking=False,
    use_nesterov=False,
    name=None
)
",Update '*var' according to the momentum scheme.View aliases
tf.raw_ops.ResourceApplyPowerSign,"tf.raw_ops.ResourceApplyPowerSign(
    var, m, lr, logbase, sign_decay, beta, grad, use_locking=False, name=None
)
",Update '*var' according to the AddSign update.View aliases
tf.raw_ops.ResourceApplyProximalAdagrad,"tf.raw_ops.ResourceApplyProximalAdagrad(
    var, accum, lr, l1, l2, grad, use_locking=False, name=None
)
",Update 'var' and 'accum' according to FOBOS with Adagrad learning rate.View aliases
tf.raw_ops.ResourceApplyProximalGradientDescent,"tf.raw_ops.ResourceApplyProximalGradientDescent(
    var, alpha, l1, l2, delta, use_locking=False, name=None
)
",Update '*var' as FOBOS algorithm with fixed learning rate.View aliases
tf.raw_ops.ResourceApplyRMSProp,"tf.raw_ops.ResourceApplyRMSProp(
    var,
    ms,
    mom,
    lr,
    rho,
    momentum,
    epsilon,
    grad,
    use_locking=False,
    name=None
)
",Update '*var' according to the RMSProp algorithm.View aliases
tf.raw_ops.ResourceConditionalAccumulator,"tf.raw_ops.ResourceConditionalAccumulator(
    dtype,
    shape,
    container='',
    shared_name='',
    reduction_type='MEAN',
    name=None
)
",A conditional accumulator for aggregating gradients.View aliases
tf.raw_ops.ResourceCountUpTo,"tf.raw_ops.ResourceCountUpTo(
    resource, limit, T, name=None
)
",Increments variable pointed to by 'resource' until it reaches 'limit'.View aliases
tf.raw_ops.ResourceGather,"tf.raw_ops.ResourceGather(
    resource, indices, dtype, batch_dims=0, validate_indices=True, name=None
)
",Gather slices from the variable pointed to by resource according to indices.View aliases
tf.raw_ops.ResourceGatherNd,"tf.raw_ops.ResourceGatherNd(
    resource, indices, dtype, name=None
)
",View aliases
tf.raw_ops.ResourceScatterAdd,"tf.raw_ops.ResourceScatterAdd(
    resource, indices, updates, name=None
)
",Adds sparse updates to the variable referenced by resource.View aliases
tf.raw_ops.ResourceScatterDiv,"tf.raw_ops.ResourceScatterDiv(
    resource, indices, updates, name=None
)
",Divides sparse updates into the variable referenced by resource.View aliases
tf.raw_ops.ResourceScatterMax,"tf.raw_ops.ResourceScatterMax(
    resource, indices, updates, name=None
)
",Reduces sparse updates into the variable referenced by resource using the max operation.View aliases
tf.raw_ops.ResourceScatterMin,"tf.raw_ops.ResourceScatterMin(
    resource, indices, updates, name=None
)
",Reduces sparse updates into the variable referenced by resource using the min operation.View aliases
tf.raw_ops.ResourceScatterMul,"tf.raw_ops.ResourceScatterMul(
    resource, indices, updates, name=None
)
",Multiplies sparse updates into the variable referenced by resource.View aliases
tf.raw_ops.ResourceScatterNdAdd,"tf.raw_ops.ResourceScatterNdAdd(
    ref, indices, updates, use_locking=True, name=None
)
",Applies sparse addition to individual values or slices in a Variable.View aliases
tf.raw_ops.ResourceScatterNdMax,"tf.raw_ops.ResourceScatterNdMax(
    ref, indices, updates, use_locking=True, name=None
)
",View aliases
tf.raw_ops.ResourceScatterNdMin,"tf.raw_ops.ResourceScatterNdMin(
    ref, indices, updates, use_locking=True, name=None
)
",View aliases
tf.raw_ops.ResourceScatterNdSub,"tf.raw_ops.ResourceScatterNdSub(
    ref, indices, updates, use_locking=True, name=None
)
",Applies sparse subtraction to individual values or slices in a Variable.View aliases
tf.raw_ops.ResourceScatterNdUpdate,"tf.raw_ops.ResourceScatterNdUpdate(
    ref, indices, updates, use_locking=True, name=None
)
",Applies sparse updates to individual values or slices within a givenView aliases
tf.raw_ops.ResourceScatterSub,"tf.raw_ops.ResourceScatterSub(
    resource, indices, updates, name=None
)
",Subtracts sparse updates from the variable referenced by resource.View aliases
tf.raw_ops.ResourceScatterUpdate,"tf.raw_ops.ResourceScatterUpdate(
    resource, indices, updates, name=None
)
",Assigns sparse updates to the variable referenced by resource.View aliases
tf.raw_ops.ResourceSparseApplyAdadelta,"tf.raw_ops.ResourceSparseApplyAdadelta(
    var,
    accum,
    accum_update,
    lr,
    rho,
    epsilon,
    grad,
    indices,
    use_locking=False,
    name=None
)
",var: Should be from a Variable().View aliases
tf.raw_ops.ResourceSparseApplyAdagrad,"tf.raw_ops.ResourceSparseApplyAdagrad(
    var,
    accum,
    lr,
    grad,
    indices,
    use_locking=False,
    update_slots=True,
    name=None
)
",Update relevant entries in 'var' and 'accum' according to the adagrad scheme.View aliases
tf.raw_ops.ResourceSparseApplyAdagradDA,"tf.raw_ops.ResourceSparseApplyAdagradDA(
    var,
    gradient_accumulator,
    gradient_squared_accumulator,
    grad,
    indices,
    lr,
    l1,
    l2,
    global_step,
    use_locking=False,
    name=None
)
",Update entries in 'var' and 'accum' according to the proximal adagrad scheme.View aliases
tf.raw_ops.ResourceSparseApplyAdagradV2,"tf.raw_ops.ResourceSparseApplyAdagradV2(
    var,
    accum,
    lr,
    epsilon,
    grad,
    indices,
    use_locking=False,
    update_slots=True,
    name=None
)
",Update relevant entries in 'var' and 'accum' according to the adagrad scheme.View aliases
tf.raw_ops.ResourceSparseApplyCenteredRMSProp,"tf.raw_ops.ResourceSparseApplyCenteredRMSProp(
    var,
    mg,
    ms,
    mom,
    lr,
    rho,
    momentum,
    epsilon,
    grad,
    indices,
    use_locking=False,
    name=None
)
",Update '*var' according to the centered RMSProp algorithm.View aliases
tf.raw_ops.ResourceSparseApplyFtrl,"tf.raw_ops.ResourceSparseApplyFtrl(
    var,
    accum,
    linear,
    grad,
    indices,
    lr,
    l1,
    l2,
    lr_power,
    use_locking=False,
    multiply_linear_by_lr=False,
    name=None
)
",Update relevant entries in '*var' according to the Ftrl-proximal scheme.View aliases
tf.raw_ops.ResourceSparseApplyFtrlV2,"tf.raw_ops.ResourceSparseApplyFtrlV2(
    var,
    accum,
    linear,
    grad,
    indices,
    lr,
    l1,
    l2,
    l2_shrinkage,
    lr_power,
    use_locking=False,
    multiply_linear_by_lr=False,
    name=None
)
",Update relevant entries in '*var' according to the Ftrl-proximal scheme.View aliases
tf.raw_ops.ResourceSparseApplyKerasMomentum,"tf.raw_ops.ResourceSparseApplyKerasMomentum(
    var,
    accum,
    lr,
    grad,
    indices,
    momentum,
    use_locking=False,
    use_nesterov=False,
    name=None
)
",Update relevant entries in 'var' and 'accum' according to the momentum scheme.View aliases
tf.raw_ops.ResourceSparseApplyMomentum,"tf.raw_ops.ResourceSparseApplyMomentum(
    var,
    accum,
    lr,
    grad,
    indices,
    momentum,
    use_locking=False,
    use_nesterov=False,
    name=None
)
",Update relevant entries in 'var' and 'accum' according to the momentum scheme.View aliases
tf.raw_ops.ResourceSparseApplyProximalAdagrad,"tf.raw_ops.ResourceSparseApplyProximalAdagrad(
    var, accum, lr, l1, l2, grad, indices, use_locking=False, name=None
)
",Sparse update entries in 'var' and 'accum' according to FOBOS algorithm.View aliases
tf.raw_ops.ResourceSparseApplyProximalGradientDescent,"tf.raw_ops.ResourceSparseApplyProximalGradientDescent(
    var, alpha, l1, l2, grad, indices, use_locking=False, name=None
)
",Sparse update '*var' as FOBOS algorithm with fixed learning rate.View aliases
tf.raw_ops.ResourceSparseApplyRMSProp,"tf.raw_ops.ResourceSparseApplyRMSProp(
    var,
    ms,
    mom,
    lr,
    rho,
    momentum,
    epsilon,
    grad,
    indices,
    use_locking=False,
    name=None
)
",Update '*var' according to the RMSProp algorithm.View aliases
tf.raw_ops.ResourceStridedSliceAssign,"tf.raw_ops.ResourceStridedSliceAssign(
    ref,
    begin,
    end,
    strides,
    value,
    begin_mask=0,
    end_mask=0,
    ellipsis_mask=0,
    new_axis_mask=0,
    shrink_axis_mask=0,
    name=None
)
",Assign value to the sliced l-value reference of ref.View aliases
tf.raw_ops.Restore,"tf.raw_ops.Restore(
    file_pattern, tensor_name, dt, preferred_shard=-1, name=None
)
",Restores a tensor from checkpoint files.View aliases
tf.raw_ops.RestoreSlice,"tf.raw_ops.RestoreSlice(
    file_pattern,
    tensor_name,
    shape_and_slice,
    dt,
    preferred_shard=-1,
    name=None
)
",Restores a tensor from checkpoint files.View aliases
tf.raw_ops.RestoreV2,"tf.raw_ops.RestoreV2(
    prefix, tensor_names, shape_and_slices, dtypes, name=None
)
",Restores tensors from a V2 checkpoint.View aliases
tf.raw_ops.RetrieveTPUEmbeddingADAMParameters,"tf.raw_ops.RetrieveTPUEmbeddingADAMParameters(
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Retrieve ADAM embedding parameters.View aliases
tf.raw_ops.RetrieveTPUEmbeddingAdadeltaParameters,"tf.raw_ops.RetrieveTPUEmbeddingAdadeltaParameters(
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Retrieve Adadelta embedding parameters.View aliases
tf.raw_ops.RetrieveTPUEmbeddingAdagradMomentumParameters,"tf.raw_ops.RetrieveTPUEmbeddingAdagradMomentumParameters(
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Retrieve Adagrad Momentum embedding parameters.View aliases
tf.raw_ops.RetrieveTPUEmbeddingAdagradParameters,"tf.raw_ops.RetrieveTPUEmbeddingAdagradParameters(
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Retrieve Adagrad embedding parameters.View aliases
tf.raw_ops.RetrieveTPUEmbeddingCenteredRMSPropParameters,"tf.raw_ops.RetrieveTPUEmbeddingCenteredRMSPropParameters(
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Retrieve centered RMSProp embedding parameters.View aliases
tf.raw_ops.RetrieveTPUEmbeddingFTRLParameters,"tf.raw_ops.RetrieveTPUEmbeddingFTRLParameters(
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Retrieve FTRL embedding parameters.View aliases
tf.raw_ops.RetrieveTPUEmbeddingFrequencyEstimatorParameters,"tf.raw_ops.RetrieveTPUEmbeddingFrequencyEstimatorParameters(
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Retrieve frequency estimator embedding parameters.View aliases
tf.raw_ops.RetrieveTPUEmbeddingMDLAdagradLightParameters,"tf.raw_ops.RetrieveTPUEmbeddingMDLAdagradLightParameters(
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Retrieve MDL Adagrad Light embedding parameters.View aliases
tf.raw_ops.RetrieveTPUEmbeddingMomentumParameters,"tf.raw_ops.RetrieveTPUEmbeddingMomentumParameters(
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Retrieve Momentum embedding parameters.View aliases
tf.raw_ops.RetrieveTPUEmbeddingProximalAdagradParameters,"tf.raw_ops.RetrieveTPUEmbeddingProximalAdagradParameters(
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Retrieve proximal Adagrad embedding parameters.View aliases
tf.raw_ops.RetrieveTPUEmbeddingProximalYogiParameters,"tf.raw_ops.RetrieveTPUEmbeddingProximalYogiParameters(
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",View aliases
tf.raw_ops.RetrieveTPUEmbeddingRMSPropParameters,"tf.raw_ops.RetrieveTPUEmbeddingRMSPropParameters(
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Retrieve RMSProp embedding parameters.View aliases
tf.raw_ops.RetrieveTPUEmbeddingStochasticGradientDescentParameters,"tf.raw_ops.RetrieveTPUEmbeddingStochasticGradientDescentParameters(
    num_shards,
    shard_id,
    table_id=-1,
    table_name='',
    config='',
    name=None
)
",Retrieve SGD embedding parameters.View aliases
tf.raw_ops.Reverse,"tf.raw_ops.Reverse(
    tensor, dims, name=None
)
",Reverses specific dimensions of a tensor.View aliases
tf.raw_ops.ReverseSequence,"tf.raw_ops.ReverseSequence(
    input, seq_lengths, seq_dim, batch_dim=0, name=None
)
",Reverses variable length slices.View aliases
tf.raw_ops.ReverseV2,"tf.raw_ops.ReverseV2(
    tensor, axis, name=None
)
",Reverses specific dimensions of a tensor.View aliases
tf.raw_ops.RewriteDataset,"tf.raw_ops.RewriteDataset(
    input_dataset, rewrite_name, output_types, output_shapes, name=None
)
",View aliases
tf.raw_ops.RightShift,"tf.raw_ops.RightShift(
    x, y, name=None
)
",Elementwise computes the bitwise right-shift of x and y.View aliases
tf.raw_ops.Rint,"tf.raw_ops.Rint(
    x, name=None
)
",Returns element-wise integer closest to x.View aliases
tf.raw_ops.RngReadAndSkip,"tf.raw_ops.RngReadAndSkip(
    resource, alg, delta, name=None
)
",Advance the counter of a counter-based RNG.View aliases
tf.raw_ops.RngSkip,"tf.raw_ops.RngSkip(
    resource, algorithm, delta, name=None
)
",Advance the counter of a counter-based RNG.View aliases
tf.raw_ops.Roll,"tf.raw_ops.Roll(
    input, shift, axis, name=None
)
",Rolls the elements of a tensor along an axis.View aliases
tf.raw_ops.Round,"tf.raw_ops.Round(
    x, name=None
)
","Rounds the values of a tensor to the nearest integer, element-wise.View aliases"
tf.raw_ops.Rsqrt,"tf.raw_ops.Rsqrt(
    x, name=None
)
",Computes reciprocal of square root of x element-wise.View aliases
tf.raw_ops.RsqrtGrad,"tf.raw_ops.RsqrtGrad(
    y, dy, name=None
)
",Computes the gradient for the rsqrt of x wrt its input.View aliases
tf.raw_ops.SampleDistortedBoundingBox,"tf.raw_ops.SampleDistortedBoundingBox(
    image_size,
    bounding_boxes,
    seed=0,
    seed2=0,
    min_object_covered=0.1,
    aspect_ratio_range=[0.75, 1.33],
    area_range=[0.05, 1],
    max_attempts=100,
    use_image_if_no_bounding_boxes=False,
    name=None
)
",Generate a single randomly distorted bounding box for an image.View aliases
tf.raw_ops.SampleDistortedBoundingBoxV2,"tf.raw_ops.SampleDistortedBoundingBoxV2(
    image_size,
    bounding_boxes,
    min_object_covered,
    seed=0,
    seed2=0,
    aspect_ratio_range=[0.75, 1.33],
    area_range=[0.05, 1],
    max_attempts=100,
    use_image_if_no_bounding_boxes=False,
    name=None
)
",Generate a single randomly distorted bounding box for an image.View aliases
tf.raw_ops.SamplingDataset,"tf.raw_ops.SamplingDataset(
    input_dataset, rate, seed, seed2, output_types, output_shapes, name=None
)
",Creates a dataset that takes a Bernoulli sample of the contents of another dataset.View aliases
tf.raw_ops.Save,"tf.raw_ops.Save(
    filename, tensor_names, data, name=None
)
",Saves the input tensors to disk.View aliases
tf.raw_ops.SaveDataset,"tf.raw_ops.SaveDataset(
    input_dataset,
    path,
    shard_func_other_args,
    shard_func,
    compression='',
    use_shard_func=True,
    name=None
)
",View aliases
tf.raw_ops.SaveDatasetV2,"tf.raw_ops.SaveDatasetV2(
    input_dataset,
    path,
    shard_func_other_args,
    shard_func,
    output_types,
    output_shapes,
    compression='',
    use_shard_func=True,
    name=None
)
",View aliases
tf.raw_ops.SaveSlices,"tf.raw_ops.SaveSlices(
    filename, tensor_names, shapes_and_slices, data, name=None
)
",Saves input tensors slices to disk.View aliases
tf.raw_ops.SaveV2,"tf.raw_ops.SaveV2(
    prefix, tensor_names, shape_and_slices, tensors, name=None
)
",Saves tensors in V2 checkpoint format.View aliases
tf.raw_ops.ScalarSummary,"tf.raw_ops.ScalarSummary(
    tags, values, name=None
)
",Outputs a Summary protocol buffer with scalar values.View aliases
tf.raw_ops.ScaleAndTranslate,"tf.raw_ops.ScaleAndTranslate(
    images,
    size,
    scale,
    translation,
    kernel_type='lanczos3',
    antialias=True,
    name=None
)
",View aliases
tf.raw_ops.ScaleAndTranslateGrad,"tf.raw_ops.ScaleAndTranslateGrad(
    grads,
    original_image,
    scale,
    translation,
    kernel_type='lanczos3',
    antialias=True,
    name=None
)
",View aliases
tf.raw_ops.ScanDataset,"tf.raw_ops.ScanDataset(
    input_dataset,
    initial_state,
    other_arguments,
    f,
    output_types,
    output_shapes,
    preserve_cardinality=False,
    use_default_device=True,
    metadata='',
    name=None
)
",Creates a dataset successively reduces f over the elements of input_dataset.View aliases
tf.raw_ops.ScatterAdd,"tf.raw_ops.ScatterAdd(
    ref, indices, updates, use_locking=False, name=None
)
",Adds sparse updates to a variable reference.View aliases
tf.raw_ops.ScatterDiv,"tf.raw_ops.ScatterDiv(
    ref, indices, updates, use_locking=False, name=None
)
",Divides a variable reference by sparse updates.View aliases
tf.raw_ops.ScatterMax,"tf.raw_ops.ScatterMax(
    ref, indices, updates, use_locking=False, name=None
)
",Reduces sparse updates into a variable reference using the max operation.View aliases
tf.raw_ops.ScatterMin,"tf.raw_ops.ScatterMin(
    ref, indices, updates, use_locking=False, name=None
)
",Reduces sparse updates into a variable reference using the min operation.View aliases
tf.raw_ops.ScatterMul,"tf.raw_ops.ScatterMul(
    ref, indices, updates, use_locking=False, name=None
)
",Multiplies sparse updates into a variable reference.View aliases
tf.raw_ops.ScatterNd,"tf.raw_ops.ScatterNd(
    indices, updates, shape, name=None
)
",Scatters updates into a tensor of shape shape according to indices.View aliases
tf.raw_ops.ScatterNdAdd,"tf.raw_ops.ScatterNdAdd(
    ref, indices, updates, use_locking=False, name=None
)
",Applies sparse addition to individual values or slices in a Variable.View aliases
tf.raw_ops.ScatterNdMax,"tf.raw_ops.ScatterNdMax(
    ref, indices, updates, use_locking=False, name=None
)
",Computes element-wise maximum.View aliases
tf.raw_ops.ScatterNdMin,"tf.raw_ops.ScatterNdMin(
    ref, indices, updates, use_locking=False, name=None
)
",Computes element-wise minimum.View aliases
tf.raw_ops.ScatterNdNonAliasingAdd,"tf.raw_ops.ScatterNdNonAliasingAdd(
    input, indices, updates, name=None
)
",Applies sparse addition to input using individual values or slicesView aliases
tf.raw_ops.ScatterNdSub,"tf.raw_ops.ScatterNdSub(
    ref, indices, updates, use_locking=False, name=None
)
",Applies sparse subtraction to individual values or slices in a Variable.View aliases
tf.raw_ops.ScatterNdUpdate,"tf.raw_ops.ScatterNdUpdate(
    ref, indices, updates, use_locking=True, name=None
)
",Applies sparse updates to individual values or slices within a givenView aliases
tf.raw_ops.ScatterSub,"tf.raw_ops.ScatterSub(
    ref, indices, updates, use_locking=False, name=None
)
",Subtracts sparse updates to a variable reference.View aliases
tf.raw_ops.ScatterUpdate,"tf.raw_ops.ScatterUpdate(
    ref, indices, updates, use_locking=True, name=None
)
",Applies sparse updates to a variable reference.View aliases
tf.raw_ops.SdcaFprint,"tf.raw_ops.SdcaFprint(
    input, name=None
)
",Computes fingerprints of the input strings.View aliases
tf.raw_ops.SdcaOptimizer,"tf.raw_ops.SdcaOptimizer(
    sparse_example_indices,
    sparse_feature_indices,
    sparse_feature_values,
    dense_features,
    example_weights,
    example_labels,
    sparse_indices,
    sparse_weights,
    dense_weights,
    example_state_data,
    loss_type,
    l1,
    l2,
    num_loss_partitions,
    num_inner_iterations,
    adaptative=True,
    name=None
)
",Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer forView aliases
tf.raw_ops.SdcaOptimizerV2,"tf.raw_ops.SdcaOptimizerV2(
    sparse_example_indices,
    sparse_feature_indices,
    sparse_feature_values,
    dense_features,
    example_weights,
    example_labels,
    sparse_indices,
    sparse_weights,
    dense_weights,
    example_state_data,
    loss_type,
    l1,
    l2,
    num_loss_partitions,
    num_inner_iterations,
    adaptive=True,
    name=None
)
",Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer forView aliases
tf.raw_ops.SdcaShrinkL1,"tf.raw_ops.SdcaShrinkL1(
    weights, l1, l2, name=None
)
",Applies L1 regularization shrink step on the parameters.View aliases
tf.raw_ops.SegmentMax,"tf.raw_ops.SegmentMax(
    data, segment_ids, name=None
)
",Computes the maximum along segments of a tensor.View aliases
tf.raw_ops.SegmentMean,"tf.raw_ops.SegmentMean(
    data, segment_ids, name=None
)
",Computes the mean along segments of a tensor.View aliases
tf.raw_ops.SegmentMin,"tf.raw_ops.SegmentMin(
    data, segment_ids, name=None
)
",Computes the minimum along segments of a tensor.View aliases
tf.raw_ops.SegmentProd,"tf.raw_ops.SegmentProd(
    data, segment_ids, name=None
)
",Computes the product along segments of a tensor.View aliases
tf.raw_ops.SegmentSum,"tf.raw_ops.SegmentSum(
    data, segment_ids, name=None
)
",Computes the sum along segments of a tensor.View aliases
tf.raw_ops.Select,"tf.raw_ops.Select(
    condition, x, y, name=None
)
","Selects elements from x or y, depending on condition.View aliases"
tf.raw_ops.SelectV2,"tf.raw_ops.SelectV2(
    condition, t, e, name=None
)
",View aliases
tf.raw_ops.SelfAdjointEig,"tf.raw_ops.SelfAdjointEig(
    input, name=None
)
",Computes the Eigen Decomposition of a batch of square self-adjoint matrices.View aliases
tf.raw_ops.SelfAdjointEigV2,"tf.raw_ops.SelfAdjointEigV2(
    input, compute_v=True, name=None
)
",Computes the eigen decomposition of one or more square self-adjoint matrices.View aliases
tf.raw_ops.Selu,"tf.raw_ops.Selu(
    features, name=None
)
",Computes scaled exponential linear: scale * alpha * (exp(features) - 1)View aliases
tf.raw_ops.SeluGrad,"tf.raw_ops.SeluGrad(
    gradients, outputs, name=None
)
",Computes gradients for the scaled exponential linear (Selu) operation.View aliases
tf.raw_ops.Send,"tf.raw_ops.Send(
    tensor,
    tensor_name,
    send_device,
    send_device_incarnation,
    recv_device,
    client_terminated=False,
    name=None
)
",Sends the named tensor from send_device to recv_device.View aliases
tf.raw_ops.SendTPUEmbeddingGradients,"tf.raw_ops.SendTPUEmbeddingGradients(
    inputs, learning_rates, config, name=None
)
",Performs gradient updates of embedding tables.View aliases
tf.raw_ops.SerializeIterator,"tf.raw_ops.SerializeIterator(
    resource_handle, external_state_policy=0, name=None
)
",Converts the given resource_handle representing an iterator to a variant tensor.View aliases
tf.raw_ops.SerializeManySparse,"tf.raw_ops.SerializeManySparse(
    sparse_indices,
    sparse_values,
    sparse_shape,
    out_type=tf.dtypes.string,
    name=None
)
","Serialize an N-minibatch SparseTensor into an [N, 3] Tensor object.View aliases"
tf.raw_ops.SerializeSparse,"tf.raw_ops.SerializeSparse(
    sparse_indices,
    sparse_values,
    sparse_shape,
    out_type=tf.dtypes.string,
    name=None
)
",Serialize a SparseTensor into a [3] Tensor object.View aliases
tf.raw_ops.SerializeTensor,"tf.raw_ops.SerializeTensor(
    tensor, name=None
)
",Transforms a Tensor into a serialized TensorProto proto.View aliases
tf.raw_ops.SetSize,"tf.raw_ops.SetSize(
    set_indices, set_values, set_shape, validate_indices=True, name=None
)
",Number of unique elements along last dimension of input set.View aliases
tf.raw_ops.SetStatsAggregatorDataset,"tf.raw_ops.SetStatsAggregatorDataset(
    input_dataset,
    stats_aggregator,
    tag,
    counter_prefix,
    output_types,
    output_shapes,
    name=None
)
",View aliases
tf.raw_ops.Shape,"tf.raw_ops.Shape(
    input,
    out_type=tf.dtypes.int32,
    name=None
)
",Returns the shape of a tensor.View aliases
tf.raw_ops.ShapeN,"tf.raw_ops.ShapeN(
    input,
    out_type=tf.dtypes.int32,
    name=None
)
",Returns shape of tensors.View aliases
tf.raw_ops.ShardDataset,"tf.raw_ops.ShardDataset(
    input_dataset,
    num_shards,
    index,
    output_types,
    output_shapes,
    require_non_empty=False,
    metadata='',
    name=None
)
",Creates a Dataset that includes only 1/num_shards of this dataset.View aliases
tf.raw_ops.ShardedFilename,"tf.raw_ops.ShardedFilename(
    basename, shard, num_shards, name=None
)
",Generate a sharded filename. The filename is printf formatted asView aliases
tf.raw_ops.ShardedFilespec,"tf.raw_ops.ShardedFilespec(
    basename, num_shards, name=None
)
",Generate a glob pattern matching all sharded file names.View aliases
tf.raw_ops.ShuffleAndRepeatDataset,"tf.raw_ops.ShuffleAndRepeatDataset(
    input_dataset,
    buffer_size,
    seed,
    seed2,
    count,
    output_types,
    output_shapes,
    reshuffle_each_iteration=True,
    metadata='',
    name=None
)
",Creates a dataset that shuffles and repeats elements from input_datasetView aliases
tf.raw_ops.ShuffleAndRepeatDatasetV2,"tf.raw_ops.ShuffleAndRepeatDatasetV2(
    input_dataset,
    buffer_size,
    seed,
    seed2,
    count,
    seed_generator,
    output_types,
    output_shapes,
    reshuffle_each_iteration=True,
    metadata='',
    name=None
)
",View aliases
tf.raw_ops.ShuffleDataset,"tf.raw_ops.ShuffleDataset(
    input_dataset,
    buffer_size,
    seed,
    seed2,
    output_types,
    output_shapes,
    reshuffle_each_iteration=True,
    metadata='',
    name=None
)
",Creates a dataset that shuffles elements from input_dataset pseudorandomly.View aliases
tf.raw_ops.ShuffleDatasetV2,"tf.raw_ops.ShuffleDatasetV2(
    input_dataset,
    buffer_size,
    seed_generator,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",View aliases
tf.raw_ops.ShuffleDatasetV3,"tf.raw_ops.ShuffleDatasetV3(
    input_dataset,
    buffer_size,
    seed,
    seed2,
    seed_generator,
    output_types,
    output_shapes,
    reshuffle_each_iteration=True,
    metadata='',
    name=None
)
",View aliases
tf.raw_ops.ShutdownDistributedTPU,"tf.raw_ops.ShutdownDistributedTPU(
    name=None
)
",Shuts down a running distributed TPU system.View aliases
tf.raw_ops.Sigmoid,"tf.raw_ops.Sigmoid(
    x, name=None
)
",Computes sigmoid of x element-wise.View aliases
tf.raw_ops.SigmoidGrad,"tf.raw_ops.SigmoidGrad(
    y, dy, name=None
)
",Computes the gradient of the sigmoid of x wrt its input.View aliases
tf.raw_ops.Sign,"tf.raw_ops.Sign(
    x, name=None
)
",Returns an element-wise indication of the sign of a number.View aliases
tf.raw_ops.Sin,"tf.raw_ops.Sin(
    x, name=None
)
",Computes sine of x element-wise.View aliases
tf.raw_ops.Sinh,"tf.raw_ops.Sinh(
    x, name=None
)
",Computes hyperbolic sine of x element-wise.View aliases
tf.raw_ops.Size,"tf.raw_ops.Size(
    input,
    out_type=tf.dtypes.int32,
    name=None
)
",Returns the size of a tensor.View aliases
tf.raw_ops.SkipDataset,"tf.raw_ops.SkipDataset(
    input_dataset,
    count,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that skips count elements from the input_dataset.View aliases
tf.raw_ops.SleepDataset,"tf.raw_ops.SleepDataset(
    input_dataset, sleep_microseconds, output_types, output_shapes, name=None
)
",View aliases
tf.raw_ops.Slice,"tf.raw_ops.Slice(
    input, begin, size, name=None
)
",Return a slice from 'input'.View aliases
tf.raw_ops.SlidingWindowDataset,"tf.raw_ops.SlidingWindowDataset(
    input_dataset,
    window_size,
    window_shift,
    window_stride,
    output_types,
    output_shapes,
    drop_remainder=True,
    name=None
)
",Creates a dataset that passes a sliding window over input_dataset.View aliases
tf.raw_ops.Snapshot,"tf.raw_ops.Snapshot(
    input, name=None
)
",Returns a copy of the input tensor.View aliases
tf.raw_ops.SnapshotDataset,"tf.raw_ops.SnapshotDataset(
    input_dataset,
    path,
    output_types,
    output_shapes,
    compression='',
    reader_path_prefix='',
    writer_path_prefix='',
    shard_size_bytes=10737418240,
    pending_snapshot_expiry_seconds=86400,
    num_reader_threads=1,
    reader_buffer_size=1,
    num_writer_threads=1,
    writer_buffer_size=1,
    shuffle_on_read=False,
    seed=0,
    seed2=0,
    mode='auto',
    snapshot_name='',
    name=None
)
",Creates a dataset that will write to / read from a snapshot.View aliases
tf.raw_ops.SnapshotDatasetReader,"tf.raw_ops.SnapshotDatasetReader(
    shard_dir,
    start_index,
    output_types,
    output_shapes,
    version,
    compression='',
    name=None
)
",View aliases
tf.raw_ops.SnapshotDatasetV2,"tf.raw_ops.SnapshotDatasetV2(
    input_dataset,
    path,
    reader_func_other_args,
    shard_func_other_args,
    output_types,
    output_shapes,
    reader_func,
    shard_func,
    compression='',
    reader_prefix='',
    writer_prefix='',
    hash_valid=False,
    hash=0,
    metadata='',
    name=None
)
",Creates a dataset that will write to / read from a snapshot.View aliases
tf.raw_ops.SnapshotNestedDatasetReader,"tf.raw_ops.SnapshotNestedDatasetReader(
    inputs, output_types, output_shapes, name=None
)
",View aliases
tf.raw_ops.SobolSample,"tf.raw_ops.SobolSample(
    dim,
    num_results,
    skip,
    dtype=tf.dtypes.float32,
    name=None
)
",Generates points from the Sobol sequence.View aliases
tf.raw_ops.Softmax,"tf.raw_ops.Softmax(
    logits, name=None
)
",Computes softmax activations.View aliases
tf.raw_ops.SoftmaxCrossEntropyWithLogits,"tf.raw_ops.SoftmaxCrossEntropyWithLogits(
    features, labels, name=None
)
",Computes softmax cross entropy cost and gradients to backpropagate.View aliases
tf.raw_ops.Softplus,"tf.raw_ops.Softplus(
    features, name=None
)
",View aliases
tf.raw_ops.SoftplusGrad,"tf.raw_ops.SoftplusGrad(
    gradients, features, name=None
)
",Computes softplus gradients for a softplus operation.View aliases
tf.raw_ops.Softsign,"tf.raw_ops.Softsign(
    features, name=None
)
",Computes softsign: features / (abs(features) + 1).View aliases
tf.raw_ops.SoftsignGrad,"tf.raw_ops.SoftsignGrad(
    gradients, features, name=None
)
",Computes softsign gradients for a softsign operation.View aliases
tf.raw_ops.SpaceToBatch,"tf.raw_ops.SpaceToBatch(
    input, paddings, block_size, name=None
)
",SpaceToBatch for 4-D tensors of type T.View aliases
tf.raw_ops.SpaceToBatchND,"tf.raw_ops.SpaceToBatchND(
    input, block_shape, paddings, name=None
)
",SpaceToBatch for N-D tensors of type T.View aliases
tf.raw_ops.SpaceToDepth,"tf.raw_ops.SpaceToDepth(
    input, block_size, data_format='NHWC', name=None
)
",SpaceToDepth for tensors of type T.View aliases
tf.raw_ops.SparseAccumulatorApplyGradient,"tf.raw_ops.SparseAccumulatorApplyGradient(
    handle,
    local_step,
    gradient_indices,
    gradient_values,
    gradient_shape,
    has_known_shape,
    name=None
)
",Applies a sparse gradient to a given accumulator.View aliases
tf.raw_ops.SparseAccumulatorTakeGradient,"tf.raw_ops.SparseAccumulatorTakeGradient(
    handle, num_required, dtype, name=None
)
",Extracts the average sparse gradient in a SparseConditionalAccumulator.View aliases
tf.raw_ops.SparseAdd,"tf.raw_ops.SparseAdd(
    a_indices,
    a_values,
    a_shape,
    b_indices,
    b_values,
    b_shape,
    thresh,
    name=None
)
",Adds two SparseTensor objects to produce another SparseTensor.View aliases
tf.raw_ops.SparseAddGrad,"tf.raw_ops.SparseAddGrad(
    backprop_val_grad, a_indices, b_indices, sum_indices, name=None
)
",The gradient operator for the SparseAdd op.View aliases
tf.raw_ops.SparseApplyAdadelta,"tf.raw_ops.SparseApplyAdadelta(
    var,
    accum,
    accum_update,
    lr,
    rho,
    epsilon,
    grad,
    indices,
    use_locking=False,
    name=None
)
",var: Should be from a Variable().View aliases
tf.raw_ops.SparseApplyAdagrad,"tf.raw_ops.SparseApplyAdagrad(
    var,
    accum,
    lr,
    grad,
    indices,
    use_locking=False,
    update_slots=True,
    name=None
)
",Update relevant entries in 'var' and 'accum' according to the adagrad scheme.View aliases
tf.raw_ops.SparseApplyAdagradDA,"tf.raw_ops.SparseApplyAdagradDA(
    var,
    gradient_accumulator,
    gradient_squared_accumulator,
    grad,
    indices,
    lr,
    l1,
    l2,
    global_step,
    use_locking=False,
    name=None
)
",Update entries in 'var' and 'accum' according to the proximal adagrad scheme.View aliases
tf.raw_ops.SparseApplyAdagradV2,"tf.raw_ops.SparseApplyAdagradV2(
    var,
    accum,
    lr,
    epsilon,
    grad,
    indices,
    use_locking=False,
    update_slots=True,
    name=None
)
",Update relevant entries in 'var' and 'accum' according to the adagrad scheme.View aliases
tf.raw_ops.SparseApplyCenteredRMSProp,"tf.raw_ops.SparseApplyCenteredRMSProp(
    var,
    mg,
    ms,
    mom,
    lr,
    rho,
    momentum,
    epsilon,
    grad,
    indices,
    use_locking=False,
    name=None
)
",Update '*var' according to the centered RMSProp algorithm.View aliases
tf.raw_ops.SparseApplyFtrl,"tf.raw_ops.SparseApplyFtrl(
    var,
    accum,
    linear,
    grad,
    indices,
    lr,
    l1,
    l2,
    lr_power,
    use_locking=False,
    multiply_linear_by_lr=False,
    name=None
)
",Update relevant entries in '*var' according to the Ftrl-proximal scheme.View aliases
tf.raw_ops.SparseApplyFtrlV2,"tf.raw_ops.SparseApplyFtrlV2(
    var,
    accum,
    linear,
    grad,
    indices,
    lr,
    l1,
    l2,
    l2_shrinkage,
    lr_power,
    use_locking=False,
    multiply_linear_by_lr=False,
    name=None
)
",Update relevant entries in '*var' according to the Ftrl-proximal scheme.View aliases
tf.raw_ops.SparseApplyMomentum,"tf.raw_ops.SparseApplyMomentum(
    var,
    accum,
    lr,
    grad,
    indices,
    momentum,
    use_locking=False,
    use_nesterov=False,
    name=None
)
",Update relevant entries in 'var' and 'accum' according to the momentum scheme.View aliases
tf.raw_ops.SparseApplyProximalAdagrad,"tf.raw_ops.SparseApplyProximalAdagrad(
    var, accum, lr, l1, l2, grad, indices, use_locking=False, name=None
)
",Sparse update entries in 'var' and 'accum' according to FOBOS algorithm.View aliases
tf.raw_ops.SparseApplyProximalGradientDescent,"tf.raw_ops.SparseApplyProximalGradientDescent(
    var, alpha, l1, l2, grad, indices, use_locking=False, name=None
)
",Sparse update '*var' as FOBOS algorithm with fixed learning rate.View aliases
tf.raw_ops.SparseApplyRMSProp,"tf.raw_ops.SparseApplyRMSProp(
    var,
    ms,
    mom,
    lr,
    rho,
    momentum,
    epsilon,
    grad,
    indices,
    use_locking=False,
    name=None
)
",Update '*var' according to the RMSProp algorithm.View aliases
tf.raw_ops.SparseBincount,"tf.raw_ops.SparseBincount(
    indices, values, dense_shape, size, weights, binary_output=False, name=None
)
",Counts the number of occurrences of each value in an integer array.View aliases
tf.raw_ops.SparseConcat,"tf.raw_ops.SparseConcat(
    indices, values, shapes, concat_dim, name=None
)
",Concatenates a list of SparseTensor along the specified dimension.View aliases
tf.raw_ops.SparseConditionalAccumulator,"tf.raw_ops.SparseConditionalAccumulator(
    dtype,
    shape,
    container='',
    shared_name='',
    reduction_type='MEAN',
    name=None
)
",A conditional accumulator for aggregating sparse gradients.View aliases
tf.raw_ops.SparseCountSparseOutput,"tf.raw_ops.SparseCountSparseOutput(
    indices,
    values,
    dense_shape,
    weights,
    binary_output,
    minlength=-1,
    maxlength=-1,
    name=None
)
",Performs sparse-output bin counting for a sparse tensor input.View aliases
tf.raw_ops.SparseCross,"tf.raw_ops.SparseCross(
    indices,
    values,
    shapes,
    dense_inputs,
    hashed_output,
    num_buckets,
    hash_key,
    out_type,
    internal_type,
    name=None
)
",Generates sparse cross from a list of sparse and dense tensors.View aliases
tf.raw_ops.SparseCrossHashed,"tf.raw_ops.SparseCrossHashed(
    indices,
    values,
    shapes,
    dense_inputs,
    num_buckets,
    strong_hash,
    salt,
    name=None
)
",Generates sparse cross from a list of sparse and dense tensors.View aliases
tf.raw_ops.SparseCrossV2,"tf.raw_ops.SparseCrossV2(
    indices, values, shapes, dense_inputs, sep, name=None
)
",Generates sparse cross from a list of sparse and dense tensors.View aliases
tf.raw_ops.SparseDenseCwiseAdd,"tf.raw_ops.SparseDenseCwiseAdd(
    sp_indices, sp_values, sp_shape, dense, name=None
)
","Adds up a SparseTensor and a dense Tensor, using these special rules:View aliases"
tf.raw_ops.SparseDenseCwiseDiv,"tf.raw_ops.SparseDenseCwiseDiv(
    sp_indices, sp_values, sp_shape, dense, name=None
)
",Component-wise divides a SparseTensor by a dense Tensor.View aliases
tf.raw_ops.SparseDenseCwiseMul,"tf.raw_ops.SparseDenseCwiseMul(
    sp_indices, sp_values, sp_shape, dense, name=None
)
",Component-wise multiplies a SparseTensor by a dense Tensor.View aliases
tf.raw_ops.SparseFillEmptyRows,"tf.raw_ops.SparseFillEmptyRows(
    indices, values, dense_shape, default_value, name=None
)
",Fills empty rows in the input 2-D SparseTensor with a default value.View aliases
tf.raw_ops.SparseFillEmptyRowsGrad,"tf.raw_ops.SparseFillEmptyRowsGrad(
    reverse_index_map, grad_values, name=None
)
",The gradient of SparseFillEmptyRows.View aliases
tf.raw_ops.SparseMatMul,"tf.raw_ops.SparseMatMul(
    a,
    b,
    transpose_a=False,
    transpose_b=False,
    a_is_sparse=False,
    b_is_sparse=False,
    name=None
)
","Multiply matrix ""a"" by matrix ""b"".View aliases"
tf.raw_ops.SparseMatrixAdd,"tf.raw_ops.SparseMatrixAdd(
    a, b, alpha, beta, name=None
)
","Sparse addition of two CSR matrices, C = alpha * A + beta * B.View aliases"
tf.raw_ops.SparseMatrixMatMul,"tf.raw_ops.SparseMatrixMatMul(
    a,
    b,
    transpose_a=False,
    transpose_b=False,
    adjoint_a=False,
    adjoint_b=False,
    transpose_output=False,
    conjugate_output=False,
    name=None
)
",Matrix-multiplies a sparse matrix with a dense matrix.View aliases
tf.raw_ops.SparseMatrixMul,"tf.raw_ops.SparseMatrixMul(
    a, b, name=None
)
",Element-wise multiplication of a sparse matrix with a dense tensor.View aliases
tf.raw_ops.SparseMatrixNNZ,"tf.raw_ops.SparseMatrixNNZ(
    sparse_matrix, name=None
)
",Returns the number of nonzeroes of sparse_matrix.View aliases
tf.raw_ops.SparseMatrixOrderingAMD,"tf.raw_ops.SparseMatrixOrderingAMD(
    input, name=None
)
",Computes the Approximate Minimum Degree (AMD) ordering of input.View aliases
tf.raw_ops.SparseMatrixSoftmax,"tf.raw_ops.SparseMatrixSoftmax(
    logits, type, name=None
)
",Calculates the softmax of a CSRSparseMatrix.View aliases
tf.raw_ops.SparseMatrixSoftmaxGrad,"tf.raw_ops.SparseMatrixSoftmaxGrad(
    softmax, grad_softmax, type, name=None
)
",Calculates the gradient of the SparseMatrixSoftmax op.View aliases
tf.raw_ops.SparseMatrixSparseCholesky,"tf.raw_ops.SparseMatrixSparseCholesky(
    input, permutation, type, name=None
)
",Computes the sparse Cholesky decomposition of input.View aliases
tf.raw_ops.SparseMatrixSparseMatMul,"tf.raw_ops.SparseMatrixSparseMatMul(
    a,
    b,
    type,
    transpose_a=False,
    transpose_b=False,
    adjoint_a=False,
    adjoint_b=False,
    name=None
)
",Sparse-matrix-multiplies two CSR matrices a and b.View aliases
tf.raw_ops.SparseMatrixTranspose,"tf.raw_ops.SparseMatrixTranspose(
    input, type, conjugate=False, name=None
)
",Transposes the inner (matrix) dimensions of a CSRSparseMatrix.View aliases
tf.raw_ops.SparseMatrixZeros,"tf.raw_ops.SparseMatrixZeros(
    dense_shape, type, name=None
)
",Creates an all-zeros CSRSparseMatrix with shape dense_shape.View aliases
tf.raw_ops.SparseReduceMax,"tf.raw_ops.SparseReduceMax(
    input_indices,
    input_values,
    input_shape,
    reduction_axes,
    keep_dims=False,
    name=None
)
",Computes the max of elements across dimensions of a SparseTensor.View aliases
tf.raw_ops.SparseReduceMaxSparse,"tf.raw_ops.SparseReduceMaxSparse(
    input_indices,
    input_values,
    input_shape,
    reduction_axes,
    keep_dims=False,
    name=None
)
",Computes the max of elements across dimensions of a SparseTensor.View aliases
tf.raw_ops.SparseReduceSum,"tf.raw_ops.SparseReduceSum(
    input_indices,
    input_values,
    input_shape,
    reduction_axes,
    keep_dims=False,
    name=None
)
",Computes the sum of elements across dimensions of a SparseTensor.View aliases
tf.raw_ops.SparseReduceSumSparse,"tf.raw_ops.SparseReduceSumSparse(
    input_indices,
    input_values,
    input_shape,
    reduction_axes,
    keep_dims=False,
    name=None
)
",Computes the sum of elements across dimensions of a SparseTensor.View aliases
tf.raw_ops.SparseReorder,"tf.raw_ops.SparseReorder(
    input_indices, input_values, input_shape, name=None
)
","Reorders a SparseTensor into the canonical, row-major ordering.View aliases"
tf.raw_ops.SparseReshape,"tf.raw_ops.SparseReshape(
    input_indices, input_shape, new_shape, name=None
)
",Reshapes a SparseTensor to represent values in a new dense shape.View aliases
tf.raw_ops.SparseSegmentMean,"tf.raw_ops.SparseSegmentMean(
    data, indices, segment_ids, name=None
)
",Computes the mean along sparse segments of a tensor.View aliases
tf.raw_ops.SparseSegmentMeanGrad,"tf.raw_ops.SparseSegmentMeanGrad(
    grad, indices, segment_ids, output_dim0, name=None
)
",Computes gradients for SparseSegmentMean.View aliases
tf.raw_ops.SparseSegmentMeanWithNumSegments,"tf.raw_ops.SparseSegmentMeanWithNumSegments(
    data, indices, segment_ids, num_segments, name=None
)
",Computes the mean along sparse segments of a tensor.View aliases
tf.raw_ops.SparseSegmentSqrtN,"tf.raw_ops.SparseSegmentSqrtN(
    data, indices, segment_ids, name=None
)
",Computes the sum along sparse segments of a tensor divided by the sqrt of N.View aliases
tf.raw_ops.SparseSegmentSqrtNGrad,"tf.raw_ops.SparseSegmentSqrtNGrad(
    grad, indices, segment_ids, output_dim0, name=None
)
",Computes gradients for SparseSegmentSqrtN.View aliases
tf.raw_ops.SparseSegmentSqrtNWithNumSegments,"tf.raw_ops.SparseSegmentSqrtNWithNumSegments(
    data, indices, segment_ids, num_segments, name=None
)
",Computes the sum along sparse segments of a tensor divided by the sqrt of N.View aliases
tf.raw_ops.SparseSegmentSum,"tf.raw_ops.SparseSegmentSum(
    data, indices, segment_ids, name=None
)
",Computes the sum along sparse segments of a tensor.View aliases
tf.raw_ops.SparseSegmentSumGrad,"tf.raw_ops.SparseSegmentSumGrad(
    grad, indices, segment_ids, output_dim0, name=None
)
",Computes gradients for SparseSegmentSum.View aliases
tf.raw_ops.SparseSegmentSumWithNumSegments,"tf.raw_ops.SparseSegmentSumWithNumSegments(
    data, indices, segment_ids, num_segments, name=None
)
",Computes the sum along sparse segments of a tensor.View aliases
tf.raw_ops.SparseSlice,"tf.raw_ops.SparseSlice(
    indices, values, shape, start, size, name=None
)
",Slice a SparseTensor based on the start and size.View aliases
tf.raw_ops.SparseSliceGrad,"tf.raw_ops.SparseSliceGrad(
    backprop_val_grad, input_indices, input_start, output_indices, name=None
)
",The gradient operator for the SparseSlice op.View aliases
tf.raw_ops.SparseSoftmax,"tf.raw_ops.SparseSoftmax(
    sp_indices, sp_values, sp_shape, name=None
)
",Applies softmax to a batched N-D SparseTensor.View aliases
tf.raw_ops.SparseSoftmaxCrossEntropyWithLogits,"tf.raw_ops.SparseSoftmaxCrossEntropyWithLogits(
    features, labels, name=None
)
",Computes softmax cross entropy cost and gradients to backpropagate.View aliases
tf.raw_ops.SparseSparseMaximum,"tf.raw_ops.SparseSparseMaximum(
    a_indices, a_values, a_shape, b_indices, b_values, b_shape, name=None
)
",Returns the element-wise max of two SparseTensors.View aliases
tf.raw_ops.SparseSparseMinimum,"tf.raw_ops.SparseSparseMinimum(
    a_indices, a_values, a_shape, b_indices, b_values, b_shape, name=None
)
",Returns the element-wise min of two SparseTensors.View aliases
tf.raw_ops.SparseSplit,"tf.raw_ops.SparseSplit(
    split_dim, indices, values, shape, num_split, name=None
)
",Split a SparseTensor into num_split tensors along one dimension.View aliases
tf.raw_ops.SparseTensorDenseAdd,"tf.raw_ops.SparseTensorDenseAdd(
    a_indices, a_values, a_shape, b, name=None
)
","Adds up a SparseTensor and a dense Tensor, producing a dense Tensor.View aliases"
tf.raw_ops.SparseTensorDenseMatMul,"tf.raw_ops.SparseTensorDenseMatMul(
    a_indices,
    a_values,
    a_shape,
    b,
    adjoint_a=False,
    adjoint_b=False,
    name=None
)
","Multiply SparseTensor (of rank 2) ""A"" by dense matrix ""B"".View aliases"
tf.raw_ops.SparseTensorSliceDataset,"tf.raw_ops.SparseTensorSliceDataset(
    indices, values, dense_shape, name=None
)
",Creates a dataset that splits a SparseTensor into elements row-wise.View aliases
tf.raw_ops.SparseTensorToCSRSparseMatrix,"tf.raw_ops.SparseTensorToCSRSparseMatrix(
    indices, values, dense_shape, name=None
)
",Converts a SparseTensor to a (possibly batched) CSRSparseMatrix.View aliases
tf.raw_ops.SparseToDense,"tf.raw_ops.SparseToDense(
    sparse_indices,
    output_shape,
    sparse_values,
    default_value,
    validate_indices=True,
    name=None
)
",Converts a sparse representation into a dense tensor.View aliases
tf.raw_ops.SparseToSparseSetOperation,"tf.raw_ops.SparseToSparseSetOperation(
    set1_indices,
    set1_values,
    set1_shape,
    set2_indices,
    set2_values,
    set2_shape,
    set_operation,
    validate_indices=True,
    name=None
)
",Applies set operation along last dimension of 2 SparseTensor inputs.View aliases
tf.raw_ops.Spence,"tf.raw_ops.Spence(
    x, name=None
)
",View aliases
tf.raw_ops.Split,"tf.raw_ops.Split(
    axis, value, num_split, name=None
)
",Splits a tensor into num_split tensors along one dimension.View aliases
tf.raw_ops.SplitV,"tf.raw_ops.SplitV(
    value, size_splits, axis, num_split, name=None
)
",Splits a tensor into num_split tensors along one dimension.View aliases
tf.raw_ops.SqlDataset,"tf.raw_ops.SqlDataset(
    driver_name,
    data_source_name,
    query,
    output_types,
    output_shapes,
    name=None
)
",Creates a dataset that executes a SQL query and emits rows of the result set.View aliases
tf.raw_ops.Sqrt,"tf.raw_ops.Sqrt(
    x, name=None
)
",Computes square root of x element-wise.View aliases
tf.raw_ops.SqrtGrad,"tf.raw_ops.SqrtGrad(
    y, dy, name=None
)
",Computes the gradient for the sqrt of x wrt its input.View aliases
tf.raw_ops.Square,"tf.raw_ops.Square(
    x, name=None
)
",Computes square of x element-wise.View aliases
tf.raw_ops.SquaredDifference,"tf.raw_ops.SquaredDifference(
    x, y, name=None
)
",Returns conj(x - y)(x - y) element-wise.View aliases
tf.raw_ops.Squeeze,"tf.raw_ops.Squeeze(
    input, axis=[], name=None
)
",Removes dimensions of size 1 from the shape of a tensor.View aliases
tf.raw_ops.Stack,"tf.raw_ops.Stack(
    elem_type, stack_name='', name=None
)
","Deprecated, use StackV2.View aliases"
tf.raw_ops.StackClose,"tf.raw_ops.StackClose(
    handle, name=None
)
","Deprecated, use StackCloseV2.View aliases"
tf.raw_ops.StackCloseV2,"tf.raw_ops.StackCloseV2(
    handle, name=None
)
",Delete the stack from its resource container.View aliases
tf.raw_ops.StackPop,"tf.raw_ops.StackPop(
    handle, elem_type, name=None
)
","Deprecated, use StackPopV2.View aliases"
tf.raw_ops.StackPopV2,"tf.raw_ops.StackPopV2(
    handle, elem_type, name=None
)
",Pop the element at the top of the stack.View aliases
tf.raw_ops.StackPush,"tf.raw_ops.StackPush(
    handle, elem, swap_memory=False, name=None
)
","Deprecated, use StackPushV2.View aliases"
tf.raw_ops.StackPushV2,"tf.raw_ops.StackPushV2(
    handle, elem, swap_memory=False, name=None
)
",Push an element onto the stack.View aliases
tf.raw_ops.StackV2,"tf.raw_ops.StackV2(
    max_size, elem_type, stack_name='', name=None
)
",A stack that produces elements in first-in last-out order.View aliases
tf.raw_ops.Stage,"tf.raw_ops.Stage(
    values,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Stage values similar to a lightweight Enqueue.View aliases
tf.raw_ops.StageClear,"tf.raw_ops.StageClear(
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op removes all elements in the underlying container.View aliases
tf.raw_ops.StagePeek,"tf.raw_ops.StagePeek(
    index,
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op peeks at the values at the specified index.  If theView aliases
tf.raw_ops.StageSize,"tf.raw_ops.StageSize(
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op returns the number of elements in the underlying container.View aliases
tf.raw_ops.StatefulPartitionedCall,"tf.raw_ops.StatefulPartitionedCall(
    args,
    Tout,
    f,
    config='',
    config_proto='',
    executor_type='',
    name=None
)
","returns f(inputs), where f's body is placed and partitioned.View aliases"
tf.raw_ops.StatefulRandomBinomial,"tf.raw_ops.StatefulRandomBinomial(
    resource,
    algorithm,
    shape,
    counts,
    probs,
    dtype=tf.dtypes.int64,
    name=None
)
",View aliases
tf.raw_ops.StatefulStandardNormal,"tf.raw_ops.StatefulStandardNormal(
    resource,
    shape,
    dtype=tf.dtypes.float32,
    name=None
)
",Outputs random values from a normal distribution. This op is deprecated in favor of op 'StatefulStandardNormalV2'View aliases
tf.raw_ops.StatefulStandardNormalV2,"tf.raw_ops.StatefulStandardNormalV2(
    resource,
    algorithm,
    shape,
    dtype=tf.dtypes.float32,
    name=None
)
",Outputs random values from a normal distribution.View aliases
tf.raw_ops.StatefulTruncatedNormal,"tf.raw_ops.StatefulTruncatedNormal(
    resource,
    algorithm,
    shape,
    dtype=tf.dtypes.float32,
    name=None
)
",Outputs random values from a truncated normal distribution.View aliases
tf.raw_ops.StatefulUniform,"tf.raw_ops.StatefulUniform(
    resource,
    algorithm,
    shape,
    dtype=tf.dtypes.float32,
    name=None
)
",Outputs random values from a uniform distribution.View aliases
tf.raw_ops.StatefulUniformFullInt,"tf.raw_ops.StatefulUniformFullInt(
    resource,
    algorithm,
    shape,
    dtype=tf.dtypes.uint64,
    name=None
)
",Outputs random integers from a uniform distribution.View aliases
tf.raw_ops.StatefulUniformInt,"tf.raw_ops.StatefulUniformInt(
    resource, algorithm, shape, minval, maxval, name=None
)
",Outputs random integers from a uniform distribution.View aliases
tf.raw_ops.StatelessCase,"tf.raw_ops.StatelessCase(
    branch_index, input, Tout, branches, output_shapes=[], name=None
)
",An n-way switch statement which calls a single branch function.View aliases
tf.raw_ops.StatelessIf,"tf.raw_ops.StatelessIf(
    cond, input, Tout, then_branch, else_branch, output_shapes=[], name=None
)
",output = cond ? then_branch(input) : else_branch(input)View aliases
tf.raw_ops.StatelessMultinomial,"tf.raw_ops.StatelessMultinomial(
    logits,
    num_samples,
    seed,
    output_dtype=tf.dtypes.int64,
    name=None
)
",Draws samples from a multinomial distribution.View aliases
tf.raw_ops.StatelessParameterizedTruncatedNormal,"tf.raw_ops.StatelessParameterizedTruncatedNormal(
    shape, seed, means, stddevs, minvals, maxvals, name=None
)
",View aliases
tf.raw_ops.StatelessRandomBinomial,"tf.raw_ops.StatelessRandomBinomial(
    shape,
    seed,
    counts,
    probs,
    dtype=tf.dtypes.int64,
    name=None
)
",Outputs deterministic pseudorandom random numbers from a binomial distribution.View aliases
tf.raw_ops.StatelessRandomGammaV2,"tf.raw_ops.StatelessRandomGammaV2(
    shape, seed, alpha, name=None
)
",Outputs deterministic pseudorandom random numbers from a gamma distribution.View aliases
tf.raw_ops.StatelessRandomGetAlg,"tf.raw_ops.StatelessRandomGetAlg(
    name=None
)
",Picks the best counter-based RNG algorithm based on device.View aliases
tf.raw_ops.StatelessRandomGetKeyCounter,"tf.raw_ops.StatelessRandomGetKeyCounter(
    seed, name=None
)
","Scrambles seed into key and counter, using the best algorithm based on device.View aliases"
tf.raw_ops.StatelessRandomGetKeyCounterAlg,"tf.raw_ops.StatelessRandomGetKeyCounterAlg(
    seed, name=None
)
","Picks the best algorithm based on device, and scrambles seed into key and counter.View aliases"
tf.raw_ops.StatelessRandomNormal,"tf.raw_ops.StatelessRandomNormal(
    shape,
    seed,
    dtype=tf.dtypes.float32,
    name=None
)
",Outputs deterministic pseudorandom values from a normal distribution.View aliases
tf.raw_ops.StatelessRandomNormalV2,"tf.raw_ops.StatelessRandomNormalV2(
    shape,
    key,
    counter,
    alg,
    dtype=tf.dtypes.float32,
    name=None
)
",Outputs deterministic pseudorandom values from a normal distribution.View aliases
tf.raw_ops.StatelessRandomPoisson,"tf.raw_ops.StatelessRandomPoisson(
    shape, seed, lam, dtype, name=None
)
",Outputs deterministic pseudorandom random numbers from a Poisson distribution.View aliases
tf.raw_ops.StatelessRandomUniform,"tf.raw_ops.StatelessRandomUniform(
    shape,
    seed,
    dtype=tf.dtypes.float32,
    name=None
)
",Outputs deterministic pseudorandom random values from a uniform distribution.View aliases
tf.raw_ops.StatelessRandomUniformFullInt,"tf.raw_ops.StatelessRandomUniformFullInt(
    shape,
    seed,
    dtype=tf.dtypes.uint64,
    name=None
)
",Outputs deterministic pseudorandom random integers from a uniform distribution.View aliases
tf.raw_ops.StatelessRandomUniformFullIntV2,"tf.raw_ops.StatelessRandomUniformFullIntV2(
    shape,
    key,
    counter,
    alg,
    dtype=tf.dtypes.uint64,
    name=None
)
",Outputs deterministic pseudorandom random integers from a uniform distribution.View aliases
tf.raw_ops.StatelessRandomUniformInt,"tf.raw_ops.StatelessRandomUniformInt(
    shape, seed, minval, maxval, name=None
)
",Outputs deterministic pseudorandom random integers from a uniform distribution.View aliases
tf.raw_ops.StatelessRandomUniformIntV2,"tf.raw_ops.StatelessRandomUniformIntV2(
    shape, key, counter, alg, minval, maxval, name=None
)
",Outputs deterministic pseudorandom random integers from a uniform distribution.View aliases
tf.raw_ops.StatelessRandomUniformV2,"tf.raw_ops.StatelessRandomUniformV2(
    shape,
    key,
    counter,
    alg,
    dtype=tf.dtypes.float32,
    name=None
)
",Outputs deterministic pseudorandom random values from a uniform distribution.View aliases
tf.raw_ops.StatelessSampleDistortedBoundingBox,"tf.raw_ops.StatelessSampleDistortedBoundingBox(
    image_size,
    bounding_boxes,
    min_object_covered,
    seed,
    aspect_ratio_range=[0.75, 1.33],
    area_range=[0.05, 1],
    max_attempts=100,
    use_image_if_no_bounding_boxes=False,
    name=None
)
",Generate a randomly distorted bounding box for an image deterministically.View aliases
tf.raw_ops.StatelessShuffle,"tf.raw_ops.StatelessShuffle(
    value, key, counter, alg, name=None
)
",Randomly and deterministically shuffles a tensor along its first dimension.View aliases
tf.raw_ops.StatelessTruncatedNormal,"tf.raw_ops.StatelessTruncatedNormal(
    shape,
    seed,
    dtype=tf.dtypes.float32,
    name=None
)
",Outputs deterministic pseudorandom values from a truncated normal distribution.View aliases
tf.raw_ops.StatelessTruncatedNormalV2,"tf.raw_ops.StatelessTruncatedNormalV2(
    shape,
    key,
    counter,
    alg,
    dtype=tf.dtypes.float32,
    name=None
)
",Outputs deterministic pseudorandom values from a truncated normal distribution.View aliases
tf.raw_ops.StatelessWhile,"tf.raw_ops.StatelessWhile(
    input, cond, body, output_shapes=[], parallel_iterations=10, name=None
)
",output = input; While (Cond(output)) { output = Body(output) }View aliases
tf.raw_ops.StaticRegexFullMatch,"tf.raw_ops.StaticRegexFullMatch(
    input, pattern, name=None
)
",Check if the input matches the regex pattern.View aliases
tf.raw_ops.StaticRegexReplace,"tf.raw_ops.StaticRegexReplace(
    input, pattern, rewrite, replace_global=True, name=None
)
",Replaces the match of pattern in input with rewrite.View aliases
tf.raw_ops.StatsAggregatorHandle,"tf.raw_ops.StatsAggregatorHandle(
    container='', shared_name='', name=None
)
",Creates a statistics manager resource.View aliases
tf.raw_ops.StatsAggregatorHandleV2,"tf.raw_ops.StatsAggregatorHandleV2(
    container='', shared_name='', name=None
)
",View aliases
tf.raw_ops.StatsAggregatorSetSummaryWriter,"tf.raw_ops.StatsAggregatorSetSummaryWriter(
    stats_aggregator, summary, name=None
)
",Set a summary_writer_interface to record statistics using given stats_aggregator.View aliases
tf.raw_ops.StatsAggregatorSummary,"tf.raw_ops.StatsAggregatorSummary(
    iterator, name=None
)
",Produces a summary of any statistics recorded by the given statistics manager.View aliases
tf.raw_ops.StopGradient,"tf.raw_ops.StopGradient(
    input, name=None
)
",Stops gradient computation.View aliases
tf.raw_ops.StridedSlice,"tf.raw_ops.StridedSlice(
    input,
    begin,
    end,
    strides,
    begin_mask=0,
    end_mask=0,
    ellipsis_mask=0,
    new_axis_mask=0,
    shrink_axis_mask=0,
    name=None
)
",Return a strided slice from input.View aliases
tf.raw_ops.StridedSliceAssign,"tf.raw_ops.StridedSliceAssign(
    ref,
    begin,
    end,
    strides,
    value,
    begin_mask=0,
    end_mask=0,
    ellipsis_mask=0,
    new_axis_mask=0,
    shrink_axis_mask=0,
    name=None
)
",Assign value to the sliced l-value reference of ref.View aliases
tf.raw_ops.StridedSliceGrad,"tf.raw_ops.StridedSliceGrad(
    shape,
    begin,
    end,
    strides,
    dy,
    begin_mask=0,
    end_mask=0,
    ellipsis_mask=0,
    new_axis_mask=0,
    shrink_axis_mask=0,
    name=None
)
",Returns the gradient of StridedSlice.View aliases
tf.raw_ops.StringFormat,"tf.raw_ops.StringFormat(
    inputs,
    template='%s',
    placeholder='%s',
    summarize=3,
    name=None
)
",Formats a string template using a list of tensors.View aliases
tf.raw_ops.StringJoin,"tf.raw_ops.StringJoin(
    inputs, separator='', name=None
)
",Joins the strings in the given list of string tensors into one tensor;View aliases
tf.raw_ops.StringLength,"tf.raw_ops.StringLength(
    input, unit='BYTE', name=None
)
",String lengths of input.View aliases
tf.raw_ops.StringLower,"tf.raw_ops.StringLower(
    input, encoding='', name=None
)
",Converts all uppercase characters into their respective lowercase replacements.View aliases
tf.raw_ops.StringNGrams,"tf.raw_ops.StringNGrams(
    data,
    data_splits,
    separator,
    ngram_widths,
    left_pad,
    right_pad,
    pad_width,
    preserve_short_sequences,
    name=None
)
",Creates ngrams from ragged string data.View aliases
tf.raw_ops.StringSplit,"tf.raw_ops.StringSplit(
    input, delimiter, skip_empty=True, name=None
)
",Split elements of input based on delimiter into a SparseTensor.View aliases
tf.raw_ops.StringSplitV2,"tf.raw_ops.StringSplitV2(
    input, sep, maxsplit=-1, name=None
)
",Split elements of source based on sep into a SparseTensor.View aliases
tf.raw_ops.StringStrip,"tf.raw_ops.StringStrip(
    input, name=None
)
",Strip leading and trailing whitespaces from the Tensor.View aliases
tf.raw_ops.StringToHashBucket,"tf.raw_ops.StringToHashBucket(
    string_tensor, num_buckets, name=None
)
",Converts each string in the input Tensor to its hash mod by a number of buckets.View aliases
tf.raw_ops.StringToHashBucketFast,"tf.raw_ops.StringToHashBucketFast(
    input, num_buckets, name=None
)
",Converts each string in the input Tensor to its hash mod by a number of buckets.View aliases
tf.raw_ops.StringToHashBucketStrong,"tf.raw_ops.StringToHashBucketStrong(
    input, num_buckets, key, name=None
)
",Converts each string in the input Tensor to its hash mod by a number of buckets.View aliases
tf.raw_ops.StringToNumber,"tf.raw_ops.StringToNumber(
    string_tensor,
    out_type=tf.dtypes.float32,
    name=None
)
",Converts each string in the input Tensor to the specified numeric type.View aliases
tf.raw_ops.StringUpper,"tf.raw_ops.StringUpper(
    input, encoding='', name=None
)
",Converts all lowercase characters into their respective uppercase replacements.View aliases
tf.raw_ops.Sub,"tf.raw_ops.Sub(
    x, y, name=None
)
",Returns x - y element-wise.View aliases
tf.raw_ops.Substr,"tf.raw_ops.Substr(
    input, pos, len, unit='BYTE', name=None
)
",Return substrings from Tensor of strings.View aliases
tf.raw_ops.Sum,"tf.raw_ops.Sum(
    input, axis, keep_dims=False, name=None
)
",Computes the sum of elements across dimensions of a tensor.View aliases
tf.raw_ops.SummaryWriter,"tf.raw_ops.SummaryWriter(
    shared_name='', container='', name=None
)
",View aliases
tf.raw_ops.Svd,"tf.raw_ops.Svd(
    input, compute_uv=True, full_matrices=False, name=None
)
",Computes the singular value decompositions of one or more matrices.View aliases
tf.raw_ops.Switch,"tf.raw_ops.Switch(
    data, pred, name=None
)
",Forwards data to the output port determined by pred.View aliases
tf.raw_ops.SymbolicGradient,"tf.raw_ops.SymbolicGradient(
    input, Tout, f, name=None
)
",Computes the gradient function for function f via backpropagation.View aliases
tf.raw_ops.TFRecordDataset,"tf.raw_ops.TFRecordDataset(
    filenames, compression_type, buffer_size, metadata='', name=None
)
",Creates a dataset that emits the records from one or more TFRecord files.View aliases
tf.raw_ops.TFRecordReader,"tf.raw_ops.TFRecordReader(
    container='',
    shared_name='',
    compression_type='',
    name=None
)
",A Reader that outputs the records from a TensorFlow Records file.View aliases
tf.raw_ops.TFRecordReaderV2,"tf.raw_ops.TFRecordReaderV2(
    container='',
    shared_name='',
    compression_type='',
    name=None
)
",A Reader that outputs the records from a TensorFlow Records file.View aliases
tf.raw_ops.TPUCompilationResult,"tf.raw_ops.TPUCompilationResult(
    name=None
)
",Returns the result of a TPU compilation.View aliases
tf.raw_ops.TPUEmbeddingActivations,"tf.raw_ops.TPUEmbeddingActivations(
    embedding_variable, sliced_activations, table_id, lookup_id, name=None
)
",An op enabling differentiation of TPU Embeddings.View aliases
tf.raw_ops.TPUOrdinalSelector,"tf.raw_ops.TPUOrdinalSelector(
    name=None
)
",A TPU core selector Op.View aliases
tf.raw_ops.TPUPartitionedCall,"tf.raw_ops.TPUPartitionedCall(
    args, device_ordinal, Tout, f, autotuner_thresh=0, name=None
)
",Calls a function placed on a specified TPU device.View aliases
tf.raw_ops.TPUPartitionedInput,"tf.raw_ops.TPUPartitionedInput(
    inputs, partition_dim=0, name=None
)
",An op that groups a list of partitioned inputs together. This opView aliases
tf.raw_ops.TPUPartitionedOutput,"tf.raw_ops.TPUPartitionedOutput(
    inputs, num_splits, partition_dim=0, name=None
)
",An op that demultiplexes a tensor to be sharded by XLA to a list of partitionedView aliases
tf.raw_ops.TPUReplicateMetadata,"tf.raw_ops.TPUReplicateMetadata(
    num_replicas,
    num_cores_per_replica=1,
    topology='',
    use_tpu=True,
    device_assignment=[],
    computation_shape=[],
    host_compute_core=[],
    padding_map=[],
    step_marker_location='STEP_MARK_AT_ENTRY',
    allow_soft_placement=False,
    use_spmd_for_xla_partitioning=False,
    tpu_compile_options_proto='',
    name=None
)
",Metadata indicating how the TPU computation should be replicated.View aliases
tf.raw_ops.TPUReplicatedInput,"tf.raw_ops.TPUReplicatedInput(
    inputs, is_mirrored_variable=False, index=-1, is_packed=False, name=None
)
",Connects N inputs to an N-way replicated TPU computation.View aliases
tf.raw_ops.TPUReplicatedOutput,"tf.raw_ops.TPUReplicatedOutput(
    input, num_replicas, name=None
)
",Connects N outputs from an N-way replicated TPU computation.View aliases
tf.raw_ops.TakeDataset,"tf.raw_ops.TakeDataset(
    input_dataset,
    count,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that contains count elements from the input_dataset.View aliases
tf.raw_ops.TakeManySparseFromTensorsMap,"tf.raw_ops.TakeManySparseFromTensorsMap(
    sparse_handles,
    dtype,
    container='',
    shared_name='',
    name=None
)
",Read SparseTensors from a SparseTensorsMap and concatenate them.View aliases
tf.raw_ops.TakeWhileDataset,"tf.raw_ops.TakeWhileDataset(
    input_dataset,
    other_arguments,
    predicate,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that stops iteration when predicate` is false.View aliases
tf.raw_ops.Tan,"tf.raw_ops.Tan(
    x, name=None
)
",Computes tan of x element-wise.View aliases
tf.raw_ops.Tanh,"tf.raw_ops.Tanh(
    x, name=None
)
",Computes hyperbolic tangent of x element-wise.View aliases
tf.raw_ops.TanhGrad,"tf.raw_ops.TanhGrad(
    y, dy, name=None
)
",Computes the gradient for the tanh of x wrt its input.View aliases
tf.raw_ops.TemporaryVariable,"tf.raw_ops.TemporaryVariable(
    shape, dtype, var_name='', name=None
)
","Returns a tensor that may be mutated, but only persists within a single step.View aliases"
tf.raw_ops.TensorArray,"tf.raw_ops.TensorArray(
    size,
    dtype,
    dynamic_size=False,
    clear_after_read=True,
    tensor_array_name='',
    element_shape=None,
    name=None
)
",View aliases
tf.raw_ops.TensorArrayClose,"tf.raw_ops.TensorArrayClose(
    handle, name=None
)
",View aliases
tf.raw_ops.TensorArrayCloseV2,"tf.raw_ops.TensorArrayCloseV2(
    handle, name=None
)
",Deprecated. Use TensorArrayCloseV3View aliases
tf.raw_ops.TensorArrayCloseV3,"tf.raw_ops.TensorArrayCloseV3(
    handle, name=None
)
",Delete the TensorArray from its resource container.View aliases
tf.raw_ops.TensorArrayConcat,"tf.raw_ops.TensorArrayConcat(
    handle, flow_in, dtype, element_shape_except0=None, name=None
)
",View aliases
tf.raw_ops.TensorArrayConcatV2,"tf.raw_ops.TensorArrayConcatV2(
    handle, flow_in, dtype, element_shape_except0=None, name=None
)
",Deprecated. Use TensorArrayConcatV3View aliases
tf.raw_ops.TensorArrayConcatV3,"tf.raw_ops.TensorArrayConcatV3(
    handle, flow_in, dtype, element_shape_except0=None, name=None
)
",Concat the elements from the TensorArray into value value.View aliases
tf.raw_ops.TensorArrayGather,"tf.raw_ops.TensorArrayGather(
    handle, indices, flow_in, dtype, element_shape=None, name=None
)
",View aliases
tf.raw_ops.TensorArrayGatherV2,"tf.raw_ops.TensorArrayGatherV2(
    handle, indices, flow_in, dtype, element_shape=None, name=None
)
",Deprecated. Use TensorArrayGatherV3View aliases
tf.raw_ops.TensorArrayGatherV3,"tf.raw_ops.TensorArrayGatherV3(
    handle, indices, flow_in, dtype, element_shape=None, name=None
)
",Gather specific elements from the TensorArray into output value.View aliases
tf.raw_ops.TensorArrayGrad,"tf.raw_ops.TensorArrayGrad(
    handle, flow_in, source, name=None
)
",View aliases
tf.raw_ops.TensorArrayGradV2,"tf.raw_ops.TensorArrayGradV2(
    handle, flow_in, source, name=None
)
",Deprecated. Use TensorArrayGradV3View aliases
tf.raw_ops.TensorArrayGradV3,"tf.raw_ops.TensorArrayGradV3(
    handle, flow_in, source, name=None
)
",Creates a TensorArray for storing the gradients of values in the given handle.View aliases
tf.raw_ops.TensorArrayGradWithShape,"tf.raw_ops.TensorArrayGradWithShape(
    handle, flow_in, shape_to_prepend, source, name=None
)
",Creates a TensorArray for storing multiple gradients of values in the given handle.View aliases
tf.raw_ops.TensorArrayPack,"tf.raw_ops.TensorArrayPack(
    handle, flow_in, dtype, element_shape=None, name=None
)
",View aliases
tf.raw_ops.TensorArrayRead,"tf.raw_ops.TensorArrayRead(
    handle, index, flow_in, dtype, name=None
)
",View aliases
tf.raw_ops.TensorArrayReadV2,"tf.raw_ops.TensorArrayReadV2(
    handle, index, flow_in, dtype, name=None
)
",Deprecated. Use TensorArrayReadV3View aliases
tf.raw_ops.TensorArrayReadV3,"tf.raw_ops.TensorArrayReadV3(
    handle, index, flow_in, dtype, name=None
)
",Read an element from the TensorArray into output value.View aliases
tf.raw_ops.TensorArrayScatter,"tf.raw_ops.TensorArrayScatter(
    handle, indices, value, flow_in, name=None
)
",View aliases
tf.raw_ops.TensorArrayScatterV2,"tf.raw_ops.TensorArrayScatterV2(
    handle, indices, value, flow_in, name=None
)
",Deprecated. Use TensorArrayScatterV3View aliases
tf.raw_ops.TensorArrayScatterV3,"tf.raw_ops.TensorArrayScatterV3(
    handle, indices, value, flow_in, name=None
)
",Scatter the data from the input value into specific TensorArray elements.View aliases
tf.raw_ops.TensorArraySize,"tf.raw_ops.TensorArraySize(
    handle, flow_in, name=None
)
",View aliases
tf.raw_ops.TensorArraySizeV2,"tf.raw_ops.TensorArraySizeV2(
    handle, flow_in, name=None
)
",Deprecated. Use TensorArraySizeV3View aliases
tf.raw_ops.TensorArraySizeV3,"tf.raw_ops.TensorArraySizeV3(
    handle, flow_in, name=None
)
",Get the current size of the TensorArray.View aliases
tf.raw_ops.TensorArraySplit,"tf.raw_ops.TensorArraySplit(
    handle, value, lengths, flow_in, name=None
)
",View aliases
tf.raw_ops.TensorArraySplitV2,"tf.raw_ops.TensorArraySplitV2(
    handle, value, lengths, flow_in, name=None
)
",Deprecated. Use TensorArraySplitV3View aliases
tf.raw_ops.TensorArraySplitV3,"tf.raw_ops.TensorArraySplitV3(
    handle, value, lengths, flow_in, name=None
)
",Split the data from the input value into TensorArray elements.View aliases
tf.raw_ops.TensorArrayUnpack,"tf.raw_ops.TensorArrayUnpack(
    handle, value, flow_in, name=None
)
",View aliases
tf.raw_ops.TensorArrayV2,"tf.raw_ops.TensorArrayV2(
    size,
    dtype,
    element_shape=None,
    dynamic_size=False,
    clear_after_read=True,
    tensor_array_name='',
    name=None
)
",Deprecated. Use TensorArrayV3View aliases
tf.raw_ops.TensorArrayV3,"tf.raw_ops.TensorArrayV3(
    size,
    dtype,
    element_shape=None,
    dynamic_size=False,
    clear_after_read=True,
    identical_element_shapes=False,
    tensor_array_name='',
    name=None
)
",An array of Tensors of given size.View aliases
tf.raw_ops.TensorArrayWrite,"tf.raw_ops.TensorArrayWrite(
    handle, index, value, flow_in, name=None
)
",View aliases
tf.raw_ops.TensorArrayWriteV2,"tf.raw_ops.TensorArrayWriteV2(
    handle, index, value, flow_in, name=None
)
",Deprecated. Use TensorArrayGradV3View aliases
tf.raw_ops.TensorArrayWriteV3,"tf.raw_ops.TensorArrayWriteV3(
    handle, index, value, flow_in, name=None
)
",Push an element onto the tensor_array.View aliases
tf.raw_ops.TensorDataset,"tf.raw_ops.TensorDataset(
    components, output_shapes, metadata='', name=None
)
",Creates a dataset that emits components as a tuple of tensors once.View aliases
tf.raw_ops.TensorListConcat,"tf.raw_ops.TensorListConcat(
    input_handle, element_dtype, element_shape=None, name=None
)
",Concats all tensors in the list along the 0th dimension.View aliases
tf.raw_ops.TensorListConcatLists,"tf.raw_ops.TensorListConcatLists(
    input_a, input_b, element_dtype, name=None
)
",View aliases
tf.raw_ops.TensorListConcatV2,"tf.raw_ops.TensorListConcatV2(
    input_handle, element_shape, leading_dims, element_dtype, name=None
)
",Concats all tensors in the list along the 0th dimension.View aliases
tf.raw_ops.TensorListElementShape,"tf.raw_ops.TensorListElementShape(
    input_handle, shape_type, name=None
)
","The shape of the elements of the given list, as a tensor.View aliases"
tf.raw_ops.TensorListFromTensor,"tf.raw_ops.TensorListFromTensor(
    tensor, element_shape, name=None
)
","Creates a TensorList which, when stacked, has the value of tensor.View aliases"
tf.raw_ops.TensorListGather,"tf.raw_ops.TensorListGather(
    input_handle, indices, element_shape, element_dtype, name=None
)
",Creates a Tensor by indexing into the TensorList.View aliases
tf.raw_ops.TensorListGetItem,"tf.raw_ops.TensorListGetItem(
    input_handle, index, element_shape, element_dtype, name=None
)
",Returns the item in the list with the given index.View aliases
tf.raw_ops.TensorListLength,"tf.raw_ops.TensorListLength(
    input_handle, name=None
)
",Returns the number of tensors in the input tensor list.View aliases
tf.raw_ops.TensorListPopBack,"tf.raw_ops.TensorListPopBack(
    input_handle, element_shape, element_dtype, name=None
)
",Returns the last element of the input list as well as a list with all but that element.View aliases
tf.raw_ops.TensorListPushBack,"tf.raw_ops.TensorListPushBack(
    input_handle, tensor, name=None
)
",Returns a list which has the passed-in Tensor as last element and the other elements of the given list in input_handle.View aliases
tf.raw_ops.TensorListPushBackBatch,"tf.raw_ops.TensorListPushBackBatch(
    input_handles, tensor, name=None
)
",View aliases
tf.raw_ops.TensorListReserve,"tf.raw_ops.TensorListReserve(
    element_shape, num_elements, element_dtype, name=None
)
",List of the given size with empty elements.View aliases
tf.raw_ops.TensorListResize,"tf.raw_ops.TensorListResize(
    input_handle, size, name=None
)
",Resizes the list.View aliases
tf.raw_ops.TensorListScatter,"tf.raw_ops.TensorListScatter(
    tensor, indices, element_shape, name=None
)
",Creates a TensorList by indexing into a Tensor.View aliases
tf.raw_ops.TensorListScatterIntoExistingList,"tf.raw_ops.TensorListScatterIntoExistingList(
    input_handle, tensor, indices, name=None
)
",Scatters tensor at indices in an input list.View aliases
tf.raw_ops.TensorListScatterV2,"tf.raw_ops.TensorListScatterV2(
    tensor, indices, element_shape, num_elements, name=None
)
",Creates a TensorList by indexing into a Tensor.View aliases
tf.raw_ops.TensorListSetItem,"tf.raw_ops.TensorListSetItem(
    input_handle, index, item, name=None
)
",Sets the index-th position of the list to contain the given tensor.View aliases
tf.raw_ops.TensorListSplit,"tf.raw_ops.TensorListSplit(
    tensor, element_shape, lengths, name=None
)
",Splits a tensor into a list.View aliases
tf.raw_ops.TensorListStack,"tf.raw_ops.TensorListStack(
    input_handle, element_shape, element_dtype, num_elements=-1, name=None
)
",Stacks all tensors in the list.View aliases
tf.raw_ops.TensorScatterAdd,"tf.raw_ops.TensorScatterAdd(
    tensor, indices, updates, name=None
)
",Adds sparse updates to an existing tensor according to indices.View aliases
tf.raw_ops.TensorScatterMax,"tf.raw_ops.TensorScatterMax(
    tensor, indices, updates, name=None
)
",Apply a sparse update to a tensor taking the element-wise maximum.View aliases
tf.raw_ops.TensorScatterMin,"tf.raw_ops.TensorScatterMin(
    tensor, indices, updates, name=None
)
",View aliases
tf.raw_ops.TensorScatterSub,"tf.raw_ops.TensorScatterSub(
    tensor, indices, updates, name=None
)
",Subtracts sparse updates from an existing tensor according to indices.View aliases
tf.raw_ops.TensorScatterUpdate,"tf.raw_ops.TensorScatterUpdate(
    tensor, indices, updates, name=None
)
",Scatter updates into an existing tensor according to indices.View aliases
tf.raw_ops.TensorSliceDataset,"tf.raw_ops.TensorSliceDataset(
    components,
    output_shapes,
    is_files=False,
    metadata='',
    replicate_on_split=False,
    name=None
)
",Creates a dataset that emits each dim-0 slice of components once.View aliases
tf.raw_ops.TensorStridedSliceUpdate,"tf.raw_ops.TensorStridedSliceUpdate(
    input,
    begin,
    end,
    strides,
    value,
    begin_mask=0,
    end_mask=0,
    ellipsis_mask=0,
    new_axis_mask=0,
    shrink_axis_mask=0,
    name=None
)
",Assign value to the sliced l-value reference of input.View aliases
tf.raw_ops.TensorSummary,"tf.raw_ops.TensorSummary(
    tensor,
    description='',
    labels=[],
    display_name='',
    name=None
)
",Outputs a Summary protocol buffer with a tensor.View aliases
tf.raw_ops.TensorSummaryV2,"tf.raw_ops.TensorSummaryV2(
    tag, tensor, serialized_summary_metadata, name=None
)
",Outputs a Summary protocol buffer with a tensor and per-plugin data.View aliases
tf.raw_ops.TextLineDataset,"tf.raw_ops.TextLineDataset(
    filenames, compression_type, buffer_size, metadata='', name=None
)
",Creates a dataset that emits the lines of one or more text files.View aliases
tf.raw_ops.TextLineReader,"tf.raw_ops.TextLineReader(
    skip_header_lines=0,
    container='',
    shared_name='',
    name=None
)
",A Reader that outputs the lines of a file delimited by '\n'.View aliases
tf.raw_ops.TextLineReaderV2,"tf.raw_ops.TextLineReaderV2(
    skip_header_lines=0,
    container='',
    shared_name='',
    name=None
)
",A Reader that outputs the lines of a file delimited by '\n'.View aliases
tf.raw_ops.ThreadPoolDataset,"tf.raw_ops.ThreadPoolDataset(
    input_dataset, thread_pool, output_types, output_shapes, name=None
)
",Creates a dataset that uses a custom thread pool to compute input_dataset.View aliases
tf.raw_ops.ThreadPoolHandle,"tf.raw_ops.ThreadPoolHandle(
    num_threads,
    display_name,
    max_intra_op_parallelism=1,
    container='',
    shared_name='',
    name=None
)
",Creates a dataset that uses a custom thread pool to compute input_dataset.View aliases
tf.raw_ops.ThreadUnsafeUnigramCandidateSampler,"tf.raw_ops.ThreadUnsafeUnigramCandidateSampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=0,
    seed2=0,
    name=None
)
",Generates labels for candidate sampling with a learned unigram distribution.View aliases
tf.raw_ops.Tile,"tf.raw_ops.Tile(
    input, multiples, name=None
)
",Constructs a tensor by tiling a given tensor.View aliases
tf.raw_ops.TileGrad,"tf.raw_ops.TileGrad(
    input, multiples, name=None
)
",Returns the gradient of Tile.View aliases
tf.raw_ops.Timestamp,"tf.raw_ops.Timestamp(
    name=None
)
",Provides the time since epoch in seconds.View aliases
tf.raw_ops.ToBool,"tf.raw_ops.ToBool(
    input, name=None
)
",Converts a tensor to a scalar predicate.View aliases
tf.raw_ops.TopK,"tf.raw_ops.TopK(
    input, k, sorted=True, name=None
)
",Finds values and indices of the k largest elements for the last dimension.View aliases
tf.raw_ops.TopKV2,"tf.raw_ops.TopKV2(
    input, k, sorted=True, name=None
)
",Finds values and indices of the k largest elements for the last dimension.View aliases
tf.raw_ops.Transpose,"tf.raw_ops.Transpose(
    x, perm, name=None
)
",Shuffle dimensions of x according to a permutation.View aliases
tf.raw_ops.TridiagonalMatMul,"tf.raw_ops.TridiagonalMatMul(
    superdiag, maindiag, subdiag, rhs, name=None
)
",Calculate product with tridiagonal matrix.View aliases
tf.raw_ops.TridiagonalSolve,"tf.raw_ops.TridiagonalSolve(
    diagonals, rhs, partial_pivoting=True, perturb_singular=False, name=None
)
",Solves tridiagonal systems of equations.View aliases
tf.raw_ops.TruncateDiv,"tf.raw_ops.TruncateDiv(
    x, y, name=None
)
",Returns x / y element-wise for integer types.View aliases
tf.raw_ops.TruncateMod,"tf.raw_ops.TruncateMod(
    x, y, name=None
)
",Returns element-wise remainder of division. This emulates C semantics in thatView aliases
tf.raw_ops.TruncatedNormal,"tf.raw_ops.TruncatedNormal(
    shape, dtype, seed=0, seed2=0, name=None
)
",Outputs random values from a truncated normal distribution.View aliases
tf.raw_ops.Unbatch,"tf.raw_ops.Unbatch(
    batched_tensor,
    batch_index,
    id,
    timeout_micros,
    container='',
    shared_name='',
    name=None
)
",Reverses the operation of Batch for a single output Tensor.View aliases
tf.raw_ops.UnbatchDataset,"tf.raw_ops.UnbatchDataset(
    input_dataset,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",A dataset that splits the elements of its input into multiple elements.View aliases
tf.raw_ops.UnbatchGrad,"tf.raw_ops.UnbatchGrad(
    original_input,
    batch_index,
    grad,
    id,
    container='',
    shared_name='',
    name=None
)
",Gradient of Unbatch.View aliases
tf.raw_ops.UncompressElement,"tf.raw_ops.UncompressElement(
    compressed, output_types, output_shapes, name=None
)
",Uncompresses a compressed dataset element.View aliases
tf.raw_ops.UnicodeDecode,"tf.raw_ops.UnicodeDecode(
    input,
    input_encoding,
    errors='replace',
    replacement_char=65533,
    replace_control_characters=False,
    Tsplits=tf.dtypes.int64,
    name=None
)
",Decodes each string in input into a sequence of Unicode code points.View aliases
tf.raw_ops.UnicodeDecodeWithOffsets,"tf.raw_ops.UnicodeDecodeWithOffsets(
    input,
    input_encoding,
    errors='replace',
    replacement_char=65533,
    replace_control_characters=False,
    Tsplits=tf.dtypes.int64,
    name=None
)
",Decodes each string in input into a sequence of Unicode code points.View aliases
tf.raw_ops.UnicodeEncode,"tf.raw_ops.UnicodeEncode(
    input_values,
    input_splits,
    output_encoding,
    errors='replace',
    replacement_char=65533,
    name=None
)
",Encode a tensor of ints into unicode strings.View aliases
tf.raw_ops.UnicodeScript,"tf.raw_ops.UnicodeScript(
    input, name=None
)
",Determine the script codes of a given tensor of Unicode integer code points.View aliases
tf.raw_ops.UnicodeTranscode,"tf.raw_ops.UnicodeTranscode(
    input,
    input_encoding,
    output_encoding,
    errors='replace',
    replacement_char=65533,
    replace_control_characters=False,
    name=None
)
",Transcode the input text from a source encoding to a destination encoding.View aliases
tf.raw_ops.UniformCandidateSampler,"tf.raw_ops.UniformCandidateSampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=0,
    seed2=0,
    name=None
)
",Generates labels for candidate sampling with a uniform distribution.View aliases
tf.raw_ops.Unique,"tf.raw_ops.Unique(
    x,
    out_idx=tf.dtypes.int32,
    name=None
)
",Finds unique elements in a 1-D tensor.View aliases
tf.raw_ops.UniqueDataset,"tf.raw_ops.UniqueDataset(
    input_dataset,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that contains the unique elements of input_dataset.View aliases
tf.raw_ops.UniqueV2,"tf.raw_ops.UniqueV2(
    x,
    axis,
    out_idx=tf.dtypes.int32,
    name=None
)
",Finds unique elements along an axis of a tensor.View aliases
tf.raw_ops.UniqueWithCounts,"tf.raw_ops.UniqueWithCounts(
    x,
    out_idx=tf.dtypes.int32,
    name=None
)
",Finds unique elements in a 1-D tensor.View aliases
tf.raw_ops.UniqueWithCountsV2,"tf.raw_ops.UniqueWithCountsV2(
    x,
    axis,
    out_idx=tf.dtypes.int32,
    name=None
)
",Finds unique elements along an axis of a tensor.View aliases
tf.raw_ops.Unpack,"tf.raw_ops.Unpack(
    value, num, axis=0, name=None
)
",Unpacks a given dimension of a rank-R tensor into num rank-(R-1) tensors.View aliases
tf.raw_ops.UnravelIndex,"tf.raw_ops.UnravelIndex(
    indices, dims, name=None
)
",Converts an array of flat indices into a tuple of coordinate arrays.View aliases
tf.raw_ops.UnsortedSegmentJoin,"tf.raw_ops.UnsortedSegmentJoin(
    inputs, segment_ids, num_segments, separator='', name=None
)
",View aliases
tf.raw_ops.UnsortedSegmentMax,"tf.raw_ops.UnsortedSegmentMax(
    data, segment_ids, num_segments, name=None
)
",Computes the maximum along segments of a tensor.View aliases
tf.raw_ops.UnsortedSegmentMin,"tf.raw_ops.UnsortedSegmentMin(
    data, segment_ids, num_segments, name=None
)
",Computes the minimum along segments of a tensor.View aliases
tf.raw_ops.UnsortedSegmentProd,"tf.raw_ops.UnsortedSegmentProd(
    data, segment_ids, num_segments, name=None
)
",Computes the product along segments of a tensor.View aliases
tf.raw_ops.UnsortedSegmentSum,"tf.raw_ops.UnsortedSegmentSum(
    data, segment_ids, num_segments, name=None
)
",Computes the sum along segments of a tensor.View aliases
tf.raw_ops.Unstage,"tf.raw_ops.Unstage(
    dtypes,
    capacity=0,
    memory_limit=0,
    container='',
    shared_name='',
    name=None
)
",Op is similar to a lightweight Dequeue.View aliases
tf.raw_ops.UnwrapDatasetVariant,"tf.raw_ops.UnwrapDatasetVariant(
    input_handle, name=None
)
",View aliases
tf.raw_ops.UpperBound,"tf.raw_ops.UpperBound(
    sorted_inputs,
    values,
    out_type=tf.dtypes.int32,
    name=None
)
","Applies upper_bound(sorted_search_values, values) along each row.View aliases"
tf.raw_ops.VarHandleOp,"tf.raw_ops.VarHandleOp(
    dtype,
    shape,
    container='',
    shared_name='',
    allowed_devices=[],
    name=None
)
",Creates a handle to a Variable resource.View aliases
tf.raw_ops.VarIsInitializedOp,"tf.raw_ops.VarIsInitializedOp(
    resource, name=None
)
",Checks whether a resource handle-based variable has been initialized.View aliases
tf.raw_ops.Variable,"tf.raw_ops.Variable(
    shape, dtype, container='', shared_name='', name=None
)
",Use VariableV2 instead.View aliases
tf.raw_ops.VariableShape,"tf.raw_ops.VariableShape(
    input,
    out_type=tf.dtypes.int32,
    name=None
)
",Returns the shape of the variable pointed to by resource.View aliases
tf.raw_ops.VariableV2,"tf.raw_ops.VariableV2(
    shape, dtype, container='', shared_name='', name=None
)
",Holds state in the form of a tensor that persists across steps.View aliases
tf.raw_ops.Where,"tf.raw_ops.Where(
    condition, name=None
)
",Returns locations of nonzero / true values in a tensor.View aliases
tf.raw_ops.While,"tf.raw_ops.While(
    input, cond, body, output_shapes=[], parallel_iterations=10, name=None
)
",output = input; While (Cond(output)) { output = Body(output) }View aliases
tf.raw_ops.WholeFileReader,"tf.raw_ops.WholeFileReader(
    container='', shared_name='', name=None
)
",A Reader that outputs the entire contents of a file as a value.View aliases
tf.raw_ops.WholeFileReaderV2,"tf.raw_ops.WholeFileReaderV2(
    container='', shared_name='', name=None
)
",A Reader that outputs the entire contents of a file as a value.View aliases
tf.raw_ops.WindowDataset,"tf.raw_ops.WindowDataset(
    input_dataset,
    size,
    shift,
    stride,
    drop_remainder,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Combines (nests of) input elements into a dataset of (nests of) windows.View aliases
tf.raw_ops.WindowOp,"tf.raw_ops.WindowOp(
    inputs, output_types, output_shapes, name=None
)
",View aliases
tf.raw_ops.WorkerHeartbeat,"tf.raw_ops.WorkerHeartbeat(
    request, name=None
)
",Worker heartbeat op.View aliases
tf.raw_ops.WrapDatasetVariant,"tf.raw_ops.WrapDatasetVariant(
    input_handle, name=None
)
",View aliases
tf.raw_ops.WriteAudioSummary,"tf.raw_ops.WriteAudioSummary(
    writer, step, tag, tensor, sample_rate, max_outputs=3, name=None
)
",Writes an audio summary.View aliases
tf.raw_ops.WriteFile,"tf.raw_ops.WriteFile(
    filename, contents, name=None
)
",Writes contents to the file at input filename.View aliases
tf.raw_ops.WriteGraphSummary,"tf.raw_ops.WriteGraphSummary(
    writer, step, tensor, name=None
)
",Writes a graph summary.View aliases
tf.raw_ops.WriteHistogramSummary,"tf.raw_ops.WriteHistogramSummary(
    writer, step, tag, values, name=None
)
",Writes a histogram summary.View aliases
tf.raw_ops.WriteImageSummary,"tf.raw_ops.WriteImageSummary(
    writer, step, tag, tensor, bad_color, max_images=3, name=None
)
",Writes an image summary.View aliases
tf.raw_ops.WriteRawProtoSummary,"tf.raw_ops.WriteRawProtoSummary(
    writer, step, tensor, name=None
)
",Writes a serialized proto summary.View aliases
tf.raw_ops.WriteScalarSummary,"tf.raw_ops.WriteScalarSummary(
    writer, step, tag, value, name=None
)
",Writes a scalar summary.View aliases
tf.raw_ops.WriteSummary,"tf.raw_ops.WriteSummary(
    writer, step, tensor, tag, summary_metadata, name=None
)
",Writes a tensor summary.View aliases
tf.raw_ops.Xdivy,"tf.raw_ops.Xdivy(
    x, y, name=None
)
","Returns 0 if x == 0, and x / y otherwise, elementwise.View aliases"
tf.raw_ops.XlaConcatND,"tf.raw_ops.XlaConcatND(
    inputs, num_concats, paddings=[], name=None
)
",Concats input tensor across all dimensions.View aliases
tf.raw_ops.XlaSplitND,"tf.raw_ops.XlaSplitND(
    input, N, num_splits, paddings=[], name=None
)
",Splits input tensor across all dimensions.View aliases
tf.raw_ops.Xlog1py,"tf.raw_ops.Xlog1py(
    x, y, name=None
)
","Returns 0 if x == 0, and x * log1p(y) otherwise, elementwise.View aliases"
tf.raw_ops.Xlogy,"tf.raw_ops.Xlogy(
    x, y, name=None
)
","Returns 0 if x == 0, and x * log(y) otherwise, elementwise.View aliases"
tf.raw_ops.ZerosLike,"tf.raw_ops.ZerosLike(
    x, name=None
)
",Returns a tensor of zeros with the same shape and type as x.View aliases
tf.raw_ops.Zeta,"tf.raw_ops.Zeta(
    x, q, name=None
)
","Compute the Hurwitz zeta function \(\zeta(x, q)\).View aliases"
tf.raw_ops.ZipDataset,"tf.raw_ops.ZipDataset(
    input_datasets,
    output_types,
    output_shapes,
    metadata='',
    name=None
)
",Creates a dataset that zips together input_datasets.View aliases
tf.realdiv,"tf.realdiv(
    x, y, name=None
)
",Returns x / y element-wise for real types.View aliases
tf.recompute_grad,"tf.recompute_grad(
    f
)
",Defines a function as a recompute-checkpoint for the tape auto-diff.View aliases
tf.math.reduce_all,"tf.math.reduce_all(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes tf.math.logical_and of elements across dimensions of a tensor.View aliases
tf.math.reduce_any,"tf.math.reduce_any(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes tf.math.logical_or of elements across dimensions of a tensor.View aliases
tf.math.reduce_logsumexp,"tf.math.reduce_logsumexp(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes log(sum(exp(elements across dimensions of a tensor))).View aliases
tf.math.reduce_max,"tf.math.reduce_max(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes tf.math.maximum of elements across dimensions of a tensor.View aliases
tf.math.reduce_mean,"tf.math.reduce_mean(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes the mean of elements across dimensions of a tensor.View aliases
tf.math.reduce_min,"tf.math.reduce_min(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes the tf.math.minimum of elements across dimensions of a tensor.View aliases
tf.math.reduce_prod,"tf.math.reduce_prod(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes tf.math.multiply of elements across dimensions of a tensor.View aliases
tf.math.reduce_sum,"tf.math.reduce_sum(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes the sum of elements across dimensions of a tensor.View aliases
tf.register_tensor_conversion_function,"tf.register_tensor_conversion_function(
    base_type, conversion_func, priority=100
)
",Registers a function for converting objects of base_type to Tensor.View aliases
tf.repeat,"tf.repeat(
    input, repeats, axis=None, name=None
)
",Repeat elements of input.View aliases
tf.required_space_to_batch_paddings,"tf.required_space_to_batch_paddings(
    input_shape, block_shape, base_paddings=None, name=None
)
",Calculate padding required to make block_shape divide input_shape.View aliases
tf.reshape,"tf.reshape(
    tensor, shape, name=None
)
",Reshapes a tensor.View aliases
tf.reverse,"tf.reverse(
    tensor, axis, name=None
)
",Reverses specific dimensions of a tensor.View aliases
tf.reverse_sequence,"tf.reverse_sequence(
    input, seq_lengths, seq_axis=None, batch_axis=None, name=None
)
",Reverses variable length slices.
tf.roll,"tf.roll(
    input, shift, axis, name=None
)
",Rolls the elements of a tensor along an axis.View aliases
tf.math.round,"tf.math.round(
    x, name=None
)
","Rounds the values of a tensor to the nearest integer, element-wise.View aliases"
tf.dtypes.saturate_cast,"tf.dtypes.saturate_cast(
    value, dtype, name=None
)
",Performs a safe saturating cast of value to dtype.View aliases
tf.saved_model.Asset,"tf.saved_model.Asset(
    path
)
",Represents a file asset to hermetically include in a SavedModel.View aliases
tf.saved_model.LoadOptions,"tf.saved_model.LoadOptions(
    allow_partial_checkpoint=False,
    experimental_io_device=None,
    experimental_skip_checkpoint=False,
    experimental_variable_policy=None
)
",Options for loading a SavedModel.
tf.saved_model.SaveOptions,"tf.saved_model.SaveOptions(
    namespace_whitelist=None,
    save_debug_info=False,
    function_aliases=None,
    experimental_io_device=None,
    experimental_variable_policy=None,
    experimental_custom_gradients=True
)
",Options for saving to SavedModel.View aliases
tf.saved_model.contains_saved_model,"tf.saved_model.contains_saved_model(
    export_dir
)
",Checks whether the provided export directory could contain a SavedModel.
tf.saved_model.experimental.TrackableResource,"tf.saved_model.experimental.TrackableResource(
    device=''
)
",Holds a Tensor which a tf.function can capture.View aliases
tf.saved_model.load,"tf.saved_model.load(
    export_dir, tags=None, options=None
)
",Load a SavedModel from export_dir.View aliases
tf.saved_model.save,"tf.saved_model.save(
    obj, export_dir, signatures=None, options=None
)
",Exports a tf.Module (and subclasses) obj to SavedModel format.View aliases
tf.math.scalar_mul,"tf.math.scalar_mul(
    scalar, x, name=None
)
",Multiplies a scalar times a Tensor or IndexedSlices object.View aliases
tf.scan,"tf.scan(
    fn,
    elems,
    initializer=None,
    parallel_iterations=10,
    back_prop=True,
    swap_memory=False,
    infer_shape=True,
    reverse=False,
    name=None
)
",scan on the list of tensors unpacked from elems on dimension 0. (deprecated argument values)
tf.scatter_nd,"tf.scatter_nd(
    indices, updates, shape, name=None
)
",Scatters updates into a tensor of shape shape according to indices.View aliases
tf.searchsorted,"tf.searchsorted(
    sorted_sequence,
    values,
    side='left',
    out_type=tf.dtypes.int32,
    name=None
)
",Searches for where a value would go in a sorted sequence.View aliases
tf.sequence_mask,"tf.sequence_mask(
    lengths,
    maxlen=None,
    dtype=tf.dtypes.bool,
    name=None
)
",Returns a mask tensor representing the first N positions of each cell.View aliases
tf.sets.difference,"tf.sets.difference(
    a, b, aminusb=True, validate_indices=True
)
",Compute set difference of elements in last dimension of a and b.View aliases
tf.sets.intersection,"tf.sets.intersection(
    a, b, validate_indices=True
)
",Compute set intersection of elements in last dimension of a and b.View aliases
tf.sets.size,"tf.sets.size(
    a, validate_indices=True
)
",Compute number of unique elements along last dimension of a.View aliases
tf.sets.union,"tf.sets.union(
    a, b, validate_indices=True
)
",Compute set union of elements in last dimension of a and b.View aliases
tf.shape,"tf.shape(
    input,
    out_type=tf.dtypes.int32,
    name=None
)
",Returns a tensor containing the shape of the input tensor.
tf.shape_n,"tf.shape_n(
    input,
    out_type=tf.dtypes.int32,
    name=None
)
",Returns shape of tensors.View aliases
tf.math.sigmoid,"tf.math.sigmoid(
    x, name=None
)
",Computes sigmoid of x element-wise.View aliases
tf.math.sign,"tf.math.sign(
    x, name=None
)
",Returns an element-wise indication of the sign of a number.View aliases
tf.signal.dct,"tf.signal.dct(
    input, type=2, n=None, axis=-1, norm=None, name=None
)
",Computes the 1D Discrete Cosine Transform (DCT) of input.View aliases
tf.signal.fft,"tf.signal.fft(
    input, name=None
)
",Fast Fourier transform.View aliases
tf.signal.fft2d,"tf.signal.fft2d(
    input, name=None
)
",2D fast Fourier transform.View aliases
tf.signal.fft3d,"tf.signal.fft3d(
    input, name=None
)
",3D fast Fourier transform.View aliases
tf.signal.fftshift,"tf.signal.fftshift(
    x, axes=None, name=None
)
",Shift the zero-frequency component to the center of the spectrum.View aliases
tf.signal.frame,"tf.signal.frame(
    signal,
    frame_length,
    frame_step,
    pad_end=False,
    pad_value=0,
    axis=-1,
    name=None
)
",Expands signal's axis dimension into frames of frame_length.View aliases
tf.signal.hamming_window,"tf.signal.hamming_window(
    window_length,
    periodic=True,
    dtype=tf.dtypes.float32,
    name=None
)
",Generate a Hamming window.View aliases
tf.signal.hann_window,"tf.signal.hann_window(
    window_length,
    periodic=True,
    dtype=tf.dtypes.float32,
    name=None
)
",Generate a Hann window.View aliases
tf.signal.idct,"tf.signal.idct(
    input, type=2, n=None, axis=-1, norm=None, name=None
)
",Computes the 1D Inverse Discrete Cosine Transform (DCT) of input.View aliases
tf.signal.ifft,"tf.signal.ifft(
    input, name=None
)
",Inverse fast Fourier transform.View aliases
tf.signal.ifft2d,"tf.signal.ifft2d(
    input, name=None
)
",Inverse 2D fast Fourier transform.View aliases
tf.signal.ifft3d,"tf.signal.ifft3d(
    input, name=None
)
",Inverse 3D fast Fourier transform.View aliases
tf.signal.ifftshift,"tf.signal.ifftshift(
    x, axes=None, name=None
)
",The inverse of fftshift.View aliases
tf.signal.inverse_mdct,"tf.signal.inverse_mdct(
    mdcts,
    window_fn=tf.signal.vorbis_window,
    norm=None,
    name=None
)
",Computes the inverse modified DCT of mdcts.View aliases
tf.signal.inverse_stft,"tf.signal.inverse_stft(
    stfts,
    frame_length,
    frame_step,
    fft_length=None,
    window_fn=tf.signal.hann_window,
    name=None
)
",Computes the inverse Short-time Fourier Transform of stfts.View aliases
tf.signal.inverse_stft_window_fn,"tf.signal.inverse_stft_window_fn(
    frame_step,
    forward_window_fn=tf.signal.hann_window,
    name=None
)
",Generates a window function that can be used in inverse_stft.View aliases
tf.signal.irfft,"tf.signal.irfft(
    input_tensor, fft_length=None, name=None
)
",Inverse real-valued fast Fourier transform.View aliases
tf.signal.irfft2d,"tf.signal.irfft2d(
    input_tensor, fft_length=None, name=None
)
",Inverse 2D real-valued fast Fourier transform.View aliases
tf.signal.irfft3d,"tf.signal.irfft3d(
    input_tensor, fft_length=None, name=None
)
",Inverse 3D real-valued fast Fourier transform.View aliases
tf.signal.kaiser_bessel_derived_window,"tf.signal.kaiser_bessel_derived_window(
    window_length,
    beta=12.0,
    dtype=tf.dtypes.float32,
    name=None
)
",Generate a Kaiser Bessel derived window.View aliases
tf.signal.kaiser_window,"tf.signal.kaiser_window(
    window_length,
    beta=12.0,
    dtype=tf.dtypes.float32,
    name=None
)
",Generate a Kaiser window.View aliases
tf.signal.linear_to_mel_weight_matrix,"tf.signal.linear_to_mel_weight_matrix(
    num_mel_bins=20,
    num_spectrogram_bins=129,
    sample_rate=8000,
    lower_edge_hertz=125.0,
    upper_edge_hertz=3800.0,
    dtype=tf.dtypes.float32,
    name=None
)
",Returns a matrix to warp linear scale spectrograms to the mel scale.View aliases
tf.signal.mdct,"tf.signal.mdct(
    signals,
    frame_length,
    window_fn=tf.signal.vorbis_window,
    pad_end=False,
    norm=None,
    name=None
)
",Computes the Modified Discrete Cosine Transform of signals.View aliases
tf.signal.mfccs_from_log_mel_spectrograms,"tf.signal.mfccs_from_log_mel_spectrograms(
    log_mel_spectrograms, name=None
)
",Computes MFCCs of log_mel_spectrograms.View aliases
tf.signal.overlap_and_add,"tf.signal.overlap_and_add(
    signal, frame_step, name=None
)
",Reconstructs a signal from a framed representation.View aliases
tf.signal.rfft,"tf.signal.rfft(
    input_tensor, fft_length=None, name=None
)
",Real-valued fast Fourier transform.View aliases
tf.signal.rfft2d,"tf.signal.rfft2d(
    input_tensor, fft_length=None, name=None
)
",2D real-valued fast Fourier transform.View aliases
tf.signal.rfft3d,"tf.signal.rfft3d(
    input_tensor, fft_length=None, name=None
)
",3D real-valued fast Fourier transform.View aliases
tf.signal.stft,"tf.signal.stft(
    signals,
    frame_length,
    frame_step,
    fft_length=None,
    window_fn=tf.signal.hann_window,
    pad_end=False,
    name=None
)
",Computes the Short-time Fourier Transform of signals.View aliases
tf.signal.vorbis_window,"tf.signal.vorbis_window(
    window_length,
    dtype=tf.dtypes.float32,
    name=None
)
",Generate a Vorbis power complementary window.View aliases
tf.math.sin,"tf.math.sin(
    x, name=None
)
",Computes sine of x element-wise.View aliases
tf.math.sinh,"tf.math.sinh(
    x, name=None
)
",Computes hyperbolic sine of x element-wise.View aliases
tf.size,"tf.size(
    input,
    out_type=tf.dtypes.int32,
    name=None
)
",Returns the size of a tensor.
tf.slice,"tf.slice(
    input_, begin, size, name=None
)
",Extracts a slice from a tensor.View aliases
tf.sort,"tf.sort(
    values, axis=-1, direction='ASCENDING', name=None
)
",Sorts a tensor.View aliases
tf.space_to_batch,"tf.space_to_batch(
    input, block_shape, paddings, name=None
)
",SpaceToBatch for N-D tensors of type T.View aliases
tf.space_to_batch_nd,"tf.space_to_batch_nd(
    input, block_shape, paddings, name=None
)
",SpaceToBatch for N-D tensors of type T.View aliases
tf.sparse.SparseTensor,"tf.sparse.SparseTensor(
    indices, values, dense_shape
)
",Represents a sparse tensor.View aliases
tf.sparse.add,"tf.sparse.add(
    a, b, threshold=0
)
","Adds two tensors, at least one of each is a SparseTensor."
tf.sparse.bincount,"tf.sparse.bincount(
    values,
    weights=None,
    axis=0,
    minlength=None,
    maxlength=None,
    binary_output=False,
    name=None
)
",Count the number of times an integer value appears in a tensor.View aliases
tf.sparse.concat,"tf.sparse.concat(
    axis, sp_inputs, expand_nonconcat_dims=False, name=None
)
",Concatenates a list of SparseTensor along the specified dimension. (deprecated arguments)
tf.sparse.cross,"tf.sparse.cross(
    inputs, name=None, separator=None
)
",Generates sparse cross from a list of sparse and dense tensors.View aliases
tf.sparse.cross_hashed,"tf.sparse.cross_hashed(
    inputs, num_buckets=0, hash_key=None, name=None
)
",Generates hashed sparse cross from a list of sparse and dense tensors.View aliases
tf.sparse.expand_dims,"tf.sparse.expand_dims(
    sp_input, axis=None, name=None
)
",Returns a tensor with an length 1 axis inserted at index axis.View aliases
tf.sparse.eye,"tf.sparse.eye(
    num_rows,
    num_columns=None,
    dtype=tf.dtypes.float32,
    name=None
)
",Creates a two-dimensional sparse tensor with ones along the diagonal.View aliases
tf.sparse.fill_empty_rows,"tf.sparse.fill_empty_rows(
    sp_input, default_value, name=None
)
",Fills empty rows in the input 2-D SparseTensor with a default value.View aliases
tf.sparse.from_dense,"tf.sparse.from_dense(
    tensor, name=None
)
",Converts a dense tensor into a sparse tensor.View aliases
tf.sparse.map_values,"tf.sparse.map_values(
    op, *args, **kwargs
)
",Applies op to the .values tensor of one or more SparseTensors.
tf.sparse.mask,"tf.sparse.mask(
    a, mask_indices, name=None
)
",Masks elements of IndexedSlices.View aliases
tf.sparse.maximum,"tf.sparse.maximum(
    sp_a, sp_b, name=None
)
",Returns the element-wise max of two SparseTensors.View aliases
tf.sparse.minimum,"tf.sparse.minimum(
    sp_a, sp_b, name=None
)
",Returns the element-wise min of two SparseTensors.View aliases
tf.sparse.reduce_max,"tf.sparse.reduce_max(
    sp_input, axis=None, keepdims=None, output_is_sparse=False, name=None
)
",Computes tf.sparse.maximum of elements across dimensions of a SparseTensor.
tf.sparse.reduce_sum,"tf.sparse.reduce_sum(
    sp_input, axis=None, keepdims=None, output_is_sparse=False, name=None
)
",Computes tf.sparse.add of elements across dimensions of a SparseTensor.
tf.sparse.reorder,"tf.sparse.reorder(
    sp_input, name=None
)
","Reorders a SparseTensor into the canonical, row-major ordering.View aliases"
tf.sparse.reset_shape,"tf.sparse.reset_shape(
    sp_input, new_shape=None
)
",Resets the shape of a SparseTensor with indices and values unchanged.View aliases
tf.sparse.reshape,"tf.sparse.reshape(
    sp_input, shape, name=None
)
",Reshapes a SparseTensor to represent values in a new dense shape.View aliases
tf.sparse.retain,"tf.sparse.retain(
    sp_input, to_retain
)
",Retains specified non-empty values within a SparseTensor.View aliases
tf.sparse.segment_mean,"tf.sparse.segment_mean(
    data, indices, segment_ids, num_segments=None, name=None
)
",Computes the mean along sparse segments of a tensor.
tf.sparse.segment_sqrt_n,"tf.sparse.segment_sqrt_n(
    data, indices, segment_ids, num_segments=None, name=None
)
",Computes the sum along sparse segments of a tensor divided by the sqrt(N).
tf.sparse.segment_sum,"tf.sparse.segment_sum(
    data, indices, segment_ids, num_segments=None, name=None
)
",Computes the sum along sparse segments of a tensor.
tf.sparse.slice,"tf.sparse.slice(
    sp_input, start, size, name=None
)
",Slice a SparseTensor based on the start and size.View aliases
tf.sparse.softmax,"tf.sparse.softmax(
    sp_input, name=None
)
",Applies softmax to a batched N-D SparseTensor.View aliases
tf.sparse.sparse_dense_matmul,"tf.sparse.sparse_dense_matmul(
    sp_a, b, adjoint_a=False, adjoint_b=False, name=None
)
","Multiply SparseTensor (or dense Matrix) (of rank 2) ""A"" by dense matrixView aliases"
tf.sparse.split,"tf.sparse.split(
    sp_input=None, num_split=None, axis=None, name=None
)
",Split a SparseTensor into num_split tensors along axis.
tf.sparse.to_dense,"tf.sparse.to_dense(
    sp_input, default_value=None, validate_indices=True, name=None
)
",Converts a SparseTensor into a dense tensor.View aliases
tf.sparse.to_indicator,"tf.sparse.to_indicator(
    sp_input, vocab_size, name=None
)
",Converts a SparseTensor of ids into a dense bool indicator tensor.View aliases
tf.sparse.transpose,"tf.sparse.transpose(
    sp_input, perm=None, name=None
)
",Transposes a SparseTensorView aliases
tf.split,"tf.split(
    value, num_or_size_splits, axis=0, num=None, name='split'
)
",Splits a tensor value into a list of sub tensors.View aliases
tf.math.sqrt,"tf.math.sqrt(
    x, name=None
)
",Computes element-wise square root of the input tensor.View aliases
tf.math.square,"tf.math.square(
    x, name=None
)
",Computes square of x element-wise.View aliases
tf.squeeze,"tf.squeeze(
    input, axis=None, name=None
)
",Removes dimensions of size 1 from the shape of a tensor.
tf.stack,"tf.stack(
    values, axis=0, name='stack'
)
",Stacks a list of rank-R tensors into one rank-(R+1) tensor.View aliases
tf.stop_gradient,"tf.stop_gradient(
    input, name=None
)
",Stops gradient computation.View aliases
tf.strided_slice,"tf.strided_slice(
    input_,
    begin,
    end,
    strides=None,
    begin_mask=0,
    end_mask=0,
    ellipsis_mask=0,
    new_axis_mask=0,
    shrink_axis_mask=0,
    var=None,
    name=None
)
",Extracts a strided slice of a tensor (generalized Python array indexing).View aliases
tf.strings.as_string,"tf.strings.as_string(
    input,
    precision=-1,
    scientific=False,
    shortest=False,
    width=-1,
    fill='',
    name=None
)
",Converts each entry in the given tensor to strings.View aliases
tf.strings.bytes_split,"tf.strings.bytes_split(
    input, name=None
)
",Split string elements of input into bytes.View aliases
tf.strings.format,"tf.strings.format(
    template, inputs, placeholder='{}', summarize=3, name=None
)
",Formats a string template using a list of tensors.View aliases
tf.strings.join,"tf.strings.join(
    inputs, separator='', name=None
)
",Perform element-wise concatenation of a list of string tensors.View aliases
tf.strings.length,"tf.strings.length(
    input, unit='BYTE', name=None
)
",String lengths of input.
tf.strings.lower,"tf.strings.lower(
    input, encoding='', name=None
)
",Converts all uppercase characters into their respective lowercase replacements.View aliases
tf.strings.ngrams,"tf.strings.ngrams(
    data,
    ngram_width,
    separator=' ',
    pad_values=None,
    padding_width=None,
    preserve_short_sequences=False,
    name=None
)
",Create a tensor of n-grams based on data.View aliases
tf.strings.reduce_join,"tf.strings.reduce_join(
    inputs, axis=None, keepdims=False, separator='', name=None
)
","Joins all strings into a single string, or joins along an axis."
tf.strings.reduce_join,"tf.strings.reduce_join([['abc','123'],","Joins all strings into a single string, or joins along an axis.tf.strings.reduce_join(    inputs, axis=None, keepdims=False, separator='', name=None)Used in the notebooksThis is the reduction operation for the elementwise tf.strings.join op."
tf.strings.regex_full_match,"tf.strings.regex_full_match(
    input, pattern, name=None
)
",Check if the input matches the regex pattern.View aliases
tf.strings.regex_replace,"tf.strings.regex_replace(
    input, pattern, rewrite, replace_global=True, name=None
)
",Replace elements of input matching regex pattern with rewrite.View aliases
tf.strings.regex_replace,"tf.strings.regex_replace(""Text with tags.<br /><b>contains html</b>"",","Replace elements of input matching regex pattern with rewrite.View aliasestf.strings.regex_replace(    input, pattern, rewrite, replace_global=True, name=None)Used in the notebooks"
tf.strings.split,"tf.strings.split(
    input, sep=None, maxsplit=-1, name=None
)
",Split elements of input based on sep into a RaggedTensor.
tf.strings.strip,"tf.strings.strip(
    input, name=None
)
",Strip leading and trailing whitespaces from the Tensor.View aliases
tf.strings.substr,"tf.strings.substr(
    input, pos, len, unit='BYTE', name=None
)
",Return substrings from Tensor of strings.
tf.strings.to_hash_bucket,"tf.strings.to_hash_bucket(
    input, num_buckets, name=None
)
",Converts each string in the input Tensor to its hash mod by a number of buckets.
tf.strings.to_hash_bucket_fast,"tf.strings.to_hash_bucket_fast(
    input, num_buckets, name=None
)
",Converts each string in the input Tensor to its hash mod by a number of buckets.View aliases
tf.strings.to_hash_bucket_strong,"tf.strings.to_hash_bucket_strong(
    input, num_buckets, key, name=None
)
",Converts each string in the input Tensor to its hash mod by a number of buckets.View aliases
tf.strings.to_number,"tf.strings.to_number(
    input,
    out_type=tf.dtypes.float32,
    name=None
)
",Converts each string in the input Tensor to the specified numeric type.
tf.strings.unicode_decode,"tf.strings.unicode_decode(
    input,
    input_encoding,
    errors='replace',
    replacement_char=65533,
    replace_control_characters=False,
    name=None
)
",Decodes each string in input into a sequence of Unicode code points.View aliases
tf.strings.unicode_decode_with_offsets,"tf.strings.unicode_decode_with_offsets(
    input,
    input_encoding,
    errors='replace',
    replacement_char=65533,
    replace_control_characters=False,
    name=None
)
",Decodes each string into a sequence of code points with start offsets.View aliases
tf.strings.unicode_encode,"tf.strings.unicode_encode(
    input,
    output_encoding,
    errors='replace',
    replacement_char=65533,
    name=None
)
",Encodes each sequence of Unicode code points in input into a string.View aliases
tf.strings.unicode_script,"tf.strings.unicode_script(
    input, name=None
)
",Determine the script codes of a given tensor of Unicode integer code points.View aliases
tf.strings.unicode_split,"tf.strings.unicode_split(
    input,
    input_encoding,
    errors='replace',
    replacement_char=65533,
    name=None
)
",Splits each string in input into a sequence of Unicode code points.View aliases
tf.strings.unicode_split_with_offsets,"tf.strings.unicode_split_with_offsets(
    input,
    input_encoding,
    errors='replace',
    replacement_char=65533,
    name=None
)
",Splits each string into a sequence of code points with start offsets.View aliases
tf.strings.unicode_transcode,"tf.strings.unicode_transcode(
    input,
    input_encoding,
    output_encoding,
    errors='replace',
    replacement_char=65533,
    replace_control_characters=False,
    name=None
)
",Transcode the input text from a source encoding to a destination encoding.View aliases
tf.strings.unsorted_segment_join,"tf.strings.unsorted_segment_join(
    inputs, segment_ids, num_segments, separator='', name=None
)
",Joins the elements of inputs based on segment_ids.View aliases
tf.strings.upper,"tf.strings.upper(
    input, encoding='', name=None
)
",Converts all lowercase characters into their respective uppercase replacements.View aliases
tf.math.subtract,"tf.math.subtract(
    x, y, name=None
)
",Returns x - y element-wise.View aliases
tf.summary.audio,"tf.summary.audio(
    name,
    data,
    sample_rate,
    step=None,
    max_outputs=3,
    encoding=None,
    description=None
)
",Write an audio summary.
tf.summary.create_file_writer,"tf.summary.create_file_writer(
    logdir,
    max_queue=None,
    flush_millis=None,
    filename_suffix=None,
    name=None,
    experimental_trackable=False
)
",Creates a summary file writer for the given log directory.
tf.summary.flush,"tf.summary.flush(
    writer=None, name=None
)
",Forces summary writer to send any buffered data to storage.
tf.summary.graph,"tf.summary.graph(
    graph_data
)
",Writes a TensorFlow graph summary.
tf.summary.histogram,"tf.summary.histogram(
    name, data, step=None, buckets=None, description=None
)
",Write a histogram summary.
tf.summary.image,"tf.summary.image(
    name, data, step=None, max_outputs=3, description=None
)
",Write an image summary.
tf.summary.scalar,"tf.summary.scalar(
    name, data, step=None, description=None
)
",Write a scalar summary.
tf.summary.text,"tf.summary.text(
    name, data, step=None, description=None
)
",Write a text summary.
tf.summary.trace_export,"tf.summary.trace_export(
    name, step=None, profiler_outdir=None
)
",Stops and exports the active trace as a Summary and/or profile file.
tf.summary.trace_on,"tf.summary.trace_on(
    graph=True, profiler=False
)
",Starts a trace to record computation graphs and profiling information.
tf.summary.write,"tf.summary.write(
    tag, tensor, step=None, metadata=None, name=None
)
",Writes a generic summary to the default SummaryWriter if one exists.
tf.switch_case,"tf.switch_case(
    branch_index, branch_fns, default=None, name='switch_case'
)
","Create a switch/case operation, i.e. an integer-indexed conditional.View aliases"
tf.math.tan,"tf.math.tan(
    x, name=None
)
",Computes tan of x element-wise.View aliases
tf.math.tanh,"tf.math.tanh(
    x, name=None
)
",Computes hyperbolic tangent of x element-wise.View aliases
tf.tensor_scatter_nd_add,"tf.tensor_scatter_nd_add(
    tensor, indices, updates, name=None
)
",Adds sparse updates to an existing tensor according to indices.View aliases
tf.tensor_scatter_nd_max,"tf.tensor_scatter_nd_max(
    tensor, indices, updates, name=None
)
",Apply a sparse update to a tensor taking the element-wise maximum.View aliases
tf.tensor_scatter_nd_min,"tf.tensor_scatter_nd_min(
    tensor, indices, updates, name=None
)
",View aliases
tf.tensor_scatter_nd_sub,"tf.tensor_scatter_nd_sub(
    tensor, indices, updates, name=None
)
",Subtracts sparse updates from an existing tensor according to indices.View aliases
tf.tensor_scatter_nd_update,"tf.tensor_scatter_nd_update(
    tensor, indices, updates, name=None
)
",Scatter updates into an existing tensor according to indices.View aliases
tf.tensordot,"tf.tensordot(
    a, b, axes, name=None
)
",Tensor contraction of a and b along specified axes and outer product.View aliases
tf.test.TestCase,"tf.test.TestCase(
    methodName='runTest'
)
",Base class for tests that need to test TensorFlow.View aliases
tf.test.TestCase.failureException,"tf.test.TestCase.failureException(
    *args, **kwargs
)
",Assertion failed.View aliases
tf.test.assert_equal_graph_def,"tf.test.assert_equal_graph_def(
    expected, actual
)
",Asserts that two GraphDefs are (mostly) the same.
tf.test.compute_gradient,"tf.test.compute_gradient(
    f, x, delta=None
)
",Computes the theoretical and numeric Jacobian of f.
tf.test.create_local_cluster,"tf.test.create_local_cluster(
    num_workers,
    num_ps,
    protocol='grpc',
    worker_config=None,
    ps_config=None
)
",Create and start local servers and return the associated Server objects.View aliases
tf.test.disable_with_predicate,"tf.test.disable_with_predicate(
    pred, skip_message
)
",Disables the test if pred is true.View aliases
tf.test.is_gpu_available,"tf.test.is_gpu_available(
    cuda_only=False, min_cuda_compute_capability=None
)
",Returns whether TensorFlow can access a GPU. (deprecated)View aliases
tf.test.main,"tf.test.main(
    argv=None
)
",Runs all unit tests.View aliases
tf.test.with_eager_op_as_function,"tf.test.with_eager_op_as_function(
    cls=None, only_as_function=False
)
",Adds methods that call original methods with eager_op_as_function enabled.View aliases
tf.tile,"tf.tile(
    input, multiples, name=None
)
",Constructs a tensor by tiling a given tensor.View aliases
tf.timestamp,"tf.timestamp(
    name=None
)
",Provides the time since epoch in seconds.View aliases
tf.tpu.XLAOptions,"tf.tpu.XLAOptions(
    use_spmd_for_xla_partitioning=True, enable_xla_dynamic_padder=True
)
",XLA compilation options.View aliases
tf.tpu.experimental.DeviceAssignment,"tf.tpu.experimental.DeviceAssignment(
    topology: tf.tpu.experimental.Topology,
    core_assignment: np.ndarray
)
",Mapping from logical cores in a computation to the physical TPU topology.View aliases
tf.tpu.experimental.HardwareFeature,"tf.tpu.experimental.HardwareFeature(
    tpu_hardware_feature_proto
)
",class holds all the feature info about the TPU.View aliases
tf.tpu.experimental.TPUSystemMetadata,"tf.tpu.experimental.TPUSystemMetadata(
    num_cores, num_hosts, num_of_cores_per_host, topology, devices
)
",Describes some metadata about the TPU system.View aliases
tf.tpu.experimental.Topology,"tf.tpu.experimental.Topology(
    serialized=None, mesh_shape=None, device_coordinates=None
)
",Describes a set of TPU devices.View aliases
tf.tpu.experimental.embedding.Adagrad,"tf.tpu.experimental.embedding.Adagrad(
    learning_rate: Union[float, Callable[[], float]] = 0.001,
    initial_accumulator_value: float = 0.1,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: bool = None,
    slot_variable_creation_fn: Optional[SlotVarCreationFnType] = None,
    clipvalue: Optional[ClipValueType] = None
)
",Optimization parameters for Adagrad with TPU embeddings.View aliases
tf.tpu.experimental.embedding.AdagradMomentum,"tf.tpu.experimental.embedding.AdagradMomentum(
    learning_rate: Union[float, Callable[[], float]] = 0.001,
    momentum: float = 0.0,
    use_nesterov: bool = False,
    exponent: float = 2,
    beta2: float = 1,
    epsilon: float = 1e-10,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: bool = None,
    slot_variable_creation_fn: Optional[SlotVarCreationFnType] = None,
    clipvalue: Optional[ClipValueType] = None
)
",Optimization parameters for Adagrad + Momentum with TPU embeddings.View aliases
tf.tpu.experimental.embedding.Adam,"tf.tpu.experimental.embedding.Adam(
    learning_rate: Union[float, Callable[[], float]] = 0.001,
    beta_1: float = 0.9,
    beta_2: float = 0.999,
    epsilon: float = 1e-07,
    lazy_adam: bool = True,
    sum_inside_sqrt: bool = True,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: bool = None,
    slot_variable_creation_fn: Optional[SlotVarCreationFnType] = None,
    clipvalue: Optional[ClipValueType] = None
)
",Optimization parameters for Adam with TPU embeddings.View aliases
tf.tpu.experimental.embedding.FTRL,"tf.tpu.experimental.embedding.FTRL(
    learning_rate: Union[float, Callable[[], float]] = 0.001,
    learning_rate_power: float = -0.5,
    l1_regularization_strength: float = 0.0,
    l2_regularization_strength: float = 0.0,
    beta: float = 0.0,
    initial_accumulator_value: float = 0.1,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: bool = None,
    slot_variable_creation_fn: Optional[SlotVarCreationFnType] = None,
    clipvalue: Optional[ClipValueType] = None,
    multiply_linear_by_learning_rate: bool = False,
    allow_zero_accumulator: bool = False
)
",Optimization parameters for FTRL with TPU embeddings.View aliases
tf.tpu.experimental.embedding.FeatureConfig,"tf.tpu.experimental.embedding.FeatureConfig(
    table: tf.tpu.experimental.embedding.TableConfig,
    max_sequence_length: int = 0,
    validate_weights_and_indices: bool = True,
    output_shape: Optional[Union[List[int], tf.TensorShape]] = None,
    name: Optional[Text] = None
)
",Configuration data for one embedding feature.View aliases
tf.tpu.experimental.embedding.SGD,"tf.tpu.experimental.embedding.SGD(
    learning_rate: Union[float, Callable[[], float]] = 0.01,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: bool = None,
    clipvalue: Optional[ClipValueType] = None
)
",Optimization parameters for stochastic gradient descent for TPU embeddings.View aliases
tf.tpu.experimental.embedding.TPUEmbedding,"tf.tpu.experimental.embedding.TPUEmbedding(
    feature_config: Union[tf.tpu.experimental.embedding.FeatureConfig, Iterable],
    optimizer: Optional[tpu_embedding_v2_utils._Optimizer],
    pipeline_execution_with_tensor_core: bool = False
)
",The TPUEmbedding mid level API.View aliases
tf.tpu.experimental.embedding.TPUEmbeddingForServing,"tf.tpu.experimental.embedding.TPUEmbeddingForServing(
    feature_config: Union[tf.tpu.experimental.embedding.FeatureConfig, Iterable],
    optimizer: Optional[tpu_embedding_v2_utils._Optimizer]
)
",The TPUEmbedding mid level API running on CPU for serving.View aliases
tf.tpu.experimental.embedding.TPUEmbeddingV0,"tf.tpu.experimental.embedding.TPUEmbeddingV0(
    feature_config: Union[tf.tpu.experimental.embedding.FeatureConfig, Iterable],
    optimizer: Optional[tpu_embedding_v2_utils._Optimizer]
)
",The TPUEmbedding mid level API running on TPU without Embedding accelerator.View aliases
tf.tpu.experimental.embedding.TableConfig,"tf.tpu.experimental.embedding.TableConfig(
    vocabulary_size: int,
    dim: int,
    initializer: Optional[Callable[[Any], None]] = None,
    optimizer: Optional[_Optimizer] = None,
    combiner: Text = 'mean',
    name: Optional[Text] = None
)
",Configuration data for one embedding table.View aliases
tf.tpu.experimental.embedding.serving_embedding_lookup,"tf.tpu.experimental.embedding.serving_embedding_lookup(
    inputs: Any,
    weights: Optional[Any],
    tables: Dict[tf.tpu.experimental.embedding.TableConfig, tf.Variable],
    feature_config: Union[tf.tpu.experimental.embedding.FeatureConfig, Iterable]
) -> Any
",Apply standard lookup ops with tf.tpu.experimental.embedding configs.View aliases
tf.tpu.experimental.initialize_tpu_system,"tf.tpu.experimental.initialize_tpu_system(
    cluster_resolver=None
)
",Initialize the TPU devices.View aliases
tf.tpu.experimental.shutdown_tpu_system,"tf.tpu.experimental.shutdown_tpu_system(
    cluster_resolver=None
)
",Shuts down the TPU devices.View aliases
tf.io.parse_example,tf.io.parse_example(,"Used in tf.train.Example protos. Holds a list of byte-strings.View aliasesUsed in the notebooksAn Example proto is a representation of the following python type:Dict[str,     Union[List[bytes],           List[int64],           List[float]]]This proto implements the List[bytes] portion.from google.protobuf import text_formatexample = text_format.Parse('''  features {    feature {key: ""my_feature""             value {bytes_list {value: ['abc', '12345' ]} } }  }''',  tf.train.Example())example.features.feature['my_feature'].bytes_list.value[""abc"", ""12345""]Use tf.io.parse_example to extract tensors from a serialized Example proto:"
tf.train.Checkpoint,"tf.train.Checkpoint(
    root=None, **kwargs
)
",Manages saving/restoring trackable values to disk.
tf.train.CheckpointManager,"tf.train.CheckpointManager(
    checkpoint,
    directory,
    max_to_keep,
    keep_checkpoint_every_n_hours=None,
    checkpoint_name='ckpt',
    step_counter=None,
    checkpoint_interval=None,
    init_fn=None
)
",Manages multiple checkpoints by keeping some and deleting unneeded ones.View aliases
tf.train.CheckpointOptions,"tf.train.CheckpointOptions(
    experimental_io_device=None, experimental_enable_async_checkpoint=False
)
",Options for constructing a Checkpoint.View aliases
tf.train.ClusterSpec,"tf.train.ClusterSpec(
    cluster
)
","Represents a cluster as a set of ""tasks"", organized into ""jobs"".View aliases"
tf.train.Coordinator,"tf.train.Coordinator(
    clean_stop_exception_types=None
)
",A coordinator for threads.View aliases
tf.io.parse_example,tf.io.parse_example(,"An Example is a standard proto storing data for training and inference.View aliasesUsed in the notebooksAn Example proto is a representation of the following python type:Dict[str,     Union[List[bytes],           List[int64],           List[float]]]It contains a key-value store Example.features where each key (string) mapsto a tf.train.Feature message which contains a fixed-type list. This flexibleand compact format allows the storage of large amounts of typed data, butrequires that the data shape and use be determined by the configuration filesand parsers that are used to read and write this format (refer totf.io.parse_example for details).from google.protobuf import text_formatexample = text_format.Parse('''  features {    feature {key: ""my_feature""             value {int64_list {value: [1, 2, 3, 4]} } }  }''',  tf.train.Example())Use tf.io.parse_example to extract tensors from a serialized Example proto:"
tf.train.ExponentialMovingAverage,"tf.train.ExponentialMovingAverage(
    decay,
    num_updates=None,
    zero_debias=False,
    name='ExponentialMovingAverage'
)
",Maintains moving averages of variables by employing an exponential decay.View aliases
tf.io.parse_example,tf.io.parse_example(,"Used in tf.train.Example protos. Contains a list of values.View aliasesUsed in the notebooksAn Example proto is a representation of the following python type:Dict[str,     Union[List[bytes],           List[int64],           List[float]]]This proto implements the Union.The contained list can be one of three types:tf.train.BytesListtf.train.FloatListtf.train.Int64Listint_feature = tf.train.Feature(    int64_list=tf.train.Int64List(value=[1, 2, 3, 4]))float_feature = tf.train.Feature(    float_list=tf.train.FloatList(value=[1., 2., 3., 4.]))bytes_feature = tf.train.Feature(    bytes_list=tf.train.BytesList(value=[b""abc"", b""1234""]))example = tf.train.Example(    features=tf.train.Features(feature={        'my_ints': int_feature,        'my_floats': float_feature,        'my_bytes': bytes_feature,    }))Use tf.io.parse_example to extract tensors from a serialized Example proto:"
tf.io.parse_example,tf.io.parse_example(,"Used in tf.train.Example protos. Contains the mapping from keys to Feature.View aliasesUsed in the notebooksAn Example proto is a representation of the following python type:Dict[str,     Union[List[bytes],           List[int64],           List[float]]]This proto implements the Dict.int_feature = tf.train.Feature(    int64_list=tf.train.Int64List(value=[1, 2, 3, 4]))float_feature = tf.train.Feature(    float_list=tf.train.FloatList(value=[1., 2., 3., 4.]))bytes_feature = tf.train.Feature(    bytes_list=tf.train.BytesList(value=[b""abc"", b""1234""]))example = tf.train.Example(    features=tf.train.Features(feature={        'my_ints': int_feature,        'my_floats': float_feature,        'my_bytes': bytes_feature,    }))Use tf.io.parse_example to extract tensors from a serialized Example proto:"
tf.io.parse_example,tf.io.parse_example(,"Used in tf.train.Example protos. Holds a list of floats.View aliasesUsed in the notebooksAn Example proto is a representation of the following python type:Dict[str,     Union[List[bytes],           List[int64],           List[float]]]This proto implements the List[float] portion.from google.protobuf import text_formatexample = text_format.Parse('''  features {    feature {key: ""my_feature""             value {float_list {value: [1., 2., 3., 4. ]} } }  }''',  tf.train.Example())example.features.feature['my_feature'].float_list.value[1.0, 2.0, 3.0, 4.0]Use tf.io.parse_example to extract tensors from a serialized Example proto:"
tf.io.parse_example,tf.io.parse_example(,"Used in tf.train.Example protos. Holds a list of Int64s.View aliasesUsed in the notebooksAn Example proto is a representation of the following python type:Dict[str,     Union[List[bytes],           List[int64],           List[float]]]This proto implements the List[int64] portion.from google.protobuf import text_formatexample = text_format.Parse('''  features {    feature {key: ""my_feature""             value {int64_list {value: [1, 2, 3, 4]} } }  }''',  tf.train.Example())example.features.feature['my_feature'].int64_list.value[1, 2, 3, 4]Use tf.io.parse_example to extract tensors from a serialized Example proto:"
tf.train.TrackableView,"tf.train.TrackableView(
    root
)
",Gathers and serializes a trackable view.
tf.train.checkpoints_iterator,"tf.train.checkpoints_iterator(
    checkpoint_dir, min_interval_secs=0, timeout=None, timeout_fn=None
)
",Continuously yield new checkpoint files as they appear.View aliases
tf.train.get_checkpoint_state,"tf.train.get_checkpoint_state(
    checkpoint_dir, latest_filename=None
)
","Returns CheckpointState proto from the ""checkpoint"" file.View aliases"
tf.train.latest_checkpoint,"tf.train.latest_checkpoint(
    checkpoint_dir, latest_filename=None
)
",Finds the filename of latest saved checkpoint file.View aliases
tf.train.list_variables,"tf.train.list_variables(
    ckpt_dir_or_file
)
",Lists the checkpoint keys and shapes of variables in a checkpoint.View aliases
tf.train.load_checkpoint,"tf.train.load_checkpoint(
    ckpt_dir_or_file
)
",Returns CheckpointReader for checkpoint found in ckpt_dir_or_file.View aliases
tf.train.load_variable,"tf.train.load_variable(
    ckpt_dir_or_file, name
)
",Returns the tensor value of the given variable in the checkpoint.View aliases
tf.transpose,"tf.transpose(
    a, perm=None, conjugate=False, name='transpose'
)
","Transposes a, where a is a Tensor."
tf.math.truediv,"tf.math.truediv(
    x, y, name=None
)
",Divides x / y elementwise (using Python 3 division operator semantics).View aliases
tf.truncatediv,"tf.truncatediv(
    x, y, name=None
)
",Returns x / y element-wise for integer types.View aliases
tf.truncatemod,"tf.truncatemod(
    x, y, name=None
)
",Returns element-wise remainder of division. This emulates C semantics in thatView aliases
tf.tuple,"tf.tuple(
    tensors, control_inputs=None, name=None
)
",Groups tensors together.
tf.type_spec_from_value,"tf.type_spec_from_value(
    value
) -> tf.TypeSpec
",Returns a tf.TypeSpec that represents the given value.View aliases
tf.unique,"tf.unique(
    x,
    out_idx=tf.dtypes.int32,
    name=None
)
",Finds unique elements in a 1-D tensor.View aliases
tf.unique_with_counts,"tf.unique_with_counts(
    x,
    out_idx=tf.dtypes.int32,
    name=None
)
",Finds unique elements in a 1-D tensor.View aliases
tf.unravel_index,"tf.unravel_index(
    indices, dims, name=None
)
",Converts an array of flat indices into a tuple of coordinate arrays.View aliases
tf.unstack,"tf.unstack(
    value, num=None, axis=0, name='unstack'
)
",Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.View aliases
tf.vectorized_map,"tf.vectorized_map(
    fn, elems, fallback_to_while_loop=True, warn=True
)
",Parallel map on the list of tensors unpacked from elems on dimension 0.View aliases
tf.where,"tf.where(
    condition, x=None, y=None, name=None
)
","Returns the indices of non-zero elements, or multiplexes x and y.View aliases"
tf.where,"tf.where([True, False, False, True],","Returns the indices of non-zero elements, or multiplexes x and y.View aliasestf.where(    condition, x=None, y=None, name=None)Used in the notebooksThis operation has two modes:Return the indices of non-zero elementsMultiplex 1. Return the indices of non-zero elementsNote: In this mode If x and y are not provided (both are None):tf.where will return the indices of condition that are non-zero,in the form of a 2-D tensor with shape [n, d], where n is the number ofnon-zero elements in condition (tf.count_nonzero(condition)), and d isthe number of axes of condition (tf.rank(condition)).Indices are output in row-major order. The condition can have a dtype oftf.bool, or any numeric dtype.Here condition is a 1-axis bool tensor with 2 True values. The resulthas a shape of [2,1]tf.where([True, False, False, True]).numpy()array([[0],       [3]])Here condition is a 2-axis integer tensor, with 3 non-zero values. Theresult has a shape of [3, 2].tf.where([[1, 0, 0], [1, 0, 1]]).numpy()array([[0, 0],       [1, 0],       [1, 2]])Here condition is a 3-axis float tensor, with 5 non-zero values. The outputshape is [5, 3].float_tensor = [[[0.1, 0], [0, 2.2], [3.5, 1e6]],                [[0,   0], [0,   0], [99,    0]]]tf.where(float_tensor).numpy()array([[0, 0, 0],       [0, 1, 1],       [0, 2, 0],       [0, 2, 1],       [1, 2, 0]])These indices are the same that tf.sparse.SparseTensor would use torepresent the condition tensor:sparse = tf.sparse.from_dense(float_tensor)sparse.indices.numpy()array([[0, 0, 0],       [0, 1, 1],       [0, 2, 0],       [0, 2, 1],       [1, 2, 0]])A complex number is considered non-zero if either the real or imaginarycomponent is non-zero:tf.where([complex(0.), complex(1.), 0+1j, 1+1j]).numpy()array([[1],       [2],       [3]])2. Multiplex x and yNote: In this mode If x and y are also provided (both have non-None values) the conditiontensor acts as a mask that chooses whether the correspondingelement / row in the output should be taken from x (if the element incondition is True) or y (if it is False).The shape of the result is formed bybroadcastingtogether the shapes of condition, x, and y.When all three inputs have the same size, each is handled element-wise."
tf.where,"tf.where([True, False, True],","Returns the indices of non-zero elements, or multiplexes x and y.View aliasestf.where(    condition, x=None, y=None, name=None)Used in the notebooksThis operation has two modes:Return the indices of non-zero elementsMultiplex 1. Return the indices of non-zero elementsNote: In this mode If x and y are not provided (both are None):tf.where will return the indices of condition that are non-zero,in the form of a 2-D tensor with shape [n, d], where n is the number ofnon-zero elements in condition (tf.count_nonzero(condition)), and d isthe number of axes of condition (tf.rank(condition)).Indices are output in row-major order. The condition can have a dtype oftf.bool, or any numeric dtype.Here condition is a 1-axis bool tensor with 2 True values. The resulthas a shape of [2,1]tf.where([True, False, False, True]).numpy()array([[0],       [3]])Here condition is a 2-axis integer tensor, with 3 non-zero values. Theresult has a shape of [3, 2].tf.where([[1, 0, 0], [1, 0, 1]]).numpy()array([[0, 0],       [1, 0],       [1, 2]])Here condition is a 3-axis float tensor, with 5 non-zero values. The outputshape is [5, 3].float_tensor = [[[0.1, 0], [0, 2.2], [3.5, 1e6]],                [[0,   0], [0,   0], [99,    0]]]tf.where(float_tensor).numpy()array([[0, 0, 0],       [0, 1, 1],       [0, 2, 0],       [0, 2, 1],       [1, 2, 0]])These indices are the same that tf.sparse.SparseTensor would use torepresent the condition tensor:sparse = tf.sparse.from_dense(float_tensor)sparse.indices.numpy()array([[0, 0, 0],       [0, 1, 1],       [0, 2, 0],       [0, 2, 1],       [1, 2, 0]])A complex number is considered non-zero if either the real or imaginarycomponent is non-zero:tf.where([complex(0.), complex(1.), 0+1j, 1+1j]).numpy()array([[1],       [2],       [3]])2. Multiplex x and yNote: In this mode If x and y are also provided (both have non-None values) the conditiontensor acts as a mask that chooses whether the correspondingelement / row in the output should be taken from x (if the element incondition is True) or y (if it is False).The shape of the result is formed bybroadcastingtogether the shapes of condition, x, and y.When all three inputs have the same size, each is handled element-wise.tf.where([True, False, False, True],         [1, 2, 3, 4],         [100, 200, 300, 400]).numpy()array([  1, 200, 300,   4], dtype=int32)There are two main rules for broadcasting:If a tensor has fewer axes than the others, length-1 axes are added to theleft of the shape.Axes with length-1 are streched to match the coresponding axes of the othertensors.A length-1 vector is streched to match the other vectors:tf.where([True, False, False, True], [1, 2, 3, 4], [100]).numpy()array([  1, 100, 100,   4], dtype=int32)A scalar is expanded to match the other arguments:tf.where([[True, False], [False, True]], [[1, 2], [3, 4]], 100).numpy()array([[  1, 100], [100,   4]], dtype=int32)tf.where([[True, False], [False, True]], 1, 100).numpy()array([[  1, 100], [100,   1]], dtype=int32)A scalar condition returns the complete x or y tensor, withbroadcasting applied.tf.where(True, [1, 2, 3, 4], 100).numpy()array([1, 2, 3, 4], dtype=int32)tf.where(False, [1, 2, 3, 4], 100).numpy()array([100, 100, 100, 100], dtype=int32)For a non-trivial example of broadcasting, here condition has a shape of[3], x has a shape of [3,3], and y has a shape of [3,1].Broadcasting first expands the shape of condition to [1,3]. The finalbroadcast shape is [3,3]. condition will select columns from x and y.Since y only has one column, all columns from y will be identical."
tf.while_loop,"tf.while_loop(
    cond,
    body,
    loop_vars,
    shape_invariants=None,
    parallel_iterations=10,
    back_prop=True,
    swap_memory=False,
    maximum_iterations=None,
    name=None
)
",Repeat body while the condition cond is true. (deprecated argument values)
tf.xla.experimental.compile,"tf.xla.experimental.compile(
    computation, inputs=None
)
",Builds an operator that compiles and runs computation with XLA. (deprecated)View aliases
tf.zeros,"tf.zeros(
    shape,
    dtype=tf.dtypes.float32,
    name=None
)
",Creates a tensor with all elements set to zero.View aliases
tf.zeros_like,"tf.zeros_like(
    input, dtype=None, name=None
)
",Creates a tensor with all elements set to zero.
tf.debugging.Assert,"tf.debugging.Assert(
    condition, data, summarize=None, name=None
)
",Asserts that the given condition is true.View aliases
tf.compat.v1.ConditionalAccumulator,"tf.compat.v1.ConditionalAccumulator(
    dtype,
    shape=None,
    shared_name=None,
    name='conditional_accumulator',
    reduction_type='MEAN'
)
",A conditional accumulator for aggregating gradients.Inherits From: ConditionalAccumulatorBase
tf.compat.v1.ConditionalAccumulatorBase,"tf.compat.v1.ConditionalAccumulatorBase(
    dtype, shape, accumulator_ref
)
",A conditional accumulator for aggregating gradients.
tf.CriticalSection,"tf.CriticalSection(
    name=None, shared_name=None, critical_section_def=None, import_scope=None
)
",Critical section.View aliases
tf.compat.v1.DeviceSpec,"tf.compat.v1.DeviceSpec(
    job=None, replica=None, task=None, device_type=None, device_index=None
)
",Represents a (possibly partial) specification for a TensorFlow device.Inherits From: DeviceSpec
tf.compat.v1.Dimension,"tf.compat.v1.Dimension(
    value
)
",Represents the value of one dimension in a TensorShape.
tf.queue.FIFOQueue,"tf.queue.FIFOQueue(
    capacity,
    dtypes,
    shapes=None,
    names=None,
    shared_name=None,
    name='fifo_queue'
)
",A queue implementation that dequeues elements in first-in first-out order.Inherits From: QueueBaseView aliases
tf.io.FixedLenFeature,"tf.io.FixedLenFeature(
    shape, dtype, default_value=None
)
",Configuration for parsing a fixed-length input feature.View aliases
tf.io.FixedLenSequenceFeature,"tf.io.FixedLenSequenceFeature(
    shape, dtype, allow_missing=False, default_value=None
)
",Configuration for parsing a variable-length input feature into a Tensor.View aliases
tf.compat.v1.FixedLengthRecordReader,"tf.compat.v1.FixedLengthRecordReader(
    record_bytes,
    header_bytes=None,
    footer_bytes=None,
    hop_bytes=None,
    name=None,
    encoding=None
)
",A Reader that outputs fixed-length records from a file.Inherits From: ReaderBase
tf.GradientTape,"tf.GradientTape(
    persistent=False, watch_accessed_variables=True
)
",Record operations for automatic differentiation.View aliases
tf.compat.v1.IdentityReader,"tf.compat.v1.IdentityReader(
    name=None
)
",A Reader that outputs the queued work as both the key and value.Inherits From: ReaderBase
tf.IndexedSlices,"tf.IndexedSlices(
    values, indices, dense_shape=None
)
",A sparse representation of a set of tensor slices at given indices.View aliases
tf.IndexedSlicesSpec,"tf.IndexedSlicesSpec(
    shape=None,
    dtype=tf.dtypes.float32,
    indices_dtype=tf.dtypes.int64,
    dense_shape_dtype=None,
    indices_shape=None
)
","Type specification for a tf.IndexedSlices.Inherits From: TypeSpec, TraceTypeView aliases"
tf.compat.v1.InteractiveSession,"tf.compat.v1.InteractiveSession(
    target='', graph=None, config=None
)
","A TensorFlow Session for use in interactive contexts, such as a shell."
tf.compat.v1.LMDBReader,"tf.compat.v1.LMDBReader(
    name=None, options=None
)
",A Reader that outputs the records from a LMDB file.Inherits From: ReaderBase
tf.Module,"tf.Module(
    name=None
)
",Base neural network module class.View aliases
tf.no_gradient,"tf.no_gradient(
    op_type
)
",Specifies that ops of type op_type is not differentiable.View aliases
tf.no_gradient,"tf.no_gradient(
    op_type
)
",Specifies that ops of type op_type is not differentiable.View aliases
tf.errors.OpError,"tf.errors.OpError(
    node_def, op, message, error_code, *args
)
",The base class for TensorFlow exceptions.View aliases
tf.Operation,"tf.Operation(
    node_def,
    g,
    inputs=None,
    output_types=None,
    control_inputs=None,
    input_types=None,
    original_op=None,
    op_def=None
)
",Represents a graph node that performs computation on tensors.View aliases
tf.OptionalSpec,"tf.OptionalSpec(
    element_spec
)
","Type specification for tf.experimental.Optional.Inherits From: TypeSpec, TraceTypeView aliases"
tf.queue.PaddingFIFOQueue,"tf.queue.PaddingFIFOQueue(
    capacity,
    dtypes,
    shapes,
    names=None,
    shared_name=None,
    name='padding_fifo_queue'
)
",A FIFOQueue that supports batching variable-sized tensors by padding.Inherits From: QueueBaseView aliases
tf.compat.v1.Print,"tf.compat.v1.Print(
    input_, data, message=None, first_n=None, summarize=None, name=None
)
",Prints a list of tensors. (deprecated)
tf.queue.PriorityQueue,"tf.queue.PriorityQueue(
    capacity,
    types,
    shapes=None,
    names=None,
    shared_name=None,
    name='priority_queue'
)
",A queue implementation that dequeues elements in prioritized order.Inherits From: QueueBaseView aliases
tf.queue.QueueBase,"tf.queue.QueueBase(
    dtypes, shapes, names, queue_ref
)
",Base class for queue implementations.View aliases
tf.ragged.constant,"tf.ragged.constant([[0], [1, 2]]).shape","Represents a ragged tensor.View aliasesUsed in the notebooksA RaggedTensor is a tensor with one or more ragged dimensions, which aredimensions whose slices may have different lengths.  For example, the inner(column) dimension of rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []] is ragged,since the column slices (rt[0, :], ..., rt[4, :]) have different lengths.Dimensions whose slices all have the same length are called uniformdimensions.  The outermost dimension of a RaggedTensor is always uniform,since it consists of a single slice (and so there is no possibility fordiffering slice lengths).The total number of dimensions in a RaggedTensor is called its rank,and the number of ragged dimensions in a RaggedTensor is called itsragged-rank.  A RaggedTensor's ragged-rank is fixed at graph creationtime: it can't depend on the runtime values of Tensors, and can't varydynamically for different session runs.Note that the __init__ constructor is private. Please use one of thefollowing methods to construct a RaggedTensor:tf.RaggedTensor.from_row_lengthstf.RaggedTensor.from_value_rowidstf.RaggedTensor.from_row_splitstf.RaggedTensor.from_row_startstf.RaggedTensor.from_row_limitstf.RaggedTensor.from_nested_row_splitstf.RaggedTensor.from_nested_row_lengthstf.RaggedTensor.from_nested_value_rowidsPotentially Ragged TensorsMany ops support both Tensors and RaggedTensors(see tf.ragged for afull listing). The term ""potentially ragged tensor"" may be used to refer to atensor that might be either a Tensor or a RaggedTensor.  The ragged-rankof a Tensor is zero.Documenting RaggedTensor ShapesWhen documenting the shape of a RaggedTensor, ragged dimensions can beindicated by enclosing them in parentheses.  For example, the shape ofa 3-D RaggedTensor that stores the fixed-size word embedding for eachword in a sentence, for each sentence in a batch, could be written as[num_sentences, (num_words), embedding_size].  The parentheses around(num_words) indicate that dimension is ragged, and that the lengthof each element list in that dimension may vary for each item.Component TensorsInternally, a RaggedTensor consists of a concatenated list of values thatare partitioned into variable-length rows.  In particular, each RaggedTensorconsists of:A A Example:print(tf.RaggedTensor.from_row_splits(      values=[3, 1, 4, 1, 5, 9, 2, 6],      row_splits=[0, 4, 4, 7, 8, 8]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>Alternative Row-Partitioning SchemesIn addition to row_splits, ragged tensors provide support for five otherrow-partitioning schemes:row_lengthsvalue_rowidsrow_startsrow_limitsuniform_row_lengthExample: The following ragged tensors are equivalent, and all represent thenested list [[3, 1, 4, 1], [], [5, 9, 2], [6], []].values = [3, 1, 4, 1, 5, 9, 2, 6]RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_value_rowids(    values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5)<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_uniform_row_length(values, uniform_row_length=2)<tf.RaggedTensor [[3, 1], [4, 1], [5, 9], [2, 6]]>Multiple Ragged DimensionsRaggedTensors with multiple ragged dimensions can be defined by usinga nested RaggedTensor for the values tensor.  Each nested RaggedTensoradds a single ragged dimension.inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above    values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8])outer_rt = RaggedTensor.from_row_splits(    values=inner_rt, row_splits=[0, 3, 3, 5])print(outer_rt.to_list())[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]print(outer_rt.ragged_rank)2The factory function RaggedTensor.from_nested_row_splits may be used toconstruct a RaggedTensor with multiple ragged dimensions directly, byproviding a list of row_splits tensors:RaggedTensor.from_nested_row_splits(    flat_values=[3, 1, 4, 1, 5, 9, 2, 6],    nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list()[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]Uniform Inner DimensionsRaggedTensors with uniform inner dimensions can be definedby using a multidimensional Tensor for values.rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3], tf.int32),                                  row_splits=[0, 2, 5])print(rt.to_list())[[[1, 1, 1], [1, 1, 1]], [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]print(rt.shape)(2, None, 3)Uniform Outer DimensionsRaggedTensors with uniform outer dimensions can be defined by usingone or more RaggedTensor with a uniform_row_length row-partitioningtensor.  For example, a RaggedTensor with shape [2, 2, None] can beconstructed with this method from a RaggedTensor values with shape[4, None]:values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])print(values.shape)(4, None)rt6 = tf.RaggedTensor.from_uniform_row_length(values, 2)print(rt6)<tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>print(rt6.shape)(2, 2, None)Note that rt6 only contains one ragged dimension (the innermostdimension). In contrast, if from_row_splits is used to construct a similarRaggedTensor, then that RaggedTensor will have two ragged dimensions:rt7 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])print(rt7.shape)(2, None, None)Uniform and ragged outer dimensions may be interleaved, meaning that atensor with any combination of ragged and uniform dimensions may be created.For example, a RaggedTensor t4 with shape [3, None, 4, 8, None, 2] couldbe constructed as follows:t0 = tf.zeros([1000, 2])                           # Shape:         [1000, 2]t1 = RaggedTensor.from_row_lengths(t0, [...])      #           [160, None, 2]t2 = RaggedTensor.from_uniform_row_length(t1, 8)   #         [20, 8, None, 2]t3 = RaggedTensor.from_uniform_row_length(t2, 4)   #       [5, 4, 8, None, 2]t4 = RaggedTensor.from_row_lengths(t3, [...])      # [3, None, 4, 8, None, 2]Concretely, if rt.values is a Tensor, then rt.flat_values isrt.values; otherwise, rt.flat_values is rt.values.flat_values.Conceptually, flat_values is the tensor formed by flattening theoutermost dimension and all of the ragged dimensions into a singledimension.rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:](where nvals is the number of items in the flattened dimensions).Example:rt = tf.ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])print(rt.flat_values)tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)rt.nested_row_splits is a tuple containing the row_splits tensors forall ragged dimensions in rt, ordered from outermost to innermost.  Inparticular, rt.nested_row_splits = (rt.row_splits,) + value_splits where:* `value_splits = ()` if `rt.values` is a `Tensor`.* `value_splits = rt.values.nested_row_splits` otherwise.Example:rt = tf.ragged.constant(    [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])for i, splits in enumerate(rt.nested_row_splits):  print('Splits for dimension %d: %s' % (i+1, splits.numpy()))Splits for dimension 1: [0 3]Splits for dimension 2: [0 3 3 5]Splits for dimension 3: [0 4 4 7 8 8]values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])values.ragged_rank1rt = tf.RaggedTensor.from_uniform_row_length(values, 2)rt.ragged_rank2rt.row_splits specifies where the values for each row begin and end inrt.values.  In particular, the values for row rt[i] are stored inthe slice rt.values[rt.row_splits[i]:rt.row_splits[i+1]].Example:rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])print(rt.row_splits)  # indices of row splits in rt.valuestf.Tensor([0 4 4 7 8 8], shape=(6,), dtype=int64)"
tf.ragged.constant,"tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shape","Represents a ragged tensor.View aliasesUsed in the notebooksA RaggedTensor is a tensor with one or more ragged dimensions, which aredimensions whose slices may have different lengths.  For example, the inner(column) dimension of rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []] is ragged,since the column slices (rt[0, :], ..., rt[4, :]) have different lengths.Dimensions whose slices all have the same length are called uniformdimensions.  The outermost dimension of a RaggedTensor is always uniform,since it consists of a single slice (and so there is no possibility fordiffering slice lengths).The total number of dimensions in a RaggedTensor is called its rank,and the number of ragged dimensions in a RaggedTensor is called itsragged-rank.  A RaggedTensor's ragged-rank is fixed at graph creationtime: it can't depend on the runtime values of Tensors, and can't varydynamically for different session runs.Note that the __init__ constructor is private. Please use one of thefollowing methods to construct a RaggedTensor:tf.RaggedTensor.from_row_lengthstf.RaggedTensor.from_value_rowidstf.RaggedTensor.from_row_splitstf.RaggedTensor.from_row_startstf.RaggedTensor.from_row_limitstf.RaggedTensor.from_nested_row_splitstf.RaggedTensor.from_nested_row_lengthstf.RaggedTensor.from_nested_value_rowidsPotentially Ragged TensorsMany ops support both Tensors and RaggedTensors(see tf.ragged for afull listing). The term ""potentially ragged tensor"" may be used to refer to atensor that might be either a Tensor or a RaggedTensor.  The ragged-rankof a Tensor is zero.Documenting RaggedTensor ShapesWhen documenting the shape of a RaggedTensor, ragged dimensions can beindicated by enclosing them in parentheses.  For example, the shape ofa 3-D RaggedTensor that stores the fixed-size word embedding for eachword in a sentence, for each sentence in a batch, could be written as[num_sentences, (num_words), embedding_size].  The parentheses around(num_words) indicate that dimension is ragged, and that the lengthof each element list in that dimension may vary for each item.Component TensorsInternally, a RaggedTensor consists of a concatenated list of values thatare partitioned into variable-length rows.  In particular, each RaggedTensorconsists of:A A Example:print(tf.RaggedTensor.from_row_splits(      values=[3, 1, 4, 1, 5, 9, 2, 6],      row_splits=[0, 4, 4, 7, 8, 8]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>Alternative Row-Partitioning SchemesIn addition to row_splits, ragged tensors provide support for five otherrow-partitioning schemes:row_lengthsvalue_rowidsrow_startsrow_limitsuniform_row_lengthExample: The following ragged tensors are equivalent, and all represent thenested list [[3, 1, 4, 1], [], [5, 9, 2], [6], []].values = [3, 1, 4, 1, 5, 9, 2, 6]RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_value_rowids(    values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5)<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_uniform_row_length(values, uniform_row_length=2)<tf.RaggedTensor [[3, 1], [4, 1], [5, 9], [2, 6]]>Multiple Ragged DimensionsRaggedTensors with multiple ragged dimensions can be defined by usinga nested RaggedTensor for the values tensor.  Each nested RaggedTensoradds a single ragged dimension.inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above    values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8])outer_rt = RaggedTensor.from_row_splits(    values=inner_rt, row_splits=[0, 3, 3, 5])print(outer_rt.to_list())[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]print(outer_rt.ragged_rank)2The factory function RaggedTensor.from_nested_row_splits may be used toconstruct a RaggedTensor with multiple ragged dimensions directly, byproviding a list of row_splits tensors:RaggedTensor.from_nested_row_splits(    flat_values=[3, 1, 4, 1, 5, 9, 2, 6],    nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list()[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]Uniform Inner DimensionsRaggedTensors with uniform inner dimensions can be definedby using a multidimensional Tensor for values.rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3], tf.int32),                                  row_splits=[0, 2, 5])print(rt.to_list())[[[1, 1, 1], [1, 1, 1]], [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]print(rt.shape)(2, None, 3)Uniform Outer DimensionsRaggedTensors with uniform outer dimensions can be defined by usingone or more RaggedTensor with a uniform_row_length row-partitioningtensor.  For example, a RaggedTensor with shape [2, 2, None] can beconstructed with this method from a RaggedTensor values with shape[4, None]:values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])print(values.shape)(4, None)rt6 = tf.RaggedTensor.from_uniform_row_length(values, 2)print(rt6)<tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>print(rt6.shape)(2, 2, None)Note that rt6 only contains one ragged dimension (the innermostdimension). In contrast, if from_row_splits is used to construct a similarRaggedTensor, then that RaggedTensor will have two ragged dimensions:rt7 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])print(rt7.shape)(2, None, None)Uniform and ragged outer dimensions may be interleaved, meaning that atensor with any combination of ragged and uniform dimensions may be created.For example, a RaggedTensor t4 with shape [3, None, 4, 8, None, 2] couldbe constructed as follows:t0 = tf.zeros([1000, 2])                           # Shape:         [1000, 2]t1 = RaggedTensor.from_row_lengths(t0, [...])      #           [160, None, 2]t2 = RaggedTensor.from_uniform_row_length(t1, 8)   #         [20, 8, None, 2]t3 = RaggedTensor.from_uniform_row_length(t2, 4)   #       [5, 4, 8, None, 2]t4 = RaggedTensor.from_row_lengths(t3, [...])      # [3, None, 4, 8, None, 2]Concretely, if rt.values is a Tensor, then rt.flat_values isrt.values; otherwise, rt.flat_values is rt.values.flat_values.Conceptually, flat_values is the tensor formed by flattening theoutermost dimension and all of the ragged dimensions into a singledimension.rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:](where nvals is the number of items in the flattened dimensions).Example:rt = tf.ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])print(rt.flat_values)tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)rt.nested_row_splits is a tuple containing the row_splits tensors forall ragged dimensions in rt, ordered from outermost to innermost.  Inparticular, rt.nested_row_splits = (rt.row_splits,) + value_splits where:* `value_splits = ()` if `rt.values` is a `Tensor`.* `value_splits = rt.values.nested_row_splits` otherwise.Example:rt = tf.ragged.constant(    [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])for i, splits in enumerate(rt.nested_row_splits):  print('Splits for dimension %d: %s' % (i+1, splits.numpy()))Splits for dimension 1: [0 3]Splits for dimension 2: [0 3 3 5]Splits for dimension 3: [0 4 4 7 8 8]values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])values.ragged_rank1rt = tf.RaggedTensor.from_uniform_row_length(values, 2)rt.ragged_rank2rt.row_splits specifies where the values for each row begin and end inrt.values.  In particular, the values for row rt[i] are stored inthe slice rt.values[rt.row_splits[i]:rt.row_splits[i+1]].Example:rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])print(rt.row_splits)  # indices of row splits in rt.valuestf.Tensor([0 4 4 7 8 8], shape=(6,), dtype=int64)tf.ragged.constant([[0], [1, 2]]).shapeTensorShape([2, None])"
tf.ragged.constant,tf.ragged.constant(,"Represents a ragged tensor.View aliasesUsed in the notebooksA RaggedTensor is a tensor with one or more ragged dimensions, which aredimensions whose slices may have different lengths.  For example, the inner(column) dimension of rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []] is ragged,since the column slices (rt[0, :], ..., rt[4, :]) have different lengths.Dimensions whose slices all have the same length are called uniformdimensions.  The outermost dimension of a RaggedTensor is always uniform,since it consists of a single slice (and so there is no possibility fordiffering slice lengths).The total number of dimensions in a RaggedTensor is called its rank,and the number of ragged dimensions in a RaggedTensor is called itsragged-rank.  A RaggedTensor's ragged-rank is fixed at graph creationtime: it can't depend on the runtime values of Tensors, and can't varydynamically for different session runs.Note that the __init__ constructor is private. Please use one of thefollowing methods to construct a RaggedTensor:tf.RaggedTensor.from_row_lengthstf.RaggedTensor.from_value_rowidstf.RaggedTensor.from_row_splitstf.RaggedTensor.from_row_startstf.RaggedTensor.from_row_limitstf.RaggedTensor.from_nested_row_splitstf.RaggedTensor.from_nested_row_lengthstf.RaggedTensor.from_nested_value_rowidsPotentially Ragged TensorsMany ops support both Tensors and RaggedTensors(see tf.ragged for afull listing). The term ""potentially ragged tensor"" may be used to refer to atensor that might be either a Tensor or a RaggedTensor.  The ragged-rankof a Tensor is zero.Documenting RaggedTensor ShapesWhen documenting the shape of a RaggedTensor, ragged dimensions can beindicated by enclosing them in parentheses.  For example, the shape ofa 3-D RaggedTensor that stores the fixed-size word embedding for eachword in a sentence, for each sentence in a batch, could be written as[num_sentences, (num_words), embedding_size].  The parentheses around(num_words) indicate that dimension is ragged, and that the lengthof each element list in that dimension may vary for each item.Component TensorsInternally, a RaggedTensor consists of a concatenated list of values thatare partitioned into variable-length rows.  In particular, each RaggedTensorconsists of:A A Example:print(tf.RaggedTensor.from_row_splits(      values=[3, 1, 4, 1, 5, 9, 2, 6],      row_splits=[0, 4, 4, 7, 8, 8]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>Alternative Row-Partitioning SchemesIn addition to row_splits, ragged tensors provide support for five otherrow-partitioning schemes:row_lengthsvalue_rowidsrow_startsrow_limitsuniform_row_lengthExample: The following ragged tensors are equivalent, and all represent thenested list [[3, 1, 4, 1], [], [5, 9, 2], [6], []].values = [3, 1, 4, 1, 5, 9, 2, 6]RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_value_rowids(    values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5)<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8])<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>RaggedTensor.from_uniform_row_length(values, uniform_row_length=2)<tf.RaggedTensor [[3, 1], [4, 1], [5, 9], [2, 6]]>Multiple Ragged DimensionsRaggedTensors with multiple ragged dimensions can be defined by usinga nested RaggedTensor for the values tensor.  Each nested RaggedTensoradds a single ragged dimension.inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above    values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8])outer_rt = RaggedTensor.from_row_splits(    values=inner_rt, row_splits=[0, 3, 3, 5])print(outer_rt.to_list())[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]print(outer_rt.ragged_rank)2The factory function RaggedTensor.from_nested_row_splits may be used toconstruct a RaggedTensor with multiple ragged dimensions directly, byproviding a list of row_splits tensors:RaggedTensor.from_nested_row_splits(    flat_values=[3, 1, 4, 1, 5, 9, 2, 6],    nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list()[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]Uniform Inner DimensionsRaggedTensors with uniform inner dimensions can be definedby using a multidimensional Tensor for values.rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3], tf.int32),                                  row_splits=[0, 2, 5])print(rt.to_list())[[[1, 1, 1], [1, 1, 1]], [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]print(rt.shape)(2, None, 3)Uniform Outer DimensionsRaggedTensors with uniform outer dimensions can be defined by usingone or more RaggedTensor with a uniform_row_length row-partitioningtensor.  For example, a RaggedTensor with shape [2, 2, None] can beconstructed with this method from a RaggedTensor values with shape[4, None]:values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])print(values.shape)(4, None)rt6 = tf.RaggedTensor.from_uniform_row_length(values, 2)print(rt6)<tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>print(rt6.shape)(2, 2, None)Note that rt6 only contains one ragged dimension (the innermostdimension). In contrast, if from_row_splits is used to construct a similarRaggedTensor, then that RaggedTensor will have two ragged dimensions:rt7 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])print(rt7.shape)(2, None, None)Uniform and ragged outer dimensions may be interleaved, meaning that atensor with any combination of ragged and uniform dimensions may be created.For example, a RaggedTensor t4 with shape [3, None, 4, 8, None, 2] couldbe constructed as follows:t0 = tf.zeros([1000, 2])                           # Shape:         [1000, 2]t1 = RaggedTensor.from_row_lengths(t0, [...])      #           [160, None, 2]t2 = RaggedTensor.from_uniform_row_length(t1, 8)   #         [20, 8, None, 2]t3 = RaggedTensor.from_uniform_row_length(t2, 4)   #       [5, 4, 8, None, 2]t4 = RaggedTensor.from_row_lengths(t3, [...])      # [3, None, 4, 8, None, 2]Concretely, if rt.values is a Tensor, then rt.flat_values isrt.values; otherwise, rt.flat_values is rt.values.flat_values.Conceptually, flat_values is the tensor formed by flattening theoutermost dimension and all of the ragged dimensions into a singledimension.rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:](where nvals is the number of items in the flattened dimensions).Example:rt = tf.ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])print(rt.flat_values)tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)rt.nested_row_splits is a tuple containing the row_splits tensors forall ragged dimensions in rt, ordered from outermost to innermost.  Inparticular, rt.nested_row_splits = (rt.row_splits,) + value_splits where:* `value_splits = ()` if `rt.values` is a `Tensor`.* `value_splits = rt.values.nested_row_splits` otherwise.Example:rt = tf.ragged.constant(    [[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])for i, splits in enumerate(rt.nested_row_splits):  print('Splits for dimension %d: %s' % (i+1, splits.numpy()))Splits for dimension 1: [0 3]Splits for dimension 2: [0 3 3 5]Splits for dimension 3: [0 4 4 7 8 8]values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])values.ragged_rank1rt = tf.RaggedTensor.from_uniform_row_length(values, 2)rt.ragged_rank2rt.row_splits specifies where the values for each row begin and end inrt.values.  In particular, the values for row rt[i] are stored inthe slice rt.values[rt.row_splits[i]:rt.row_splits[i+1]].Example:rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])print(rt.row_splits)  # indices of row splits in rt.valuestf.Tensor([0 4 4 7 8 8], shape=(6,), dtype=int64)tf.ragged.constant([[0], [1, 2]]).shapeTensorShape([2, None])tf.ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shapeTensorShape([2, None, 2])rt1 = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])print(rt1.uniform_row_length)  # rows are ragged.Nonert2 = tf.RaggedTensor.from_uniform_row_length(    values=rt1, uniform_row_length=2)print(rt2)<tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>print(rt2.uniform_row_length)  # rows are not ragged (all have size 2).tf.Tensor(2, shape=(), dtype=int64)A RaggedTensor's rows are only considered to be uniform (i.e. non-ragged)if it can be determined statically (at graph construction time) that therows all have the same length.rt.values is a potentially ragged tensor formed by flattening the twooutermost dimensions of rt into a single dimension.rt.values.shape = [nvals] + rt.shape[2:] (where nvals is thenumber of items in the outer two dimensions of rt).rt.ragged_rank = self.ragged_rank - 1Example:rt = tf.ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])print(rt.values)tf.Tensor([3 1 4 1 5 9 2 6], shape=(8,), dtype=int32)Methodsbounding_shapeView sourcebounding_shape(    axis=None, name=None, out_type=None)Returns the tight bounding box shape for this RaggedTensor.Example:rt = tf.ragged.constant([[1, 2, 3, 4], [5], [], [6, 7, 8, 9], [10]])rt.bounding_shape().numpy()array([5, 4])consumersView sourceconsumers()from_nested_row_lengthsView source@classmethodfrom_nested_row_lengths(    flat_values, nested_row_lengths, name=None, validate=True)Creates a RaggedTensor from a nested list of row_lengths tensors.Equivalent to:result = flat_valuesfor row_lengths in reversed(nested_row_lengths):  result = from_row_lengths(result, row_lengths)from_nested_row_splitsView source@classmethodfrom_nested_row_splits(    flat_values, nested_row_splits, name=None, validate=True)Creates a RaggedTensor from a nested list of row_splits tensors.Equivalent to:result = flat_valuesfor row_splits in reversed(nested_row_splits):  result = from_row_splits(result, row_splits)from_nested_value_rowidsView source@classmethodfrom_nested_value_rowids(    flat_values,    nested_value_rowids,    nested_nrows=None,    name=None,    validate=True)Creates a RaggedTensor from a nested list of value_rowids tensors.Equivalent to:result = flat_valuesfor (rowids, nrows) in reversed(zip(nested_value_rowids, nested_nrows)):  result = from_value_rowids(result, rowids, nrows)from_row_lengthsView source@classmethodfrom_row_lengths(    values, row_lengths, name=None, validate=True)Creates a RaggedTensor with rows partitioned by row_lengths.The returned RaggedTensor corresponds with the python list defined by:result = [[values.pop(0) for i in range(length)]          for length in row_lengths]Example:print(tf.RaggedTensor.from_row_lengths(    values=[3, 1, 4, 1, 5, 9, 2, 6],    row_lengths=[4, 0, 3, 1, 0]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>from_row_limitsView source@classmethodfrom_row_limits(    values, row_limits, name=None, validate=True)Creates a RaggedTensor with rows partitioned by row_limits.Equivalent to: from_row_splits(values, concat([0, row_limits])).Example:print(tf.RaggedTensor.from_row_limits(    values=[3, 1, 4, 1, 5, 9, 2, 6],    row_limits=[4, 4, 7, 8, 8]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>from_row_splitsView source@classmethodfrom_row_splits(    values, row_splits, name=None, validate=True)Creates a RaggedTensor with rows partitioned by row_splits.The returned RaggedTensor corresponds with the python list defined by:result = [values[row_splits[i]:row_splits[i + 1]]          for i in range(len(row_splits) - 1)]Example:print(tf.RaggedTensor.from_row_splits(    values=[3, 1, 4, 1, 5, 9, 2, 6],    row_splits=[0, 4, 4, 7, 8, 8]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>from_row_startsView source@classmethodfrom_row_starts(    values, row_starts, name=None, validate=True)Creates a RaggedTensor with rows partitioned by row_starts.Equivalent to: from_row_splits(values, concat([row_starts, nvals])).Example:print(tf.RaggedTensor.from_row_starts(    values=[3, 1, 4, 1, 5, 9, 2, 6],    row_starts=[0, 4, 4, 7, 8]))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>from_sparseView source@classmethodfrom_sparse(    st_input,    name=None,    row_splits_dtype=Converts a 2D tf.sparse.SparseTensor to a RaggedTensor.Each row of the output RaggedTensor will contain the explicit valuesfrom the same row in st_input.  st_input must be ragged-right.  If notit is not ragged-right, then an error will be generated.Example:indices = [[0, 0], [0, 1], [0, 2], [1, 0], [3, 0]]st = tf.sparse.SparseTensor(indices=indices,                            values=[1, 2, 3, 4, 5],                            dense_shape=[4, 3])tf.RaggedTensor.from_sparse(st).to_list()[[1, 2, 3], [4], [], [5]]Currently, only two-dimensional SparseTensors are supported.from_tensorView source@classmethodfrom_tensor(    tensor,    lengths=None,    padding=None,    ragged_rank=1,    name=None,    row_splits_dtype=Converts a tf.Tensor into a RaggedTensor.The set of absent/default values may be specified using a vector of lengthsor a padding value (but not both).  If lengths is specified, then theoutput tensor will satisfy output[row] = tensor[row][:lengths[row]]. If'lengths' is a list of lists or tuple of lists, those lists will be usedas nested row lengths. If padding is specified, then any row suffixconsisting entirely of padding will be excluded from the returnedRaggedTensor.  If neither lengths nor padding is specified, then thereturned RaggedTensor will have no absent/default values.Examples:dt = tf.constant([[5, 7, 0], [0, 3, 0], [6, 0, 0]])tf.RaggedTensor.from_tensor(dt)<tf.RaggedTensor [[5, 7, 0], [0, 3, 0], [6, 0, 0]]>tf.RaggedTensor.from_tensor(dt, lengths=[1, 0, 3])<tf.RaggedTensor [[5], [], [6, 0, 0]]>tf.RaggedTensor.from_tensor(dt, padding=0)<tf.RaggedTensor [[5, 7], [0, 3], [6]]>dt = tf.constant([[[5, 0], [7, 0], [0, 0]],                  [[0, 0], [3, 0], [0, 0]],                  [[6, 0], [0, 0], [0, 0]]])tf.RaggedTensor.from_tensor(dt, lengths=([2, 0, 3], [1, 1, 2, 0, 1]))<tf.RaggedTensor [[[5], [7]], [], [[6, 0], [], [0]]]>from_uniform_row_lengthView source@classmethodfrom_uniform_row_length(    values, uniform_row_length, nrows=None, validate=True, name=None)Creates a RaggedTensor with rows partitioned by uniform_row_length.This method can be used to create RaggedTensors with multiple uniformouter dimensions.  For example, a RaggedTensor with shape [2, 2, None]can be constructed with this method from a RaggedTensor values with shape[4, None]:values = tf.ragged.constant([[1, 2, 3], [4], [5, 6], [7, 8, 9, 10]])print(values.shape)(4, None)rt1 = tf.RaggedTensor.from_uniform_row_length(values, 2)print(rt1)<tf.RaggedTensor [[[1, 2, 3], [4]], [[5, 6], [7, 8, 9, 10]]]>print(rt1.shape)(2, 2, None)Note that rt1 only contains one ragged dimension (the innermostdimension). In contrast, if from_row_splits is used to construct a similarRaggedTensor, then that RaggedTensor will have two ragged dimensions:rt2 = tf.RaggedTensor.from_row_splits(values, [0, 2, 4])print(rt2.shape)(2, None, None)result = [[values.pop(0) for i in range(uniform_row_length)]          for _ in range(nrows)]result.rank = values.rank + 1.result.ragged_rank = values.ragged_rank + 1.from_value_rowidsView source@classmethodfrom_value_rowids(    values, value_rowids, nrows=None, name=None, validate=True)Creates a RaggedTensor with rows partitioned by value_rowids.The returned RaggedTensor corresponds with the python list defined by:result = [[values[i] for i in range(len(values)) if value_rowids[i] == row]          for row in range(nrows)]Example:print(tf.RaggedTensor.from_value_rowids(    values=[3, 1, 4, 1, 5, 9, 2, 6],    value_rowids=[0, 0, 0, 0, 2, 2, 2, 3],    nrows=5))<tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>get_shapeView sourceget_shape()The statically known shape of this ragged tensor.Alias for shape property.Examples:tf.ragged.constant([[0], [1, 2]]).get_shape()TensorShape([2, None])"
tf.RaggedTensorSpec,"tf.RaggedTensorSpec(
    shape=None,
    dtype=tf.dtypes.float32,
    ragged_rank=None,
    row_splits_dtype=tf.dtypes.int64,
    flat_values_spec=None
)
","Type specification for a tf.RaggedTensor.Inherits From: TypeSpec, TraceTypeView aliases"
tf.queue.RandomShuffleQueue,"tf.queue.RandomShuffleQueue(
    capacity,
    min_after_dequeue,
    dtypes,
    shapes=None,
    names=None,
    seed=None,
    shared_name=None,
    name='random_shuffle_queue'
)
",A queue implementation that dequeues elements in a random order.Inherits From: QueueBaseView aliases
tf.compat.v1.ReaderBase,"tf.compat.v1.ReaderBase(
    reader_ref, supports_serialize=False
)
","Base class for different Reader types, that produce a record every step."
tf.RegisterGradient,"tf.RegisterGradient(
    op_type
)
",A decorator for registering the gradient function for an op type.View aliases
tf.compat.v1.Session,"tf.compat.v1.Session(
    target='', graph=None, config=None
)
",A class for running TensorFlow operations.
tf.compat.v1.SparseConditionalAccumulator,"tf.compat.v1.SparseConditionalAccumulator(
    dtype,
    shape=None,
    shared_name=None,
    name='sparse_conditional_accumulator',
    reduction_type='MEAN'
)
",A conditional accumulator for aggregating sparse gradients.Inherits From: ConditionalAccumulatorBaseView aliases
tf.io.SparseFeature,"tf.io.SparseFeature(
    index_key, value_key, dtype, size, already_sorted=False
)
",Configuration for parsing a sparse input feature from an Example.View aliases
tf.sparse.SparseTensor,"tf.sparse.SparseTensor(
    indices, values, dense_shape
)
",Represents a sparse tensor.View aliases
tf.SparseTensorSpec,"tf.SparseTensorSpec(
    shape=None,
    dtype=tf.dtypes.float32
)
","Type specification for a tf.sparse.SparseTensor.Inherits From: TypeSpec, TraceTypeView aliases"
tf.compat.v1.SparseTensorValue,"tf.compat.v1.SparseTensorValue(
    indices, values, dense_shape
)
","SparseTensorValue(indices, values, dense_shape)"
tf.compat.v1.TFRecordReader,"tf.compat.v1.TFRecordReader(
    name=None, options=None
)
",A Reader that outputs the records from a TFRecords file.Inherits From: ReaderBase
tf.Tensor,"tf.Tensor(
    op, value_index, dtype
)
",A tf.Tensor represents a multidimensional array of elements.View aliases
tf.TensorArray,"tf.TensorArray(
    dtype,
    size=None,
    dynamic_size=None,
    clear_after_read=None,
    tensor_array_name=None,
    handle=None,
    flow=None,
    infer_shape=True,
    element_shape=None,
    colocate_with_first_write_call=True,
    name=None
)
","Class wrapping dynamic-sized, per-time-step, write-once Tensor arrays.View aliases"
tf.TensorArraySpec,"tf.TensorArraySpec(
    element_shape=None,
    dtype=tf.dtypes.float32,
    dynamic_size=False,
    infer_shape=True
)
","Type specification for a tf.TensorArray.Inherits From: TypeSpec, TraceTypeView aliases"
tf.TensorShape,"tf.TensorShape(
    dims
)
",Represents the shape of a Tensor.Inherits From: TraceTypeView aliases
tf.TensorSpec,"tf.TensorSpec(
    shape,
    dtype=tf.dtypes.float32,
    name=None
)
","Describes a tf.Tensor.Inherits From: TypeSpec, TraceTypeView aliases"
tf.compat.v1.TextLineReader,"tf.compat.v1.TextLineReader(
    skip_header_lines=None, name=None
)
",A Reader that outputs the lines of a file delimited by newlines.Inherits From: ReaderBase
tf.io.VarLenFeature,"tf.io.VarLenFeature(
    dtype
)
",Configuration for parsing a variable-length input feature.View aliases
tf.compat.v1.Variable,"tf.compat.v1.Variable(
    initial_value=None,
    trainable=None,
    collections=None,
    validate_shape=True,
    caching_device=None,
    name=None,
    variable_def=None,
    dtype=None,
    expected_shape=None,
    import_scope=None,
    constraint=None,
    use_resource=None,
    synchronization=tf.VariableSynchronization.AUTO,
    aggregation=tf.compat.v1.VariableAggregation.NONE,
    shape=None
)
",See the Variables Guide.Inherits From: Variable
tf.Variable.SaveSliceInfo,"tf.Variable.SaveSliceInfo(
    full_name=None,
    full_shape=None,
    var_offset=None,
    var_shape=None,
    save_slice_info_def=None,
    import_scope=None
)
",Information on how to save this Variable as a slice.View aliases
tf.compat.v1.VariableScope,"tf.compat.v1.VariableScope(
    reuse,
    name='',
    initializer=None,
    regularizer=None,
    caching_device=None,
    partitioner=None,
    custom_getter=None,
    name_scope='',
    dtype=tf.dtypes.float32,
    use_resource=None,
    constraint=None
)
",Variable scope object to carry defaults to provide to get_variable.
tf.compat.v1.WholeFileReader,"tf.compat.v1.WholeFileReader(
    name=None
)
",A Reader that outputs the entire contents of a file as a value.Inherits From: ReaderBase
tf.math.abs,"tf.math.abs(
    x, name=None
)
",Computes the absolute value of a tensor.View aliases
tf.math.accumulate_n,"tf.math.accumulate_n(
    inputs, shape=None, tensor_dtype=None, name=None
)
",Returns the element-wise sum of a list of tensors.View aliases
tf.math.acos,"tf.math.acos(
    x, name=None
)
",Computes acos of x element-wise.View aliases
tf.math.acosh,"tf.math.acosh(
    x, name=None
)
",Computes inverse hyperbolic cosine of x element-wise.View aliases
tf.math.add,"tf.math.add(
    x, y, name=None
)
",Returns x + y element-wise.View aliases
tf.math.add_n,"tf.math.add_n(
    inputs, name=None
)
",Adds all input tensors element-wise.View aliases
tf.compat.v1.add_to_collection,"tf.compat.v1.add_to_collection(
    name, value
)
",Wrapper for Graph.add_to_collection() using the default graph.
tf.compat.v1.add_to_collections,"tf.compat.v1.add_to_collections(
    names, value
)
",Wrapper for Graph.add_to_collections() using the default graph.
tf.math.angle,"tf.math.angle(
    input, name=None
)
",Returns the element-wise argument of a complex (or real) tensor.View aliases
tf.compat.v1.app.run,"tf.compat.v1.app.run(
    main=None, argv=None
)
",Runs the program with an optional 'main' function and 'argv' list.
tf.approx_top_k,"tf.approx_top_k(
    input,
    k,
    reduction_dimension=-1,
    recall_target=0.95,
    is_max_k=True,
    reduction_input_size_override=-1,
    aggregate_to_topk=True,
    name=None
)
",Returns min/max k values and their indices of the input operand in an approximate manner.View aliases
tf.compat.v1.arg_max,"tf.compat.v1.arg_max(
    input,
    dimension,
    output_type=tf.dtypes.int64,
    name=None
)
",Returns the index with the largest value across dimensions of a tensor.
tf.compat.v1.arg_min,"tf.compat.v1.arg_min(
    input,
    dimension,
    output_type=tf.dtypes.int64,
    name=None
)
",Returns the index with the smallest value across dimensions of a tensor.
tf.compat.v1.argmax,"tf.compat.v1.argmax(
    input,
    axis=None,
    name=None,
    dimension=None,
    output_type=tf.dtypes.int64
)
",Returns the index with the largest value across axes of a tensor. (deprecated arguments)View aliases
tf.compat.v1.argmin,"tf.compat.v1.argmin(
    input,
    axis=None,
    name=None,
    dimension=None,
    output_type=tf.dtypes.int64
)
",Returns the index with the smallest value across axes of a tensor. (deprecated arguments)View aliases
tf.argsort,"tf.argsort(
    values, axis=-1, direction='ASCENDING', stable=False, name=None
)
",Returns the indices of a tensor that give its sorted order along an axis.View aliases
tf.dtypes.as_dtype,"tf.dtypes.as_dtype(
    type_value
)
",Converts the given type_value to a DType.View aliases
tf.strings.as_string,"tf.strings.as_string(
    input,
    precision=-1,
    scientific=False,
    shortest=False,
    width=-1,
    fill='',
    name=None
)
",Converts each entry in the given tensor to strings.View aliases
tf.math.asin,"tf.math.asin(
    x, name=None
)
",Computes the trignometric inverse sine of x element-wise.View aliases
tf.math.asinh,"tf.math.asinh(
    x, name=None
)
",Computes inverse hyperbolic sine of x element-wise.View aliases
tf.compat.v1.assert_equal,"tf.compat.v1.assert_equal(
    x, y, data=None, summarize=None, message=None, name=None
)
",Assert the condition x == y holds element-wise.View aliases
tf.compat.v1.assert_greater,"tf.compat.v1.assert_greater(
    x, y, data=None, summarize=None, message=None, name=None
)
",Assert the condition x > y holds element-wise.View aliases
tf.compat.v1.assert_greater_equal,"tf.compat.v1.assert_greater_equal(
    x, y, data=None, summarize=None, message=None, name=None
)
",Assert the condition x >= y holds element-wise.View aliases
tf.compat.v1.assert_integer,"tf.compat.v1.assert_integer(
    x, message=None, name=None
)
",Assert that x is of integer dtype.View aliases
tf.compat.v1.assert_less,"tf.compat.v1.assert_less(
    x, y, data=None, summarize=None, message=None, name=None
)
",Assert the condition x < y holds element-wise.View aliases
tf.compat.v1.assert_less_equal,"tf.compat.v1.assert_less_equal(
    x, y, data=None, summarize=None, message=None, name=None
)
",Assert the condition x <= y holds element-wise.View aliases
tf.compat.v1.assert_near,"tf.compat.v1.assert_near(
    x,
    y,
    rtol=None,
    atol=None,
    data=None,
    summarize=None,
    message=None,
    name=None
)
",Assert the condition x and y are close element-wise.View aliases
tf.compat.v1.assert_negative,"tf.compat.v1.assert_negative(
    x, data=None, summarize=None, message=None, name=None
)
",Assert the condition x < 0 holds element-wise.View aliases
tf.compat.v1.assert_non_negative,"tf.compat.v1.assert_non_negative(
    x, data=None, summarize=None, message=None, name=None
)
",Assert the condition x >= 0 holds element-wise.View aliases
tf.compat.v1.assert_non_positive,"tf.compat.v1.assert_non_positive(
    x, data=None, summarize=None, message=None, name=None
)
",Assert the condition x <= 0 holds element-wise.View aliases
tf.compat.v1.assert_none_equal,"tf.compat.v1.assert_none_equal(
    x, y, data=None, summarize=None, message=None, name=None
)
",Assert the condition x != y holds element-wise.View aliases
tf.compat.v1.assert_positive,"tf.compat.v1.assert_positive(
    x, data=None, summarize=None, message=None, name=None
)
",Assert the condition x > 0 holds element-wise.View aliases
tf.debugging.assert_proper_iterable,"tf.debugging.assert_proper_iterable(
    values
)
","Static assert that values is a ""proper"" iterable.View aliases"
tf.compat.v1.assert_rank,"tf.compat.v1.assert_rank(
    x, rank, data=None, summarize=None, message=None, name=None
)
",Assert x has rank equal to rank.View aliases
tf.compat.v1.assert_rank_at_least,"tf.compat.v1.assert_rank_at_least(
    x, rank, data=None, summarize=None, message=None, name=None
)
",Assert x has rank equal to rank or higher.View aliases
tf.compat.v1.assert_rank_in,"tf.compat.v1.assert_rank_in(
    x, ranks, data=None, summarize=None, message=None, name=None
)
",Assert x has rank in ranks.View aliases
tf.debugging.assert_same_float_dtype,"tf.debugging.assert_same_float_dtype(
    tensors=None, dtype=None
)
",Validate and return float type based on tensors and dtype.View aliases
tf.compat.v1.assert_scalar,"tf.compat.v1.assert_scalar(
    tensor, name=None, message=None
)
",Asserts that the given tensor is a scalar (i.e. zero-dimensional).View aliases
tf.compat.v1.assert_type,"tf.compat.v1.assert_type(
    tensor, tf_type, message=None, name=None
)
",Statically asserts that the given Tensor is of the specified type.View aliases
tf.compat.v1.assert_variables_initialized,"tf.compat.v1.assert_variables_initialized(
    var_list=None
)
",Returns an Op to check if variables are initialized.
tf.compat.v1.assign,"tf.compat.v1.assign(
    ref, value, validate_shape=None, use_locking=None, name=None
)
",Update ref by assigning value to it.
tf.compat.v1.assign_add,"tf.compat.v1.assign_add(
    ref, value, use_locking=None, name=None
)
",Update ref by adding value to it.
tf.compat.v1.assign_sub,"tf.compat.v1.assign_sub(
    ref, value, use_locking=None, name=None
)
",Update ref by subtracting value from it.
tf.math.atan,"tf.math.atan(
    x, name=None
)
",Computes the trignometric inverse tangent of x element-wise.View aliases
tf.math.atan2,"tf.math.atan2(
    y, x, name=None
)
","Computes arctangent of y/x element-wise, respecting signs of the arguments.View aliases"
tf.math.atanh,"tf.math.atanh(
    x, name=None
)
",Computes inverse hyperbolic tangent of x element-wise.View aliases
tf.audio.decode_wav,"tf.audio.decode_wav(
    contents, desired_channels=-1, desired_samples=-1, name=None
)
",Decode a 16-bit PCM WAV file to a float tensor.View aliases
tf.audio.encode_wav,"tf.audio.encode_wav(
    audio, sample_rate, name=None
)
",Encode audio data using the WAV file format.View aliases
tf.autograph.experimental.do_not_convert,"tf.autograph.experimental.do_not_convert(
    func=None
)
",Decorator that suppresses the conversion of a function.View aliases
tf.autograph.experimental.set_loop_options,"tf.autograph.experimental.set_loop_options(
    parallel_iterations=UNSPECIFIED,
    swap_memory=UNSPECIFIED,
    maximum_iterations=UNSPECIFIED,
    shape_invariants=UNSPECIFIED
)
",Specifies additional arguments to be passed to the enclosing while_loop.View aliases
tf.autograph.set_verbosity,"tf.autograph.set_verbosity(
    level, alsologtostdout=False
)
",Sets the AutoGraph verbosity level.View aliases
tf.compat.v1.autograph.to_code,"tf.compat.v1.autograph.to_code(
    entity,
    recursive=True,
    arg_values=None,
    arg_types=None,
    indentation='  ',
    experimental_optional_features=None
)
","Returns the source code generated by AutoGraph, as a string."
tf.compat.v1.autograph.to_graph,"tf.compat.v1.autograph.to_graph(
    entity,
    recursive=True,
    arg_values=None,
    arg_types=None,
    experimental_optional_features=None
)
",Converts a Python entity into a TensorFlow graph.
tf.autograph.trace,"tf.autograph.trace(
    *args
)
",Traces argument information at compilation time.View aliases
tf.compat.v1.batch_gather,"tf.compat.v1.batch_gather(
    params, indices, name=None
)
",Gather slices from params according to indices with leading batch dims. (deprecated)
tf.compat.v1.batch_scatter_update,"tf.compat.v1.batch_scatter_update(
    ref, indices, updates, use_locking=True, name=None
)
",Generalization of tf.compat.v1.scatter_update to axis different than 0. (deprecated)
tf.compat.v1.batch_to_space,"tf.compat.v1.batch_to_space(
    input, crops, block_size, name=None, block_shape=None
)
",BatchToSpace for 4-D tensors of type T.
tf.compat.v1.batch_to_space_nd,"tf.compat.v1.batch_to_space_nd(
    input, block_shape, crops, name=None
)
",BatchToSpace for N-D tensors of type T.View aliases
tf.math.betainc,"tf.math.betainc(
    a, b, x, name=None
)
","Compute the regularized incomplete beta integral \(I_x(a, b)\).View aliases"
tf.compat.v1.bincount,"tf.compat.v1.bincount(
    arr,
    weights=None,
    minlength=None,
    maxlength=None,
    dtype=tf.dtypes.int32
)
",Counts the number of occurrences of each value in an integer array.View aliases
tf.bitcast,"tf.bitcast(
    input, type, name=None
)
",Bitcasts a tensor from one type to another without copying data.View aliases
tf.bitwise.bitwise_and,"tf.bitwise.bitwise_and(
    x, y, name=None
)
",Elementwise computes the bitwise AND of x and y.View aliases
tf.bitwise.bitwise_or,"tf.bitwise.bitwise_or(
    x, y, name=None
)
",Elementwise computes the bitwise OR of x and y.View aliases
tf.bitwise.bitwise_xor,"tf.bitwise.bitwise_xor(
    x, y, name=None
)
",Elementwise computes the bitwise XOR of x and y.View aliases
tf.bitwise.invert,"tf.bitwise.invert(
    x, name=None
)
","Invert (flip) each bit of supported types; for example, type uint8 value 01010101 becomes 10101010.View aliases"
tf.bitwise.left_shift,"tf.bitwise.left_shift(
    x, y, name=None
)
",Elementwise computes the bitwise left-shift of x and y.View aliases
tf.bitwise.right_shift,"tf.bitwise.right_shift(
    x, y, name=None
)
",Elementwise computes the bitwise right-shift of x and y.View aliases
tf.compat.v1.boolean_mask,"tf.compat.v1.boolean_mask(
    tensor, mask, name='boolean_mask', axis=None
)
",Apply boolean mask to tensor.
tf.broadcast_dynamic_shape,"tf.broadcast_dynamic_shape(
    shape_x, shape_y
)
",Computes the shape of a broadcast given symbolic shapes.View aliases
tf.broadcast_static_shape,"tf.broadcast_static_shape(
    shape_x, shape_y
)
",Computes the shape of a broadcast given known shapes.View aliases
tf.broadcast_to,"tf.broadcast_to(
    input, shape, name=None
)
",Broadcast an array for a compatible shape.View aliases
tf.compat.v1.case,"tf.compat.v1.case(
    pred_fn_pairs,
    default=None,
    exclusive=False,
    strict=False,
    name='case'
)
",Create a case operation.
tf.cast,"tf.cast(
    x, dtype, name=None
)
",Casts a tensor to a new type.View aliases
tf.math.ceil,"tf.math.ceil(
    x, name=None
)
","Return the ceiling of the input, element-wise.View aliases"
tf.debugging.check_numerics,"tf.debugging.check_numerics(
    tensor, message, name=None
)
",Checks a tensor for NaN and Inf values.View aliases
tf.linalg.cholesky,"tf.linalg.cholesky(
    input, name=None
)
",Computes the Cholesky decomposition of one or more square matrices.View aliases
tf.linalg.cholesky_solve,"tf.linalg.cholesky_solve(
    chol, rhs, name=None
)
","Solves systems of linear eqns A X = RHS, given Cholesky factorizations.View aliases"
tf.compat.v1.clip_by_average_norm,"tf.compat.v1.clip_by_average_norm(
    t, clip_norm, name=None
)
",Clips tensor values to a maximum average L2-norm. (deprecated)
tf.clip_by_global_norm,"tf.clip_by_global_norm(
    t_list, clip_norm, use_norm=None, name=None
)
",Clips values of multiple tensors by the ratio of the sum of their norms.View aliases
tf.clip_by_norm,"tf.clip_by_norm(
    t, clip_norm, axes=None, name=None
)
",Clips tensor values to a maximum L2-norm.View aliases
tf.clip_by_value,"tf.clip_by_value(
    t, clip_value_min, clip_value_max, name=None
)
",Clips tensor values to a specified min and max.View aliases
tf.compat.v1.colocate_with,"tf.compat.v1.colocate_with(
    op, ignore_existing=False
)
",DEPRECATED FUNCTION
tf.compat.as_bytes,"tf.compat.as_bytes(
    bytes_or_text, encoding='utf-8'
)
","Converts bytearray, bytes, or unicode python input types to bytes.View aliases"
tf.compat.as_str,"tf.compat.as_str(
    bytes_or_text, encoding='utf-8'
)
",View aliases
tf.compat.as_str_any,"tf.compat.as_str_any(
    value
)
",Converts input to str type.View aliases
tf.compat.as_text,"tf.compat.as_text(
    bytes_or_text, encoding='utf-8'
)
",Converts any string-like python input types to unicode.View aliases
tf.compat.dimension_at_index,"tf.compat.dimension_at_index(
    shape, index
)
",Compatibility utility required to allow for both V1 and V2 behavior in TF.View aliases
tf.compat.dimension_value,"tf.compat.dimension_value(
    dimension
)
",Compatibility utility required to allow for both V1 and V2 behavior in TF.View aliases
tf.compat.forward_compatible,"tf.compat.forward_compatible(
    year, month, day
)
",Return true if the forward compatibility window has expired.View aliases
tf.compat.path_to_str,"tf.compat.path_to_str(
    path
)
",Converts input which is a PathLike object to str type.View aliases
tf.dtypes.complex,"tf.dtypes.complex(
    real, imag, name=None
)
",Converts two real numbers to a complex number.View aliases
tf.concat,"tf.concat(
    values, axis, name='concat'
)
",Concatenates tensors along one dimension.View aliases
tf.compat.v1.cond,"tf.compat.v1.cond(
    pred,
    true_fn=None,
    false_fn=None,
    strict=False,
    name=None,
    fn1=None,
    fn2=None
)
",Return true_fn() if the predicate pred is true else false_fn(). (deprecated arguments)
tf.config.LogicalDevice,"tf.config.LogicalDevice(
    name, device_type
)
",Abstraction for a logical device initialized by the runtime.View aliases
tf.config.LogicalDeviceConfiguration,"tf.config.LogicalDeviceConfiguration(
    memory_limit=None,
    experimental_priority=None,
    experimental_device_ordinal=0
)
",Configuration class for a logical devices.View aliases
tf.config.PhysicalDevice,"tf.config.PhysicalDevice(
    name, device_type
)
",Abstraction for a locally visible physical device.View aliases
tf.config.LogicalDeviceConfiguration,"tf.config.LogicalDeviceConfiguration(
    memory_limit=None,
    experimental_priority=None,
    experimental_device_ordinal=0
)
",Configuration class for a logical devices.View aliases
tf.config.experimental.enable_tensor_float_32_execution,"tf.config.experimental.enable_tensor_float_32_execution(
    enabled
)
",Enable or disable the use of TensorFloat-32 on supported hardware.View aliases
tf.config.experimental.get_device_details,"tf.config.experimental.get_device_details(
    device
)
",Returns details about a physical devices.View aliases
tf.config.experimental.get_memory_growth,"tf.config.experimental.get_memory_growth(
    device
)
",Get if memory growth is enabled for a PhysicalDevice.View aliases
tf.config.experimental.get_memory_info,"tf.config.experimental.get_memory_info(
    device
)
","Get memory info for the chosen device, as a dict.View aliases"
tf.config.experimental.get_memory_usage,"tf.config.experimental.get_memory_usage(
    device
)
","Get the current memory usage, in bytes, for the chosen device. (deprecated)View aliases"
tf.config.get_logical_device_configuration,"tf.config.get_logical_device_configuration(
    device
)
",Get the virtual device configuration for a tf.config.PhysicalDevice.View aliases
tf.config.get_visible_devices,"tf.config.get_visible_devices(
    device_type=None
)
",Get the list of visible physical devices.View aliases
tf.config.list_logical_devices,"tf.config.list_logical_devices(
    device_type=None
)
",Return a list of logical devices created by runtime.View aliases
tf.config.list_physical_devices,"tf.config.list_physical_devices(
    device_type=None
)
",Return a list of physical devices visible to the host runtime.View aliases
tf.config.experimental.reset_memory_stats,"tf.config.experimental.reset_memory_stats(
    device
)
",Resets the tracked memory stats for the chosen device.View aliases
tf.config.experimental.set_device_policy,"tf.config.experimental.set_device_policy(
    device_policy
)
",Sets the current thread device policy.View aliases
tf.config.experimental.set_memory_growth,"tf.config.experimental.set_memory_growth(
    device, enable
)
",Set if memory growth should be enabled for a PhysicalDevice.View aliases
tf.config.experimental.set_synchronous_execution,"tf.config.experimental.set_synchronous_execution(
    enable
)
",Specifies whether operations are executed synchronously or asynchronously.View aliases
tf.config.set_logical_device_configuration,"tf.config.set_logical_device_configuration(
    device, logical_devices
)
",Set the logical device configuration for a tf.config.PhysicalDevice.View aliases
tf.config.set_visible_devices,"tf.config.set_visible_devices(
    devices, device_type=None
)
",Set the list of visible devices.View aliases
tf.config.experimental_connect_to_cluster,"tf.config.experimental_connect_to_cluster(
    cluster_spec_or_resolver,
    job_name='localhost',
    task_index=0,
    protocol=None,
    make_master_device_default=True,
    cluster_device_filters=None
)
",Connects to the given cluster.View aliases
tf.config.experimental_connect_to_host,"tf.config.experimental_connect_to_host(
    remote_host=None, job_name='worker'
)
",Connects to a single machine to enable remote execution on it.View aliases
tf.config.experimental_run_functions_eagerly,"tf.config.experimental_run_functions_eagerly(
    run_eagerly
)
",Enables / disables eager execution of tf.functions. (deprecated)View aliases
tf.config.get_logical_device_configuration,"tf.config.get_logical_device_configuration(
    device
)
",Get the virtual device configuration for a tf.config.PhysicalDevice.View aliases
tf.config.get_visible_devices,"tf.config.get_visible_devices(
    device_type=None
)
",Get the list of visible physical devices.View aliases
tf.config.list_logical_devices,"tf.config.list_logical_devices(
    device_type=None
)
",Return a list of logical devices created by runtime.View aliases
tf.config.list_physical_devices,"tf.config.list_physical_devices(
    device_type=None
)
",Return a list of physical devices visible to the host runtime.View aliases
tf.config.optimizer.get_jit,"tf.config.optimizer.get_jit() -> str
",Returns JIT compilation configuration for code inside tf.function.View aliases
tf.config.optimizer.set_experimental_options,"tf.config.optimizer.set_experimental_options(
    options
)
",Set experimental optimizer options.View aliases
tf.config.optimizer.set_jit,"tf.config.optimizer.set_jit(
    enabled: Union[bool, str]
)
",Configure JIT compilation. (deprecated argument values)View aliases
tf.config.run_functions_eagerly,"tf.config.run_functions_eagerly(
    run_eagerly
)
",Enables / disables eager execution of tf.functions.View aliases
tf.config.set_logical_device_configuration,"tf.config.set_logical_device_configuration(
    device, logical_devices
)
",Set the logical device configuration for a tf.config.PhysicalDevice.View aliases
tf.config.set_soft_device_placement,"tf.config.set_soft_device_placement(
    enabled
)
",Enable or disable soft device placement.View aliases
tf.config.set_visible_devices,"tf.config.set_visible_devices(
    devices, device_type=None
)
",Set the list of visible devices.View aliases
tf.config.threading.set_inter_op_parallelism_threads,"tf.config.threading.set_inter_op_parallelism_threads(
    num_threads
)
",Set number of threads used for parallelism between independent operations.View aliases
tf.config.threading.set_intra_op_parallelism_threads,"tf.config.threading.set_intra_op_parallelism_threads(
    num_threads
)
",Set number of threads used within an individual op for parallelism.View aliases
tf.compat.v1.confusion_matrix,"tf.compat.v1.confusion_matrix(
    labels,
    predictions,
    num_classes=None,
    dtype=tf.dtypes.int32,
    name=None,
    weights=None
)
",Computes the confusion matrix from predictions and labels.View aliases
tf.math.conj,"tf.math.conj(
    x, name=None
)
",Returns the complex conjugate of a complex number.View aliases
tf.compat.v1.constant,"tf.compat.v1.constant(
    value, dtype=None, shape=None, name='Const', verify_shape=False
)
",Creates a constant tensor.
tf.compat.v1.keras.initializers.Constant,"tf.compat.v1.keras.initializers.Constant(
    value=0,
    dtype=tf.dtypes.float32,
    verify_shape=False
)
",Initializer that generates tensors with constant values.View aliases
tf.compat.v1.container,"tf.compat.v1.container(
    container_name
)
",Wrapper for Graph.container() using the default graph.
tf.control_dependencies,"tf.control_dependencies(
    control_inputs
)
",Wrapper for Graph.control_dependencies() using the default graph.View aliases
tf.compat.v1.convert_to_tensor,"tf.compat.v1.convert_to_tensor(
    value, dtype=None, name=None, preferred_dtype=None, dtype_hint=None
)
",Converts the given value to a Tensor.
tf.compat.v1.convert_to_tensor_or_indexed_slices,"tf.compat.v1.convert_to_tensor_or_indexed_slices(
    value, dtype=None, name=None
)
",Converts the given object to a Tensor or an IndexedSlices.
tf.compat.v1.convert_to_tensor_or_sparse_tensor,"tf.compat.v1.convert_to_tensor_or_sparse_tensor(
    value, dtype=None, name=None
)
",Converts value to a SparseTensor or Tensor.
tf.math.cos,"tf.math.cos(
    x, name=None
)
",Computes cos of x element-wise.View aliases
tf.math.cosh,"tf.math.cosh(
    x, name=None
)
",Computes hyperbolic cosine of x element-wise.View aliases
tf.compat.v1.count_nonzero,"tf.compat.v1.count_nonzero(
    input_tensor=None,
    axis=None,
    keepdims=None,
    dtype=tf.dtypes.int64,
    name=None,
    reduction_indices=None,
    keep_dims=None,
    input=None
)
",Computes number of nonzero elements across dimensions of a tensor. (deprecated arguments) (deprecated arguments)View aliases
tf.compat.v1.count_up_to,"tf.compat.v1.count_up_to(
    ref, limit, name=None
)
",Increments 'ref' until it reaches 'limit'. (deprecated)
tf.compat.v1.create_partitioned_variables,"tf.compat.v1.create_partitioned_variables(
    shape,
    slicing,
    initializer,
    dtype=tf.dtypes.float32,
    trainable=True,
    collections=None,
    name=None,
    reuse=None
)
",Create a list of partitioned variables according to the given slicing. (deprecated)
tf.linalg.cross,"tf.linalg.cross(
    a, b, name=None
)
",Compute the pairwise cross product.View aliases
tf.math.cumprod,"tf.math.cumprod(
    x, axis=0, exclusive=False, reverse=False, name=None
)
",Compute the cumulative product of the tensor x along axis.View aliases
tf.math.cumsum,"tf.math.cumsum(
    x, axis=0, exclusive=False, reverse=False, name=None
)
",Compute the cumulative sum of the tensor x along axis.View aliases
tf.custom_gradient,"tf.custom_gradient(
    f=None
)
",Decorator to define a function with a custom gradient.View aliases
tf.data.DatasetSpec,"tf.data.DatasetSpec(
    element_spec, dataset_shape=()
)
","Type specification for tf.data.Dataset.Inherits From: TypeSpec, TraceTypeView aliases"
tf.compat.v1.data.FixedLengthRecordDataset,"tf.compat.v1.data.FixedLengthRecordDataset(
    filenames,
    record_bytes,
    header_bytes=None,
    footer_bytes=None,
    buffer_size=None,
    compression_type=None,
    num_parallel_reads=None,
    name=None
)
","A Dataset of fixed-length records from one or more binary files.Inherits From: Dataset, Dataset"
tf.compat.v1.data.Iterator,"tf.compat.v1.data.Iterator(
    iterator_resource, initializer, output_types, output_shapes, output_classes
)
",Represents the state of iterating through a Dataset.
tf.compat.v1.data.TFRecordDataset,"tf.compat.v1.data.TFRecordDataset(
    filenames,
    compression_type=None,
    buffer_size=None,
    num_parallel_reads=None,
    name=None
)
","A Dataset comprising records from one or more TFRecord files.Inherits From: Dataset, Dataset"
tf.compat.v1.data.TextLineDataset,"tf.compat.v1.data.TextLineDataset(
    filenames,
    compression_type=None,
    buffer_size=None,
    num_parallel_reads=None,
    name=None
)
","A Dataset comprising lines from one or more text files.Inherits From: Dataset, Dataset"
tf.data.experimental.CheckpointInputPipelineHook,"tf.data.experimental.CheckpointInputPipelineHook(
    estimator, external_state_policy=None
)
",Checkpoints input pipeline state every N steps or seconds.Inherits From: SessionRunHookView aliases
tf.compat.v1.data.experimental.Counter,"tf.compat.v1.data.experimental.Counter(
    start=0,
    step=1,
    dtype=tf.dtypes.int64
)
",Creates a Dataset that counts from start in steps of size step.
tf.compat.v1.data.experimental.CsvDataset,"tf.compat.v1.data.experimental.CsvDataset(
    filenames,
    record_defaults,
    compression_type=None,
    buffer_size=None,
    header=False,
    field_delim=',',
    use_quote_delim=True,
    na_value='',
    select_cols=None,
    exclude_cols=None
)
","A Dataset comprising lines from one or more CSV files.Inherits From: Dataset, Dataset"
tf.data.experimental.DatasetInitializer,"tf.data.experimental.DatasetInitializer(
    dataset
)
",Creates a table initializer from a tf.data.Dataset.View aliases
tf.data.DatasetSpec,"tf.data.DatasetSpec(
    element_spec, dataset_shape=()
)
","Type specification for tf.data.Dataset.Inherits From: TypeSpec, TraceTypeView aliases"
tf.OptionalSpec,"tf.OptionalSpec(
    element_spec
)
","Type specification for tf.experimental.Optional.Inherits From: TypeSpec, TraceTypeView aliases"
tf.compat.v1.data.experimental.RaggedTensorStructure,"tf.compat.v1.data.experimental.RaggedTensorStructure(
    dtype, shape, ragged_rank
)
",DEPRECATED FUNCTION
tf.compat.v1.data.experimental.RandomDataset,"tf.compat.v1.data.experimental.RandomDataset(
    seed=None, name=None
)
","A Dataset of pseudorandom values. (deprecated)Inherits From: Dataset, Dataset"
tf.data.experimental.Reducer,"tf.data.experimental.Reducer(
    init_func, reduce_func, finalize_func
)
",A reducer is used for reducing a set of elements.View aliases
tf.compat.v1.data.experimental.SparseTensorStructure,"tf.compat.v1.data.experimental.SparseTensorStructure(
    dtype, shape
)
",DEPRECATED FUNCTION
tf.compat.v1.data.experimental.SqlDataset,"tf.compat.v1.data.experimental.SqlDataset(
    driver_name, data_source_name, query, output_types
)
","A Dataset consisting of the results from a SQL query.Inherits From: Dataset, Dataset"
tf.data.experimental.TFRecordWriter,"tf.data.experimental.TFRecordWriter(
    filename, compression_type=None
)
",Writes a dataset to a TFRecord file. (deprecated)View aliases
tf.compat.v1.data.experimental.TensorArrayStructure,"tf.compat.v1.data.experimental.TensorArrayStructure(
    dtype, element_shape, dynamic_size, infer_shape
)
",DEPRECATED FUNCTION
tf.compat.v1.data.experimental.TensorStructure,"tf.compat.v1.data.experimental.TensorStructure(
    dtype, shape
)
",DEPRECATED FUNCTION
tf.data.experimental.assert_cardinality,"tf.data.experimental.assert_cardinality(
    expected_cardinality
)
",Asserts the cardinality of the input dataset.View aliases
tf.data.experimental.bucket_by_sequence_length,"tf.data.experimental.bucket_by_sequence_length(
    element_length_func,
    bucket_boundaries,
    bucket_batch_sizes,
    padded_shapes=None,
    padding_values=None,
    pad_to_bucket_boundary=False,
    no_padding=False,
    drop_remainder=False
)
",A transformation that buckets elements in a Dataset by length. (deprecated)View aliases
tf.data.experimental.cardinality,"tf.data.experimental.cardinality(
    dataset
)
","Returns the cardinality of dataset, if known.View aliases"
tf.compat.v1.data.experimental.choose_from_datasets,"tf.compat.v1.data.experimental.choose_from_datasets(
    datasets, choice_dataset, stop_on_empty_dataset=False
)
",Creates a dataset that deterministically chooses elements from datasets. (deprecated)
tf.data.experimental.copy_to_device,"tf.data.experimental.copy_to_device(
    target_device, source_device='/cpu:0'
)
",A transformation that copies dataset elements to the given target_device.View aliases
tf.data.experimental.dense_to_ragged_batch,"tf.data.experimental.dense_to_ragged_batch(
    batch_size,
    drop_remainder=False,
    row_splits_dtype=tf.dtypes.int64
)
",A transformation that batches ragged elements into tf.RaggedTensors.View aliases
tf.data.experimental.dense_to_sparse_batch,"tf.data.experimental.dense_to_sparse_batch(
    batch_size, row_shape
)
",A transformation that batches ragged elements into tf.sparse.SparseTensors.View aliases
tf.data.experimental.enumerate_dataset,"tf.data.experimental.enumerate_dataset(
    start=0
)
",A transformation that enumerates the elements of a dataset. (deprecated)View aliases
tf.data.experimental.from_list,"tf.data.experimental.from_list(
    elements, name=None
)
",Creates a Dataset comprising the given list of elements.View aliases
tf.data.experimental.from_variant,"tf.data.experimental.from_variant(
    variant, structure
)
",Constructs a dataset from the given variant and (nested) structure.View aliases
tf.data.experimental.get_next_as_optional,"tf.data.experimental.get_next_as_optional(
    iterator
)
",Returns a tf.experimental.Optional with the next element of the iterator. (deprecated)View aliases
tf.data.experimental.get_single_element,"tf.data.experimental.get_single_element(
    dataset
)
",Returns the single element of the dataset as a nested structure of tensors. (deprecated)View aliases
tf.data.experimental.get_structure,"tf.data.experimental.get_structure(
    dataset_or_iterator
)
",Returns the type signature for elements of the input dataset / iterator.View aliases
tf.data.experimental.group_by_reducer,"tf.data.experimental.group_by_reducer(
    key_func, reducer
)
",A transformation that groups elements and performs a reduction.View aliases
tf.data.experimental.group_by_window,"tf.data.experimental.group_by_window(
    key_func, reduce_func, window_size=None, window_size_func=None
)
",A transformation that groups windows of elements by key and reduces them. (deprecated)View aliases
tf.data.experimental.ignore_errors,"tf.data.experimental.ignore_errors(
    log_warning=False
)
",Creates a Dataset from another Dataset and silently ignores any errors.View aliases
tf.data.experimental.index_table_from_dataset,"tf.data.experimental.index_table_from_dataset(
    dataset=None,
    num_oov_buckets=0,
    vocab_size=None,
    default_value=-1,
    hasher_spec=lookup_ops.FastHashSpec,
    key_dtype=tf.dtypes.string,
    name=None
)
",Returns an index lookup table based on the given dataset.View aliases
tf.compat.v1.data.experimental.make_batched_features_dataset,"tf.compat.v1.data.experimental.make_batched_features_dataset(
    file_pattern,
    batch_size,
    features,
    reader=None,
    label_key=None,
    reader_args=None,
    num_epochs=None,
    shuffle=True,
    shuffle_buffer_size=10000,
    shuffle_seed=None,
    prefetch_buffer_size=None,
    reader_num_threads=None,
    parser_num_threads=None,
    sloppy_ordering=False,
    drop_final_batch=False
)
",Returns a Dataset of feature dictionaries from Example protos.
tf.compat.v1.data.experimental.make_csv_dataset,"tf.compat.v1.data.experimental.make_csv_dataset(
    file_pattern,
    batch_size,
    column_names=None,
    column_defaults=None,
    label_name=None,
    select_columns=None,
    field_delim=',',
    use_quote_delim=True,
    na_value='',
    header=True,
    num_epochs=None,
    shuffle=True,
    shuffle_buffer_size=10000,
    shuffle_seed=None,
    prefetch_buffer_size=None,
    num_parallel_reads=None,
    sloppy=False,
    num_rows_for_inference=100,
    compression_type=None,
    ignore_errors=False
)
",Reads CSV files into a dataset.
tf.data.experimental.make_saveable_from_iterator,"tf.data.experimental.make_saveable_from_iterator(
    iterator, external_state_policy=None
)
",Returns a SaveableObject for saving/restoring iterator state using Saver. (deprecated)View aliases
tf.data.experimental.map_and_batch,"tf.data.experimental.map_and_batch(
    map_func,
    batch_size,
    num_parallel_batches=None,
    drop_remainder=False,
    num_parallel_calls=None
)
",Fused implementation of map and batch. (deprecated)View aliases
tf.compat.v1.data.experimental.map_and_batch_with_legacy_function,"tf.compat.v1.data.experimental.map_and_batch_with_legacy_function(
    map_func,
    batch_size,
    num_parallel_batches=None,
    drop_remainder=False,
    num_parallel_calls=None
)
",Fused implementation of map and batch. (deprecated)
tf.data.experimental.parallel_interleave,"tf.data.experimental.parallel_interleave(
    map_func,
    cycle_length,
    block_length=1,
    sloppy=False,
    buffer_output_elements=None,
    prefetch_input_elements=None
)
",A parallel version of the Dataset.interleave() transformation. (deprecated)View aliases
tf.data.experimental.parse_example_dataset,"tf.data.experimental.parse_example_dataset(
    features, num_parallel_calls=1, deterministic=None
)
",A transformation that parses Example protos into a dict of tensors.View aliases
tf.data.experimental.prefetch_to_device,"tf.data.experimental.prefetch_to_device(
    device, buffer_size=None
)
",A transformation that prefetches dataset values to the given device.View aliases
tf.data.experimental.rejection_resample,"tf.data.experimental.rejection_resample(
    class_func, target_dist, initial_dist=None, seed=None
)
",A transformation that resamples a dataset to achieve a target distribution. (deprecated)View aliases
tf.compat.v1.data.experimental.sample_from_datasets,"tf.compat.v1.data.experimental.sample_from_datasets(
    datasets, weights=None, seed=None, stop_on_empty_dataset=False
)
",Samples elements at random from the datasets in datasets. (deprecated)
tf.data.experimental.scan,"tf.data.experimental.scan(
    initial_state, scan_func
)
",A transformation that scans a function across an input dataset. (deprecated)View aliases
tf.data.experimental.service.CrossTrainerCache,"tf.data.experimental.service.CrossTrainerCache(
    trainer_id
)
",Options related to the tf.data service cross trainer cache.View aliases
tf.data.experimental.service.DispatcherConfig,"tf.data.experimental.service.DispatcherConfig(
    port=0,
    protocol=None,
    work_dir=None,
    fault_tolerant_mode=False,
    worker_addresses=None,
    job_gc_check_interval_ms=None,
    job_gc_timeout_ms=None
)
",Configuration class for tf.data service dispatchers.View aliases
tf.data.experimental.service.WorkerConfig,"tf.data.experimental.service.WorkerConfig(
    dispatcher_address,
    worker_address=None,
    port=0,
    protocol=None,
    heartbeat_interval_ms=None,
    dispatcher_timeout_ms=None
)
",Configuration class for tf.data service dispatchers.View aliases
tf.data.experimental.service.distribute,"tf.data.experimental.service.distribute(
    processing_mode,
    service,
    job_name=None,
    consumer_index=None,
    num_consumers=None,
    max_outstanding_requests=None,
    data_transfer_protocol=None,
    compression='AUTO',
    cross_trainer_cache=None,
    target_workers='AUTO'
)
",A transformation that moves dataset processing to the tf.data service.View aliases
tf.data.experimental.service.from_dataset_id,"tf.data.experimental.service.from_dataset_id(
    processing_mode,
    service,
    dataset_id,
    element_spec=None,
    job_name=None,
    consumer_index=None,
    num_consumers=None,
    max_outstanding_requests=None,
    data_transfer_protocol=None,
    cross_trainer_cache=None,
    target_workers='AUTO'
)
",Creates a dataset which reads data from the tf.data service.View aliases
tf.data.experimental.service.register_dataset,"tf.data.experimental.service.register_dataset(
    service, dataset, compression='AUTO', dataset_id=None
)
",Registers a dataset with the tf.data service.View aliases
tf.data.experimental.shuffle_and_repeat,"tf.data.experimental.shuffle_and_repeat(
    buffer_size, count=None, seed=None
)
","Shuffles and repeats a Dataset, reshuffling with each repetition. (deprecated)View aliases"
tf.data.experimental.snapshot,"tf.data.experimental.snapshot(
    path, compression='AUTO', reader_func=None, shard_func=None
)
",API to persist the output of the input dataset. (deprecated)View aliases
tf.data.experimental.table_from_dataset,"tf.data.experimental.table_from_dataset(
    dataset=None,
    num_oov_buckets=0,
    vocab_size=None,
    default_value=None,
    hasher_spec=lookup_ops.FastHashSpec,
    key_dtype=tf.dtypes.string,
    name=None
)
",Returns a lookup table based on the given dataset.View aliases
tf.data.experimental.take_while,"tf.data.experimental.take_while(
    predicate
)
",A transformation that stops dataset iteration based on a predicate. (deprecated)View aliases
tf.data.experimental.to_variant,"tf.data.experimental.to_variant(
    dataset
)
",Returns a variant representing the given dataset.View aliases
tf.compat.v1.data.get_output_classes,"tf.compat.v1.data.get_output_classes(
    dataset_or_iterator
)
",Returns the output classes for elements of the input dataset / iterator.
tf.compat.v1.data.get_output_shapes,"tf.compat.v1.data.get_output_shapes(
    dataset_or_iterator
)
",Returns the output shapes for elements of the input dataset / iterator.
tf.compat.v1.data.get_output_types,"tf.compat.v1.data.get_output_types(
    dataset_or_iterator
)
",Returns the output shapes for elements of the input dataset / iterator.
tf.compat.v1.data.make_initializable_iterator,"tf.compat.v1.data.make_initializable_iterator(
    dataset, shared_name=None
)
",Creates an iterator for elements of dataset.
tf.compat.v1.data.make_one_shot_iterator,"tf.compat.v1.data.make_one_shot_iterator(
    dataset
)
",Creates an iterator for elements of dataset.
tf.debugging.Assert,"tf.debugging.Assert(
    condition, data, summarize=None, name=None
)
",Asserts that the given condition is true.View aliases
tf.compat.v1.verify_tensor_all_finite,"tf.compat.v1.verify_tensor_all_finite(
    t=None, msg=None, name=None, x=None, message=None
)
",Assert that the tensor does not contain any NaN's or Inf's.View aliases
tf.compat.v1.assert_equal,"tf.compat.v1.assert_equal(
    x, y, data=None, summarize=None, message=None, name=None
)
",Assert the condition x == y holds element-wise.View aliases
tf.compat.v1.assert_greater,"tf.compat.v1.assert_greater(
    x, y, data=None, summarize=None, message=None, name=None
)
",Assert the condition x > y holds element-wise.View aliases
tf.compat.v1.assert_greater_equal,"tf.compat.v1.assert_greater_equal(
    x, y, data=None, summarize=None, message=None, name=None
)
",Assert the condition x >= y holds element-wise.View aliases
tf.compat.v1.assert_integer,"tf.compat.v1.assert_integer(
    x, message=None, name=None
)
",Assert that x is of integer dtype.View aliases
tf.compat.v1.assert_less,"tf.compat.v1.assert_less(
    x, y, data=None, summarize=None, message=None, name=None
)
",Assert the condition x < y holds element-wise.View aliases
tf.compat.v1.assert_less_equal,"tf.compat.v1.assert_less_equal(
    x, y, data=None, summarize=None, message=None, name=None
)
",Assert the condition x <= y holds element-wise.View aliases
tf.compat.v1.assert_near,"tf.compat.v1.assert_near(
    x,
    y,
    rtol=None,
    atol=None,
    data=None,
    summarize=None,
    message=None,
    name=None
)
",Assert the condition x and y are close element-wise.View aliases
tf.compat.v1.assert_negative,"tf.compat.v1.assert_negative(
    x, data=None, summarize=None, message=None, name=None
)
",Assert the condition x < 0 holds element-wise.View aliases
tf.compat.v1.assert_non_negative,"tf.compat.v1.assert_non_negative(
    x, data=None, summarize=None, message=None, name=None
)
",Assert the condition x >= 0 holds element-wise.View aliases
tf.compat.v1.assert_non_positive,"tf.compat.v1.assert_non_positive(
    x, data=None, summarize=None, message=None, name=None
)
",Assert the condition x <= 0 holds element-wise.View aliases
tf.compat.v1.assert_none_equal,"tf.compat.v1.assert_none_equal(
    x, y, data=None, summarize=None, message=None, name=None
)
",Assert the condition x != y holds element-wise.View aliases
tf.compat.v1.assert_positive,"tf.compat.v1.assert_positive(
    x, data=None, summarize=None, message=None, name=None
)
",Assert the condition x > 0 holds element-wise.View aliases
tf.debugging.assert_proper_iterable,"tf.debugging.assert_proper_iterable(
    values
)
","Static assert that values is a ""proper"" iterable.View aliases"
tf.compat.v1.assert_rank,"tf.compat.v1.assert_rank(
    x, rank, data=None, summarize=None, message=None, name=None
)
",Assert x has rank equal to rank.View aliases
tf.compat.v1.assert_rank_at_least,"tf.compat.v1.assert_rank_at_least(
    x, rank, data=None, summarize=None, message=None, name=None
)
",Assert x has rank equal to rank or higher.View aliases
tf.compat.v1.assert_rank_in,"tf.compat.v1.assert_rank_in(
    x, ranks, data=None, summarize=None, message=None, name=None
)
",Assert x has rank in ranks.View aliases
tf.debugging.assert_same_float_dtype,"tf.debugging.assert_same_float_dtype(
    tensors=None, dtype=None
)
",Validate and return float type based on tensors and dtype.View aliases
tf.compat.v1.assert_scalar,"tf.compat.v1.assert_scalar(
    tensor, name=None, message=None
)
",Asserts that the given tensor is a scalar (i.e. zero-dimensional).View aliases
tf.compat.v1.debugging.assert_shapes,"tf.compat.v1.debugging.assert_shapes(
    shapes, data=None, summarize=None, message=None, name=None
)
",Assert tensor shapes and dimension size relationships between tensors.
tf.debugging.assert_shapes,tf.debugging.assert_shapes([,"Assert tensor shapes and dimension size relationships between tensors.tf.compat.v1.debugging.assert_shapes(    shapes, data=None, summarize=None, message=None, name=None)This Op checks that a collection of tensors shape relationshipssatisfies given constraints.Example:n = 10q = 3d = 7x = tf.zeros([n,q])y = tf.ones([n,d])param = tf.Variable([1.0, 2.0, 3.0])scalar = 1.0tf.debugging.assert_shapes([ (x, ('N', 'Q')), (y, ('N', 'D')), (param, ('Q',)), (scalar, ()),])"
tf.compat.v1.assert_type,"tf.compat.v1.assert_type(
    tensor, tf_type, message=None, name=None
)
",Statically asserts that the given Tensor is of the specified type.View aliases
tf.debugging.check_numerics,"tf.debugging.check_numerics(
    tensor, message, name=None
)
",Checks a tensor for NaN and Inf values.View aliases
tf.debugging.enable_check_numerics,"tf.debugging.enable_check_numerics(
    stack_height_limit=30, path_length_limit=50
)
",Enable tensor numerics checking in an eager/graph unified fashion.View aliases
tf.debugging.experimental.enable_dump_debug_info,"tf.debugging.experimental.enable_dump_debug_info(
    dump_root,
    tensor_debug_mode=DEFAULT_TENSOR_DEBUG_MODE,
    circular_buffer_size=1000,
    op_regex=None,
    tensor_dtypes=None
)
",Enable dumping debugging information from a TensorFlow program.View aliases
tf.math.is_finite,"tf.math.is_finite(
    x, name=None
)
",Returns which elements of x are finite.View aliases
tf.math.is_inf,"tf.math.is_inf(
    x, name=None
)
",Returns which elements of x are Inf.View aliases
tf.math.is_nan,"tf.math.is_nan(
    x, name=None
)
",Returns which elements of x are NaN.View aliases
tf.math.is_non_decreasing,"tf.math.is_non_decreasing(
    x, name=None
)
",Returns True if x is non-decreasing.View aliases
tf.debugging.is_numeric_tensor,"tf.debugging.is_numeric_tensor(
    tensor
)
",Returns True if the elements of tensor are numbers.View aliases
tf.math.is_strictly_increasing,"tf.math.is_strictly_increasing(
    x, name=None
)
",Returns True if x is strictly increasing.View aliases
tf.debugging.set_log_device_placement,"tf.debugging.set_log_device_placement(
    enabled
)
",Turns logging for device placement decisions on or off.View aliases
tf.io.decode_base64,"tf.io.decode_base64(
    input, name=None
)
",Decode web-safe base64-encoded strings.View aliases
tf.io.decode_compressed,"tf.io.decode_compressed(
    bytes, compression_type='', name=None
)
",Decompress strings.View aliases
tf.compat.v1.decode_csv,"tf.compat.v1.decode_csv(
    records,
    record_defaults,
    field_delim=',',
    use_quote_delim=True,
    name=None,
    na_value='',
    select_cols=None
)
",Convert CSV records to tensors. Each column maps to one tensor.View aliases
tf.io.decode_json_example,"tf.io.decode_json_example(
    json_examples, name=None
)
",Convert JSON-encoded Example records to binary protocol buffer strings.View aliases
tf.io.decode_json_example,tf.io.decode_json_example([,"Convert JSON-encoded Example records to binary protocol buffer strings.View aliasestf.io.decode_json_example(    json_examples, name=None)Note: This is This op converts JSON-serialized tf.train.Example (maybe created withjson_format.MessageToJson, following thestandard JSON mapping)to a binary-serialized tf.train.Example (equivalent toExample.SerializeToString()) suitable for conversion to tensors withtf.io.parse_example.Here is a tf.train.Example proto:example = tf.train.Example(  features=tf.train.Features(      feature={          ""a"": tf.train.Feature(              int64_list=tf.train.Int64List(                  value=[1, 1, 3]))}))Here it is converted to JSON:from google.protobuf import json_formatexample_json = json_format.MessageToJson(example)print(example_json){  ""features"": {    ""feature"": {      ""a"": {        ""int64List"": {          ""value"": [            ""1"",            ""1"",            ""3""          ]        }      }    }  }}This op converts the above json string to a binary proto:example_binary = tf.io.decode_json_example(example_json)example_binary.numpy()b'\n\x0f\n\r\n\x01a\x12\x08\x1a\x06\x08\x01\x08\x01\x08\x03'The OP works on string tensors of andy shape:"
tf.io.parse_example,tf.io.parse_example(,"Convert JSON-encoded Example records to binary protocol buffer strings.View aliasestf.io.decode_json_example(    json_examples, name=None)Note: This is This op converts JSON-serialized tf.train.Example (maybe created withjson_format.MessageToJson, following thestandard JSON mapping)to a binary-serialized tf.train.Example (equivalent toExample.SerializeToString()) suitable for conversion to tensors withtf.io.parse_example.Here is a tf.train.Example proto:example = tf.train.Example(  features=tf.train.Features(      feature={          ""a"": tf.train.Feature(              int64_list=tf.train.Int64List(                  value=[1, 1, 3]))}))Here it is converted to JSON:from google.protobuf import json_formatexample_json = json_format.MessageToJson(example)print(example_json){  ""features"": {    ""feature"": {      ""a"": {        ""int64List"": {          ""value"": [            ""1"",            ""1"",            ""3""          ]        }      }    }  }}This op converts the above json string to a binary proto:example_binary = tf.io.decode_json_example(example_json)example_binary.numpy()b'\n\x0f\n\r\n\x01a\x12\x08\x1a\x06\x08\x01\x08\x01\x08\x03'The OP works on string tensors of andy shape:tf.io.decode_json_example([    [example_json, example_json],    [example_json, example_json]]).shape.as_list()[2, 2]This resulting binary-string is equivalent to Example.SerializeToString(),and can be converted to Tensors using tf.io.parse_example and relatedfunctions:"
tf.compat.v1.decode_raw,"tf.compat.v1.decode_raw(
    input_bytes=None, out_type=None, little_endian=True, name=None, bytes=None
)
",Convert raw byte strings into tensors. (deprecated arguments)View aliases
tf.compat.v1.delete_session_tensor,"tf.compat.v1.delete_session_tensor(
    handle, name=None
)
",Delete the tensor for the given tensor handle.
tf.compat.v1.depth_to_space,"tf.compat.v1.depth_to_space(
    input, block_size, name=None, data_format='NHWC'
)
",DepthToSpace for tensors of type T.View aliases
tf.quantization.dequantize,"tf.quantization.dequantize(
    input,
    min_range,
    max_range,
    mode='MIN_COMBINED',
    name=None,
    axis=None,
    narrow_range=False,
    dtype=tf.dtypes.float32
)
",Dequantize the 'input' tensor into a float or bfloat16 Tensor.View aliases
tf.io.deserialize_many_sparse,"tf.io.deserialize_many_sparse(
    serialized_sparse, dtype, rank=None, name=None
)
",Deserialize and concatenate SparseTensors from a serialized minibatch.View aliases
tf.compat.v1.device,"tf.compat.v1.device(
    device_name_or_function
)
",Wrapper for Graph.device() using the default graph.
tf.linalg.tensor_diag,"tf.linalg.tensor_diag(
    diagonal, name=None
)
",Returns a diagonal tensor with a given diagonal values.View aliases
tf.linalg.tensor_diag_part,"tf.linalg.tensor_diag_part(
    input, name=None
)
",Returns the diagonal part of the tensor.View aliases
tf.math.digamma,"tf.math.digamma(
    x, name=None
)
","Computes Psi, the derivative of Lgamma (the log of the absolute value ofView aliases"
tf.compat.dimension_at_index,"tf.compat.dimension_at_index(
    shape, index
)
",Compatibility utility required to allow for both V1 and V2 behavior in TF.View aliases
tf.compat.dimension_value,"tf.compat.dimension_value(
    dimension
)
",Compatibility utility required to allow for both V1 and V2 behavior in TF.View aliases
tf.distribute.HierarchicalCopyAllReduce,"tf.distribute.HierarchicalCopyAllReduce(
    num_packs=1
)
",Hierarchical copy all-reduce implementation of CrossDeviceOps.Inherits From: CrossDeviceOpsView aliases
tf.distribute.InputContext,"tf.distribute.InputContext(
    num_input_pipelines=1, input_pipeline_id=0, num_replicas_in_sync=1
)
",A class wrapping information needed by an input function.View aliases
tf.compat.v1.distribute.MirroredStrategy,"tf.compat.v1.distribute.MirroredStrategy(
    devices=None, cross_device_ops=None
)
",Synchronous training across multiple replicas on one machine.Inherits From: Strategy
tf.distribute.NcclAllReduce,"tf.distribute.NcclAllReduce(
    num_packs=1
)
",NCCL all-reduce implementation of CrossDeviceOps.Inherits From: CrossDeviceOpsView aliases
tf.compat.v1.distribute.OneDeviceStrategy,"tf.compat.v1.distribute.OneDeviceStrategy(
    device
)
",A distribution strategy for running on a single device.Inherits From: Strategy
tf.distribute.ReductionToOneDevice,"tf.distribute.ReductionToOneDevice(
    reduce_to_device=None, accumulation_fn=None
)
",A CrossDeviceOps implementation that copies values to one device to reduce.Inherits From: CrossDeviceOpsView aliases
tf.compat.v1.distribute.ReplicaContext,"tf.compat.v1.distribute.ReplicaContext(
    strategy, replica_id_in_sync_group
)
",A class with a collection of APIs that can be called in a replica context.
tf.distribute.RunOptions,"tf.distribute.RunOptions(
    experimental_enable_dynamic_batch_size=True,
    experimental_bucketizing_dynamic_shape=False,
    experimental_xla_options=None
)
",Run options for strategy.run.View aliases
tf.distribute.Server,"tf.distribute.Server(
    server_or_cluster_def,
    job_name=None,
    task_index=None,
    protocol=None,
    config=None,
    start=True
)
","An in-process TensorFlow server, for use in distributed training.View aliases"
tf.compat.v1.distribute.Strategy,"tf.compat.v1.distribute.Strategy(
    extended
)
",A list of devices with a state & compute distribution policy.
tf.compat.v1.distribute.StrategyExtended,"tf.compat.v1.distribute.StrategyExtended(
    container_strategy
)
",Additional APIs for algorithms that need to be distribution-aware.Inherits From: StrategyExtended
tf.distribute.cluster_resolver.GCEClusterResolver,"tf.distribute.cluster_resolver.GCEClusterResolver(
    project,
    zone,
    instance_group,
    port,
    task_type='worker',
    task_id=0,
    rpc_layer='grpc',
    credentials='default',
    service=None
)
",ClusterResolver for Google Compute Engine.Inherits From: ClusterResolverView aliases
tf.distribute.cluster_resolver.KubernetesClusterResolver,"tf.distribute.cluster_resolver.KubernetesClusterResolver(
    job_to_label_mapping=None,
    tf_server_port=8470,
    rpc_layer='grpc',
    override_client=None
)
",ClusterResolver for Kubernetes.Inherits From: ClusterResolverView aliases
tf.distribute.cluster_resolver.SimpleClusterResolver,"tf.distribute.cluster_resolver.SimpleClusterResolver(
    cluster_spec,
    master='',
    task_type=None,
    task_id=None,
    environment='',
    num_accelerators=None,
    rpc_layer=None
)
",Simple implementation of ClusterResolver that accepts all attributes.Inherits From: ClusterResolverView aliases
tf.distribute.cluster_resolver.SlurmClusterResolver,"tf.distribute.cluster_resolver.SlurmClusterResolver(
    jobs=None,
    port_base=8888,
    gpus_per_node=None,
    gpus_per_task=None,
    tasks_per_node=None,
    auto_set_gpu=True,
    rpc_layer='grpc'
)
",ClusterResolver for system with Slurm workload manager.Inherits From: ClusterResolverView aliases
tf.distribute.cluster_resolver.TFConfigClusterResolver,"tf.distribute.cluster_resolver.TFConfigClusterResolver(
    task_type=None, task_id=None, rpc_layer=None, environment=None
)
",Implementation of a ClusterResolver which reads the TF_CONFIG EnvVar.Inherits From: ClusterResolverView aliases
tf.distribute.cluster_resolver.TPUClusterResolver,"tf.distribute.cluster_resolver.TPUClusterResolver(
    tpu=None,
    zone=None,
    project=None,
    job_name='worker',
    coordinator_name=None,
    coordinator_address=None,
    credentials='default',
    service=None,
    discovery_url=None
)
",Cluster Resolver for Google Cloud TPUs.Inherits From: ClusterResolverView aliases
tf.distribute.cluster_resolver.UnionResolver,"tf.distribute.cluster_resolver.UnionResolver(
    *args, **kwargs
)
",Performs a union on underlying ClusterResolvers.Inherits From: ClusterResolverView aliases
tf.compat.v1.distribute.experimental.CentralStorageStrategy,"tf.compat.v1.distribute.experimental.CentralStorageStrategy(
    compute_devices=None, parameter_device=None
)
",A one-machine strategy that puts all variables on a single device.Inherits From: Strategy
tf.distribute.experimental.CollectiveHints,"tf.distribute.experimental.CollectiveHints(
    bytes_per_pack=0, timeout_seconds=None
)
",Hints for collective operations like AllReduce.View aliases
tf.distribute.experimental.CommunicationOptions,"tf.distribute.experimental.CommunicationOptions(
    bytes_per_pack=0,
    timeout_seconds=None,
    implementation=tf.distribute.experimental.CollectiveCommunication.AUTO
)
",Options for cross device communications like All-reduce.View aliases
tf.compat.v1.distribute.experimental.MultiWorkerMirroredStrategy,"tf.compat.v1.distribute.experimental.MultiWorkerMirroredStrategy(
    communication=tf.distribute.experimental.CollectiveCommunication.AUTO,
    cluster_resolver=None
)
",A distribution strategy for synchronous training on multiple workers.Inherits From: Strategy
tf.compat.v1.distribute.experimental.ParameterServerStrategy,"tf.compat.v1.distribute.experimental.ParameterServerStrategy(
    cluster_resolver=None
)
",An asynchronous multi-worker parameter server tf.distribute strategy.Inherits From: Strategy
tf.compat.v1.distribute.experimental.TPUStrategy,"tf.compat.v1.distribute.experimental.TPUStrategy(
    tpu_cluster_resolver=None, steps_per_run=None, device_assignment=None
)
",TPU distribution strategy implementation.Inherits From: Strategy
tf.distribute.experimental_set_strategy,"tf.distribute.experimental_set_strategy(
    strategy
)
",Set a tf.distribute.Strategy as current without with strategy.scope().View aliases
tf.compat.v1.distributions.Bernoulli,"tf.compat.v1.distributions.Bernoulli(
    logits=None,
    probs=None,
    dtype=tf.dtypes.int32,
    validate_args=False,
    allow_nan_stats=True,
    name='Bernoulli'
)
",Bernoulli distribution.Inherits From: Distribution
tf.compat.v1.distributions.Beta,"tf.compat.v1.distributions.Beta(
    concentration1=None,
    concentration0=None,
    validate_args=False,
    allow_nan_stats=True,
    name='Beta'
)
",Beta distribution.Inherits From: Distribution
tf.compat.v1.distributions.Categorical,"tf.compat.v1.distributions.Categorical(
    logits=None,
    probs=None,
    dtype=tf.dtypes.int32,
    validate_args=False,
    allow_nan_stats=True,
    name='Categorical'
)
",Categorical distribution.Inherits From: Distribution
tf.compat.v1.distributions.Dirichlet,"tf.compat.v1.distributions.Dirichlet(
    concentration,
    validate_args=False,
    allow_nan_stats=True,
    name='Dirichlet'
)
",Dirichlet distribution.Inherits From: Distribution
tf.compat.v1.distributions.DirichletMultinomial,"tf.compat.v1.distributions.DirichletMultinomial(
    total_count,
    concentration,
    validate_args=False,
    allow_nan_stats=True,
    name='DirichletMultinomial'
)
",Dirichlet-Multinomial compound distribution.Inherits From: Distribution
tf.compat.v1.distributions.Distribution,"tf.compat.v1.distributions.Distribution(
    dtype,
    reparameterization_type,
    validate_args,
    allow_nan_stats,
    parameters=None,
    graph_parents=None,
    name=None
)
",A generic probability distribution base class.
tf.compat.v1.distributions.Exponential,"tf.compat.v1.distributions.Exponential(
    rate,
    validate_args=False,
    allow_nan_stats=True,
    name='Exponential'
)
","Exponential distribution.Inherits From: Gamma, Distribution"
tf.compat.v1.distributions.Gamma,"tf.compat.v1.distributions.Gamma(
    concentration,
    rate,
    validate_args=False,
    allow_nan_stats=True,
    name='Gamma'
)
",Gamma distribution.Inherits From: Distribution
tf.compat.v1.distributions.Laplace,"tf.compat.v1.distributions.Laplace(
    loc,
    scale,
    validate_args=False,
    allow_nan_stats=True,
    name='Laplace'
)
",The Laplace distribution with location loc and scale parameters.Inherits From: Distribution
tf.compat.v1.distributions.Multinomial,"tf.compat.v1.distributions.Multinomial(
    total_count,
    logits=None,
    probs=None,
    validate_args=False,
    allow_nan_stats=True,
    name='Multinomial'
)
",Multinomial distribution.Inherits From: Distribution
tf.compat.v1.distributions.Normal,"tf.compat.v1.distributions.Normal(
    loc,
    scale,
    validate_args=False,
    allow_nan_stats=True,
    name='Normal'
)
",The Normal distribution with location loc and scale parameters.Inherits From: Distribution
tf.compat.v1.distributions.RegisterKL,"tf.compat.v1.distributions.RegisterKL(
    dist_cls_a, dist_cls_b
)
",Decorator to register a KL divergence implementation function.
tf.compat.v1.distributions.ReparameterizationType,"tf.compat.v1.distributions.ReparameterizationType(
    rep_type
)
",Instances of this class represent how sampling is reparameterized.
tf.compat.v1.distributions.StudentT,"tf.compat.v1.distributions.StudentT(
    df,
    loc,
    scale,
    validate_args=False,
    allow_nan_stats=True,
    name='StudentT'
)
",Student's t-distribution.Inherits From: Distribution
tf.compat.v1.distributions.Uniform,"tf.compat.v1.distributions.Uniform(
    low=0.0,
    high=1.0,
    validate_args=False,
    allow_nan_stats=True,
    name='Uniform'
)
",Uniform distribution with low and high parameters.Inherits From: Distribution
tf.compat.v1.distributions.kl_divergence,"tf.compat.v1.distributions.kl_divergence(
    distribution_a, distribution_b, allow_nan_stats=True, name=None
)
",Get the KL-divergence KL(distribution_a || distribution_b). (deprecated)
tf.compat.v1.div,"tf.compat.v1.div(
    x, y, name=None
)
",Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)
tf.math.divide_no_nan,"tf.math.divide_no_nan(
    x, y, name=None
)
",Computes a safe divide which returns 0 if y (denominator) is zero.View aliases
tf.constant,tf.constant(3.0) / 0.0,"Computes a safe divide which returns 0 if y (denominator) is zero.View aliasestf.math.divide_no_nan(    x, y, name=None)For example:"
tf.math.divide,"tf.math.divide(
    x, y, name=None
)
",Computes Python style division of x by y.View aliases
tf.dtypes.as_dtype,"tf.dtypes.as_dtype(
    type_value
)
",Converts the given type_value to a DType.View aliases
tf.strings.as_string,"tf.strings.as_string(
    input,
    precision=-1,
    scientific=False,
    shortest=False,
    width=-1,
    fill='',
    name=None
)
",Converts each entry in the given tensor to strings.View aliases
tf.cast,"tf.cast(
    x, dtype, name=None
)
",Casts a tensor to a new type.View aliases
tf.dtypes.complex,"tf.dtypes.complex(
    real, imag, name=None
)
",Converts two real numbers to a complex number.View aliases
tf.dtypes.saturate_cast,"tf.dtypes.saturate_cast(
    value, dtype, name=None
)
",Performs a safe saturating cast of value to dtype.View aliases
tf.dynamic_partition,"tf.dynamic_partition(
    data, partitions, num_partitions, name=None
)
",Partitions data into num_partitions tensors using indices from partitions.View aliases
tf.dynamic_stitch,"tf.dynamic_stitch(
    indices, data, name=None
)
",Interleave the values from the data tensors into a single tensor.View aliases
tf.edit_distance,"tf.edit_distance(
    hypothesis, truth, normalize=True, name='edit_distance'
)
",Computes the Levenshtein distance between sequences.View aliases
tf.einsum,"tf.einsum(
    equation, *inputs, **kwargs
)
",Tensor contraction over specified indices and outer product.View aliases
tf.compat.v1.enable_eager_execution,"tf.compat.v1.enable_eager_execution(
    config=None, device_policy=None, execution_mode=None
)
",Enables eager execution for the lifetime of this program.
tf.io.encode_base64,"tf.io.encode_base64(
    input, pad=False, name=None
)
",Encode strings into web-safe base64 format.View aliases
tf.ensure_shape,"tf.ensure_shape(
    x, shape, name=None
)
",Updates the shape of a tensor and checks at runtime that the shape holds.View aliases
tf.math.equal,"tf.math.equal(
    x, y, name=None
)
",Returns the truth value of (x == y) element-wise.View aliases
tf.math.erf,"tf.math.erf(
    x, name=None
)
","Computes the Gauss error function of x element-wise. In statistics, for non-negative values of \(x\), the error function has the following interpretation: for a random variable \(Y\) that is normally distributed with mean 0 and variance \(1/\sqrt{2}\), \(erf(x)\) is the probability that \(Y\) falls in the range \([x, x]\).View aliases"
tf.math.erfc,"tf.math.erfc(
    x, name=None
)
",Computes the complementary error function of x element-wise.View aliases
tf.errors.AbortedError,"tf.errors.AbortedError(
    node_def, op, message, *args
)
","The operation was aborted, typically due to a concurrent action.Inherits From: OpErrorView aliases"
tf.errors.AlreadyExistsError,"tf.errors.AlreadyExistsError(
    node_def, op, message, *args
)
",Raised when an entity that we attempted to create already exists.Inherits From: OpErrorView aliases
tf.errors.CancelledError,"tf.errors.CancelledError(
    node_def, op, message, *args
)
",Raised when an operation or step is cancelled.Inherits From: OpErrorView aliases
tf.errors.DataLossError,"tf.errors.DataLossError(
    node_def, op, message, *args
)
",Raised when unrecoverable data loss or corruption is encountered.Inherits From: OpErrorView aliases
tf.errors.DeadlineExceededError,"tf.errors.DeadlineExceededError(
    node_def, op, message, *args
)
",Raised when a deadline expires before an operation could complete.Inherits From: OpErrorView aliases
tf.errors.FailedPreconditionError,"tf.errors.FailedPreconditionError(
    node_def, op, message, *args
)
",Operation was rejected because the system is not in a state to execute it.Inherits From: OpErrorView aliases
tf.errors.InternalError,"tf.errors.InternalError(
    node_def, op, message, *args
)
",Raised when the system experiences an internal error.Inherits From: OpErrorView aliases
tf.errors.InvalidArgumentError,"tf.errors.InvalidArgumentError(
    node_def, op, message, *args
)
",Raised when an operation receives an invalid argument.Inherits From: OpErrorView aliases
tf.errors.NotFoundError,"tf.errors.NotFoundError(
    node_def, op, message, *args
)
","Raised when a requested entity (e.g., a file or directory) was not found.Inherits From: OpErrorView aliases"
tf.errors.OpError,"tf.errors.OpError(
    node_def, op, message, error_code, *args
)
",The base class for TensorFlow exceptions.View aliases
tf.errors.OutOfRangeError,"tf.errors.OutOfRangeError(
    node_def, op, message, *args
)
",Raised when an operation iterates past the valid input range.Inherits From: OpErrorView aliases
tf.errors.PermissionDeniedError,"tf.errors.PermissionDeniedError(
    node_def, op, message, *args
)
",Raised when the caller does not have permission to run an operation.Inherits From: OpErrorView aliases
tf.errors.ResourceExhaustedError,"tf.errors.ResourceExhaustedError(
    node_def, op, message, *args
)
",Some resource has been exhausted.Inherits From: OpErrorView aliases
tf.errors.UnauthenticatedError,"tf.errors.UnauthenticatedError(
    node_def, op, message, *args
)
",The request does not have valid authentication credentials.Inherits From: OpErrorView aliases
tf.errors.UnavailableError,"tf.errors.UnavailableError(
    node_def, op, message, *args
)
",Raised when the runtime is currently unavailable.Inherits From: OpErrorView aliases
tf.errors.UnimplementedError,"tf.errors.UnimplementedError(
    node_def, op, message, *args
)
",Raised when an operation has not been implemented.Inherits From: OpErrorView aliases
tf.errors.UnknownError,"tf.errors.UnknownError(
    node_def, op, message, *args
)
",Unknown error.Inherits From: OpErrorView aliases
tf.compat.v1.errors.error_code_from_exception_type,"tf.compat.v1.errors.error_code_from_exception_type(
    cls
)
",nan
tf.compat.v1.errors.exception_type_from_error_code,"tf.compat.v1.errors.exception_type_from_error_code(
    error_code
)
",nan
tf.compat.v1.estimator.BaselineClassifier,"tf.compat.v1.estimator.BaselineClassifier(
    model_dir=None,
    n_classes=2,
    weight_column=None,
    label_vocabulary=None,
    optimizer='Ftrl',
    config=None,
    loss_reduction=tf.compat.v1.losses.Reduction.SUM
)
",A classifier that can establish a simple baseline.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.compat.v1.estimator.BaselineEstimator,"tf.compat.v1.estimator.BaselineEstimator(
    head, model_dir=None, optimizer='Ftrl', config=None
)
",An estimator that can establish a simple baseline.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.compat.v1.estimator.BaselineRegressor,"tf.compat.v1.estimator.BaselineRegressor(
    model_dir=None,
    label_dimension=1,
    weight_column=None,
    optimizer='Ftrl',
    config=None,
    loss_reduction=tf.compat.v1.losses.Reduction.SUM
)
",A regressor that can establish a simple baseline.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.estimator.BestExporter,"tf.estimator.BestExporter(
    name='best_exporter',
    serving_input_receiver_fn=None,
    event_file_pattern='eval/*.tfevents.*',
    compare_fn=_loss_smaller,
    assets_extra=None,
    as_text=False,
    exports_to_keep=5
)
",This class exports the serving graph and checkpoints of the best models.Inherits From: ExporterView aliases
tf.estimator.BinaryClassHead,"tf.estimator.BinaryClassHead(
    weight_column=None,
    thresholds=None,
    label_vocabulary=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    loss_fn=None,
    name=None
)
",Creates a Head for single label binary classification.Inherits From: HeadView aliases
tf.estimator.CheckpointSaverHook,"tf.estimator.CheckpointSaverHook(
    checkpoint_dir,
    save_secs=None,
    save_steps=None,
    saver=None,
    checkpoint_basename='model.ckpt',
    scaffold=None,
    listeners=None,
    save_graph_def=True
)
",Saves checkpoints every N steps or seconds.Inherits From: SessionRunHookView aliases
tf.compat.v1.estimator.DNNClassifier,"tf.compat.v1.estimator.DNNClassifier(
    hidden_units,
    feature_columns,
    model_dir=None,
    n_classes=2,
    weight_column=None,
    label_vocabulary=None,
    optimizer='Adagrad',
    activation_fn=tf.nn.relu,
    dropout=None,
    input_layer_partitioner=None,
    config=None,
    warm_start_from=None,
    loss_reduction=tf.compat.v1.losses.Reduction.SUM,
    batch_norm=False
)
",A classifier for TensorFlow DNN models.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.compat.v1.estimator.DNNEstimator,"tf.compat.v1.estimator.DNNEstimator(
    head,
    hidden_units,
    feature_columns,
    model_dir=None,
    optimizer='Adagrad',
    activation_fn=tf.nn.relu,
    dropout=None,
    input_layer_partitioner=None,
    config=None,
    warm_start_from=None,
    batch_norm=False
)
",An estimator for TensorFlow DNN models with user-specified head.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.compat.v1.estimator.DNNLinearCombinedClassifier,"tf.compat.v1.estimator.DNNLinearCombinedClassifier(
    model_dir=None,
    linear_feature_columns=None,
    linear_optimizer='Ftrl',
    dnn_feature_columns=None,
    dnn_optimizer='Adagrad',
    dnn_hidden_units=None,
    dnn_activation_fn=tf.nn.relu,
    dnn_dropout=None,
    n_classes=2,
    weight_column=None,
    label_vocabulary=None,
    input_layer_partitioner=None,
    config=None,
    warm_start_from=None,
    loss_reduction=tf.compat.v1.losses.Reduction.SUM,
    batch_norm=False,
    linear_sparse_combiner='sum'
)
",An estimator for TensorFlow Linear and DNN joined classification models.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.compat.v1.estimator.DNNLinearCombinedEstimator,"tf.compat.v1.estimator.DNNLinearCombinedEstimator(
    head,
    model_dir=None,
    linear_feature_columns=None,
    linear_optimizer='Ftrl',
    dnn_feature_columns=None,
    dnn_optimizer='Adagrad',
    dnn_hidden_units=None,
    dnn_activation_fn=tf.nn.relu,
    dnn_dropout=None,
    input_layer_partitioner=None,
    config=None,
    batch_norm=False,
    linear_sparse_combiner='sum'
)
",An estimator for TensorFlow Linear and DNN joined models with custom head.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.compat.v1.estimator.DNNLinearCombinedRegressor,"tf.compat.v1.estimator.DNNLinearCombinedRegressor(
    model_dir=None,
    linear_feature_columns=None,
    linear_optimizer='Ftrl',
    dnn_feature_columns=None,
    dnn_optimizer='Adagrad',
    dnn_hidden_units=None,
    dnn_activation_fn=tf.nn.relu,
    dnn_dropout=None,
    label_dimension=1,
    weight_column=None,
    input_layer_partitioner=None,
    config=None,
    warm_start_from=None,
    loss_reduction=tf.compat.v1.losses.Reduction.SUM,
    batch_norm=False,
    linear_sparse_combiner='sum'
)
",An estimator for TensorFlow Linear and DNN joined models for regression.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.compat.v1.estimator.DNNRegressor,"tf.compat.v1.estimator.DNNRegressor(
    hidden_units,
    feature_columns,
    model_dir=None,
    label_dimension=1,
    weight_column=None,
    optimizer='Adagrad',
    activation_fn=tf.nn.relu,
    dropout=None,
    input_layer_partitioner=None,
    config=None,
    warm_start_from=None,
    loss_reduction=tf.compat.v1.losses.Reduction.SUM,
    batch_norm=False
)
",A regressor for TensorFlow DNN models.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.compat.v1.estimator.Estimator,"tf.compat.v1.estimator.Estimator(
    model_fn, model_dir=None, config=None, params=None, warm_start_from=None
)
",Estimator class to train and evaluate TensorFlow models.Warning: Estimators are not recommended for new code.  Estimators run
tf.estimator.EstimatorSpec,"tf.estimator.EstimatorSpec(
    mode,
    predictions=None,
    loss=None,
    train_op=None,
    eval_metric_ops=None,
    export_outputs=None,
    training_chief_hooks=None,
    training_hooks=None,
    scaffold=None,
    evaluation_hooks=None,
    prediction_hooks=None
)
",Ops and objects returned from a model_fn and passed to an Estimator.View aliases
tf.estimator.EvalSpec,"tf.estimator.EvalSpec(
    input_fn,
    steps=100,
    name=None,
    hooks=None,
    exporters=None,
    start_delay_secs=120,
    throttle_secs=600
)
","Configuration for the ""eval"" part for the train_and_evaluate call.View aliases"
tf.estimator.FeedFnHook,"tf.estimator.FeedFnHook(
    feed_fn
)
",Runs feed_fn and sets the feed_dict accordingly.Inherits From: SessionRunHookView aliases
tf.estimator.FinalExporter,"tf.estimator.FinalExporter(
    name, serving_input_receiver_fn, assets_extra=None, as_text=False
)
",This class exports the serving graph and checkpoints at the end.Inherits From: ExporterView aliases
tf.estimator.FinalOpsHook,"tf.estimator.FinalOpsHook(
    final_ops, final_ops_feed_dict=None
)
",A hook which evaluates Tensors at the end of a session.Inherits From: SessionRunHookView aliases
tf.estimator.GlobalStepWaiterHook,"tf.estimator.GlobalStepWaiterHook(
    wait_until_step
)
",Delays execution until global step reaches wait_until_step.Inherits From: SessionRunHookView aliases
tf.estimator.LatestExporter,"tf.estimator.LatestExporter(
    name,
    serving_input_receiver_fn,
    assets_extra=None,
    as_text=False,
    exports_to_keep=5
)
",This class regularly exports the serving graph and checkpoints.Inherits From: ExporterView aliases
tf.compat.v1.estimator.LinearClassifier,"tf.compat.v1.estimator.LinearClassifier(
    feature_columns,
    model_dir=None,
    n_classes=2,
    weight_column=None,
    label_vocabulary=None,
    optimizer='Ftrl',
    config=None,
    partitioner=None,
    warm_start_from=None,
    loss_reduction=tf.compat.v1.losses.Reduction.SUM,
    sparse_combiner='sum'
)
",Linear classifier model.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.compat.v1.estimator.LinearEstimator,"tf.compat.v1.estimator.LinearEstimator(
    head,
    feature_columns,
    model_dir=None,
    optimizer='Ftrl',
    config=None,
    partitioner=None,
    sparse_combiner='sum',
    warm_start_from=None
)
",An estimator for TensorFlow linear models with user-specified head.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.compat.v1.estimator.LinearRegressor,"tf.compat.v1.estimator.LinearRegressor(
    feature_columns,
    model_dir=None,
    label_dimension=1,
    weight_column=None,
    optimizer='Ftrl',
    config=None,
    partitioner=None,
    warm_start_from=None,
    loss_reduction=tf.compat.v1.losses.Reduction.SUM,
    sparse_combiner='sum'
)
",An estimator for TensorFlow Linear regression problems.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.estimator.LoggingTensorHook,"tf.estimator.LoggingTensorHook(
    tensors, every_n_iter=None, every_n_secs=None, at_end=False, formatter=None
)
","Prints the given tensors every N local steps, every N seconds, or at end.Inherits From: SessionRunHookView aliases"
tf.estimator.LogisticRegressionHead,"tf.estimator.LogisticRegressionHead(
    weight_column=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    name=None
)
","Creates a Head for logistic regression.Inherits From: RegressionHead, HeadView aliases"
tf.estimator.MultiClassHead,"tf.estimator.MultiClassHead(
    n_classes,
    weight_column=None,
    label_vocabulary=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    loss_fn=None,
    name=None
)
",Creates a Head for multi class classification.Inherits From: HeadView aliases
tf.estimator.MultiHead,"tf.estimator.MultiHead(
    heads, head_weights=None
)
",Creates a Head for multi-objective learning.Inherits From: HeadView aliases
tf.estimator.MultiLabelHead,"tf.estimator.MultiLabelHead(
    n_classes,
    weight_column=None,
    thresholds=None,
    label_vocabulary=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    loss_fn=None,
    classes_for_class_based_metrics=None,
    name=None
)
",Creates a Head for multi-label classification.Inherits From: HeadView aliases
tf.estimator.NanLossDuringTrainingError,"tf.estimator.NanLossDuringTrainingError(
    *args, **kwargs
)
",Unspecified run-time error.View aliases
tf.estimator.NanTensorHook,"tf.estimator.NanTensorHook(
    loss_tensor, fail_on_nan_loss=True
)
",Monitors the loss tensor and stops training if loss is NaN.Inherits From: SessionRunHookView aliases
tf.estimator.PoissonRegressionHead,"tf.estimator.PoissonRegressionHead(
    label_dimension=1,
    weight_column=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    compute_full_loss=True,
    name=None
)
","Creates a Head for poisson regression using tf.nn.log_poisson_loss.Inherits From: RegressionHead, HeadView aliases"
tf.estimator.ProfilerHook,"tf.estimator.ProfilerHook(
    save_steps=None,
    save_secs=None,
    output_dir='',
    show_dataflow=True,
    show_memory=False
)
",Captures CPU/GPU profiling information every N steps or seconds.Inherits From: SessionRunHookView aliases
tf.estimator.RegressionHead,"tf.estimator.RegressionHead(
    label_dimension=1,
    weight_column=None,
    loss_reduction=tf.losses.Reduction.SUM_OVER_BATCH_SIZE,
    loss_fn=None,
    inverse_link_fn=None,
    name=None
)
",Creates a Head for regression using the mean_squared_error loss.Inherits From: HeadView aliases
tf.estimator.RunConfig,"tf.estimator.RunConfig(
    model_dir=None,
    tf_random_seed=None,
    save_summary_steps=100,
    save_checkpoints_steps=_USE_DEFAULT,
    save_checkpoints_secs=_USE_DEFAULT,
    session_config=None,
    keep_checkpoint_max=5,
    keep_checkpoint_every_n_hours=10000,
    log_step_count_steps=100,
    train_distribute=None,
    device_fn=None,
    protocol=None,
    eval_distribute=None,
    experimental_distribute=None,
    experimental_max_worker_delay_secs=None,
    session_creation_timeout_secs=7200,
    checkpoint_save_graph_def=True
)
",This class specifies the configurations for an Estimator run.View aliases
tf.estimator.SecondOrStepTimer,"tf.estimator.SecondOrStepTimer(
    every_secs=None, every_steps=None
)
",Timer that triggers at most once every N seconds or once every N steps.View aliases
tf.estimator.SessionRunArgs,"tf.estimator.SessionRunArgs(
    fetches, feed_dict=None, options=None
)
",Represents arguments to be added to a Session.run() call.View aliases
tf.estimator.SessionRunContext,"tf.estimator.SessionRunContext(
    original_args, session
)
",Provides information about the session.run() call being made.View aliases
tf.estimator.SessionRunValues,"tf.estimator.SessionRunValues(
    results, options, run_metadata
)
",Contains the results of Session.run().View aliases
tf.estimator.StepCounterHook,"tf.estimator.StepCounterHook(
    every_n_steps=100, every_n_secs=None, output_dir=None, summary_writer=None
)
",Hook that counts steps per second.Inherits From: SessionRunHookView aliases
tf.estimator.StopAtStepHook,"tf.estimator.StopAtStepHook(
    num_steps=None, last_step=None
)
",Hook that requests stop at a specified step.Inherits From: SessionRunHookView aliases
tf.estimator.SummarySaverHook,"tf.estimator.SummarySaverHook(
    save_steps=None,
    save_secs=None,
    output_dir=None,
    summary_writer=None,
    scaffold=None,
    summary_op=None
)
",Saves summaries every N steps.Inherits From: SessionRunHookView aliases
tf.estimator.TrainSpec,"tf.estimator.TrainSpec(
    input_fn, max_steps=None, hooks=None, saving_listeners=None
)
","Configuration for the ""train"" part for the train_and_evaluate call.View aliases"
tf.estimator.VocabInfo,"tf.estimator.VocabInfo(
    new_vocab,
    new_vocab_size,
    num_oov_buckets,
    old_vocab,
    old_vocab_size=-1,
    backup_initializer=None,
    axis=0
)
",Vocabulary information for warm-starting.View aliases
tf.estimator.WarmStartSettings,"tf.estimator.WarmStartSettings(
    ckpt_to_initialize_from,
    vars_to_warm_start='.*',
    var_name_to_vocab_info=None,
    var_name_to_prev_var_name=None
)
",Settings for warm-starting in tf.estimator.Estimators.View aliases
tf.estimator.add_metrics,"tf.estimator.add_metrics(
    estimator, metric_fn
)
",Creates a new tf.estimator.Estimator which has given metrics.View aliases
tf.compat.v1.estimator.classifier_parse_example_spec,"tf.compat.v1.estimator.classifier_parse_example_spec(
    feature_columns,
    label_key,
    label_dtype=tf.dtypes.int64,
    label_default=None,
    weight_column=None
)
",Generates parsing spec for tf.parse_example to be used with classifiers.
tf.estimator.experimental.InMemoryEvaluatorHook,"tf.estimator.experimental.InMemoryEvaluatorHook(
    estimator, input_fn, steps=None, hooks=None, name=None, every_n_iter=100
)
",Hook to run evaluation in training without a checkpoint.Inherits From: SessionRunHookView aliases
tf.compat.v1.estimator.experimental.KMeans,"tf.compat.v1.estimator.experimental.KMeans(
    num_clusters,
    model_dir=None,
    initial_clusters=RANDOM_INIT,
    distance_metric=SQUARED_EUCLIDEAN_DISTANCE,
    seed=None,
    use_mini_batch=True,
    mini_batch_steps_per_iteration=1,
    kmeans_plus_plus_num_retries=2,
    relative_tolerance=None,
    config=None,
    feature_columns=None
)
",An Estimator for K-Means clustering.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.estimator.experimental.LinearSDCA,"tf.estimator.experimental.LinearSDCA(
    example_id_column,
    num_loss_partitions=1,
    num_table_shards=None,
    symmetric_l1_regularization=0.0,
    symmetric_l2_regularization=1.0,
    adaptive=False
)
",Stochastic Dual Coordinate Ascent helper for linear estimators.View aliases
tf.estimator.experimental.build_raw_supervised_input_receiver_fn,"tf.estimator.experimental.build_raw_supervised_input_receiver_fn(
    features, labels, default_batch_size=None
)
",Build a supervised_input_receiver_fn for raw features and labels.View aliases
tf.estimator.experimental.call_logit_fn,"tf.estimator.experimental.call_logit_fn(
    logit_fn, features, mode, params, config
)
",Calls logit_fn (experimental).View aliases
tf.compat.v1.estimator.experimental.dnn_logit_fn_builder,"tf.compat.v1.estimator.experimental.dnn_logit_fn_builder(
    units,
    hidden_units,
    feature_columns,
    activation_fn,
    dropout,
    input_layer_partitioner,
    batch_norm
)
",Function builder for a dnn logit_fn.
tf.compat.v1.estimator.experimental.linear_logit_fn_builder,"tf.compat.v1.estimator.experimental.linear_logit_fn_builder(
    units, feature_columns, sparse_combiner='sum'
)
",Function builder for a linear logit_fn.
tf.estimator.experimental.make_early_stopping_hook,"tf.estimator.experimental.make_early_stopping_hook(
    estimator, should_stop_fn, run_every_secs=60, run_every_steps=None
)
",Creates early-stopping hook.View aliases
tf.estimator.experimental.make_stop_at_checkpoint_step_hook,"tf.estimator.experimental.make_stop_at_checkpoint_step_hook(
    estimator, last_step, wait_after_file_check_secs=30
)
",Creates a proper StopAtCheckpointStepHook based on chief status.View aliases
tf.estimator.experimental.stop_if_higher_hook,"tf.estimator.experimental.stop_if_higher_hook(
    estimator,
    metric_name,
    threshold,
    eval_dir=None,
    min_steps=0,
    run_every_secs=60,
    run_every_steps=None
)
",Creates hook to stop if the given metric is higher than the threshold.View aliases
tf.estimator.experimental.stop_if_lower_hook,"tf.estimator.experimental.stop_if_lower_hook(
    estimator,
    metric_name,
    threshold,
    eval_dir=None,
    min_steps=0,
    run_every_secs=60,
    run_every_steps=None
)
",Creates hook to stop if the given metric is lower than the threshold.View aliases
tf.estimator.experimental.stop_if_no_decrease_hook,"tf.estimator.experimental.stop_if_no_decrease_hook(
    estimator,
    metric_name,
    max_steps_without_decrease,
    eval_dir=None,
    min_steps=0,
    run_every_secs=60,
    run_every_steps=None
)
",Creates hook to stop if metric does not decrease within given max steps.View aliases
tf.estimator.experimental.stop_if_no_increase_hook,"tf.estimator.experimental.stop_if_no_increase_hook(
    estimator,
    metric_name,
    max_steps_without_increase,
    eval_dir=None,
    min_steps=0,
    run_every_secs=60,
    run_every_steps=None
)
",Creates hook to stop if metric does not increase within given max steps.View aliases
tf.estimator.export.ClassificationOutput,"tf.estimator.export.ClassificationOutput(
    scores=None, classes=None
)
",Represents the output of a classification head.Inherits From: ExportOutputView aliases
tf.estimator.export.EvalOutput,"tf.estimator.export.EvalOutput(
    loss=None, predictions=None, metrics=None
)
",Represents the output of a supervised eval process.Inherits From: ExportOutputView aliases
tf.estimator.export.PredictOutput,"tf.estimator.export.PredictOutput(
    outputs
)
",Represents the output of a generic prediction head.Inherits From: ExportOutputView aliases
tf.estimator.export.RegressionOutput,"tf.estimator.export.RegressionOutput(
    value
)
",Represents the output of a regression head.Inherits From: ExportOutputView aliases
tf.estimator.export.ServingInputReceiver,"tf.estimator.export.ServingInputReceiver(
    features, receiver_tensors, receiver_tensors_alternatives=None
)
",A return type for a serving_input_receiver_fn.View aliases
tf.estimator.export.TensorServingInputReceiver,"tf.estimator.export.TensorServingInputReceiver(
    features, receiver_tensors, receiver_tensors_alternatives=None
)
",A return type for a serving_input_receiver_fn.View aliases
tf.estimator.export.build_parsing_serving_input_receiver_fn,"tf.estimator.export.build_parsing_serving_input_receiver_fn(
    feature_spec, default_batch_size=None
)
",Build a serving_input_receiver_fn expecting fed tf.Examples.View aliases
tf.estimator.export.build_raw_serving_input_receiver_fn,"tf.estimator.export.build_raw_serving_input_receiver_fn(
    features, default_batch_size=None
)
",Build a serving_input_receiver_fn expecting feature Tensors.View aliases
tf.compat.v1.estimator.inputs.numpy_input_fn,"tf.compat.v1.estimator.inputs.numpy_input_fn(
    x,
    y=None,
    batch_size=128,
    num_epochs=1,
    shuffle=None,
    queue_capacity=1000,
    num_threads=1
)
",Returns input function that would feed dict of numpy arrays into the model.
tf.compat.v1.estimator.inputs.pandas_input_fn,"tf.compat.v1.estimator.inputs.pandas_input_fn(
    x,
    y=None,
    batch_size=128,
    num_epochs=1,
    shuffle=None,
    queue_capacity=1000,
    num_threads=1,
    target_column='target'
)
",Returns input function that would feed Pandas DataFrame into the model.
tf.compat.v1.estimator.regressor_parse_example_spec,"tf.compat.v1.estimator.regressor_parse_example_spec(
    feature_columns,
    label_key,
    label_dtype=tf.dtypes.float32,
    label_default=None,
    label_dimension=1,
    weight_column=None
)
",Generates parsing spec for tf.parse_example to be used with regressors.
tf.compat.v1.estimator.tpu.RunConfig,"tf.compat.v1.estimator.tpu.RunConfig(
    tpu_config=None,
    evaluation_master=None,
    master=None,
    cluster=None,
    **kwargs
)
",RunConfig with TPU support.Inherits From: RunConfig
tf.compat.v1.estimator.tpu.TPUConfig,"tf.compat.v1.estimator.tpu.TPUConfig(
    iterations_per_loop=2,
    num_shards=None,
    num_cores_per_replica=None,
    per_host_input_for_training=True,
    tpu_job_name=None,
    initial_infeed_sleep_secs=None,
    input_partition_dims=None,
    eval_training_input_configuration=InputPipelineConfig.PER_HOST_V1,
    experimental_host_call_every_n_steps=1,
    experimental_allow_per_host_v2_parallel_get_next=False,
    experimental_feed_hook=None
)
",TPU related configuration required by TPUEstimator.
tf.compat.v1.estimator.tpu.TPUEstimator,"tf.compat.v1.estimator.tpu.TPUEstimator(
    model_fn=None,
    model_dir=None,
    config=None,
    params=None,
    use_tpu=True,
    train_batch_size=None,
    eval_batch_size=None,
    predict_batch_size=None,
    batch_axis=None,
    eval_on_tpu=True,
    export_to_tpu=True,
    export_to_cpu=True,
    warm_start_from=None,
    embedding_config_spec=None,
    export_saved_model_api_version=ExportSavedModelApiVersion.V1
)
",Estimator with TPU support.Warning: Estimators are not recommended for new code.  Estimators runInherits From: Estimator
tf.compat.v1.estimator.tpu.TPUEstimatorSpec,"tf.compat.v1.estimator.tpu.TPUEstimatorSpec(
    mode,
    predictions=None,
    loss=None,
    train_op=None,
    eval_metrics=None,
    export_outputs=None,
    scaffold_fn=None,
    host_call=None,
    training_hooks=None,
    evaluation_hooks=None,
    prediction_hooks=None
)
",Ops and objects returned from a model_fn and passed to TPUEstimator.
tf.compat.v1.estimator.tpu.experimental.EmbeddingConfigSpec,"tf.compat.v1.estimator.tpu.experimental.EmbeddingConfigSpec(
    feature_columns=None,
    optimization_parameters=None,
    clipping_limit=None,
    pipeline_execution_with_tensor_core=False,
    experimental_gradient_multiplier_fn=None,
    feature_to_config_dict=None,
    table_to_config_dict=None,
    partition_strategy='div',
    profile_data_directory=None
)
",Class to keep track of the specification for TPU embeddings.
tf.estimator.train_and_evaluate,"tf.estimator.train_and_evaluate(
    estimator, train_spec, eval_spec
)
",Train and evaluate the estimator.View aliases
tf.math.exp,"tf.math.exp(
    x, name=None
)
",Computes exponential of x element-wise.  \(y = e^x\).View aliases
tf.compat.v1.expand_dims,"tf.compat.v1.expand_dims(
    input, axis=None, name=None, dim=None
)
",Returns a tensor with a length 1 axis inserted at index axis. (deprecated arguments)
tf.experimental.BatchableExtensionType,"tf.experimental.BatchableExtensionType(
    *args, **kwargs
)
",An ExtensionType that can be batched and unbatched.Inherits From: ExtensionTypeView aliases
tf.experimental.DynamicRaggedShape,"tf.experimental.DynamicRaggedShape(
    row_partitions: Sequence[tf.experimental.RowPartition],
    inner_shape: tf.types.experimental.TensorLike,
    dtype: Optional[tf.dtypes.DType] = None,
    validate: bool = False,
    static_inner_shape: ... = None
)
","The shape of a ragged or dense tensor.Inherits From: BatchableExtensionType, ExtensionTypeView aliases"
tf.experimental.DynamicRaggedShape.Spec,"tf.experimental.DynamicRaggedShape.Spec(
    row_partitions: Tuple[RowPartitionSpec, ...],
    static_inner_shape: tf.TensorShape,
    dtype: tf.dtypes.DType
)
","A Spec for DynamicRaggedShape: similar to a static shape.Inherits From: TypeSpec, TraceTypeView aliases"
tf.experimental.ExtensionType,"tf.experimental.ExtensionType(
    *args, **kwargs
)
",Base class for TensorFlow ExtensionType classes.View aliases
tf.experimental.RowPartition,"tf.experimental.RowPartition(
    row_splits,
    row_lengths=None,
    value_rowids=None,
    nrows=None,
    uniform_row_length=None,
    nvals=None,
    internal=False
)
","Partitioning of a sequence of values into contiguous subsequences (""rows"").View aliases"
tf.experimental.dispatch_for_api,"tf.experimental.dispatch_for_api(
    api, *signatures
)
",Decorator that overrides the default implementation for a TensorFlow API.View aliases
tf.experimental.dispatch_for_binary_elementwise_apis,"tf.experimental.dispatch_for_binary_elementwise_apis(
    x_type, y_type
)
",Decorator to override default implementation for binary elementwise APIs.View aliases
tf.experimental.dispatch_for_binary_elementwise_assert_apis,"tf.experimental.dispatch_for_binary_elementwise_assert_apis(
    x_type, y_type
)
",Decorator to override default implementation for binary elementwise assert APIs.View aliases
tf.experimental.dispatch_for_unary_elementwise_apis,"tf.experimental.dispatch_for_unary_elementwise_apis(
    x_type
)
",Decorator to override default implementation for unary elementwise APIs.View aliases
tf.compat.v1.experimental.output_all_intermediates,"tf.compat.v1.experimental.output_all_intermediates(
    state
)
",Whether to output all intermediates from functional control flow ops.
tf.experimental.register_filesystem_plugin,"tf.experimental.register_filesystem_plugin(
    plugin_location
)
",Loads a TensorFlow FileSystem plugin.View aliases
tf.experimental.unregister_dispatch_for,"tf.experimental.unregister_dispatch_for(
    dispatch_target
)
",Unregisters a function that was registered with @dispatch_for_*.View aliases
tf.math.expm1,"tf.math.expm1(
    x, name=None
)
",Computes exp(x) - 1 element-wise.View aliases
tf.compat.v1.extract_image_patches,"tf.compat.v1.extract_image_patches(
    images,
    ksizes=None,
    strides=None,
    rates=None,
    padding=None,
    name=None,
    sizes=None
)
","Extract patches from images and put them in the ""depth"" output dimension.View aliases"
tf.extract_volume_patches,"tf.extract_volume_patches(
    input, ksizes, strides, padding, name=None
)
","Extract patches from input and put them in the ""depth"" output dimension. 3D extension of extract_image_patches.View aliases"
tf.eye,"tf.eye(
    num_rows,
    num_columns=None,
    batch_shape=None,
    dtype=tf.dtypes.float32,
    name=None
)
","Construct an identity matrix, or a batch of matrices.View aliases"
tf.quantization.fake_quant_with_min_max_args,"tf.quantization.fake_quant_with_min_max_args(
    inputs, min=-6, max=6, num_bits=8, narrow_range=False, name=None
)
","Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.View aliases"
tf.quantization.fake_quant_with_min_max_args_gradient,"tf.quantization.fake_quant_with_min_max_args_gradient(
    gradients, inputs, min=-6, max=6, num_bits=8, narrow_range=False, name=None
)
",Compute gradients for a FakeQuantWithMinMaxArgs operation.View aliases
tf.quantization.fake_quant_with_min_max_vars,"tf.quantization.fake_quant_with_min_max_vars(
    inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Fake-quantize the 'inputs' tensor of type float via global float scalarsView aliases
tf.quantization.fake_quant_with_min_max_vars_gradient,"tf.quantization.fake_quant_with_min_max_vars_gradient(
    gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Compute gradients for a FakeQuantWithMinMaxVars operation.View aliases
tf.quantization.fake_quant_with_min_max_vars_per_channel,"tf.quantization.fake_quant_with_min_max_vars_per_channel(
    inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Fake-quantize the 'inputs' tensor of type float via per-channel floatsView aliases
tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient,"tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient(
    gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.View aliases
tf.feature_column.bucketized_column,"tf.feature_column.bucketized_column(
    source_column, boundaries
)
",Represents discretized dense input bucketed by boundaries.View aliases
tf.feature_column.categorical_column_with_hash_bucket,"tf.feature_column.categorical_column_with_hash_bucket(
    key,
    hash_bucket_size,
    dtype=tf.dtypes.string
)
",Represents sparse feature where ids are set by hashing.View aliases
tf.feature_column.categorical_column_with_identity,"tf.feature_column.categorical_column_with_identity(
    key, num_buckets, default_value=None
)
",A CategoricalColumn that returns identity values.View aliases
tf.compat.v1.feature_column.categorical_column_with_vocabulary_file,"tf.compat.v1.feature_column.categorical_column_with_vocabulary_file(
    key,
    vocabulary_file,
    vocabulary_size=None,
    num_oov_buckets=0,
    default_value=None,
    dtype=tf.dtypes.string
)
",A CategoricalColumn with a vocabulary file.
tf.feature_column.categorical_column_with_vocabulary_list,"tf.feature_column.categorical_column_with_vocabulary_list(
    key, vocabulary_list, dtype=None, default_value=-1, num_oov_buckets=0
)
",A CategoricalColumn with in-memory vocabulary.View aliases
tf.feature_column.crossed_column,"tf.feature_column.crossed_column(
    keys, hash_bucket_size, hash_key=None
)
",Returns a column for performing crosses of categorical features.View aliases
tf.feature_column.embedding_column,"tf.feature_column.embedding_column(
    categorical_column,
    dimension,
    combiner='mean',
    initializer=None,
    ckpt_to_load_from=None,
    tensor_name_in_ckpt=None,
    max_norm=None,
    trainable=True,
    use_safe_embedding_lookup=True
)
","DenseColumn that converts from sparse, categorical input.View aliases"
tf.feature_column.indicator_column,"tf.feature_column.indicator_column(
    categorical_column
)
",Represents multi-hot representation of given categorical column.View aliases
tf.compat.v1.feature_column.input_layer,"tf.compat.v1.feature_column.input_layer(
    features,
    feature_columns,
    weight_collections=None,
    trainable=True,
    cols_to_vars=None,
    cols_to_output_tensors=None
)
",Returns a dense Tensor as input layer based on given feature_columns.
tf.compat.v1.feature_column.linear_model,"tf.compat.v1.feature_column.linear_model(
    features,
    feature_columns,
    units=1,
    sparse_combiner='sum',
    weight_collections=None,
    trainable=True,
    cols_to_vars=None
)
",Returns a linear prediction Tensor based on given feature_columns.
tf.compat.v1.feature_column.make_parse_example_spec,"tf.compat.v1.feature_column.make_parse_example_spec(
    feature_columns
)
",Creates parsing spec dictionary from input feature_columns.
tf.feature_column.numeric_column,"tf.feature_column.numeric_column(
    key,
    shape=(1,),
    default_value=None,
    dtype=tf.dtypes.float32,
    normalizer_fn=None
)
",Represents real valued or numerical features.View aliases
tf.feature_column.sequence_categorical_column_with_hash_bucket,"tf.feature_column.sequence_categorical_column_with_hash_bucket(
    key,
    hash_bucket_size,
    dtype=tf.dtypes.string
)
",A sequence of categorical terms where ids are set by hashing.View aliases
tf.feature_column.sequence_categorical_column_with_identity,"tf.feature_column.sequence_categorical_column_with_identity(
    key, num_buckets, default_value=None
)
",Returns a feature column that represents sequences of integers.View aliases
tf.feature_column.sequence_categorical_column_with_vocabulary_file,"tf.feature_column.sequence_categorical_column_with_vocabulary_file(
    key,
    vocabulary_file,
    vocabulary_size=None,
    num_oov_buckets=0,
    default_value=None,
    dtype=tf.dtypes.string
)
",A sequence of categorical terms where ids use a vocabulary file.View aliases
tf.feature_column.sequence_categorical_column_with_vocabulary_list,"tf.feature_column.sequence_categorical_column_with_vocabulary_list(
    key, vocabulary_list, dtype=None, default_value=-1, num_oov_buckets=0
)
",A sequence of categorical terms where ids use an in-memory list.View aliases
tf.feature_column.sequence_numeric_column,"tf.feature_column.sequence_numeric_column(
    key,
    shape=(1,),
    default_value=0.0,
    dtype=tf.dtypes.float32,
    normalizer_fn=None
)
",Returns a feature column that represents sequences of numeric data.View aliases
tf.compat.v1.feature_column.shared_embedding_columns,"tf.compat.v1.feature_column.shared_embedding_columns(
    categorical_columns,
    dimension,
    combiner='mean',
    initializer=None,
    shared_embedding_collection_name=None,
    ckpt_to_load_from=None,
    tensor_name_in_ckpt=None,
    max_norm=None,
    trainable=True,
    use_safe_embedding_lookup=True
)
","List of dense columns that convert from sparse, categorical input."
tf.feature_column.weighted_categorical_column,"tf.feature_column.weighted_categorical_column(
    categorical_column,
    weight_feature_key,
    dtype=tf.dtypes.float32
)
",Applies weight values to a CategoricalColumn.View aliases
tf.signal.fft,"tf.signal.fft(
    input, name=None
)
",Fast Fourier transform.View aliases
tf.signal.fft2d,"tf.signal.fft2d(
    input, name=None
)
",2D fast Fourier transform.View aliases
tf.signal.fft3d,"tf.signal.fft3d(
    input, name=None
)
",3D fast Fourier transform.View aliases
tf.fill,"tf.fill(
    dims, value, name=None
)
",Creates a tensor filled with a scalar value.View aliases
tf.fingerprint,"tf.fingerprint(
    data, method='farmhash64', name=None
)
",Generates fingerprint values.View aliases
tf.compat.v1.fixed_size_partitioner,"tf.compat.v1.fixed_size_partitioner(
    num_shards, axis=0
)
",Partitioner to specify a fixed number of shards along given axis.
tf.compat.v1.flags.BaseListParser,"tf.compat.v1.flags.BaseListParser(
    token=None, name=None
)
",Base class for a parser of lists of strings.Inherits From: ArgumentParser
tf.compat.v1.flags.BooleanFlag,"tf.compat.v1.flags.BooleanFlag(
    name, default, help, short_name=None, **args
)
",Basic boolean flag.Inherits From: Flag
tf.compat.v1.flags.CsvListSerializer,"tf.compat.v1.flags.CsvListSerializer(
    list_sep
)
",Base class for generating string representations of a flag value.Inherits From: ArgumentSerializer
tf.compat.v1.flags.DEFINE,"tf.compat.v1.flags.DEFINE(
    parser,
    name,
    default,
    help,
    flag_values=_flagvalues.FLAGS,
    serializer=None,
    module_name=None,
    required=False,
    **args
)
",Registers a generic Flag object.
tf.compat.v1.flags.DEFINE_alias,"tf.compat.v1.flags.DEFINE_alias(
    name, original_name, flag_values=_flagvalues.FLAGS, module_name=None
)
",Defines an alias flag for an existing one.
tf.compat.v1.flags.DEFINE_bool,"tf.compat.v1.flags.DEFINE_bool(
    name,
    default,
    help,
    flag_values=_flagvalues.FLAGS,
    module_name=None,
    required=False,
    **args
)
",Registers a boolean flag.View aliases
tf.compat.v1.flags.DEFINE_bool,"tf.compat.v1.flags.DEFINE_bool(
    name,
    default,
    help,
    flag_values=_flagvalues.FLAGS,
    module_name=None,
    required=False,
    **args
)
",Registers a boolean flag.View aliases
tf.compat.v1.flags.DEFINE_enum,"tf.compat.v1.flags.DEFINE_enum(
    name,
    default,
    enum_values,
    help,
    flag_values=_flagvalues.FLAGS,
    module_name=None,
    required=False,
    **args
)
",Registers a flag whose value can be any string from enum_values.
tf.compat.v1.flags.DEFINE_enum_class,"tf.compat.v1.flags.DEFINE_enum_class(
    name,
    default,
    enum_class,
    help,
    flag_values=_flagvalues.FLAGS,
    module_name=None,
    case_sensitive=False,
    required=False,
    **args
)
",Registers a flag whose value can be the name of enum members.
tf.compat.v1.flags.DEFINE_flag,"tf.compat.v1.flags.DEFINE_flag(
    flag, flag_values=_flagvalues.FLAGS, module_name=None, required=False
)
",Registers a :class:Flag object with a :class:FlagValues object.
tf.compat.v1.flags.DEFINE_float,"tf.compat.v1.flags.DEFINE_float(
    name,
    default,
    help,
    lower_bound=None,
    upper_bound=None,
    flag_values=_flagvalues.FLAGS,
    required=False,
    **args
)
",Registers a flag whose value must be a float.
tf.compat.v1.flags.DEFINE_integer,"tf.compat.v1.flags.DEFINE_integer(
    name,
    default,
    help,
    lower_bound=None,
    upper_bound=None,
    flag_values=_flagvalues.FLAGS,
    required=False,
    **args
)
",Registers a flag whose value must be an integer.
tf.compat.v1.flags.DEFINE_list,"tf.compat.v1.flags.DEFINE_list(
    name, default, help, flag_values=_flagvalues.FLAGS, required=False, **args
)
",Registers a flag whose value is a comma-separated list of strings.
tf.compat.v1.flags.DEFINE_multi,"tf.compat.v1.flags.DEFINE_multi(
    parser,
    serializer,
    name,
    default,
    help,
    flag_values=_flagvalues.FLAGS,
    module_name=None,
    required=False,
    **args
)
",Registers a generic MultiFlag that parses its args with a given parser.
tf.compat.v1.flags.DEFINE_multi_enum,"tf.compat.v1.flags.DEFINE_multi_enum(
    name,
    default,
    enum_values,
    help,
    flag_values=_flagvalues.FLAGS,
    case_sensitive=True,
    required=False,
    **args
)
",Registers a flag whose value can be a list strings from enum_values.
tf.compat.v1.flags.DEFINE_multi_enum_class,"tf.compat.v1.flags.DEFINE_multi_enum_class(
    name,
    default,
    enum_class,
    help,
    flag_values=_flagvalues.FLAGS,
    module_name=None,
    case_sensitive=False,
    required=False,
    **args
)
",Registers a flag whose value can be a list of enum members.
tf.compat.v1.flags.DEFINE_multi_float,"tf.compat.v1.flags.DEFINE_multi_float(
    name,
    default,
    help,
    lower_bound=None,
    upper_bound=None,
    flag_values=_flagvalues.FLAGS,
    required=False,
    **args
)
",Registers a flag whose value can be a list of arbitrary floats.
tf.compat.v1.flags.DEFINE_multi_integer,"tf.compat.v1.flags.DEFINE_multi_integer(
    name,
    default,
    help,
    lower_bound=None,
    upper_bound=None,
    flag_values=_flagvalues.FLAGS,
    required=False,
    **args
)
",Registers a flag whose value can be a list of arbitrary integers.
tf.compat.v1.flags.DEFINE_multi_string,"tf.compat.v1.flags.DEFINE_multi_string(
    name, default, help, flag_values=_flagvalues.FLAGS, required=False, **args
)
",Registers a flag whose value can be a list of any strings.
tf.compat.v1.flags.DEFINE_spaceseplist,"tf.compat.v1.flags.DEFINE_spaceseplist(
    name,
    default,
    help,
    comma_compat=False,
    flag_values=_flagvalues.FLAGS,
    required=False,
    **args
)
",Registers a flag whose value is a whitespace-separated list of strings.
tf.compat.v1.flags.DEFINE_string,"tf.compat.v1.flags.DEFINE_string(
    name, default, help, flag_values=_flagvalues.FLAGS, required=False, **args
)
",Registers a flag whose value can be any string.
tf.compat.v1.flags.EnumClassFlag,"tf.compat.v1.flags.EnumClassFlag(
    name,
    default,
    help,
    enum_class,
    short_name=None,
    case_sensitive=False,
    **args
)
",Basic enum flag; its value is an enum class's member.Inherits From: Flag
tf.compat.v1.flags.EnumClassListSerializer,"tf.compat.v1.flags.EnumClassListSerializer(
    list_sep, **kwargs
)
","A serializer for :class:MultiEnumClass flags.Inherits From: ListSerializer, ArgumentSerializer"
tf.compat.v1.flags.EnumClassParser,"tf.compat.v1.flags.EnumClassParser(
    enum_class, case_sensitive=True
)
",Parser of an Enum class member.Inherits From: ArgumentParser
tf.compat.v1.flags.EnumClassSerializer,"tf.compat.v1.flags.EnumClassSerializer(
    lowercase
)
",Class for generating string representations of an enum class flag value.Inherits From: ArgumentSerializer
tf.compat.v1.flags.EnumFlag,"tf.compat.v1.flags.EnumFlag(
    name,
    default,
    help,
    enum_values,
    short_name=None,
    case_sensitive=True,
    **args
)
",Basic enum flag; its value can be any string from list of enum_values.Inherits From: Flag
tf.compat.v1.flags.EnumParser,"tf.compat.v1.flags.EnumParser(
    enum_values, case_sensitive=True
)
",Parser of a string enum value (a string value from a given set).Inherits From: ArgumentParser
tf.compat.v1.flags.FLAGS,"tf.compat.v1.flags.FLAGS(
    *args, **kwargs
)
",Registry of :class:~absl.flags.Flag objects.
tf.compat.v1.flags.Flag,"tf.compat.v1.flags.Flag(
    parser,
    serializer,
    name,
    default,
    help_string,
    short_name=None,
    boolean=False,
    allow_override=False,
    allow_override_cpp=False,
    allow_hide_cpp=False,
    allow_overwrite=True,
    allow_using_method_names=False
)
",Information about a command-line flag.
tf.compat.v1.flags.FlagHolder,"tf.compat.v1.flags.FlagHolder(
    flag_values, flag, ensure_non_none_value=False
)
",Holds a defined flag.
tf.compat.v1.flags.FloatParser,"tf.compat.v1.flags.FloatParser(
    lower_bound=None, upper_bound=None
)
",Parser of floating point values.Inherits From: ArgumentParser
tf.compat.v1.flags.IntegerParser,"tf.compat.v1.flags.IntegerParser(
    lower_bound=None, upper_bound=None
)
",Parser of an integer value.Inherits From: ArgumentParser
tf.compat.v1.flags.ListSerializer,"tf.compat.v1.flags.ListSerializer(
    list_sep
)
",Base class for generating string representations of a flag value.Inherits From: ArgumentSerializer
tf.compat.v1.flags.MultiEnumClassFlag,"tf.compat.v1.flags.MultiEnumClassFlag(
    name, default, help_string, enum_class, case_sensitive=False, **args
)
","A multi_enum_class flag.Inherits From: MultiFlag, Flag"
tf.compat.v1.flags.MultiFlag,"tf.compat.v1.flags.MultiFlag(
    *args, **kwargs
)
",A flag that can appear multiple time on the command-line.Inherits From: Flag
tf.compat.v1.flags.UnrecognizedFlagError,"tf.compat.v1.flags.UnrecognizedFlagError(
    flagname, flagvalue='', suggestions=None
)
",Raised when a flag is unrecognized.Inherits From: Error
tf.compat.v1.flags.WhitespaceSeparatedListParser,"tf.compat.v1.flags.WhitespaceSeparatedListParser(
    comma_compat=False
)
","Parser for a whitespace-separated list of strings.Inherits From: BaseListParser, ArgumentParser"
tf.compat.v1.flags.adopt_module_key_flags,"tf.compat.v1.flags.adopt_module_key_flags(
    module, flag_values=_flagvalues.FLAGS
)
",Declares that all flags key to a module are key to the current module.
tf.compat.v1.flags.declare_key_flag,"tf.compat.v1.flags.declare_key_flag(
    flag_name, flag_values=_flagvalues.FLAGS
)
",Declares one flag as key to the current module.
tf.compat.v1.flags.doc_to_help,"tf.compat.v1.flags.doc_to_help(
    doc
)
",Takes a doc string and reformats it as help.
tf.compat.v1.flags.flag_dict_to_args,"tf.compat.v1.flags.flag_dict_to_args(
    flag_map, multi_flags=None
)
",Convert a dict of values into process call parameters.
tf.compat.v1.flags.mark_bool_flags_as_mutual_exclusive,"tf.compat.v1.flags.mark_bool_flags_as_mutual_exclusive(
    flag_names, required=False, flag_values=_flagvalues.FLAGS
)
",Ensures that only one flag among flag_names is True.
tf.compat.v1.flags.mark_flag_as_required,"tf.compat.v1.flags.mark_flag_as_required(
    flag_name, flag_values=_flagvalues.FLAGS
)
",Ensures that flag is not None during program execution.
tf.compat.v1.flags.mark_flags_as_mutual_exclusive,"tf.compat.v1.flags.mark_flags_as_mutual_exclusive(
    flag_names, required=False, flag_values=_flagvalues.FLAGS
)
",Ensures that only one flag among flag_names is not None.
tf.compat.v1.flags.mark_flags_as_required,"tf.compat.v1.flags.mark_flags_as_required(
    flag_names, flag_values=_flagvalues.FLAGS
)
",Ensures that flags are not None during program execution.
tf.compat.v1.flags.multi_flags_validator,"tf.compat.v1.flags.multi_flags_validator(
    flag_names,
    message='Flag validation failed',
    flag_values=_flagvalues.FLAGS
)
",A function decorator for defining a multi-flag validator.
tf.compat.v1.flags.register_multi_flags_validator,"tf.compat.v1.flags.register_multi_flags_validator(
    flag_names,
    multi_flags_checker,
    message='Flags validation failed',
    flag_values=_flagvalues.FLAGS
)
",Adds a constraint to multiple flags.
tf.compat.v1.flags.register_validator,"tf.compat.v1.flags.register_validator(
    flag_name,
    checker,
    message='Flag validation failed',
    flag_values=_flagvalues.FLAGS
)
","Adds a constraint, which will be enforced during program execution."
tf.compat.v1.flags.set_default,"tf.compat.v1.flags.set_default(
    flag_holder, value
)
",Changes the default value of the provided flag object.
tf.compat.v1.flags.text_wrap,"tf.compat.v1.flags.text_wrap(
    text, length=None, indent='', firstline_indent=None
)
",Wraps a given text to a maximum line length and returns it.
tf.compat.v1.flags.validator,"tf.compat.v1.flags.validator(
    flag_name,
    message='Flag validation failed',
    flag_values=_flagvalues.FLAGS
)
",A function decorator for defining a flag validator.
tf.math.floor,"tf.math.floor(
    x, name=None
)
",Returns element-wise largest integer not greater than x.View aliases
tf.compat.v1.floor_div,"tf.compat.v1.floor_div(
    x, y, name=None
)
",Returns x // y element-wise.
tf.math.floordiv,"tf.math.floordiv(
    x, y, name=None
)
","Divides x / y elementwise, rounding toward the most negative integer.View aliases"
tf.math.floormod,"tf.math.floormod(
    x, y, name=None
)
",Returns element-wise remainder of division. When x < 0 xor y < 0 isView aliases
tf.compat.v1.foldl,"tf.compat.v1.foldl(
    fn,
    elems,
    initializer=None,
    parallel_iterations=10,
    back_prop=True,
    swap_memory=False,
    name=None
)
",foldl on the list of tensors unpacked from elems on dimension 0.
tf.compat.v1.foldr,"tf.compat.v1.foldr(
    fn,
    elems,
    initializer=None,
    parallel_iterations=10,
    back_prop=True,
    swap_memory=False,
    name=None
)
",foldr on the list of tensors unpacked from elems on dimension 0.
tf.function,"tf.function(
    func=None,
    input_signature=None,
    autograph=True,
    jit_compile=None,
    reduce_retracing=False,
    experimental_implements=None,
    experimental_autograph_options=None,
    experimental_relax_shapes=None,
    experimental_compile=None,
    experimental_follow_type_hints=None
) -> tf.types.experimental.GenericFunction
",Compiles a function into a callable TensorFlow graph. (deprecated arguments) (deprecated arguments)View aliases
tf.compat.v1.gather,"tf.compat.v1.gather(
    params, indices, validate_indices=None, name=None, axis=None, batch_dims=0
)
",Gather slices from params axis axis according to indices. (deprecated arguments)
tf.compat.v1.gather_nd,"tf.compat.v1.gather_nd(
    params, indices, name=None, batch_dims=0
)
",Gather slices from params into a Tensor with shape specified by indices.View aliases
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)tf.gather_nd(    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0'],        [b'a1', b'b1']],       [[b'a0', b'b0'],        [b'c1', b'd1']]], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)tf.gather_nd(    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0'],        [b'a1', b'b1']],       [[b'a0', b'b0'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'b0', b'b1'],       [b'd0', b'c1']], dtype=object)Examples with batched 'params' and 'indices':"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)tf.gather_nd(    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0'],        [b'a1', b'b1']],       [[b'a0', b'b0'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'b0', b'b1'],       [b'd0', b'c1']], dtype=object)Examples with batched 'params' and 'indices':tf.gather_nd(    batch_dims = 1,    indices = [[1],               [0]],    params = [[['a0', 'b0'],               ['c0', 'd0']],              [['a1', 'b1'],               ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)tf.gather_nd(    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0'],        [b'a1', b'b1']],       [[b'a0', b'b0'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'b0', b'b1'],       [b'd0', b'c1']], dtype=object)Examples with batched 'params' and 'indices':tf.gather_nd(    batch_dims = 1,    indices = [[1],               [0]],    params = [[['a0', 'b0'],               ['c0', 'd0']],              [['a1', 'b1'],               ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    batch_dims = 1,    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0']],       [[b'a1', b'b1']]], dtype=object)"
tf.compat.v1.get_collection,"tf.compat.v1.get_collection(
    key, scope=None
)
",Wrapper for Graph.get_collection() using the default graph.
tf.compat.v1.get_collection_ref,"tf.compat.v1.get_collection_ref(
    key
)
",Wrapper for Graph.get_collection_ref() using the default graph.
tf.compat.v1.get_local_variable,"tf.compat.v1.get_local_variable(
    name,
    shape=None,
    dtype=None,
    initializer=None,
    regularizer=None,
    trainable=False,
    collections=None,
    caching_device=None,
    partitioner=None,
    validate_shape=True,
    use_resource=None,
    custom_getter=None,
    constraint=None,
    synchronization=tf.VariableSynchronization.AUTO,
    aggregation=tf.compat.v1.VariableAggregation.NONE
)
",Gets an existing local variable or creates a new one.
tf.compat.v1.get_seed,"tf.compat.v1.get_seed(
    op_seed
)
",Returns the local seeds an operation should use given an op-specific seed.View aliases
tf.compat.v1.get_session_handle,"tf.compat.v1.get_session_handle(
    data, name=None
)
",Return the handle of data.
tf.compat.v1.get_session_tensor,"tf.compat.v1.get_session_tensor(
    handle, dtype, name=None
)
",Get the tensor of type dtype by feeding a tensor handle.
tf.get_static_value,"tf.get_static_value(
    tensor, partial=False
)
","Returns the constant value of the given tensor, if efficiently calculable.View aliases"
tf.compat.v1.get_variable,"tf.compat.v1.get_variable(
    name,
    shape=None,
    dtype=None,
    initializer=None,
    regularizer=None,
    trainable=None,
    collections=None,
    caching_device=None,
    partitioner=None,
    validate_shape=True,
    use_resource=None,
    custom_getter=None,
    constraint=None,
    synchronization=tf.VariableSynchronization.AUTO,
    aggregation=tf.compat.v1.VariableAggregation.NONE
)
",Gets an existing variable with these parameters or create a new one.
tf.compat.v1.gfile.Copy,"tf.compat.v1.gfile.Copy(
    oldpath, newpath, overwrite=False
)
",Copies data from src to dst.
tf.compat.v1.gfile.DeleteRecursively,"tf.compat.v1.gfile.DeleteRecursively(
    dirname
)
",Deletes everything under dirname recursively.
tf.compat.v1.gfile.Exists,"tf.compat.v1.gfile.Exists(
    filename
)
",Determines whether a path exists or not.
tf.compat.v1.gfile.FastGFile,"tf.compat.v1.gfile.FastGFile(
    name, mode='r'
)
",File I/O wrappers without thread locking.
tf.io.gfile.GFile,"tf.io.gfile.GFile(
    name, mode='r'
)
",File I/O wrappers without thread locking.View aliases
tf.compat.v1.gfile.Glob,"tf.compat.v1.gfile.Glob(
    filename
)
",Returns a list of files that match the given pattern(s).
tf.compat.v1.gfile.IsDirectory,"tf.compat.v1.gfile.IsDirectory(
    dirname
)
",Returns whether the path is a directory or not.
tf.compat.v1.gfile.ListDirectory,"tf.compat.v1.gfile.ListDirectory(
    dirname
)
",Returns a list of entries contained within a directory.
tf.compat.v1.gfile.MakeDirs,"tf.compat.v1.gfile.MakeDirs(
    dirname
)
",Creates a directory and all parent/intermediate directories.
tf.compat.v1.gfile.MkDir,"tf.compat.v1.gfile.MkDir(
    dirname
)
",Creates a directory with the name dirname.
tf.io.gfile.GFile,"tf.io.gfile.GFile(
    name, mode='r'
)
",File I/O wrappers without thread locking.View aliases
tf.compat.v1.gfile.Remove,"tf.compat.v1.gfile.Remove(
    filename
)
",Deletes the file located at 'filename'.
tf.compat.v1.gfile.Rename,"tf.compat.v1.gfile.Rename(
    oldname, newname, overwrite=False
)
",Rename or move a file / directory.
tf.compat.v1.gfile.Stat,"tf.compat.v1.gfile.Stat(
    filename
)
",Returns file statistics for a given path.
tf.compat.v1.gfile.Walk,"tf.compat.v1.gfile.Walk(
    top, in_order=True
)
",Recursive directory tree generator for directories.
tf.linalg.global_norm,"tf.linalg.global_norm(
    t_list, name=None
)
",Computes the global norm of multiple tensors.View aliases
tf.compat.v1.global_variables,"tf.compat.v1.global_variables(
    scope=None
)
",Returns global variables.
tf.compat.v1.keras.initializers.glorot_normal,"tf.compat.v1.keras.initializers.glorot_normal(
    seed=None,
    dtype=tf.dtypes.float32
)
","The Glorot normal initializer, also called Xavier normal initializer.Inherits From: VarianceScalingView aliases"
tf.compat.v1.keras.initializers.glorot_uniform,"tf.compat.v1.keras.initializers.glorot_uniform(
    seed=None,
    dtype=tf.dtypes.float32
)
","The Glorot uniform initializer, also called Xavier uniform initializer.Inherits From: VarianceScalingView aliases"
tf.grad_pass_through,"tf.grad_pass_through(
    f
)
",Creates a grad-pass-through op with the forward behavior provided in f.View aliases
tf.compat.v1.gradients,"tf.compat.v1.gradients(
    ys,
    xs,
    grad_ys=None,
    name='gradients',
    colocate_gradients_with_ops=False,
    gate_gradients=False,
    aggregation_method=None,
    stop_gradients=None,
    unconnected_gradients=tf.UnconnectedGradients.NONE
)
",Constructs symbolic derivatives of sum of ys w.r.t. x in xs.
tf.compat.v1.graph_util.convert_variables_to_constants,"tf.compat.v1.graph_util.convert_variables_to_constants(
    sess,
    input_graph_def,
    output_node_names,
    variable_names_whitelist=None,
    variable_names_blacklist=None
)
",Replaces all the variables in a graph with constants of the same values. (deprecated)
tf.compat.v1.graph_util.extract_sub_graph,"tf.compat.v1.graph_util.extract_sub_graph(
    graph_def, dest_nodes
)
",Extract the subgraph that can reach any of the nodes in 'dest_nodes'. (deprecated)
tf.graph_util.import_graph_def,"tf.graph_util.import_graph_def(
    graph_def,
    input_map=None,
    return_elements=None,
    name=None,
    op_dict=None,
    producer_op_list=None
)
",Imports the graph from graph_def into the current default Graph. (deprecated arguments)View aliases
tf.compat.v1.graph_util.must_run_on_cpu,"tf.compat.v1.graph_util.must_run_on_cpu(
    node, pin_variables_on_cpu=False
)
","Returns True if the given node_def must run on CPU, otherwise False. (deprecated)"
tf.compat.v1.graph_util.remove_training_nodes,"tf.compat.v1.graph_util.remove_training_nodes(
    input_graph, protected_nodes=None
)
",Prunes out nodes that aren't needed for inference. (deprecated)
tf.compat.v1.graph_util.tensor_shape_from_node_def_name,"tf.compat.v1.graph_util.tensor_shape_from_node_def_name(
    graph, input_name
)
",Convenience function to get a shape from a NodeDef's input string. (deprecated)
tf.math.greater,"tf.math.greater(
    x, y, name=None
)
",Returns the truth value of (x > y) element-wise.View aliases
tf.math.greater_equal,"tf.math.greater_equal(
    x, y, name=None
)
",Returns the truth value of (x >= y) element-wise.View aliases
tf.group,"tf.group(
    *inputs, **kwargs
)
",Create an op that groups multiple operations.View aliases
tf.guarantee_const,"tf.guarantee_const(
    input, name=None
)
",Promise to the TF runtime that the input tensor is a constant. (deprecated)View aliases
tf.compat.v1.hessians,"tf.compat.v1.hessians(
    ys,
    xs,
    name='hessians',
    colocate_gradients_with_ops=False,
    gate_gradients=False,
    aggregation_method=None
)
",Constructs the Hessian of sum of ys with respect to x in xs.
tf.histogram_fixed_width,"tf.histogram_fixed_width(
    values,
    value_range,
    nbins=100,
    dtype=tf.dtypes.int32,
    name=None
)
",Return histogram of values.View aliases
tf.histogram_fixed_width_bins,"tf.histogram_fixed_width_bins(
    values,
    value_range,
    nbins=100,
    dtype=tf.dtypes.int32,
    name=None
)
",Bins the given values for use in a histogram.View aliases
tf.identity,"tf.identity(
    input, name=None
)
",Return a Tensor with the same shape and contents as input.View aliases
tf.identity_n,"tf.identity_n(
    input, name=None
)
",Returns a list of tensors with the same shapes and contents as the inputView aliases
tf.signal.ifft,"tf.signal.ifft(
    input, name=None
)
",Inverse fast Fourier transform.View aliases
tf.signal.ifft2d,"tf.signal.ifft2d(
    input, name=None
)
",Inverse 2D fast Fourier transform.View aliases
tf.signal.ifft3d,"tf.signal.ifft3d(
    input, name=None
)
",Inverse 3D fast Fourier transform.View aliases
tf.math.igamma,"tf.math.igamma(
    a, x, name=None
)
","Compute the lower regularized incomplete Gamma function P(a, x).View aliases"
tf.math.igammac,"tf.math.igammac(
    a, x, name=None
)
","Compute the upper regularized incomplete Gamma function Q(a, x).View aliases"
tf.math.imag,"tf.math.imag(
    input, name=None
)
",Returns the imaginary part of a complex (or real) tensor.View aliases
tf.image.adjust_brightness,"tf.image.adjust_brightness(
    image, delta
)
",Adjust the brightness of RGB or Grayscale images.View aliases
tf.image.adjust_contrast,"tf.image.adjust_contrast(
    images, contrast_factor
)
",Adjust contrast of RGB or grayscale images.View aliases
tf.image.adjust_gamma,"tf.image.adjust_gamma(
    image, gamma=1, gain=1
)
",Performs Gamma Correction.View aliases
tf.image.adjust_hue,"tf.image.adjust_hue(
    image, delta, name=None
)
",Adjust hue of RGB images.View aliases
tf.image.adjust_jpeg_quality,"tf.image.adjust_jpeg_quality(
    image, jpeg_quality, name=None
)
",Adjust jpeg encoding quality of an image.View aliases
tf.image.adjust_saturation,"tf.image.adjust_saturation(
    image, saturation_factor, name=None
)
",Adjust saturation of RGB images.View aliases
tf.image.central_crop,"tf.image.central_crop(
    image, central_fraction
)
",Crop the central region of the image(s).View aliases
tf.image.combined_non_max_suppression,"tf.image.combined_non_max_suppression(
    boxes,
    scores,
    max_output_size_per_class,
    max_total_size,
    iou_threshold=0.5,
    score_threshold=float('-inf'),
    pad_per_class=False,
    clip_boxes=True,
    name=None
)
",Greedily selects a subset of bounding boxes in descending order of score.View aliases
tf.image.convert_image_dtype,"tf.image.convert_image_dtype(
    image, dtype, saturate=False, name=None
)
","Convert image to dtype, scaling its values if needed.View aliases"
tf.compat.v1.image.crop_and_resize,"tf.compat.v1.image.crop_and_resize(
    image,
    boxes,
    box_ind=None,
    crop_size=None,
    method='bilinear',
    extrapolation_value=0,
    name=None,
    box_indices=None
)
",Extracts crops from the input image tensor and resizes them.
tf.image.crop_to_bounding_box,"tf.image.crop_to_bounding_box(
    image, offset_height, offset_width, target_height, target_width
)
",Crops an image to a specified bounding box.View aliases
tf.io.decode_and_crop_jpeg,"tf.io.decode_and_crop_jpeg(
    contents,
    crop_window,
    channels=0,
    ratio=1,
    fancy_upscaling=True,
    try_recover_truncated=False,
    acceptable_fraction=1,
    dct_method='',
    name=None
)
",Decode and Crop a JPEG-encoded image to a uint8 tensor.View aliases
tf.io.decode_bmp,"tf.io.decode_bmp(
    contents, channels=0, name=None
)
",Decode the first frame of a BMP-encoded image to a uint8 tensor.View aliases
tf.io.decode_gif,"tf.io.decode_gif(
    contents, name=None
)
",Decode the frame(s) of a GIF-encoded image to a uint8 tensor.View aliases
tf.io.decode_image,"tf.io.decode_image(
    contents,
    channels=None,
    dtype=tf.dtypes.uint8,
    name=None,
    expand_animations=True
)
","Function for decode_bmp, decode_gif, decode_jpeg, and decode_png.View aliases"
tf.io.decode_jpeg,"tf.io.decode_jpeg(
    contents,
    channels=0,
    ratio=1,
    fancy_upscaling=True,
    try_recover_truncated=False,
    acceptable_fraction=1,
    dct_method='',
    name=None
)
",Decode a JPEG-encoded image to a uint8 tensor.View aliases
tf.io.decode_png,"tf.io.decode_png(
    contents,
    channels=0,
    dtype=tf.dtypes.uint8,
    name=None
)
",Decode a PNG-encoded image to a uint8 or uint16 tensor.View aliases
tf.compat.v1.image.draw_bounding_boxes,"tf.compat.v1.image.draw_bounding_boxes(
    images, boxes, name=None, colors=None
)
",Draw bounding boxes on a batch of images.
tf.io.encode_jpeg,"tf.io.encode_jpeg(
    image,
    format='',
    quality=95,
    progressive=False,
    optimize_size=False,
    chroma_downsampling=True,
    density_unit='in',
    x_density=300,
    y_density=300,
    xmp_metadata='',
    name=None
)
",JPEG-encode an image.View aliases
tf.io.encode_png,"tf.io.encode_png(
    image, compression=-1, name=None
)
",PNG-encode an image.View aliases
tf.compat.v1.image.extract_glimpse,"tf.compat.v1.image.extract_glimpse(
    input,
    size,
    offsets,
    centered=True,
    normalized=True,
    uniform_noise=True,
    name=None
)
",Extracts a glimpse from the input tensor.
tf.compat.v1.extract_image_patches,"tf.compat.v1.extract_image_patches(
    images,
    ksizes=None,
    strides=None,
    rates=None,
    padding=None,
    name=None,
    sizes=None
)
","Extract patches from images and put them in the ""depth"" output dimension.View aliases"
tf.io.extract_jpeg_shape,"tf.io.extract_jpeg_shape(
    contents,
    output_type=tf.dtypes.int32,
    name=None
)
",Extract the shape information of a JPEG-encoded image.View aliases
tf.image.extract_patches,"tf.image.extract_patches(
    images, sizes, strides, rates, padding, name=None
)
",Extract patches from images.View aliases
tf.image.flip_left_right,"tf.image.flip_left_right(
    image
)
",Flip an image horizontally (left to right).View aliases
tf.image.flip_up_down,"tf.image.flip_up_down(
    image
)
",Flip an image vertically (upside down).View aliases
tf.image.generate_bounding_box_proposals,"tf.image.generate_bounding_box_proposals(
    scores,
    bbox_deltas,
    image_info,
    anchors,
    nms_threshold=0.7,
    pre_nms_topn=6000,
    min_size=16,
    post_nms_topn=300,
    name=None
)
",Generate bounding box proposals from encoded bounding boxes.View aliases
tf.image.grayscale_to_rgb,"tf.image.grayscale_to_rgb(
    images, name=None
)
",Converts one or more images from Grayscale to RGB.View aliases
tf.image.hsv_to_rgb,"tf.image.hsv_to_rgb(
    images, name=None
)
",Convert one or more images from HSV to RGB.View aliases
tf.image.image_gradients,"tf.image.image_gradients(
    image
)
","Returns image gradients (dy, dx) for each color channel.View aliases"
tf.io.is_jpeg,"tf.io.is_jpeg(
    contents, name=None
)
",Convenience function to check if the 'contents' encodes a JPEG image.View aliases
tf.image.non_max_suppression,"tf.image.non_max_suppression(
    boxes,
    scores,
    max_output_size,
    iou_threshold=0.5,
    score_threshold=float('-inf'),
    name=None
)
",Greedily selects a subset of bounding boxes in descending order of score.View aliases
tf.image.non_max_suppression_overlaps,"tf.image.non_max_suppression_overlaps(
    overlaps,
    scores,
    max_output_size,
    overlap_threshold=0.5,
    score_threshold=float('-inf'),
    name=None
)
",Greedily selects a subset of bounding boxes in descending order of score.View aliases
tf.image.non_max_suppression_padded,"tf.image.non_max_suppression_padded(
    boxes,
    scores,
    max_output_size,
    iou_threshold=0.5,
    score_threshold=float('-inf'),
    pad_to_max_output_size=False,
    name=None,
    sorted_input=False,
    canonicalized_coordinates=False,
    tile_size=512
)
",Greedily selects a subset of bounding boxes in descending order of score.View aliases
tf.image.non_max_suppression_with_scores,"tf.image.non_max_suppression_with_scores(
    boxes,
    scores,
    max_output_size,
    iou_threshold=0.5,
    score_threshold=float('-inf'),
    soft_nms_sigma=0.0,
    name=None
)
",Greedily selects a subset of bounding boxes in descending order of score.View aliases
tf.image.pad_to_bounding_box,"tf.image.pad_to_bounding_box(
    image, offset_height, offset_width, target_height, target_width
)
",Pad image with zeros to the specified height and width.View aliases
tf.image.per_image_standardization,"tf.image.per_image_standardization(
    image
)
",Linearly scales each image in image to have mean 0 and variance 1.View aliases
tf.image.psnr,"tf.image.psnr(
    a, b, max_val, name=None
)
",Returns the Peak Signal-to-Noise Ratio between a and b.View aliases
tf.image.random_brightness,"tf.image.random_brightness(
    image, max_delta, seed=None
)
",Adjust the brightness of images by a random factor.View aliases
tf.image.random_contrast,"tf.image.random_contrast(
    image, lower, upper, seed=None
)
",Adjust the contrast of an image or images by a random factor.View aliases
tf.image.random_crop,"tf.image.random_crop(
    value, size, seed=None, name=None
)
",Randomly crops a tensor to a given size.View aliases
tf.image.random_flip_left_right,"tf.image.random_flip_left_right(
    image, seed=None
)
",Randomly flip an image horizontally (left to right).View aliases
tf.image.random_flip_up_down,"tf.image.random_flip_up_down(
    image, seed=None
)
",Randomly flips an image vertically (upside down).View aliases
tf.image.random_hue,"tf.image.random_hue(
    image, max_delta, seed=None
)
",Adjust the hue of RGB images by a random factor.View aliases
tf.image.random_jpeg_quality,"tf.image.random_jpeg_quality(
    image, min_jpeg_quality, max_jpeg_quality, seed=None
)
",Randomly changes jpeg encoding quality for inducing jpeg noise.View aliases
tf.image.random_saturation,"tf.image.random_saturation(
    image, lower, upper, seed=None
)
",Adjust the saturation of RGB images by a random factor.View aliases
tf.compat.v1.image.resize,"tf.compat.v1.image.resize(
    images,
    size,
    method=ResizeMethodV1.BILINEAR,
    align_corners=False,
    preserve_aspect_ratio=False,
    name=None
)
",Resize images to size using the specified method.View aliases
tf.compat.v1.image.resize_area,"tf.compat.v1.image.resize_area(
    images, size, align_corners=False, name=None
)
",Resize images to size using area interpolation.
tf.compat.v1.image.resize_bicubic,"tf.compat.v1.image.resize_bicubic(
    images, size, align_corners=False, name=None, half_pixel_centers=False
)
",nan
tf.compat.v1.image.resize_bilinear,"tf.compat.v1.image.resize_bilinear(
    images, size, align_corners=False, name=None, half_pixel_centers=False
)
",nan
tf.image.resize_with_crop_or_pad,"tf.image.resize_with_crop_or_pad(
    image, target_height, target_width
)
",Crops and/or pads an image to a target width and height.View aliases
tf.compat.v1.image.resize_image_with_pad,"tf.compat.v1.image.resize_image_with_pad(
    image,
    target_height,
    target_width,
    method=ResizeMethodV1.BILINEAR,
    align_corners=False
)
",Resizes and pads an image to a target width and height.
tf.compat.v1.image.resize,"tf.compat.v1.image.resize(
    images,
    size,
    method=ResizeMethodV1.BILINEAR,
    align_corners=False,
    preserve_aspect_ratio=False,
    name=None
)
",Resize images to size using the specified method.View aliases
tf.compat.v1.image.resize_nearest_neighbor,"tf.compat.v1.image.resize_nearest_neighbor(
    images, size, align_corners=False, name=None, half_pixel_centers=False
)
",nan
tf.image.resize_with_crop_or_pad,"tf.image.resize_with_crop_or_pad(
    image, target_height, target_width
)
",Crops and/or pads an image to a target width and height.View aliases
tf.image.rgb_to_grayscale,"tf.image.rgb_to_grayscale(
    images, name=None
)
",Converts one or more images from RGB to Grayscale.View aliases
tf.image.rgb_to_hsv,"tf.image.rgb_to_hsv(
    images, name=None
)
",Converts one or more images from RGB to HSV.View aliases
tf.image.rgb_to_yiq,"tf.image.rgb_to_yiq(
    images
)
",Converts one or more images from RGB to YIQ.View aliases
tf.image.rgb_to_yuv,"tf.image.rgb_to_yuv(
    images
)
",Converts one or more images from RGB to YUV.View aliases
tf.image.rot90,"tf.image.rot90(
    image, k=1, name=None
)
",Rotate image(s) counter-clockwise by 90 degrees.View aliases
tf.compat.v1.image.sample_distorted_bounding_box,"tf.compat.v1.image.sample_distorted_bounding_box(
    image_size,
    bounding_boxes,
    seed=None,
    seed2=None,
    min_object_covered=0.1,
    aspect_ratio_range=None,
    area_range=None,
    max_attempts=None,
    use_image_if_no_bounding_boxes=None,
    name=None
)
",Generate a single randomly distorted bounding box for an image. (deprecated)
tf.image.sobel_edges,"tf.image.sobel_edges(
    image
)
",Returns a tensor holding Sobel edge maps.View aliases
tf.image.ssim,"tf.image.ssim(
    img1, img2, max_val, filter_size=11, filter_sigma=1.5, k1=0.01, k2=0.03
)
",Computes SSIM index between img1 and img2.View aliases
tf.image.ssim_multiscale,"tf.image.ssim_multiscale(
    img1,
    img2,
    max_val,
    power_factors=_MSSSIM_WEIGHTS,
    filter_size=11,
    filter_sigma=1.5,
    k1=0.01,
    k2=0.03
)
",Computes the MS-SSIM between img1 and img2.View aliases
tf.image.total_variation,"tf.image.total_variation(
    images, name=None
)
",Calculate and return the total variation for one or more images.View aliases
tf.image.transpose,"tf.image.transpose(
    image, name=None
)
",Transpose image(s) by swapping the height and width dimension.View aliases
tf.image.transpose,"tf.image.transpose(
    image, name=None
)
",Transpose image(s) by swapping the height and width dimension.View aliases
tf.image.yiq_to_rgb,"tf.image.yiq_to_rgb(
    images
)
",Converts one or more images from YIQ to RGB.View aliases
tf.image.yuv_to_rgb,"tf.image.yuv_to_rgb(
    images
)
",Converts one or more images from YUV to RGB.View aliases
tf.graph_util.import_graph_def,"tf.graph_util.import_graph_def(
    graph_def,
    input_map=None,
    return_elements=None,
    name=None,
    op_dict=None,
    producer_op_list=None
)
",Imports the graph from graph_def into the current default Graph. (deprecated arguments)View aliases
tf.compat.v1.initialize_all_tables,"tf.compat.v1.initialize_all_tables(
    name='init_all_tables'
)
",Returns an Op that initializes all tables of the default graph. (deprecated)
tf.compat.v1.initialize_variables,"tf.compat.v1.initialize_variables(
    var_list, name='init'
)
",See tf.compat.v1.variables_initializer. (deprecated)
tf.compat.v1.keras.initializers.Constant,"tf.compat.v1.keras.initializers.Constant(
    value=0,
    dtype=tf.dtypes.float32,
    verify_shape=False
)
",Initializer that generates tensors with constant values.View aliases
tf.compat.v1.keras.initializers.glorot_normal,"tf.compat.v1.keras.initializers.glorot_normal(
    seed=None,
    dtype=tf.dtypes.float32
)
","The Glorot normal initializer, also called Xavier normal initializer.Inherits From: VarianceScalingView aliases"
tf.compat.v1.keras.initializers.glorot_uniform,"tf.compat.v1.keras.initializers.glorot_uniform(
    seed=None,
    dtype=tf.dtypes.float32
)
","The Glorot uniform initializer, also called Xavier uniform initializer.Inherits From: VarianceScalingView aliases"
tf.compat.v1.initializers.he_normal,"tf.compat.v1.initializers.he_normal(
    seed=None
)
",He normal initializer.
tf.compat.v1.initializers.he_uniform,"tf.compat.v1.initializers.he_uniform(
    seed=None
)
",He uniform variance scaling initializer.
tf.compat.v1.keras.initializers.Identity,"tf.compat.v1.keras.initializers.Identity(
    gain=1.0,
    dtype=tf.dtypes.float32
)
",Initializer that generates the identity matrix.View aliases
tf.compat.v1.initializers.lecun_normal,"tf.compat.v1.initializers.lecun_normal(
    seed=None
)
",LeCun normal initializer.
tf.compat.v1.initializers.lecun_uniform,"tf.compat.v1.initializers.lecun_uniform(
    seed=None
)
",LeCun uniform initializer.
tf.compat.v1.keras.initializers.Ones,"tf.compat.v1.keras.initializers.Ones(
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors initialized to 1.View aliases
tf.compat.v1.keras.initializers.Orthogonal,"tf.compat.v1.keras.initializers.Orthogonal(
    gain=1.0,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates an orthogonal matrix.View aliases
tf.compat.v1.random_normal_initializer,"tf.compat.v1.random_normal_initializer(
    mean=0.0,
    stddev=1.0,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors with a normal distribution.View aliases
tf.compat.v1.random_uniform_initializer,"tf.compat.v1.random_uniform_initializer(
    minval=0.0,
    maxval=None,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors with a uniform distribution.View aliases
tf.compat.v1.tables_initializer,"tf.compat.v1.tables_initializer(
    name='init_all_tables'
)
",Returns an Op that initializes all tables of the default graph.View aliases
tf.compat.v1.truncated_normal_initializer,"tf.compat.v1.truncated_normal_initializer(
    mean=0.0,
    stddev=1.0,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates a truncated normal distribution.View aliases
tf.compat.v1.uniform_unit_scaling_initializer,"tf.compat.v1.uniform_unit_scaling_initializer(
    factor=1.0,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors without scaling variance.View aliases
tf.compat.v1.variables_initializer,"tf.compat.v1.variables_initializer(
    var_list, name='init'
)
",Returns an Op that initializes a list of variables.View aliases
tf.compat.v1.keras.initializers.VarianceScaling,"tf.compat.v1.keras.initializers.VarianceScaling(
    scale=1.0,
    mode='fan_in',
    distribution='truncated_normal',
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer capable of adapting its scale to the shape of weights tensors.View aliases
tf.compat.v1.keras.initializers.Zeros,"tf.compat.v1.keras.initializers.Zeros(
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors initialized to 0.View aliases
tf.math.invert_permutation,"tf.math.invert_permutation(
    x, name=None
)
",Computes the inverse permutation of a tensor.View aliases
tf.io.FixedLenFeature,"tf.io.FixedLenFeature(
    shape, dtype, default_value=None
)
",Configuration for parsing a fixed-length input feature.View aliases
tf.io.FixedLenSequenceFeature,"tf.io.FixedLenSequenceFeature(
    shape, dtype, allow_missing=False, default_value=None
)
",Configuration for parsing a variable-length input feature into a Tensor.View aliases
tf.queue.PaddingFIFOQueue,"tf.queue.PaddingFIFOQueue(
    capacity,
    dtypes,
    shapes,
    names=None,
    shared_name=None,
    name='padding_fifo_queue'
)
",A FIFOQueue that supports batching variable-sized tensors by padding.Inherits From: QueueBaseView aliases
tf.queue.PriorityQueue,"tf.queue.PriorityQueue(
    capacity,
    types,
    shapes=None,
    names=None,
    shared_name=None,
    name='priority_queue'
)
",A queue implementation that dequeues elements in prioritized order.Inherits From: QueueBaseView aliases
tf.queue.QueueBase,"tf.queue.QueueBase(
    dtypes, shapes, names, queue_ref
)
",Base class for queue implementations.View aliases
tf.io.RaggedFeature,"tf.io.RaggedFeature(
    dtype,
    value_key=None,
    partitions=(),
    row_splits_dtype=tf.dtypes.int32,
    validate=False
)
",Configuration for passing a RaggedTensor input feature.View aliases
tf.io.RaggedFeature.RowLengths,"tf.io.RaggedFeature.RowLengths(
    key
)
","RowLengths(key,)View aliases"
tf.io.RaggedFeature.RowLimits,"tf.io.RaggedFeature.RowLimits(
    key
)
","RowLimits(key,)View aliases"
tf.io.RaggedFeature.RowSplits,"tf.io.RaggedFeature.RowSplits(
    key
)
","RowSplits(key,)View aliases"
tf.io.RaggedFeature.RowStarts,"tf.io.RaggedFeature.RowStarts(
    key
)
","RowStarts(key,)View aliases"
tf.io.RaggedFeature.UniformRowLength,"tf.io.RaggedFeature.UniformRowLength(
    length
)
","UniformRowLength(length,)View aliases"
tf.io.RaggedFeature.ValueRowIds,"tf.io.RaggedFeature.ValueRowIds(
    key
)
","ValueRowIds(key,)View aliases"
tf.queue.RandomShuffleQueue,"tf.queue.RandomShuffleQueue(
    capacity,
    min_after_dequeue,
    dtypes,
    shapes=None,
    names=None,
    seed=None,
    shared_name=None,
    name='random_shuffle_queue'
)
",A queue implementation that dequeues elements in a random order.Inherits From: QueueBaseView aliases
tf.io.SparseFeature,"tf.io.SparseFeature(
    index_key, value_key, dtype, size, already_sorted=False
)
",Configuration for parsing a sparse input feature from an Example.View aliases
tf.io.TFRecordOptions,"tf.io.TFRecordOptions(
    compression_type=None,
    flush_mode=None,
    input_buffer_size=None,
    output_buffer_size=None,
    window_bits=None,
    compression_level=None,
    compression_method=None,
    mem_level=None,
    compression_strategy=None
)
",Options used for manipulating TFRecord files.View aliases
tf.io.TFRecordWriter,"tf.io.TFRecordWriter(
    path, options=None
)
",A class to write records to a TFRecords file.View aliases
tf.io.VarLenFeature,"tf.io.VarLenFeature(
    dtype
)
",Configuration for parsing a variable-length input feature.View aliases
tf.io.decode_and_crop_jpeg,"tf.io.decode_and_crop_jpeg(
    contents,
    crop_window,
    channels=0,
    ratio=1,
    fancy_upscaling=True,
    try_recover_truncated=False,
    acceptable_fraction=1,
    dct_method='',
    name=None
)
",Decode and Crop a JPEG-encoded image to a uint8 tensor.View aliases
tf.io.decode_base64,"tf.io.decode_base64(
    input, name=None
)
",Decode web-safe base64-encoded strings.View aliases
tf.io.decode_bmp,"tf.io.decode_bmp(
    contents, channels=0, name=None
)
",Decode the first frame of a BMP-encoded image to a uint8 tensor.View aliases
tf.io.decode_compressed,"tf.io.decode_compressed(
    bytes, compression_type='', name=None
)
",Decompress strings.View aliases
tf.compat.v1.decode_csv,"tf.compat.v1.decode_csv(
    records,
    record_defaults,
    field_delim=',',
    use_quote_delim=True,
    name=None,
    na_value='',
    select_cols=None
)
",Convert CSV records to tensors. Each column maps to one tensor.View aliases
tf.io.decode_gif,"tf.io.decode_gif(
    contents, name=None
)
",Decode the frame(s) of a GIF-encoded image to a uint8 tensor.View aliases
tf.io.decode_image,"tf.io.decode_image(
    contents,
    channels=None,
    dtype=tf.dtypes.uint8,
    name=None,
    expand_animations=True
)
","Function for decode_bmp, decode_gif, decode_jpeg, and decode_png.View aliases"
tf.io.decode_jpeg,"tf.io.decode_jpeg(
    contents,
    channels=0,
    ratio=1,
    fancy_upscaling=True,
    try_recover_truncated=False,
    acceptable_fraction=1,
    dct_method='',
    name=None
)
",Decode a JPEG-encoded image to a uint8 tensor.View aliases
tf.io.decode_json_example,"tf.io.decode_json_example(
    json_examples, name=None
)
",Convert JSON-encoded Example records to binary protocol buffer strings.View aliases
tf.io.decode_json_example,tf.io.decode_json_example([,"Convert JSON-encoded Example records to binary protocol buffer strings.View aliasestf.io.decode_json_example(    json_examples, name=None)Note: This is This op converts JSON-serialized tf.train.Example (maybe created withjson_format.MessageToJson, following thestandard JSON mapping)to a binary-serialized tf.train.Example (equivalent toExample.SerializeToString()) suitable for conversion to tensors withtf.io.parse_example.Here is a tf.train.Example proto:example = tf.train.Example(  features=tf.train.Features(      feature={          ""a"": tf.train.Feature(              int64_list=tf.train.Int64List(                  value=[1, 1, 3]))}))Here it is converted to JSON:from google.protobuf import json_formatexample_json = json_format.MessageToJson(example)print(example_json){  ""features"": {    ""feature"": {      ""a"": {        ""int64List"": {          ""value"": [            ""1"",            ""1"",            ""3""          ]        }      }    }  }}This op converts the above json string to a binary proto:example_binary = tf.io.decode_json_example(example_json)example_binary.numpy()b'\n\x0f\n\r\n\x01a\x12\x08\x1a\x06\x08\x01\x08\x01\x08\x03'The OP works on string tensors of andy shape:"
tf.io.parse_example,tf.io.parse_example(,"Convert JSON-encoded Example records to binary protocol buffer strings.View aliasestf.io.decode_json_example(    json_examples, name=None)Note: This is This op converts JSON-serialized tf.train.Example (maybe created withjson_format.MessageToJson, following thestandard JSON mapping)to a binary-serialized tf.train.Example (equivalent toExample.SerializeToString()) suitable for conversion to tensors withtf.io.parse_example.Here is a tf.train.Example proto:example = tf.train.Example(  features=tf.train.Features(      feature={          ""a"": tf.train.Feature(              int64_list=tf.train.Int64List(                  value=[1, 1, 3]))}))Here it is converted to JSON:from google.protobuf import json_formatexample_json = json_format.MessageToJson(example)print(example_json){  ""features"": {    ""feature"": {      ""a"": {        ""int64List"": {          ""value"": [            ""1"",            ""1"",            ""3""          ]        }      }    }  }}This op converts the above json string to a binary proto:example_binary = tf.io.decode_json_example(example_json)example_binary.numpy()b'\n\x0f\n\r\n\x01a\x12\x08\x1a\x06\x08\x01\x08\x01\x08\x03'The OP works on string tensors of andy shape:tf.io.decode_json_example([    [example_json, example_json],    [example_json, example_json]]).shape.as_list()[2, 2]This resulting binary-string is equivalent to Example.SerializeToString(),and can be converted to Tensors using tf.io.parse_example and relatedfunctions:"
tf.io.decode_png,"tf.io.decode_png(
    contents,
    channels=0,
    dtype=tf.dtypes.uint8,
    name=None
)
",Decode a PNG-encoded image to a uint8 or uint16 tensor.View aliases
tf.io.decode_proto,"tf.io.decode_proto(
    bytes,
    message_type,
    field_names,
    output_types,
    descriptor_source='local://',
    message_format='binary',
    sanitize=False,
    name=None
)
",The op extracts fields from a serialized protocol buffers message into tensors.View aliases
tf.compat.v1.decode_raw,"tf.compat.v1.decode_raw(
    input_bytes=None, out_type=None, little_endian=True, name=None, bytes=None
)
",Convert raw byte strings into tensors. (deprecated arguments)View aliases
tf.io.deserialize_many_sparse,"tf.io.deserialize_many_sparse(
    serialized_sparse, dtype, rank=None, name=None
)
",Deserialize and concatenate SparseTensors from a serialized minibatch.View aliases
tf.io.encode_base64,"tf.io.encode_base64(
    input, pad=False, name=None
)
",Encode strings into web-safe base64 format.View aliases
tf.io.encode_jpeg,"tf.io.encode_jpeg(
    image,
    format='',
    quality=95,
    progressive=False,
    optimize_size=False,
    chroma_downsampling=True,
    density_unit='in',
    x_density=300,
    y_density=300,
    xmp_metadata='',
    name=None
)
",JPEG-encode an image.View aliases
tf.io.encode_png,"tf.io.encode_png(
    image, compression=-1, name=None
)
",PNG-encode an image.View aliases
tf.io.encode_proto,"tf.io.encode_proto(
    sizes,
    values,
    field_names,
    message_type,
    descriptor_source='local://',
    name=None
)
",The op serializes protobuf messages provided in the input tensors.View aliases
tf.io.extract_jpeg_shape,"tf.io.extract_jpeg_shape(
    contents,
    output_type=tf.dtypes.int32,
    name=None
)
",Extract the shape information of a JPEG-encoded image.View aliases
tf.io.gfile.GFile,"tf.io.gfile.GFile(
    name, mode='r'
)
",File I/O wrappers without thread locking.View aliases
tf.io.gfile.copy,"tf.io.gfile.copy(
    src, dst, overwrite=False
)
",Copies data from src to dst.View aliases
tf.io.gfile.exists,"tf.io.gfile.exists(
    path
)
",Determines whether a path exists or not.View aliases
tf.io.gfile.glob,"tf.io.gfile.glob(
    pattern
)
",Returns a list of files that match the given pattern(s).View aliases
tf.io.gfile.isdir,"tf.io.gfile.isdir(
    path
)
",Returns whether the path is a directory or not.View aliases
tf.io.gfile.join,"tf.io.gfile.join(
    path, *paths
)
",Join one or more path components intelligently.View aliases
tf.io.gfile.listdir,"tf.io.gfile.listdir(
    path
)
",Returns a list of entries contained within a directory.View aliases
tf.io.gfile.makedirs,"tf.io.gfile.makedirs(
    path
)
",Creates a directory and all parent/intermediate directories.View aliases
tf.io.gfile.mkdir,"tf.io.gfile.mkdir(
    path
)
",Creates a directory with the name given by path.View aliases
tf.io.gfile.remove,"tf.io.gfile.remove(
    path
)
",Deletes the path located at 'path'.View aliases
tf.io.gfile.rename,"tf.io.gfile.rename(
    src, dst, overwrite=False
)
",Rename or move a file / directory.View aliases
tf.io.gfile.rmtree,"tf.io.gfile.rmtree(
    path
)
",Deletes everything under path recursively.View aliases
tf.io.gfile.stat,"tf.io.gfile.stat(
    path
)
",Returns file statistics for a given path.View aliases
tf.io.gfile.walk,"tf.io.gfile.walk(
    top, topdown=True, onerror=None
)
",Recursive directory tree generator for directories.View aliases
tf.io.is_jpeg,"tf.io.is_jpeg(
    contents, name=None
)
",Convenience function to check if the 'contents' encodes a JPEG image.View aliases
tf.io.match_filenames_once,"tf.io.match_filenames_once(
    pattern, name=None
)
","Save the list of files matching pattern, so it is only computed once.View aliases"
tf.io.matching_files,"tf.io.matching_files(
    pattern, name=None
)
",Returns the set of files matching one or more glob patterns.View aliases
tf.compat.v1.parse_example,"tf.compat.v1.parse_example(
    serialized, features, name=None, example_names=None
)
",Parses Example protos into a dict of tensors.View aliases
tf.io.parse_sequence_example,"tf.io.parse_sequence_example(
    serialized,
    context_features=None,
    sequence_features=None,
    example_names=None,
    name=None
)
",Parses a batch of SequenceExample protos.View aliases
tf.compat.v1.parse_single_example,"tf.compat.v1.parse_single_example(
    serialized, features, name=None, example_names=None
)
",Parses a single Example proto.View aliases
tf.io.parse_single_sequence_example,"tf.io.parse_single_sequence_example(
    serialized,
    context_features=None,
    sequence_features=None,
    example_name=None,
    name=None
)
",Parses a single SequenceExample proto.View aliases
tf.io.parse_tensor,"tf.io.parse_tensor(
    serialized, out_type, name=None
)
",Transforms a serialized tensorflow.TensorProto proto into a Tensor.View aliases
tf.io.read_file,"tf.io.read_file(
    filename, name=None
)
",Reads the contents of file.View aliases
tf.compat.v1.serialize_many_sparse,"tf.compat.v1.serialize_many_sparse(
    sp_input,
    name=None,
    out_type=tf.dtypes.string
)
","Serialize N-minibatch SparseTensor into an [N, 3] Tensor.View aliases"
tf.compat.v1.serialize_sparse,"tf.compat.v1.serialize_sparse(
    sp_input,
    name=None,
    out_type=tf.dtypes.string
)
",Serialize a SparseTensor into a 3-vector (1-D Tensor) object.View aliases
tf.io.serialize_tensor,"tf.io.serialize_tensor(
    tensor, name=None
)
",Transforms a Tensor into a serialized TensorProto proto.View aliases
tf.compat.v1.io.tf_record_iterator,"tf.compat.v1.io.tf_record_iterator(
    path, options=None
)
",An iterator that read the records from a TFRecords file. (deprecated)View aliases
tf.io.write_file,"tf.io.write_file(
    filename, contents, name=None
)
",Writes contents to the file at input filename.View aliases
tf.io.write_graph,"tf.io.write_graph(
    graph_or_graph_def, logdir, name, as_text=True
)
",Writes a graph proto to a file.View aliases
tf.math.is_finite,"tf.math.is_finite(
    x, name=None
)
",Returns which elements of x are finite.View aliases
tf.math.is_inf,"tf.math.is_inf(
    x, name=None
)
",Returns which elements of x are Inf.View aliases
tf.math.is_nan,"tf.math.is_nan(
    x, name=None
)
",Returns which elements of x are NaN.View aliases
tf.math.is_non_decreasing,"tf.math.is_non_decreasing(
    x, name=None
)
",Returns True if x is non-decreasing.View aliases
tf.debugging.is_numeric_tensor,"tf.debugging.is_numeric_tensor(
    tensor
)
",Returns True if the elements of tensor are numbers.View aliases
tf.math.is_strictly_increasing,"tf.math.is_strictly_increasing(
    x, name=None
)
",Returns True if x is strictly increasing.View aliases
tf.is_tensor,"tf.is_tensor(
    x
)
",Checks whether x is a TF-native type that can be passed to many TF ops.View aliases
tf.compat.v1.is_variable_initialized,"tf.compat.v1.is_variable_initialized(
    variable
)
",Tests if a variable has been initialized.
tf.keras.Input,"tf.keras.Input(
    shape=None,
    batch_size=None,
    name=None,
    dtype=None,
    sparse=None,
    tensor=None,
    ragged=None,
    type_spec=None,
    **kwargs
)
",Input() is used to instantiate a Keras tensor.View aliases
tf.keras.Model,"tf.keras.Model(
    *args, **kwargs
)
","Model groups layers into an object with training and inference features.Inherits From: Layer, ModuleView aliases"
tf.keras.Sequential,"tf.keras.Sequential(
    layers=None, name=None
)
","Sequential groups a linear stack of layers into a tf.keras.Model.Inherits From: Model, Layer, ModuleView aliases"
tf.keras.activations.deserialize,"tf.keras.activations.deserialize(
    name, custom_objects=None
)
",Returns activation function given a string identifier.View aliases
tf.keras.activations.elu,"tf.keras.activations.elu(
    x, alpha=1.0
)
",Exponential Linear Unit.View aliases
tf.keras.activations.exponential,"tf.keras.activations.exponential(
    x
)
",Exponential activation function.View aliases
tf.keras.activations.get,"tf.keras.activations.get(
    identifier
)
",Returns function.View aliases
tf.keras.activations.hard_sigmoid,"tf.keras.activations.hard_sigmoid(
    x
)
",Hard sigmoid activation function.View aliases
tf.keras.activations.linear,"tf.keras.activations.linear(
    x
)
",Linear activation function (pass-through).View aliases
tf.keras.activations.relu,"tf.keras.activations.relu(
    x, alpha=0.0, max_value=None, threshold=0.0
)
",Applies the rectified linear unit activation function.View aliases
tf.keras.activations.selu,"tf.keras.activations.selu(
    x
)
",Scaled Exponential Linear Unit (SELU).View aliases
tf.keras.activations.serialize,"tf.keras.activations.serialize(
    activation
)
",Returns the string identifier of an activation function.View aliases
tf.keras.activations.sigmoid,"tf.keras.activations.sigmoid(
    x
)
","Sigmoid activation function, sigmoid(x) = 1 / (1 + exp(-x)).View aliases"
tf.keras.activations.softmax,"tf.keras.activations.softmax(
    x, axis=-1
)
",Softmax converts a vector of values to a probability distribution.View aliases
tf.keras.activations.softplus,"tf.keras.activations.softplus(
    x
)
","Softplus activation function, softplus(x) = log(exp(x) + 1).View aliases"
tf.keras.activations.softsign,"tf.keras.activations.softsign(
    x
)
","Softsign activation function, softsign(x) = x / (abs(x) + 1).View aliases"
tf.keras.activations.swish,"tf.keras.activations.swish(
    x
)
","Swish activation function, swish(x) = x * sigmoid(x).View aliases"
tf.keras.activations.tanh,"tf.keras.activations.tanh(
    x
)
",Hyperbolic tangent activation function.View aliases
tf.keras.applications.convnext.ConvNeXtBase,"tf.keras.applications.convnext.ConvNeXtBase(
    model_name='convnext_base',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtBase architecture.View aliases
tf.keras.applications.convnext.ConvNeXtLarge,"tf.keras.applications.convnext.ConvNeXtLarge(
    model_name='convnext_large',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtLarge architecture.View aliases
tf.keras.applications.convnext.ConvNeXtSmall,"tf.keras.applications.convnext.ConvNeXtSmall(
    model_name='convnext_small',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtSmall architecture.View aliases
tf.keras.applications.convnext.ConvNeXtTiny,"tf.keras.applications.convnext.ConvNeXtTiny(
    model_name='convnext_tiny',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtTiny architecture.View aliases
tf.keras.applications.convnext.ConvNeXtXLarge,"tf.keras.applications.convnext.ConvNeXtXLarge(
    model_name='convnext_xlarge',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtXLarge architecture.View aliases
tf.keras.applications.densenet.DenseNet121,"tf.keras.applications.densenet.DenseNet121(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Densenet121 architecture.View aliases
tf.keras.applications.densenet.DenseNet169,"tf.keras.applications.densenet.DenseNet169(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Densenet169 architecture.View aliases
tf.keras.applications.densenet.DenseNet201,"tf.keras.applications.densenet.DenseNet201(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Densenet201 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB0,"tf.keras.applications.efficientnet.EfficientNetB0(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB0 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB1,"tf.keras.applications.efficientnet.EfficientNetB1(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB1 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB2,"tf.keras.applications.efficientnet.EfficientNetB2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB2 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB3,"tf.keras.applications.efficientnet.EfficientNetB3(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB3 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB4,"tf.keras.applications.efficientnet.EfficientNetB4(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB4 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB5,"tf.keras.applications.efficientnet.EfficientNetB5(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB5 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB6,"tf.keras.applications.efficientnet.EfficientNetB6(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB6 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB7,"tf.keras.applications.efficientnet.EfficientNetB7(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB7 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B0,"tf.keras.applications.efficientnet_v2.EfficientNetV2B0(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B0 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B1,"tf.keras.applications.efficientnet_v2.EfficientNetV2B1(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B1 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B2,"tf.keras.applications.efficientnet_v2.EfficientNetV2B2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B2 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B3,"tf.keras.applications.efficientnet_v2.EfficientNetV2B3(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B3 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2L,"tf.keras.applications.efficientnet_v2.EfficientNetV2L(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2L architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2M,"tf.keras.applications.efficientnet_v2.EfficientNetV2M(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2M architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2S,"tf.keras.applications.efficientnet_v2.EfficientNetV2S(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2S architecture.View aliases
tf.keras.applications.inception_resnet_v2.InceptionResNetV2,"tf.keras.applications.inception_resnet_v2.InceptionResNetV2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the Inception-ResNet v2 architecture.View aliases
tf.keras.applications.inception_v3.InceptionV3,"tf.keras.applications.inception_v3.InceptionV3(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Inception v3 architecture.View aliases
tf.keras.applications.mobilenet.MobileNet,"tf.keras.applications.mobilenet.MobileNet(
    input_shape=None,
    alpha=1.0,
    depth_multiplier=1,
    dropout=0.001,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the MobileNet architecture.View aliases
tf.keras.applications.mobilenet_v2.MobileNetV2,"tf.keras.applications.mobilenet_v2.MobileNetV2(
    input_shape=None,
    alpha=1.0,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the MobileNetV2 architecture.View aliases
tf.keras.applications.MobileNetV3Large,"tf.keras.applications.MobileNetV3Large(
    input_shape=None,
    alpha=1.0,
    minimalistic=False,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    classes=1000,
    pooling=None,
    dropout_rate=0.2,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the MobileNetV3Large architecture.View aliases
tf.keras.applications.MobileNetV3Small,"tf.keras.applications.MobileNetV3Small(
    input_shape=None,
    alpha=1.0,
    minimalistic=False,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    classes=1000,
    pooling=None,
    dropout_rate=0.2,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the MobileNetV3Small architecture.View aliases
tf.keras.applications.nasnet.NASNetLarge,"tf.keras.applications.nasnet.NASNetLarge(
    input_shape=None,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates a NASNet model in ImageNet mode.View aliases
tf.keras.applications.nasnet.NASNetMobile,"tf.keras.applications.nasnet.NASNetMobile(
    input_shape=None,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates a Mobile NASNet model in ImageNet mode.View aliases
tf.keras.applications.regnet.RegNetX002,"tf.keras.applications.regnet.RegNetX002(
    model_name='regnetx002',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX002 architecture.View aliases
tf.keras.applications.regnet.RegNetX004,"tf.keras.applications.regnet.RegNetX004(
    model_name='regnetx004',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX004 architecture.View aliases
tf.keras.applications.regnet.RegNetX006,"tf.keras.applications.regnet.RegNetX006(
    model_name='regnetx006',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX006 architecture.View aliases
tf.keras.applications.regnet.RegNetX008,"tf.keras.applications.regnet.RegNetX008(
    model_name='regnetx008',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX008 architecture.View aliases
tf.keras.applications.regnet.RegNetX016,"tf.keras.applications.regnet.RegNetX016(
    model_name='regnetx016',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX016 architecture.View aliases
tf.keras.applications.regnet.RegNetX032,"tf.keras.applications.regnet.RegNetX032(
    model_name='regnetx032',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX032 architecture.View aliases
tf.keras.applications.regnet.RegNetX040,"tf.keras.applications.regnet.RegNetX040(
    model_name='regnetx040',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX040 architecture.View aliases
tf.keras.applications.regnet.RegNetX064,"tf.keras.applications.regnet.RegNetX064(
    model_name='regnetx064',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX064 architecture.View aliases
tf.keras.applications.regnet.RegNetX080,"tf.keras.applications.regnet.RegNetX080(
    model_name='regnetx080',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX080 architecture.View aliases
tf.keras.applications.regnet.RegNetX120,"tf.keras.applications.regnet.RegNetX120(
    model_name='regnetx120',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX120 architecture.View aliases
tf.keras.applications.regnet.RegNetX160,"tf.keras.applications.regnet.RegNetX160(
    model_name='regnetx160',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX160 architecture.View aliases
tf.keras.applications.regnet.RegNetX320,"tf.keras.applications.regnet.RegNetX320(
    model_name='regnetx320',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX320 architecture.View aliases
tf.keras.applications.regnet.RegNetY002,"tf.keras.applications.regnet.RegNetY002(
    model_name='regnety002',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY002 architecture.View aliases
tf.keras.applications.regnet.RegNetY004,"tf.keras.applications.regnet.RegNetY004(
    model_name='regnety004',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY004 architecture.View aliases
tf.keras.applications.regnet.RegNetY006,"tf.keras.applications.regnet.RegNetY006(
    model_name='regnety006',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY006 architecture.View aliases
tf.keras.applications.regnet.RegNetY008,"tf.keras.applications.regnet.RegNetY008(
    model_name='regnety008',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY008 architecture.View aliases
tf.keras.applications.regnet.RegNetY016,"tf.keras.applications.regnet.RegNetY016(
    model_name='regnety016',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY016 architecture.View aliases
tf.keras.applications.regnet.RegNetY032,"tf.keras.applications.regnet.RegNetY032(
    model_name='regnety032',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY032 architecture.View aliases
tf.keras.applications.regnet.RegNetY040,"tf.keras.applications.regnet.RegNetY040(
    model_name='regnety040',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY040 architecture.View aliases
tf.keras.applications.regnet.RegNetY064,"tf.keras.applications.regnet.RegNetY064(
    model_name='regnety064',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY064 architecture.View aliases
tf.keras.applications.regnet.RegNetY080,"tf.keras.applications.regnet.RegNetY080(
    model_name='regnety080',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY080 architecture.View aliases
tf.keras.applications.regnet.RegNetY120,"tf.keras.applications.regnet.RegNetY120(
    model_name='regnety120',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY120 architecture.View aliases
tf.keras.applications.regnet.RegNetY160,"tf.keras.applications.regnet.RegNetY160(
    model_name='regnety160',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY160 architecture.View aliases
tf.keras.applications.regnet.RegNetY320,"tf.keras.applications.regnet.RegNetY320(
    model_name='regnety320',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY320 architecture.View aliases
tf.keras.applications.resnet.ResNet101,"tf.keras.applications.resnet.ResNet101(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet101 architecture.View aliases
tf.keras.applications.resnet_v2.ResNet101V2,"tf.keras.applications.resnet_v2.ResNet101V2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ResNet101V2 architecture.View aliases
tf.keras.applications.resnet.ResNet152,"tf.keras.applications.resnet.ResNet152(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet152 architecture.View aliases
tf.keras.applications.resnet_v2.ResNet152V2,"tf.keras.applications.resnet_v2.ResNet152V2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ResNet152V2 architecture.View aliases
tf.keras.applications.resnet50.ResNet50,"tf.keras.applications.resnet50.ResNet50(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet50 architecture.View aliases
tf.keras.applications.resnet_v2.ResNet50V2,"tf.keras.applications.resnet_v2.ResNet50V2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ResNet50V2 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS101,"tf.keras.applications.resnet_rs.ResNetRS101(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS101 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS152,"tf.keras.applications.resnet_rs.ResNetRS152(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS152 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS200,"tf.keras.applications.resnet_rs.ResNetRS200(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS200 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS270,"tf.keras.applications.resnet_rs.ResNetRS270(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS270 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS350,"tf.keras.applications.resnet_rs.ResNetRS350(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS350 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS420,"tf.keras.applications.resnet_rs.ResNetRS420(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS420 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS50,"tf.keras.applications.resnet_rs.ResNetRS50(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS50 architecture.View aliases
tf.keras.applications.vgg16.VGG16,"tf.keras.applications.vgg16.VGG16(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the VGG16 model.View aliases
tf.keras.applications.vgg19.VGG19,"tf.keras.applications.vgg19.VGG19(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the VGG19 architecture.View aliases
tf.keras.applications.xception.Xception,"tf.keras.applications.xception.Xception(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Xception architecture.View aliases
tf.keras.applications.convnext.ConvNeXtBase,"tf.keras.applications.convnext.ConvNeXtBase(
    model_name='convnext_base',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtBase architecture.View aliases
tf.keras.applications.convnext.ConvNeXtLarge,"tf.keras.applications.convnext.ConvNeXtLarge(
    model_name='convnext_large',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtLarge architecture.View aliases
tf.keras.applications.convnext.ConvNeXtSmall,"tf.keras.applications.convnext.ConvNeXtSmall(
    model_name='convnext_small',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtSmall architecture.View aliases
tf.keras.applications.convnext.ConvNeXtTiny,"tf.keras.applications.convnext.ConvNeXtTiny(
    model_name='convnext_tiny',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtTiny architecture.View aliases
tf.keras.applications.convnext.ConvNeXtXLarge,"tf.keras.applications.convnext.ConvNeXtXLarge(
    model_name='convnext_xlarge',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ConvNeXtXLarge architecture.View aliases
tf.keras.applications.convnext.decode_predictions,"tf.keras.applications.convnext.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.convnext.preprocess_input,"tf.keras.applications.convnext.preprocess_input(
    x, data_format=None
)
",A placeholder method for backward compatibility.View aliases
tf.keras.applications.densenet.DenseNet121,"tf.keras.applications.densenet.DenseNet121(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Densenet121 architecture.View aliases
tf.keras.applications.densenet.DenseNet169,"tf.keras.applications.densenet.DenseNet169(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Densenet169 architecture.View aliases
tf.keras.applications.densenet.DenseNet201,"tf.keras.applications.densenet.DenseNet201(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Densenet201 architecture.View aliases
tf.keras.applications.densenet.decode_predictions,"tf.keras.applications.densenet.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.densenet.preprocess_input,"tf.keras.applications.densenet.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.efficientnet.EfficientNetB0,"tf.keras.applications.efficientnet.EfficientNetB0(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB0 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB1,"tf.keras.applications.efficientnet.EfficientNetB1(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB1 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB2,"tf.keras.applications.efficientnet.EfficientNetB2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB2 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB3,"tf.keras.applications.efficientnet.EfficientNetB3(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB3 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB4,"tf.keras.applications.efficientnet.EfficientNetB4(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB4 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB5,"tf.keras.applications.efficientnet.EfficientNetB5(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB5 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB6,"tf.keras.applications.efficientnet.EfficientNetB6(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB6 architecture.View aliases
tf.keras.applications.efficientnet.EfficientNetB7,"tf.keras.applications.efficientnet.EfficientNetB7(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the EfficientNetB7 architecture.View aliases
tf.keras.applications.efficientnet.decode_predictions,"tf.keras.applications.efficientnet.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.efficientnet.preprocess_input,"tf.keras.applications.efficientnet.preprocess_input(
    x, data_format=None
)
",A placeholder method for backward compatibility.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B0,"tf.keras.applications.efficientnet_v2.EfficientNetV2B0(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B0 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B1,"tf.keras.applications.efficientnet_v2.EfficientNetV2B1(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B1 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B2,"tf.keras.applications.efficientnet_v2.EfficientNetV2B2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B2 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2B3,"tf.keras.applications.efficientnet_v2.EfficientNetV2B3(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2B3 architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2L,"tf.keras.applications.efficientnet_v2.EfficientNetV2L(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2L architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2M,"tf.keras.applications.efficientnet_v2.EfficientNetV2M(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2M architecture.View aliases
tf.keras.applications.efficientnet_v2.EfficientNetV2S,"tf.keras.applications.efficientnet_v2.EfficientNetV2S(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the EfficientNetV2S architecture.View aliases
tf.keras.applications.efficientnet_v2.decode_predictions,"tf.keras.applications.efficientnet_v2.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.efficientnet_v2.preprocess_input,"tf.keras.applications.efficientnet_v2.preprocess_input(
    x, data_format=None
)
",A placeholder method for backward compatibility.View aliases
tf.keras.applications.imagenet_utils.decode_predictions,"tf.keras.applications.imagenet_utils.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.imagenet_utils.preprocess_input,"tf.keras.applications.imagenet_utils.preprocess_input(
    x, data_format=None, mode='caffe'
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.inception_resnet_v2.InceptionResNetV2,"tf.keras.applications.inception_resnet_v2.InceptionResNetV2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the Inception-ResNet v2 architecture.View aliases
tf.keras.applications.inception_resnet_v2.decode_predictions,"tf.keras.applications.inception_resnet_v2.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.inception_resnet_v2.preprocess_input,"tf.keras.applications.inception_resnet_v2.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.inception_v3.InceptionV3,"tf.keras.applications.inception_v3.InceptionV3(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Inception v3 architecture.View aliases
tf.keras.applications.inception_v3.decode_predictions,"tf.keras.applications.inception_v3.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.inception_v3.preprocess_input,"tf.keras.applications.inception_v3.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.mobilenet.MobileNet,"tf.keras.applications.mobilenet.MobileNet(
    input_shape=None,
    alpha=1.0,
    depth_multiplier=1,
    dropout=0.001,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the MobileNet architecture.View aliases
tf.keras.applications.mobilenet.decode_predictions,"tf.keras.applications.mobilenet.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.mobilenet.preprocess_input,"tf.keras.applications.mobilenet.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.mobilenet_v2.MobileNetV2,"tf.keras.applications.mobilenet_v2.MobileNetV2(
    input_shape=None,
    alpha=1.0,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax',
    **kwargs
)
",Instantiates the MobileNetV2 architecture.View aliases
tf.keras.applications.mobilenet_v2.decode_predictions,"tf.keras.applications.mobilenet_v2.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.mobilenet_v2.preprocess_input,"tf.keras.applications.mobilenet_v2.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.mobilenet_v3.decode_predictions,"tf.keras.applications.mobilenet_v3.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.mobilenet_v3.preprocess_input,"tf.keras.applications.mobilenet_v3.preprocess_input(
    x, data_format=None
)
",A placeholder method for backward compatibility.View aliases
tf.keras.applications.nasnet.NASNetLarge,"tf.keras.applications.nasnet.NASNetLarge(
    input_shape=None,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates a NASNet model in ImageNet mode.View aliases
tf.keras.applications.nasnet.NASNetMobile,"tf.keras.applications.nasnet.NASNetMobile(
    input_shape=None,
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates a Mobile NASNet model in ImageNet mode.View aliases
tf.keras.applications.nasnet.decode_predictions,"tf.keras.applications.nasnet.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.nasnet.preprocess_input,"tf.keras.applications.nasnet.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.regnet.RegNetX002,"tf.keras.applications.regnet.RegNetX002(
    model_name='regnetx002',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX002 architecture.View aliases
tf.keras.applications.regnet.RegNetX004,"tf.keras.applications.regnet.RegNetX004(
    model_name='regnetx004',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX004 architecture.View aliases
tf.keras.applications.regnet.RegNetX006,"tf.keras.applications.regnet.RegNetX006(
    model_name='regnetx006',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX006 architecture.View aliases
tf.keras.applications.regnet.RegNetX008,"tf.keras.applications.regnet.RegNetX008(
    model_name='regnetx008',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX008 architecture.View aliases
tf.keras.applications.regnet.RegNetX016,"tf.keras.applications.regnet.RegNetX016(
    model_name='regnetx016',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX016 architecture.View aliases
tf.keras.applications.regnet.RegNetX032,"tf.keras.applications.regnet.RegNetX032(
    model_name='regnetx032',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX032 architecture.View aliases
tf.keras.applications.regnet.RegNetX040,"tf.keras.applications.regnet.RegNetX040(
    model_name='regnetx040',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX040 architecture.View aliases
tf.keras.applications.regnet.RegNetX064,"tf.keras.applications.regnet.RegNetX064(
    model_name='regnetx064',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX064 architecture.View aliases
tf.keras.applications.regnet.RegNetX080,"tf.keras.applications.regnet.RegNetX080(
    model_name='regnetx080',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX080 architecture.View aliases
tf.keras.applications.regnet.RegNetX120,"tf.keras.applications.regnet.RegNetX120(
    model_name='regnetx120',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX120 architecture.View aliases
tf.keras.applications.regnet.RegNetX160,"tf.keras.applications.regnet.RegNetX160(
    model_name='regnetx160',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX160 architecture.View aliases
tf.keras.applications.regnet.RegNetX320,"tf.keras.applications.regnet.RegNetX320(
    model_name='regnetx320',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetX320 architecture.View aliases
tf.keras.applications.regnet.RegNetY002,"tf.keras.applications.regnet.RegNetY002(
    model_name='regnety002',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY002 architecture.View aliases
tf.keras.applications.regnet.RegNetY004,"tf.keras.applications.regnet.RegNetY004(
    model_name='regnety004',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY004 architecture.View aliases
tf.keras.applications.regnet.RegNetY006,"tf.keras.applications.regnet.RegNetY006(
    model_name='regnety006',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY006 architecture.View aliases
tf.keras.applications.regnet.RegNetY008,"tf.keras.applications.regnet.RegNetY008(
    model_name='regnety008',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY008 architecture.View aliases
tf.keras.applications.regnet.RegNetY016,"tf.keras.applications.regnet.RegNetY016(
    model_name='regnety016',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY016 architecture.View aliases
tf.keras.applications.regnet.RegNetY032,"tf.keras.applications.regnet.RegNetY032(
    model_name='regnety032',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY032 architecture.View aliases
tf.keras.applications.regnet.RegNetY040,"tf.keras.applications.regnet.RegNetY040(
    model_name='regnety040',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY040 architecture.View aliases
tf.keras.applications.regnet.RegNetY064,"tf.keras.applications.regnet.RegNetY064(
    model_name='regnety064',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY064 architecture.View aliases
tf.keras.applications.regnet.RegNetY080,"tf.keras.applications.regnet.RegNetY080(
    model_name='regnety080',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY080 architecture.View aliases
tf.keras.applications.regnet.RegNetY120,"tf.keras.applications.regnet.RegNetY120(
    model_name='regnety120',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY120 architecture.View aliases
tf.keras.applications.regnet.RegNetY160,"tf.keras.applications.regnet.RegNetY160(
    model_name='regnety160',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY160 architecture.View aliases
tf.keras.applications.regnet.RegNetY320,"tf.keras.applications.regnet.RegNetY320(
    model_name='regnety320',
    include_top=True,
    include_preprocessing=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the RegNetY320 architecture.View aliases
tf.keras.applications.regnet.decode_predictions,"tf.keras.applications.regnet.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.regnet.preprocess_input,"tf.keras.applications.regnet.preprocess_input(
    x, data_format=None
)
",A placeholder method for backward compatibility.View aliases
tf.keras.applications.resnet.ResNet101,"tf.keras.applications.resnet.ResNet101(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet101 architecture.View aliases
tf.keras.applications.resnet.ResNet152,"tf.keras.applications.resnet.ResNet152(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet152 architecture.View aliases
tf.keras.applications.resnet50.ResNet50,"tf.keras.applications.resnet50.ResNet50(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet50 architecture.View aliases
tf.keras.applications.resnet50.decode_predictions,"tf.keras.applications.resnet50.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.resnet50.preprocess_input,"tf.keras.applications.resnet50.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.resnet50.ResNet50,"tf.keras.applications.resnet50.ResNet50(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    **kwargs
)
",Instantiates the ResNet50 architecture.View aliases
tf.keras.applications.resnet50.decode_predictions,"tf.keras.applications.resnet50.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.resnet50.preprocess_input,"tf.keras.applications.resnet50.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.resnet_rs.ResNetRS101,"tf.keras.applications.resnet_rs.ResNetRS101(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS101 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS152,"tf.keras.applications.resnet_rs.ResNetRS152(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS152 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS200,"tf.keras.applications.resnet_rs.ResNetRS200(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS200 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS270,"tf.keras.applications.resnet_rs.ResNetRS270(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS270 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS350,"tf.keras.applications.resnet_rs.ResNetRS350(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS350 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS420,"tf.keras.applications.resnet_rs.ResNetRS420(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS420 architecture.View aliases
tf.keras.applications.resnet_rs.ResNetRS50,"tf.keras.applications.resnet_rs.ResNetRS50(
    include_top=True,
    weights='imagenet',
    classes=1000,
    input_shape=None,
    input_tensor=None,
    pooling=None,
    classifier_activation='softmax',
    include_preprocessing=True
)
",Instantiates the ResNetRS50 architecture.View aliases
tf.keras.applications.resnet_rs.decode_predictions,"tf.keras.applications.resnet_rs.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.resnet_rs.preprocess_input,"tf.keras.applications.resnet_rs.preprocess_input(
    x, data_format=None
)
",A placeholder method for backward compatibility.View aliases
tf.keras.applications.resnet_v2.ResNet101V2,"tf.keras.applications.resnet_v2.ResNet101V2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ResNet101V2 architecture.View aliases
tf.keras.applications.resnet_v2.ResNet152V2,"tf.keras.applications.resnet_v2.ResNet152V2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ResNet152V2 architecture.View aliases
tf.keras.applications.resnet_v2.ResNet50V2,"tf.keras.applications.resnet_v2.ResNet50V2(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the ResNet50V2 architecture.View aliases
tf.keras.applications.resnet_v2.decode_predictions,"tf.keras.applications.resnet_v2.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.resnet_v2.preprocess_input,"tf.keras.applications.resnet_v2.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.vgg16.VGG16,"tf.keras.applications.vgg16.VGG16(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the VGG16 model.View aliases
tf.keras.applications.vgg16.decode_predictions,"tf.keras.applications.vgg16.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.vgg16.preprocess_input,"tf.keras.applications.vgg16.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.vgg19.VGG19,"tf.keras.applications.vgg19.VGG19(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the VGG19 architecture.View aliases
tf.keras.applications.vgg19.decode_predictions,"tf.keras.applications.vgg19.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.vgg19.preprocess_input,"tf.keras.applications.vgg19.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.keras.applications.xception.Xception,"tf.keras.applications.xception.Xception(
    include_top=True,
    weights='imagenet',
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation='softmax'
)
",Instantiates the Xception architecture.View aliases
tf.keras.applications.xception.decode_predictions,"tf.keras.applications.xception.decode_predictions(
    preds, top=5
)
",Decodes the prediction of an ImageNet model.View aliases
tf.keras.applications.xception.preprocess_input,"tf.keras.applications.xception.preprocess_input(
    x, data_format=None
)
",Preprocesses a tensor or Numpy array encoding a batch of images.View aliases
tf.compat.v1.keras.backend.get_session,"tf.compat.v1.keras.backend.get_session(
    op_input_list=()
)
",Returns the TF session to be used by the backend.
tf.keras.backend.get_uid,"tf.keras.backend.get_uid(
    prefix=''
)
",Associates a string prefix with an integer counter in a TensorFlow graph.View aliases
tf.keras.backend.is_keras_tensor,"tf.keras.backend.is_keras_tensor(
    x
)
",Returns whether x is a Keras tensor.View aliases
tf.compat.v1.keras.backend.name_scope,"tf.compat.v1.keras.backend.name_scope(
    name, default_name=None, values=None
)
",A context manager for use when defining a Python op.View aliases
tf.keras.backend.rnn,"tf.keras.backend.rnn(
    step_function,
    inputs,
    initial_states,
    go_backwards=False,
    mask=None,
    constants=None,
    unroll=False,
    input_length=None,
    time_major=False,
    zero_output_for_mask=False,
    return_all_outputs=True
)
",Iterates over the time dimension of a tensor.View aliases
tf.keras.backend.set_epsilon,"tf.keras.backend.set_epsilon(
    value
)
",Sets the value of the fuzz factor used in numeric expressions.View aliases
tf.keras.backend.set_floatx,"tf.keras.backend.set_floatx(
    value
)
",Sets the default float type.View aliases
tf.keras.backend.set_image_data_format,"tf.keras.backend.set_image_data_format(
    data_format
)
",Sets the value of the image data format convention.View aliases
tf.compat.v1.keras.backend.set_session,"tf.compat.v1.keras.backend.set_session(
    session
)
",Sets the global TensorFlow session.
tf.keras.callbacks.BaseLogger,"tf.keras.callbacks.BaseLogger(
    stateful_metrics=None
)
",Callback that accumulates epoch averages of metrics.Inherits From: CallbackView aliases
tf.keras.callbacks.CSVLogger,"tf.keras.callbacks.CSVLogger(
    filename, separator=',', append=False
)
",Callback that streams epoch results to a CSV file.Inherits From: CallbackView aliases
tf.keras.callbacks.CallbackList,"tf.keras.callbacks.CallbackList(
    callbacks=None, add_history=False, add_progbar=False, model=None, **params
)
",Container abstracting a list of callbacks.View aliases
tf.keras.callbacks.EarlyStopping,"tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    min_delta=0,
    patience=0,
    verbose=0,
    mode='auto',
    baseline=None,
    restore_best_weights=False
)
",Stop training when a monitored metric has stopped improving.Inherits From: CallbackView aliases
tf.keras.callbacks.LambdaCallback,"tf.keras.callbacks.LambdaCallback(
    on_epoch_begin=None,
    on_epoch_end=None,
    on_batch_begin=None,
    on_batch_end=None,
    on_train_begin=None,
    on_train_end=None,
    **kwargs
)
","Callback for creating simple, custom callbacks on-the-fly.Inherits From: CallbackView aliases"
tf.keras.callbacks.LearningRateScheduler,"tf.keras.callbacks.LearningRateScheduler(
    schedule, verbose=0
)
",Learning rate scheduler.Inherits From: CallbackView aliases
tf.keras.callbacks.ModelCheckpoint,"tf.keras.callbacks.ModelCheckpoint(
    filepath,
    monitor: str = 'val_loss',
    verbose: int = 0,
    save_best_only: bool = False,
    save_weights_only: bool = False,
    mode: str = 'auto',
    save_freq='epoch',
    options=None,
    initial_value_threshold=None,
    **kwargs
)
",Callback to save the Keras model or model weights at some frequency.Inherits From: CallbackView aliases
tf.keras.callbacks.ProgbarLogger,"tf.keras.callbacks.ProgbarLogger(
    count_mode: str = 'samples', stateful_metrics=None
)
",Callback that prints metrics to stdout.Inherits From: CallbackView aliases
tf.keras.callbacks.ReduceLROnPlateau,"tf.keras.callbacks.ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.1,
    patience=10,
    verbose=0,
    mode='auto',
    min_delta=0.0001,
    cooldown=0,
    min_lr=0,
    **kwargs
)
",Reduce learning rate when a metric has stopped improving.Inherits From: CallbackView aliases
tf.keras.callbacks.RemoteMonitor,"tf.keras.callbacks.RemoteMonitor(
    root='http://localhost:9000',
    path='/publish/epoch/end/',
    field='data',
    headers=None,
    send_as_json=False
)
",Callback used to stream events to a server.Inherits From: CallbackView aliases
tf.compat.v1.keras.callbacks.TensorBoard,"tf.compat.v1.keras.callbacks.TensorBoard(
    log_dir='./logs',
    histogram_freq=0,
    batch_size=32,
    write_graph=True,
    write_grads=False,
    write_images=False,
    embeddings_freq=0,
    embeddings_layer_names=None,
    embeddings_metadata=None,
    embeddings_data=None,
    update_freq='epoch',
    profile_batch=2
)
","Enable visualizations for TensorBoard.Inherits From: TensorBoard, Callback"
tf.keras.constraints.MaxNorm,"tf.keras.constraints.MaxNorm(
    max_value=2, axis=0
)
",MaxNorm weight constraint.Inherits From: ConstraintView aliases
tf.keras.constraints.MinMaxNorm,"tf.keras.constraints.MinMaxNorm(
    min_value=0.0, max_value=1.0, rate=1.0, axis=0
)
",MinMaxNorm weight constraint.Inherits From: ConstraintView aliases
tf.keras.constraints.UnitNorm,"tf.keras.constraints.UnitNorm(
    axis=0
)
",Constrains the weights incident to each hidden unit to have unit norm.Inherits From: ConstraintView aliases
tf.keras.constraints.deserialize,"tf.keras.constraints.deserialize(
    config, custom_objects=None
)
",View aliases
tf.keras.constraints.get,"tf.keras.constraints.get(
    identifier
)
",Retrieves a Keras constraint function.View aliases
tf.keras.constraints.MaxNorm,"tf.keras.constraints.MaxNorm(
    max_value=2, axis=0
)
",MaxNorm weight constraint.Inherits From: ConstraintView aliases
tf.keras.constraints.MinMaxNorm,"tf.keras.constraints.MinMaxNorm(
    min_value=0.0, max_value=1.0, rate=1.0, axis=0
)
",MinMaxNorm weight constraint.Inherits From: ConstraintView aliases
tf.keras.constraints.serialize,"tf.keras.constraints.serialize(
    constraint
)
",View aliases
tf.keras.constraints.UnitNorm,"tf.keras.constraints.UnitNorm(
    axis=0
)
",Constrains the weights incident to each hidden unit to have unit norm.Inherits From: ConstraintView aliases
tf.keras.datasets.boston_housing.load_data,"tf.keras.datasets.boston_housing.load_data(
    path='boston_housing.npz', test_split=0.2, seed=113
)
",Loads the Boston Housing dataset.View aliases
tf.keras.datasets.cifar100.load_data,"tf.keras.datasets.cifar100.load_data(
    label_mode='fine'
)
",Loads the CIFAR100 dataset.View aliases
tf.keras.datasets.imdb.get_word_index,"tf.keras.datasets.imdb.get_word_index(
    path='imdb_word_index.json'
)
",Retrieves a dict mapping words to their index in the IMDB dataset.View aliases
tf.keras.datasets.imdb.load_data,"tf.keras.datasets.imdb.load_data(
    path='imdb.npz',
    num_words=None,
    skip_top=0,
    maxlen=None,
    seed=113,
    start_char=1,
    oov_char=2,
    index_from=3,
    **kwargs
)
",Loads the IMDB dataset.View aliases
tf.keras.datasets.mnist.load_data,"tf.keras.datasets.mnist.load_data(
    path='mnist.npz'
)
",Loads the MNIST dataset.View aliases
tf.keras.datasets.reuters.get_word_index,"tf.keras.datasets.reuters.get_word_index(
    path='reuters_word_index.json'
)
",Retrieves a dict mapping words to their index in the Reuters dataset.View aliases
tf.keras.datasets.reuters.load_data,"tf.keras.datasets.reuters.load_data(
    path='reuters.npz',
    num_words=None,
    skip_top=0,
    maxlen=None,
    test_split=0.2,
    seed=113,
    start_char=1,
    oov_char=2,
    index_from=3,
    **kwargs
)
",Loads the Reuters newswire classification dataset.View aliases
tf.compat.v1.keras.estimator.model_to_estimator,"tf.compat.v1.keras.estimator.model_to_estimator(
    keras_model=None,
    keras_model_path=None,
    custom_objects=None,
    model_dir=None,
    config=None,
    checkpoint_format='saver',
    metric_names_map=None,
    export_outputs=None
)
",Constructs an Estimator instance from given keras model.
tf.keras.optimizers.schedules.CosineDecay,"tf.keras.optimizers.schedules.CosineDecay(
    initial_learning_rate, decay_steps, alpha=0.0, name=None
)
",A LearningRateSchedule that uses a cosine decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.CosineDecayRestarts,"tf.keras.optimizers.schedules.CosineDecayRestarts(
    initial_learning_rate,
    first_decay_steps,
    t_mul=2.0,
    m_mul=1.0,
    alpha=0.0,
    name=None
)
",A LearningRateSchedule that uses a cosine decay schedule with restarts.Inherits From: LearningRateScheduleView aliases
tf.keras.experimental.LinearModel,"tf.keras.experimental.LinearModel(
    units=1,
    activation=None,
    use_bias=True,
    kernel_initializer='zeros',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    **kwargs
)
","Linear Model for regression and classification problems.Inherits From: Model, Layer, ModuleView aliases"
tf.keras.experimental.SequenceFeatures,"tf.keras.experimental.SequenceFeatures(
    feature_columns, trainable=True, name=None, **kwargs
)
","A layer for sequence input.Inherits From: Layer, ModuleView aliases"
tf.keras.experimental.WideDeepModel,"tf.keras.experimental.WideDeepModel(
    linear_model, dnn_model, activation=None, **kwargs
)
","Wide & Deep Model for regression and classification problems.Inherits From: Model, Layer, ModuleView aliases"
tf.compat.v1.keras.experimental.export_saved_model,"tf.compat.v1.keras.experimental.export_saved_model(
    model,
    saved_model_path,
    custom_objects=None,
    as_text=False,
    input_signature=None,
    serving_only=False
)
",Exports a tf.keras.Model as a Tensorflow SavedModel.
tf.compat.v1.keras.experimental.load_from_saved_model,"tf.compat.v1.keras.experimental.load_from_saved_model(
    saved_model_path, custom_objects=None
)
",Loads a keras Model from a SavedModel created by export_saved_model().
tf.compat.v1.keras.initializers.Constant,"tf.compat.v1.keras.initializers.Constant(
    value=0,
    dtype=tf.dtypes.float32,
    verify_shape=False
)
",Initializer that generates tensors with constant values.View aliases
tf.compat.v1.keras.initializers.Identity,"tf.compat.v1.keras.initializers.Identity(
    gain=1.0,
    dtype=tf.dtypes.float32
)
",Initializer that generates the identity matrix.View aliases
tf.compat.v1.keras.initializers.Ones,"tf.compat.v1.keras.initializers.Ones(
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors initialized to 1.View aliases
tf.compat.v1.keras.initializers.Orthogonal,"tf.compat.v1.keras.initializers.Orthogonal(
    gain=1.0,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates an orthogonal matrix.View aliases
tf.compat.v1.keras.initializers.RandomNormal,"tf.compat.v1.keras.initializers.RandomNormal(
    mean=0.0,
    stddev=0.05,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates a normal distribution.Inherits From: random_normal_initializerView aliases
tf.compat.v1.keras.initializers.RandomUniform,"tf.compat.v1.keras.initializers.RandomUniform(
    minval=-0.05,
    maxval=0.05,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors with a uniform distribution.Inherits From: random_uniform_initializerView aliases
tf.compat.v1.keras.initializers.TruncatedNormal,"tf.compat.v1.keras.initializers.TruncatedNormal(
    mean=0.0,
    stddev=0.05,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates a truncated normal distribution.Inherits From: truncated_normal_initializerView aliases
tf.compat.v1.keras.initializers.VarianceScaling,"tf.compat.v1.keras.initializers.VarianceScaling(
    scale=1.0,
    mode='fan_in',
    distribution='truncated_normal',
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer capable of adapting its scale to the shape of weights tensors.View aliases
tf.compat.v1.keras.initializers.Zeros,"tf.compat.v1.keras.initializers.Zeros(
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors initialized to 0.View aliases
tf.compat.v1.keras.initializers.Constant,"tf.compat.v1.keras.initializers.Constant(
    value=0,
    dtype=tf.dtypes.float32,
    verify_shape=False
)
",Initializer that generates tensors with constant values.View aliases
tf.keras.initializers.deserialize,"tf.keras.initializers.deserialize(
    config, custom_objects=None
)
",Return an Initializer object from its config.View aliases
tf.keras.initializers.get,"tf.keras.initializers.get(
    identifier
)
",Retrieve a Keras initializer by the identifier.View aliases
tf.compat.v1.keras.initializers.glorot_normal,"tf.compat.v1.keras.initializers.glorot_normal(
    seed=None,
    dtype=tf.dtypes.float32
)
","The Glorot normal initializer, also called Xavier normal initializer.Inherits From: VarianceScalingView aliases"
tf.compat.v1.keras.initializers.glorot_uniform,"tf.compat.v1.keras.initializers.glorot_uniform(
    seed=None,
    dtype=tf.dtypes.float32
)
","The Glorot uniform initializer, also called Xavier uniform initializer.Inherits From: VarianceScalingView aliases"
tf.compat.v1.keras.initializers.he_normal,"tf.compat.v1.keras.initializers.he_normal(
    seed=None
)
",Initializer capable of adapting its scale to the shape of weights tensors.Inherits From: VarianceScaling
tf.compat.v1.keras.initializers.he_uniform,"tf.compat.v1.keras.initializers.he_uniform(
    seed=None
)
",Initializer capable of adapting its scale to the shape of weights tensors.Inherits From: VarianceScaling
tf.compat.v1.keras.initializers.Identity,"tf.compat.v1.keras.initializers.Identity(
    gain=1.0,
    dtype=tf.dtypes.float32
)
",Initializer that generates the identity matrix.View aliases
tf.compat.v1.keras.initializers.lecun_normal,"tf.compat.v1.keras.initializers.lecun_normal(
    seed=None
)
",Initializer capable of adapting its scale to the shape of weights tensors.Inherits From: VarianceScaling
tf.compat.v1.keras.initializers.lecun_uniform,"tf.compat.v1.keras.initializers.lecun_uniform(
    seed=None
)
",Initializer capable of adapting its scale to the shape of weights tensors.Inherits From: VarianceScaling
tf.compat.v1.keras.initializers.RandomNormal,"tf.compat.v1.keras.initializers.RandomNormal(
    mean=0.0,
    stddev=0.05,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates a normal distribution.Inherits From: random_normal_initializerView aliases
tf.compat.v1.keras.initializers.Ones,"tf.compat.v1.keras.initializers.Ones(
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors initialized to 1.View aliases
tf.compat.v1.keras.initializers.Orthogonal,"tf.compat.v1.keras.initializers.Orthogonal(
    gain=1.0,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates an orthogonal matrix.View aliases
tf.compat.v1.keras.initializers.RandomNormal,"tf.compat.v1.keras.initializers.RandomNormal(
    mean=0.0,
    stddev=0.05,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates a normal distribution.Inherits From: random_normal_initializerView aliases
tf.compat.v1.keras.initializers.RandomUniform,"tf.compat.v1.keras.initializers.RandomUniform(
    minval=-0.05,
    maxval=0.05,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors with a uniform distribution.Inherits From: random_uniform_initializerView aliases
tf.keras.initializers.serialize,"tf.keras.initializers.serialize(
    initializer
)
",View aliases
tf.compat.v1.keras.initializers.TruncatedNormal,"tf.compat.v1.keras.initializers.TruncatedNormal(
    mean=0.0,
    stddev=0.05,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates a truncated normal distribution.Inherits From: truncated_normal_initializerView aliases
tf.compat.v1.keras.initializers.RandomUniform,"tf.compat.v1.keras.initializers.RandomUniform(
    minval=-0.05,
    maxval=0.05,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors with a uniform distribution.Inherits From: random_uniform_initializerView aliases
tf.compat.v1.keras.initializers.Zeros,"tf.compat.v1.keras.initializers.Zeros(
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors initialized to 0.View aliases
tf.keras.layers.AbstractRNNCell,"tf.keras.layers.AbstractRNNCell(
    trainable=True, name=None, dtype=None, dynamic=False, **kwargs
)
","Abstract object representing an RNN cell.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Activation,"tf.keras.layers.Activation(
    activation, **kwargs
)
","Applies an activation function to an output.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.ActivityRegularization,"tf.keras.layers.ActivityRegularization(
    l1=0.0, l2=0.0, **kwargs
)
","Layer that applies an update to the cost function based input activity.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Add,"tf.keras.layers.Add(
    **kwargs
)
","Layer that adds a list of inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AdditiveAttention,"tf.keras.layers.AdditiveAttention(
    use_scale=True, **kwargs
)
","Additive attention layer, a.k.a. Bahdanau-style attention.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AlphaDropout,"tf.keras.layers.AlphaDropout(
    rate, noise_shape=None, seed=None, **kwargs
)
","Applies Alpha Dropout to the input.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Attention,"tf.keras.layers.Attention(
    use_scale=False, score_mode='dot', **kwargs
)
","Dot-product attention layer, a.k.a. Luong-style attention.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Average,"tf.keras.layers.Average(
    **kwargs
)
","Layer that averages a list of inputs element-wise.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AveragePooling1D,"tf.keras.layers.AveragePooling1D(
    pool_size=2,
    strides=None,
    padding='valid',
    data_format='channels_last',
    **kwargs
)
","Average pooling for temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AveragePooling2D,"tf.keras.layers.AveragePooling2D(
    pool_size=(2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Average pooling operation for spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AveragePooling3D,"tf.keras.layers.AveragePooling3D(
    pool_size=(2, 2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Average pooling operation for 3D data (spatial or spatio-temporal).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AveragePooling1D,"tf.keras.layers.AveragePooling1D(
    pool_size=2,
    strides=None,
    padding='valid',
    data_format='channels_last',
    **kwargs
)
","Average pooling for temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AveragePooling2D,"tf.keras.layers.AveragePooling2D(
    pool_size=(2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Average pooling operation for spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.AveragePooling3D,"tf.keras.layers.AveragePooling3D(
    pool_size=(2, 2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Average pooling operation for 3D data (spatial or spatio-temporal).Inherits From: Layer, ModuleView aliases"
tf.compat.v1.keras.layers.BatchNormalization,"tf.compat.v1.keras.layers.BatchNormalization(
    axis=-1,
    momentum=0.99,
    epsilon=0.001,
    center=True,
    scale=True,
    beta_initializer='zeros',
    gamma_initializer='ones',
    moving_mean_initializer='zeros',
    moving_variance_initializer='ones',
    beta_regularizer=None,
    gamma_regularizer=None,
    beta_constraint=None,
    gamma_constraint=None,
    renorm=False,
    renorm_clipping=None,
    renorm_momentum=0.99,
    fused=None,
    trainable=True,
    virtual_batch_size=None,
    adjustment=None,
    name=None,
    **kwargs
)
","Layer that normalizes its inputs.Inherits From: Layer, Module"
tf.keras.layers.Bidirectional,"tf.keras.layers.Bidirectional(
    layer,
    merge_mode='concat',
    weights=None,
    backward_layer=None,
    **kwargs
)
","Bidirectional wrapper for RNNs.Inherits From: Wrapper, Layer, ModuleView aliases"
tf.keras.layers.CategoryEncoding,"tf.keras.layers.CategoryEncoding(
    num_tokens=None, output_mode='multi_hot', sparse=False, **kwargs
)
","A preprocessing layer which encodes integer features.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.CenterCrop,"tf.keras.layers.CenterCrop(
    height, width, **kwargs
)
","A preprocessing layer which crops images.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Concatenate,"tf.keras.layers.Concatenate(
    axis=-1, **kwargs
)
","Layer that concatenates a list of inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv1D,"tf.keras.layers.Conv1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format='channels_last',
    dilation_rate=1,
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","1D convolution layer (e.g. temporal convolution).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv1DTranspose,"tf.keras.layers.Conv1DTranspose(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    output_padding=None,
    data_format=None,
    dilation_rate=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Transposed convolution layer (sometimes called Deconvolution).Inherits From: Conv1D, Layer, ModuleView aliases"
tf.keras.layers.Conv2D,"tf.keras.layers.Conv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1),
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","2D convolution layer (e.g. spatial convolution over images).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv2DTranspose,"tf.keras.layers.Conv2DTranspose(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    output_padding=None,
    data_format=None,
    dilation_rate=(1, 1),
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Transposed convolution layer (sometimes called Deconvolution).Inherits From: Conv2D, Layer, ModuleView aliases"
tf.keras.layers.Conv3D,"tf.keras.layers.Conv3D(
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1, 1),
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","3D convolution layer (e.g. spatial convolution over volumes).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv3DTranspose,"tf.keras.layers.Conv3DTranspose(
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    output_padding=None,
    data_format=None,
    dilation_rate=(1, 1, 1),
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Transposed convolution layer (sometimes called Deconvolution).Inherits From: Conv3D, Layer, ModuleView aliases"
tf.keras.layers.ConvLSTM1D,"tf.keras.layers.ConvLSTM1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format=None,
    dilation_rate=1,
    activation='tanh',
    recurrent_activation='hard_sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    unit_forget_bias=True,
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    dropout=0.0,
    recurrent_dropout=0.0,
    **kwargs
)
","1D Convolutional LSTM.Inherits From: RNN, Layer, ModuleView aliases"
tf.keras.layers.ConvLSTM2D,"tf.keras.layers.ConvLSTM2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1),
    activation='tanh',
    recurrent_activation='hard_sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    unit_forget_bias=True,
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    dropout=0.0,
    recurrent_dropout=0.0,
    **kwargs
)
","2D Convolutional LSTM.Inherits From: RNN, Layer, ModuleView aliases"
tf.keras.layers.ConvLSTM3D,"tf.keras.layers.ConvLSTM3D(
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1, 1),
    activation='tanh',
    recurrent_activation='hard_sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    unit_forget_bias=True,
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    dropout=0.0,
    recurrent_dropout=0.0,
    **kwargs
)
","3D Convolutional LSTM.Inherits From: RNN, Layer, ModuleView aliases"
tf.keras.layers.Conv1D,"tf.keras.layers.Conv1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format='channels_last',
    dilation_rate=1,
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","1D convolution layer (e.g. temporal convolution).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv1DTranspose,"tf.keras.layers.Conv1DTranspose(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    output_padding=None,
    data_format=None,
    dilation_rate=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Transposed convolution layer (sometimes called Deconvolution).Inherits From: Conv1D, Layer, ModuleView aliases"
tf.keras.layers.Conv2D,"tf.keras.layers.Conv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1),
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","2D convolution layer (e.g. spatial convolution over images).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv2DTranspose,"tf.keras.layers.Conv2DTranspose(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    output_padding=None,
    data_format=None,
    dilation_rate=(1, 1),
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Transposed convolution layer (sometimes called Deconvolution).Inherits From: Conv2D, Layer, ModuleView aliases"
tf.keras.layers.Conv3D,"tf.keras.layers.Conv3D(
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1, 1),
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","3D convolution layer (e.g. spatial convolution over volumes).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Conv3DTranspose,"tf.keras.layers.Conv3DTranspose(
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    output_padding=None,
    data_format=None,
    dilation_rate=(1, 1, 1),
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Transposed convolution layer (sometimes called Deconvolution).Inherits From: Conv3D, Layer, ModuleView aliases"
tf.keras.layers.Cropping1D,"tf.keras.layers.Cropping1D(
    cropping=(1, 1), **kwargs
)
","Cropping layer for 1D input (e.g. temporal sequence).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Cropping2D,"tf.keras.layers.Cropping2D(
    cropping=((0, 0), (0, 0)), data_format=None, **kwargs
)
","Cropping layer for 2D input (e.g. picture).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Cropping3D,"tf.keras.layers.Cropping3D(
    cropping=((1, 1), (1, 1), (1, 1)), data_format=None, **kwargs
)
","Cropping layer for 3D data (e.g. spatial or spatio-temporal).Inherits From: Layer, ModuleView aliases"
tf.compat.v1.keras.layers.CuDNNGRU,"tf.compat.v1.keras.layers.CuDNNGRU(
    units,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    **kwargs
)
","Fast GRU implementation backed by cuDNN.Inherits From: RNN, Layer, Module"
tf.compat.v1.keras.layers.CuDNNLSTM,"tf.compat.v1.keras.layers.CuDNNLSTM(
    units,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    unit_forget_bias=True,
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    **kwargs
)
","Fast LSTM implementation backed by cuDNN.Inherits From: RNN, Layer, Module"
tf.keras.layers.Dense,"tf.keras.layers.Dense(
    units,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Just your regular densely-connected NN layer.Inherits From: Layer, ModuleView aliases"
tf.compat.v1.keras.layers.DenseFeatures,"tf.compat.v1.keras.layers.DenseFeatures(
    feature_columns, trainable=True, name=None, partitioner=None, **kwargs
)
","A layer that produces a dense Tensor based on given feature_columns.Inherits From: Layer, Module"
tf.keras.layers.DepthwiseConv1D,"tf.keras.layers.DepthwiseConv1D(
    kernel_size,
    strides=1,
    padding='valid',
    depth_multiplier=1,
    data_format=None,
    dilation_rate=1,
    activation=None,
    use_bias=True,
    depthwise_initializer='glorot_uniform',
    bias_initializer='zeros',
    depthwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Depthwise 1D convolution.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.DepthwiseConv2D,"tf.keras.layers.DepthwiseConv2D(
    kernel_size,
    strides=(1, 1),
    padding='valid',
    depth_multiplier=1,
    data_format=None,
    dilation_rate=(1, 1),
    activation=None,
    use_bias=True,
    depthwise_initializer='glorot_uniform',
    bias_initializer='zeros',
    depthwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Depthwise 2D convolution.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Discretization,"tf.keras.layers.Discretization(
    bin_boundaries=None,
    num_bins=None,
    epsilon=0.01,
    output_mode='int',
    sparse=False,
    **kwargs
)
","A preprocessing layer which buckets continuous features by ranges.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.Dot,"tf.keras.layers.Dot(
    axes, normalize=False, **kwargs
)
","Layer that computes a dot product between samples in two tensors.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Dropout,"tf.keras.layers.Dropout(
    rate, noise_shape=None, seed=None, **kwargs
)
","Applies Dropout to the input.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.ELU,"tf.keras.layers.ELU(
    alpha=1.0, **kwargs
)
","Exponential Linear Unit.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.EinsumDense,"tf.keras.layers.EinsumDense(
    equation,
    output_shape,
    activation=None,
    bias_axes=None,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","A layer that uses tf.einsum as the backing computation.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Embedding,"tf.keras.layers.Embedding(
    input_dim,
    output_dim,
    embeddings_initializer='uniform',
    embeddings_regularizer=None,
    activity_regularizer=None,
    embeddings_constraint=None,
    mask_zero=False,
    input_length=None,
    **kwargs
)
","Turns positive integers (indexes) into dense vectors of fixed size.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Flatten,"tf.keras.layers.Flatten(
    data_format=None, **kwargs
)
","Flattens the input. Does not affect the batch size.Inherits From: Layer, ModuleView aliases"
tf.compat.v1.keras.layers.GRU,"tf.compat.v1.keras.layers.GRU(
    units,
    activation='tanh',
    recurrent_activation='hard_sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    dropout=0.0,
    recurrent_dropout=0.0,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    unroll=False,
    reset_after=False,
    **kwargs
)
","Gated Recurrent Unit - Cho et al. 2014.Inherits From: RNN, Layer, Module"
tf.compat.v1.keras.layers.GRUCell,"tf.compat.v1.keras.layers.GRUCell(
    units,
    activation='tanh',
    recurrent_activation='hard_sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    dropout=0.0,
    recurrent_dropout=0.0,
    reset_after=False,
    **kwargs
)
","Cell class for the GRU layer.Inherits From: GRUCell, Layer, Module"
tf.keras.layers.GaussianDropout,"tf.keras.layers.GaussianDropout(
    rate, seed=None, **kwargs
)
","Apply multiplicative 1-centered Gaussian noise.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GaussianNoise,"tf.keras.layers.GaussianNoise(
    stddev, seed=None, **kwargs
)
","Apply additive zero-centered Gaussian noise.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalAveragePooling1D,"tf.keras.layers.GlobalAveragePooling1D(
    data_format='channels_last', **kwargs
)
","Global average pooling operation for temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalAveragePooling2D,"tf.keras.layers.GlobalAveragePooling2D(
    data_format=None, keepdims=False, **kwargs
)
","Global average pooling operation for spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalAveragePooling3D,"tf.keras.layers.GlobalAveragePooling3D(
    data_format=None, keepdims=False, **kwargs
)
","Global Average pooling operation for 3D data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalAveragePooling1D,"tf.keras.layers.GlobalAveragePooling1D(
    data_format='channels_last', **kwargs
)
","Global average pooling operation for temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalAveragePooling2D,"tf.keras.layers.GlobalAveragePooling2D(
    data_format=None, keepdims=False, **kwargs
)
","Global average pooling operation for spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalAveragePooling3D,"tf.keras.layers.GlobalAveragePooling3D(
    data_format=None, keepdims=False, **kwargs
)
","Global Average pooling operation for 3D data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalMaxPool1D,"tf.keras.layers.GlobalMaxPool1D(
    data_format='channels_last', keepdims=False, **kwargs
)
","Global max pooling operation for 1D temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalMaxPool2D,"tf.keras.layers.GlobalMaxPool2D(
    data_format=None, keepdims=False, **kwargs
)
","Global max pooling operation for spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalMaxPool3D,"tf.keras.layers.GlobalMaxPool3D(
    data_format=None, keepdims=False, **kwargs
)
","Global Max pooling operation for 3D data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalMaxPool1D,"tf.keras.layers.GlobalMaxPool1D(
    data_format='channels_last', keepdims=False, **kwargs
)
","Global max pooling operation for 1D temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalMaxPool2D,"tf.keras.layers.GlobalMaxPool2D(
    data_format=None, keepdims=False, **kwargs
)
","Global max pooling operation for spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.GlobalMaxPool3D,"tf.keras.layers.GlobalMaxPool3D(
    data_format=None, keepdims=False, **kwargs
)
","Global Max pooling operation for 3D data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Hashing,"tf.keras.layers.Hashing(
    num_bins,
    mask_value=None,
    salt=None,
    output_mode='int',
    sparse=False,
    **kwargs
)
","A preprocessing layer which hashes and bins categorical features.Inherits From: Layer, ModuleView aliases"
tf.keras.Input,"tf.keras.Input(
    shape=None,
    batch_size=None,
    name=None,
    dtype=None,
    sparse=None,
    tensor=None,
    ragged=None,
    type_spec=None,
    **kwargs
)
",Input() is used to instantiate a Keras tensor.View aliases
tf.keras.layers.InputLayer,"tf.keras.layers.InputLayer(
    input_shape=None,
    batch_size=None,
    dtype=None,
    input_tensor=None,
    sparse=None,
    name=None,
    ragged=None,
    type_spec=None,
    **kwargs
)
","Layer to be used as an entry point into a Network (a graph of layers).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.InputSpec,"tf.keras.layers.InputSpec(
    dtype=None,
    shape=None,
    ndim=None,
    max_ndim=None,
    min_ndim=None,
    axes=None,
    allow_last_axis_squeeze=False,
    name=None
)
","Specifies the rank, dtype and shape of every input to a layer.View aliases"
tf.compat.v1.keras.layers.LSTM,"tf.compat.v1.keras.layers.LSTM(
    units,
    activation='tanh',
    recurrent_activation='hard_sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    unit_forget_bias=True,
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    dropout=0.0,
    recurrent_dropout=0.0,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    unroll=False,
    **kwargs
)
","Long Short-Term Memory layer - Hochreiter 1997.Inherits From: RNN, Layer, Module"
tf.compat.v1.keras.layers.LSTMCell,"tf.compat.v1.keras.layers.LSTMCell(
    units,
    activation='tanh',
    recurrent_activation='hard_sigmoid',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    unit_forget_bias=True,
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    dropout=0.0,
    recurrent_dropout=0.0,
    **kwargs
)
","Cell class for the LSTM layer.Inherits From: LSTMCell, Layer, Module"
tf.keras.layers.Lambda,"tf.keras.layers.Lambda(
    function, output_shape=None, mask=None, arguments=None, **kwargs
)
","Wraps arbitrary expressions as a Layer object.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Layer,"tf.keras.layers.Layer(
    trainable=True, name=None, dtype=None, dynamic=False, **kwargs
)
",This is the class from which all layers inherit.Inherits From: ModuleView aliases
tf.keras.layers.LayerNormalization,"tf.keras.layers.LayerNormalization(
    axis=-1,
    epsilon=0.001,
    center=True,
    scale=True,
    beta_initializer='zeros',
    gamma_initializer='ones',
    beta_regularizer=None,
    gamma_regularizer=None,
    beta_constraint=None,
    gamma_constraint=None,
    **kwargs
)
","Layer normalization layer (Ba et al., 2016).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.LeakyReLU,"tf.keras.layers.LeakyReLU(
    alpha=0.3, **kwargs
)
","Leaky version of a Rectified Linear Unit.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.LocallyConnected1D,"tf.keras.layers.LocallyConnected1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format=None,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    implementation=1,
    **kwargs
)
","Locally-connected layer for 1D inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.LocallyConnected2D,"tf.keras.layers.LocallyConnected2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format=None,
    activation=None,
    use_bias=True,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    implementation=1,
    **kwargs
)
","Locally-connected layer for 2D inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Masking,"tf.keras.layers.Masking(
    mask_value=0.0, **kwargs
)
","Masks a sequence by using a mask value to skip timesteps.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.MaxPool1D,"tf.keras.layers.MaxPool1D(
    pool_size=2,
    strides=None,
    padding='valid',
    data_format='channels_last',
    **kwargs
)
","Max pooling operation for 1D temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.MaxPool2D,"tf.keras.layers.MaxPool2D(
    pool_size=(2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Max pooling operation for 2D spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.MaxPool3D,"tf.keras.layers.MaxPool3D(
    pool_size=(2, 2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Max pooling operation for 3D data (spatial or spatio-temporal).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.MaxPool1D,"tf.keras.layers.MaxPool1D(
    pool_size=2,
    strides=None,
    padding='valid',
    data_format='channels_last',
    **kwargs
)
","Max pooling operation for 1D temporal data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.MaxPool2D,"tf.keras.layers.MaxPool2D(
    pool_size=(2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Max pooling operation for 2D spatial data.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.MaxPool3D,"tf.keras.layers.MaxPool3D(
    pool_size=(2, 2, 2),
    strides=None,
    padding='valid',
    data_format=None,
    **kwargs
)
","Max pooling operation for 3D data (spatial or spatio-temporal).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Maximum,"tf.keras.layers.Maximum(
    **kwargs
)
","Layer that computes the maximum (element-wise) a list of inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Maximum,"tf.keras.layers.Maximum()([np.arange(5).reshape(5, 1),","Layer that computes the maximum (element-wise) a list of inputs.Inherits From: Layer, ModuleView aliasestf.keras.layers.Maximum(    **kwargs)It takes as input a list of tensors, all of the same shape, and returnsa single tensor (also of the same shape)."
tf.keras.layers.Minimum,"tf.keras.layers.Minimum(
    **kwargs
)
","Layer that computes the minimum (element-wise) a list of inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Minimum,"tf.keras.layers.Minimum()([np.arange(5).reshape(5, 1),","Layer that computes the minimum (element-wise) a list of inputs.Inherits From: Layer, ModuleView aliasestf.keras.layers.Minimum(    **kwargs)It takes as input a list of tensors, all of the same shape, and returnsa single tensor (also of the same shape)."
tf.keras.layers.MultiHeadAttention,"tf.keras.layers.MultiHeadAttention(
    num_heads,
    key_dim,
    value_dim=None,
    dropout=0.0,
    use_bias=True,
    output_shape=None,
    attention_axes=None,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","MultiHeadAttention layer.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Multiply,"tf.keras.layers.Multiply(
    **kwargs
)
","Layer that multiplies (element-wise) a list of inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Multiply,"tf.keras.layers.Multiply()([np.arange(5).reshape(5, 1),","Layer that multiplies (element-wise) a list of inputs.Inherits From: Layer, ModuleView aliasestf.keras.layers.Multiply(    **kwargs)It takes as input a list of tensors, all of the same shape, and returnsa single tensor (also of the same shape)."
tf.keras.layers.Normalization,"tf.keras.layers.Normalization(
    axis=-1, mean=None, variance=None, invert=False, **kwargs
)
","A preprocessing layer which normalizes continuous features.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.PReLU,"tf.keras.layers.PReLU(
    alpha_initializer='zeros',
    alpha_regularizer=None,
    alpha_constraint=None,
    shared_axes=None,
    **kwargs
)
","Parametric Rectified Linear Unit.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Permute,"tf.keras.layers.Permute(
    dims, **kwargs
)
","Permutes the dimensions of the input according to a given pattern.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RNN,"tf.keras.layers.RNN(
    cell,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    unroll=False,
    time_major=False,
    **kwargs
)
","Base class for recurrent layers.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.ReLU,"tf.keras.layers.ReLU(
    max_value=None, negative_slope=0.0, threshold=0.0, **kwargs
)
","Rectified Linear Unit activation function.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.RepeatVector,"tf.keras.layers.RepeatVector(
    n, **kwargs
)
","Repeats the input n times.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Rescaling,"tf.keras.layers.Rescaling(
    scale, offset=0.0, **kwargs
)
","A preprocessing layer which rescales input values to a new range.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Reshape,"tf.keras.layers.Reshape(
    target_shape, **kwargs
)
","Layer that reshapes inputs into the given shape.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Resizing,"tf.keras.layers.Resizing(
    height,
    width,
    interpolation='bilinear',
    crop_to_aspect_ratio=False,
    **kwargs
)
","A preprocessing layer which resizes images.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.SeparableConv1D,"tf.keras.layers.SeparableConv1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format=None,
    dilation_rate=1,
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    depthwise_initializer='glorot_uniform',
    pointwise_initializer='glorot_uniform',
    bias_initializer='zeros',
    depthwise_regularizer=None,
    pointwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    pointwise_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Depthwise separable 1D convolution.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.SeparableConv2D,"tf.keras.layers.SeparableConv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1),
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    depthwise_initializer='glorot_uniform',
    pointwise_initializer='glorot_uniform',
    bias_initializer='zeros',
    depthwise_regularizer=None,
    pointwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    pointwise_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Depthwise separable 2D convolution.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.SeparableConv1D,"tf.keras.layers.SeparableConv1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format=None,
    dilation_rate=1,
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    depthwise_initializer='glorot_uniform',
    pointwise_initializer='glorot_uniform',
    bias_initializer='zeros',
    depthwise_regularizer=None,
    pointwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    pointwise_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Depthwise separable 1D convolution.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.SeparableConv2D,"tf.keras.layers.SeparableConv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format=None,
    dilation_rate=(1, 1),
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    depthwise_initializer='glorot_uniform',
    pointwise_initializer='glorot_uniform',
    bias_initializer='zeros',
    depthwise_regularizer=None,
    pointwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    pointwise_constraint=None,
    bias_constraint=None,
    **kwargs
)
","Depthwise separable 2D convolution.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.SimpleRNN,"tf.keras.layers.SimpleRNN(
    units,
    activation='tanh',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    dropout=0.0,
    recurrent_dropout=0.0,
    return_sequences=False,
    return_state=False,
    go_backwards=False,
    stateful=False,
    unroll=False,
    **kwargs
)
","Fully-connected RNN where the output is to be fed back to input.Inherits From: RNN, Layer, ModuleView aliases"
tf.keras.layers.SimpleRNNCell,"tf.keras.layers.SimpleRNNCell(
    units,
    activation='tanh',
    use_bias=True,
    kernel_initializer='glorot_uniform',
    recurrent_initializer='orthogonal',
    bias_initializer='zeros',
    kernel_regularizer=None,
    recurrent_regularizer=None,
    bias_regularizer=None,
    kernel_constraint=None,
    recurrent_constraint=None,
    bias_constraint=None,
    dropout=0.0,
    recurrent_dropout=0.0,
    **kwargs
)
","Cell class for SimpleRNN.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Softmax,"tf.keras.layers.Softmax(
    axis=-1, **kwargs
)
","Softmax activation function.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.SpatialDropout1D,"tf.keras.layers.SpatialDropout1D(
    rate, **kwargs
)
","Spatial 1D version of Dropout.Inherits From: Dropout, Layer, ModuleView aliases"
tf.keras.layers.SpatialDropout2D,"tf.keras.layers.SpatialDropout2D(
    rate, data_format=None, **kwargs
)
","Spatial 2D version of Dropout.Inherits From: Dropout, Layer, ModuleView aliases"
tf.keras.layers.SpatialDropout3D,"tf.keras.layers.SpatialDropout3D(
    rate, data_format=None, **kwargs
)
","Spatial 3D version of Dropout.Inherits From: Dropout, Layer, ModuleView aliases"
tf.keras.layers.StackedRNNCells,"tf.keras.layers.StackedRNNCells(
    cells, **kwargs
)
","Wrapper allowing a stack of RNN cells to behave as a single cell.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Subtract,"tf.keras.layers.Subtract(
    **kwargs
)
","Layer that subtracts two inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.ThresholdedReLU,"tf.keras.layers.ThresholdedReLU(
    theta=1.0, **kwargs
)
","Thresholded Rectified Linear Unit.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.TimeDistributed,"tf.keras.layers.TimeDistributed(
    layer, **kwargs
)
","This wrapper allows to apply a layer to every temporal slice of an input.Inherits From: Wrapper, Layer, ModuleView aliases"
tf.keras.layers.UpSampling1D,"tf.keras.layers.UpSampling1D(
    size=2, **kwargs
)
","Upsampling layer for 1D inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.UpSampling2D,"tf.keras.layers.UpSampling2D(
    size=(2, 2), data_format=None, interpolation='nearest', **kwargs
)
","Upsampling layer for 2D inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.UpSampling3D,"tf.keras.layers.UpSampling3D(
    size=(2, 2, 2), data_format=None, **kwargs
)
","Upsampling layer for 3D inputs.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Wrapper,"tf.keras.layers.Wrapper(
    layer, **kwargs
)
","Abstract wrapper base class.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.ZeroPadding1D,"tf.keras.layers.ZeroPadding1D(
    padding=1, **kwargs
)
","Zero-padding layer for 1D input (e.g. temporal sequence).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.ZeroPadding2D,"tf.keras.layers.ZeroPadding2D(
    padding=(1, 1), data_format=None, **kwargs
)
","Zero-padding layer for 2D input (e.g. picture).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.ZeroPadding3D,"tf.keras.layers.ZeroPadding3D(
    padding=(1, 1, 1), data_format=None, **kwargs
)
","Zero-padding layer for 3D data (spatial or spatio-temporal).Inherits From: Layer, ModuleView aliases"
tf.keras.layers.add,"tf.keras.layers.add(
    inputs, **kwargs
)
",Functional interface to the tf.keras.layers.Add layer.View aliases
tf.keras.layers.average,"tf.keras.layers.average(
    inputs, **kwargs
)
",Functional interface to the tf.keras.layers.Average layer.View aliases
tf.keras.layers.concatenate,"tf.keras.layers.concatenate(
    inputs, axis=-1, **kwargs
)
",Functional interface to the Concatenate layer.View aliases
tf.keras.layers.deserialize,"tf.keras.layers.deserialize(
    config, custom_objects=None
)
",Instantiates a layer from a config dictionary.View aliases
tf.keras.layers.dot,"tf.keras.layers.dot(
    inputs, axes, normalize=False, **kwargs
)
",Functional interface to the Dot layer.View aliases
tf.keras.layers.EinsumDense,"tf.keras.layers.EinsumDense(
    equation,
    output_shape,
    activation=None,
    bias_axes=None,
    kernel_initializer='glorot_uniform',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
","A layer that uses tf.einsum as the backing computation.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.experimental.RandomFourierFeatures,"tf.keras.layers.experimental.RandomFourierFeatures(
    output_dim,
    kernel_initializer='gaussian',
    scale=None,
    trainable=False,
    name=None,
    **kwargs
)
","Layer that projects its inputs into a random feature space.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.CategoryEncoding,"tf.keras.layers.CategoryEncoding(
    num_tokens=None, output_mode='multi_hot', sparse=False, **kwargs
)
","A preprocessing layer which encodes integer features.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.CenterCrop,"tf.keras.layers.CenterCrop(
    height, width, **kwargs
)
","A preprocessing layer which crops images.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Discretization,"tf.keras.layers.Discretization(
    bin_boundaries=None,
    num_bins=None,
    epsilon=0.01,
    output_mode='int',
    sparse=False,
    **kwargs
)
","A preprocessing layer which buckets continuous features by ranges.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.experimental.preprocessing.HashedCrossing,"tf.keras.layers.experimental.preprocessing.HashedCrossing(
    num_bins, output_mode='int', sparse=False, **kwargs
)
","A preprocessing layer which crosses features using the ""hashing trick"".Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Hashing,"tf.keras.layers.Hashing(
    num_bins,
    mask_value=None,
    salt=None,
    output_mode='int',
    sparse=False,
    **kwargs
)
","A preprocessing layer which hashes and bins categorical features.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Normalization,"tf.keras.layers.Normalization(
    axis=-1, mean=None, variance=None, invert=False, **kwargs
)
","A preprocessing layer which normalizes continuous features.Inherits From: PreprocessingLayer, Layer, ModuleView aliases"
tf.keras.layers.experimental.preprocessing.PreprocessingLayer,"tf.keras.layers.experimental.preprocessing.PreprocessingLayer(
    **kwargs
)
","Base class for Preprocessing Layers.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Rescaling,"tf.keras.layers.Rescaling(
    scale, offset=0.0, **kwargs
)
","A preprocessing layer which rescales input values to a new range.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.Resizing,"tf.keras.layers.Resizing(
    height,
    width,
    interpolation='bilinear',
    crop_to_aspect_ratio=False,
    **kwargs
)
","A preprocessing layer which resizes images.Inherits From: Layer, ModuleView aliases"
tf.keras.layers.maximum,"tf.keras.layers.maximum(
    inputs, **kwargs
)
",Functional interface to compute maximum (element-wise) list of inputs.View aliases
tf.keras.layers.minimum,"tf.keras.layers.minimum(
    inputs, **kwargs
)
",Functional interface to the Minimum layer.View aliases
tf.keras.layers.multiply,"tf.keras.layers.multiply(
    inputs, **kwargs
)
",Functional interface to the Multiply layer.View aliases
tf.keras.layers.serialize,"tf.keras.layers.serialize(
    layer
)
",Serializes a Layer object into a JSON-compatible representation.View aliases
tf.keras.layers.subtract,"tf.keras.layers.subtract(
    inputs, **kwargs
)
",Functional interface to the Subtract layer.View aliases
tf.keras.losses.BinaryCrossentropy,"tf.keras.losses.BinaryCrossentropy(
    from_logits=False,
    label_smoothing=0.0,
    axis=-1,
    reduction=losses_utils.ReductionV2.AUTO,
    name='binary_crossentropy'
)
",Computes the cross-entropy loss between true labels and predicted labels.Inherits From: LossView aliases
tf.keras.losses.BinaryFocalCrossentropy,"tf.keras.losses.BinaryFocalCrossentropy(
    apply_class_balancing=False,
    alpha=0.25,
    gamma=2.0,
    from_logits=False,
    label_smoothing=0.0,
    axis=-1,
    reduction=losses_utils.ReductionV2.AUTO,
    name='binary_focal_crossentropy'
)
",Computes the focal cross-entropy loss between true labels and predictions.Inherits From: LossView aliases
tf.keras.losses.CategoricalCrossentropy,"tf.keras.losses.CategoricalCrossentropy(
    from_logits=False,
    label_smoothing=0.0,
    axis=-1,
    reduction=losses_utils.ReductionV2.AUTO,
    name='categorical_crossentropy'
)
",Computes the crossentropy loss between the labels and predictions.Inherits From: LossView aliases
tf.keras.losses.CategoricalHinge,"tf.keras.losses.CategoricalHinge(
    reduction=losses_utils.ReductionV2.AUTO, name='categorical_hinge'
)
",Computes the categorical hinge loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.CosineSimilarity,"tf.keras.losses.CosineSimilarity(
    axis=-1,
    reduction=losses_utils.ReductionV2.AUTO,
    name='cosine_similarity'
)
",Computes the cosine similarity between labels and predictions.Inherits From: LossView aliases
tf.keras.losses.Hinge,"tf.keras.losses.Hinge(
    reduction=losses_utils.ReductionV2.AUTO, name='hinge'
)
",Computes the hinge loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.Huber,"tf.keras.losses.Huber(
    delta=1.0,
    reduction=losses_utils.ReductionV2.AUTO,
    name='huber_loss'
)
",Computes the Huber loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.losses.KLDivergence,"tf.keras.losses.KLDivergence(
    reduction=losses_utils.ReductionV2.AUTO, name='kl_divergence'
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.LogCosh,"tf.keras.losses.LogCosh(
    reduction=losses_utils.ReductionV2.AUTO, name='log_cosh'
)
",Computes the logarithm of the hyperbolic cosine of the prediction error.Inherits From: LossView aliases
tf.keras.losses.Loss,"tf.keras.losses.Loss(
    reduction=losses_utils.ReductionV2.AUTO, name=None
)
",Loss base class.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.losses.MeanAbsoluteError,"tf.keras.losses.MeanAbsoluteError(
    reduction=losses_utils.ReductionV2.AUTO,
    name='mean_absolute_error'
)
",Computes the mean of absolute difference between labels and predictions.Inherits From: LossView aliases
tf.keras.losses.MeanAbsolutePercentageError,"tf.keras.losses.MeanAbsolutePercentageError(
    reduction=losses_utils.ReductionV2.AUTO,
    name='mean_absolute_percentage_error'
)
",Computes the mean absolute percentage error between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.MeanSquaredError,"tf.keras.losses.MeanSquaredError(
    reduction=losses_utils.ReductionV2.AUTO,
    name='mean_squared_error'
)
",Computes the mean of squares of errors between labels and predictions.Inherits From: LossView aliases
tf.keras.losses.MeanSquaredLogarithmicError,"tf.keras.losses.MeanSquaredLogarithmicError(
    reduction=losses_utils.ReductionV2.AUTO,
    name='mean_squared_logarithmic_error'
)
",Computes the mean squared logarithmic error between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.Poisson,"tf.keras.losses.Poisson(
    reduction=losses_utils.ReductionV2.AUTO, name='poisson'
)
",Computes the Poisson loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.losses.SparseCategoricalCrossentropy,"tf.keras.losses.SparseCategoricalCrossentropy(
    from_logits=False,
    ignore_class=None,
    reduction=losses_utils.ReductionV2.AUTO,
    name='sparse_categorical_crossentropy'
)
",Computes the crossentropy loss between the labels and predictions.Inherits From: LossView aliases
tf.keras.losses.SquaredHinge,"tf.keras.losses.SquaredHinge(
    reduction=losses_utils.ReductionV2.AUTO, name='squared_hinge'
)
",Computes the squared hinge loss between y_true and y_pred.Inherits From: LossView aliases
tf.keras.metrics.binary_crossentropy,"tf.keras.metrics.binary_crossentropy(
    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1
)
",Computes the binary crossentropy loss.View aliases
tf.keras.metrics.binary_focal_crossentropy,"tf.keras.metrics.binary_focal_crossentropy(
    y_true,
    y_pred,
    apply_class_balancing=False,
    alpha=0.25,
    gamma=2.0,
    from_logits=False,
    label_smoothing=0.0,
    axis=-1
)
",Computes the binary focal crossentropy loss.View aliases
tf.keras.metrics.categorical_crossentropy,"tf.keras.metrics.categorical_crossentropy(
    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1
)
",Computes the categorical crossentropy loss.View aliases
tf.keras.losses.categorical_hinge,"tf.keras.losses.categorical_hinge(
    y_true, y_pred
)
",Computes the categorical hinge loss between y_true and y_pred.View aliases
tf.keras.losses.cosine_similarity,"tf.keras.losses.cosine_similarity(
    y_true, y_pred, axis=-1
)
",Computes the cosine similarity between labels and predictions.View aliases
tf.keras.losses.cosine_similarity,"tf.keras.losses.cosine_similarity(
    y_true, y_pred, axis=-1
)
",Computes the cosine similarity between labels and predictions.View aliases
tf.keras.losses.cosine_similarity,"tf.keras.losses.cosine_similarity(
    y_true, y_pred, axis=-1
)
",Computes the cosine similarity between labels and predictions.View aliases
tf.keras.losses.deserialize,"tf.keras.losses.deserialize(
    name, custom_objects=None
)
",Deserializes a serialized loss class/function instance.View aliases
tf.keras.losses.get,"tf.keras.losses.get(
    identifier
)
",Retrieves a Keras loss as a function/Loss class instance.View aliases
tf.keras.metrics.hinge,"tf.keras.metrics.hinge(
    y_true, y_pred
)
",Computes the hinge loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.losses.log_cosh,"tf.keras.losses.log_cosh(
    y_true, y_pred
)
",Logarithm of the hyperbolic cosine of the prediction error.View aliases
tf.keras.losses.log_cosh,"tf.keras.losses.log_cosh(
    y_true, y_pred
)
",Logarithm of the hyperbolic cosine of the prediction error.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.poisson,"tf.keras.metrics.poisson(
    y_true, y_pred
)
",Computes the Poisson loss between y_true and y_pred.View aliases
tf.keras.losses.serialize,"tf.keras.losses.serialize(
    loss
)
",Serializes loss function or Loss instance.View aliases
tf.keras.metrics.sparse_categorical_crossentropy,"tf.keras.metrics.sparse_categorical_crossentropy(
    y_true, y_pred, from_logits=False, axis=-1, ignore_class=None
)
",Computes the sparse categorical crossentropy loss.View aliases
tf.keras.metrics.squared_hinge,"tf.keras.metrics.squared_hinge(
    y_true, y_pred
)
",Computes the squared hinge loss between y_true and y_pred.View aliases
tf.keras.metrics.AUC,"tf.keras.metrics.AUC(
    num_thresholds=200,
    curve='ROC',
    summation_method='interpolation',
    name=None,
    dtype=None,
    thresholds=None,
    multi_label=False,
    num_labels=None,
    label_weights=None,
    from_logits=False
)
","Approximates the AUC (Area under the curve) of the ROC or PR curves.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.Accuracy,"tf.keras.metrics.Accuracy(
    name='accuracy', dtype=None
)
","Calculates how often predictions equal labels.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.BinaryAccuracy,"tf.keras.metrics.BinaryAccuracy(
    name='binary_accuracy', dtype=None, threshold=0.5
)
","Calculates how often predictions match binary labels.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.BinaryCrossentropy,"tf.keras.metrics.BinaryCrossentropy(
    name='binary_crossentropy',
    dtype=None,
    from_logits=False,
    label_smoothing=0
)
","Computes the crossentropy metric between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.BinaryIoU,"tf.keras.metrics.BinaryIoU(
    target_class_ids: Union[List[int], Tuple[int, ...]] = (0, 1),
    threshold=0.5,
    name=None,
    dtype=None
)
","Computes the Intersection-Over-Union metric for class 0 and/or 1.Inherits From: IoU, Metric, Layer, ModuleView aliases"
tf.keras.metrics.CategoricalAccuracy,"tf.keras.metrics.CategoricalAccuracy(
    name='categorical_accuracy', dtype=None
)
","Calculates how often predictions match one-hot labels.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.CategoricalCrossentropy,"tf.keras.metrics.CategoricalCrossentropy(
    name='categorical_crossentropy',
    dtype=None,
    from_logits=False,
    label_smoothing=0,
    axis=-1
)
","Computes the crossentropy metric between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.CategoricalHinge,"tf.keras.metrics.CategoricalHinge(
    name='categorical_hinge', dtype=None
)
","Computes the categorical hinge metric between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.CosineSimilarity,"tf.keras.metrics.CosineSimilarity(
    name='cosine_similarity', dtype=None, axis=-1
)
","Computes the cosine similarity between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.FalseNegatives,"tf.keras.metrics.FalseNegatives(
    thresholds=None, name=None, dtype=None
)
","Calculates the number of false negatives.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.FalsePositives,"tf.keras.metrics.FalsePositives(
    thresholds=None, name=None, dtype=None
)
","Calculates the number of false positives.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.Hinge,"tf.keras.metrics.Hinge(
    name='hinge', dtype=None
)
","Computes the hinge metric between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.IoU,"tf.keras.metrics.IoU(
    num_classes: int,
    target_class_ids: Union[List[int], Tuple[int, ...]],
    name: Optional[str] = None,
    dtype: Optional[Union[str, tf.dtypes.DType]] = None,
    ignore_class: Optional[int] = None,
    sparse_y_true: bool = True,
    sparse_y_pred: bool = True,
    axis: int = -1
)
","Computes the Intersection-Over-Union metric for specific target classes.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.KLDivergence,"tf.keras.metrics.KLDivergence(
    name='kullback_leibler_divergence', dtype=None
)
","Computes Kullback-Leibler divergence metric between y_true andInherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.LogCoshError,"tf.keras.metrics.LogCoshError(
    name='logcosh', dtype=None
)
","Computes the logarithm of the hyperbolic cosine of the prediction error.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.Mean,"tf.keras.metrics.Mean(
    name='mean', dtype=None
)
","Computes the (weighted) mean of the given values.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanAbsoluteError,"tf.keras.metrics.MeanAbsoluteError(
    name='mean_absolute_error', dtype=None
)
","Computes the mean absolute error between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanAbsolutePercentageError,"tf.keras.metrics.MeanAbsolutePercentageError(
    name='mean_absolute_percentage_error', dtype=None
)
","Computes the mean absolute percentage error between y_true andInherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanIoU,"tf.keras.metrics.MeanIoU(
    num_classes: int,
    name: Optional[str] = None,
    dtype: Optional[Union[str, tf.dtypes.DType]] = None,
    ignore_class: Optional[int] = None,
    sparse_y_true: bool = True,
    sparse_y_pred: bool = True,
    axis: int = -1
)
","Computes the mean Intersection-Over-Union metric.Inherits From: IoU, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanMetricWrapper,"tf.keras.metrics.MeanMetricWrapper(
    fn, name=None, dtype=None, **kwargs
)
","Wraps a stateless metric function with the Mean metric.Inherits From: Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanRelativeError,"tf.keras.metrics.MeanRelativeError(
    normalizer, name=None, dtype=None
)
","Computes the mean relative error by normalizing with the given values.Inherits From: Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanSquaredError,"tf.keras.metrics.MeanSquaredError(
    name='mean_squared_error', dtype=None
)
","Computes the mean squared error between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanSquaredLogarithmicError,"tf.keras.metrics.MeanSquaredLogarithmicError(
    name='mean_squared_logarithmic_error', dtype=None
)
","Computes the mean squared logarithmic error between y_true andInherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.MeanTensor,"tf.keras.metrics.MeanTensor(
    name='mean_tensor', dtype=None, shape=None
)
","Computes the element-wise (weighted) mean of the given tensors.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.Metric,"tf.keras.metrics.Metric(
    name=None, dtype=None, **kwargs
)
","Encapsulates metric logic and state.Inherits From: Layer, ModuleView aliases"
tf.keras.metrics.OneHotIoU,"tf.keras.metrics.OneHotIoU(
    num_classes: int,
    target_class_ids: Union[List[int], Tuple[int, ...]],
    name=None,
    dtype=None,
    ignore_class: Optional[int] = None,
    sparse_y_pred: bool = False,
    axis: int = -1
)
","Computes the Intersection-Over-Union metric for one-hot encoded labels.Inherits From: IoU, Metric, Layer, ModuleView aliases"
tf.keras.metrics.OneHotMeanIoU,"tf.keras.metrics.OneHotMeanIoU(
    num_classes: int,
    name: str = None,
    dtype: Optional[Union[str, tf.dtypes.DType]] = None,
    ignore_class: Optional[int] = None,
    sparse_y_pred: bool = False,
    axis: int = -1
)
","Computes mean Intersection-Over-Union metric for one-hot encoded labels.Inherits From: MeanIoU, IoU, Metric, Layer, ModuleView aliases"
tf.keras.metrics.Poisson,"tf.keras.metrics.Poisson(
    name='poisson', dtype=None
)
","Computes the Poisson metric between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.Precision,"tf.keras.metrics.Precision(
    thresholds=None, top_k=None, class_id=None, name=None, dtype=None
)
","Computes the precision of the predictions with respect to the labels.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.PrecisionAtRecall,"tf.keras.metrics.PrecisionAtRecall(
    recall, num_thresholds=200, class_id=None, name=None, dtype=None
)
","Computes best precision where recall is >= specified value.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.Recall,"tf.keras.metrics.Recall(
    thresholds=None, top_k=None, class_id=None, name=None, dtype=None
)
","Computes the recall of the predictions with respect to the labels.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.RecallAtPrecision,"tf.keras.metrics.RecallAtPrecision(
    precision, num_thresholds=200, class_id=None, name=None, dtype=None
)
","Computes best recall where precision is >= specified value.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.RootMeanSquaredError,"tf.keras.metrics.RootMeanSquaredError(
    name='root_mean_squared_error', dtype=None
)
","Computes root mean squared error metric between y_true and y_pred.Inherits From: Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.SensitivityAtSpecificity,"tf.keras.metrics.SensitivityAtSpecificity(
    specificity, num_thresholds=200, class_id=None, name=None, dtype=None
)
","Computes best sensitivity where specificity is >= specified value.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.SparseCategoricalAccuracy,"tf.keras.metrics.SparseCategoricalAccuracy(
    name='sparse_categorical_accuracy', dtype=None
)
","Calculates how often predictions match integer labels.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.SparseCategoricalCrossentropy,"tf.keras.metrics.SparseCategoricalCrossentropy(
    name: str = 'sparse_categorical_crossentropy',
    dtype: Optional[Union[str, tf.dtypes.DType]] = None,
    from_logits: bool = False,
    ignore_class: Optional[int] = None,
    axis: int = -1
)
","Computes the crossentropy metric between the labels and predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.SparseTopKCategoricalAccuracy,"tf.keras.metrics.SparseTopKCategoricalAccuracy(
    k=5, name='sparse_top_k_categorical_accuracy', dtype=None
)
","Computes how often integer targets are in the top K predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.SpecificityAtSensitivity,"tf.keras.metrics.SpecificityAtSensitivity(
    sensitivity, num_thresholds=200, class_id=None, name=None, dtype=None
)
","Computes best specificity where sensitivity is >= specified value.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.SquaredHinge,"tf.keras.metrics.SquaredHinge(
    name='squared_hinge', dtype=None
)
","Computes the squared hinge metric between y_true and y_pred.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.Sum,"tf.keras.metrics.Sum(
    name='sum', dtype=None
)
","Computes the (weighted) sum of the given values.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.TopKCategoricalAccuracy,"tf.keras.metrics.TopKCategoricalAccuracy(
    k=5, name='top_k_categorical_accuracy', dtype=None
)
","Computes how often targets are in the top K predictions.Inherits From: MeanMetricWrapper, Mean, Metric, Layer, ModuleView aliases"
tf.keras.metrics.TrueNegatives,"tf.keras.metrics.TrueNegatives(
    thresholds=None, name=None, dtype=None
)
","Calculates the number of true negatives.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.TruePositives,"tf.keras.metrics.TruePositives(
    thresholds=None, name=None, dtype=None
)
","Calculates the number of true positives.Inherits From: Metric, Layer, ModuleView aliases"
tf.keras.metrics.binary_accuracy,"tf.keras.metrics.binary_accuracy(
    y_true, y_pred, threshold=0.5
)
",Calculates how often predictions match binary labels.View aliases
tf.keras.metrics.binary_crossentropy,"tf.keras.metrics.binary_crossentropy(
    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1
)
",Computes the binary crossentropy loss.View aliases
tf.keras.metrics.binary_focal_crossentropy,"tf.keras.metrics.binary_focal_crossentropy(
    y_true,
    y_pred,
    apply_class_balancing=False,
    alpha=0.25,
    gamma=2.0,
    from_logits=False,
    label_smoothing=0.0,
    axis=-1
)
",Computes the binary focal crossentropy loss.View aliases
tf.keras.metrics.categorical_accuracy,"tf.keras.metrics.categorical_accuracy(
    y_true, y_pred
)
",Calculates how often predictions match one-hot labels.View aliases
tf.keras.metrics.categorical_crossentropy,"tf.keras.metrics.categorical_crossentropy(
    y_true, y_pred, from_logits=False, label_smoothing=0.0, axis=-1
)
",Computes the categorical crossentropy loss.View aliases
tf.keras.losses.cosine_similarity,"tf.keras.losses.cosine_similarity(
    y_true, y_pred, axis=-1
)
",Computes the cosine similarity between labels and predictions.View aliases
tf.keras.losses.cosine_similarity,"tf.keras.losses.cosine_similarity(
    y_true, y_pred, axis=-1
)
",Computes the cosine similarity between labels and predictions.View aliases
tf.keras.metrics.deserialize,"tf.keras.metrics.deserialize(
    config, custom_objects=None
)
",Deserializes a serialized metric class/function instance.View aliases
tf.keras.metrics.get,"tf.keras.metrics.get(
    identifier
)
",Retrieves a Keras metric as a function/Metric class instance.View aliases
tf.keras.metrics.hinge,"tf.keras.metrics.hinge(
    y_true, y_pred
)
",Computes the hinge loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.metrics.kl_divergence,"tf.keras.metrics.kl_divergence(
    y_true, y_pred
)
",Computes Kullback-Leibler divergence loss between y_true and y_pred.View aliases
tf.keras.losses.log_cosh,"tf.keras.losses.log_cosh(
    y_true, y_pred
)
",Logarithm of the hyperbolic cosine of the prediction error.View aliases
tf.keras.losses.log_cosh,"tf.keras.losses.log_cosh(
    y_true, y_pred
)
",Logarithm of the hyperbolic cosine of the prediction error.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_absolute_error,"tf.keras.metrics.mean_absolute_error(
    y_true, y_pred
)
",Computes the mean absolute error between labels and predictions.View aliases
tf.keras.metrics.mean_absolute_percentage_error,"tf.keras.metrics.mean_absolute_percentage_error(
    y_true, y_pred
)
",Computes the mean absolute percentage error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.mean_squared_error,"tf.keras.metrics.mean_squared_error(
    y_true, y_pred
)
",Computes the mean squared error between labels and predictions.View aliases
tf.keras.metrics.mean_squared_logarithmic_error,"tf.keras.metrics.mean_squared_logarithmic_error(
    y_true, y_pred
)
",Computes the mean squared logarithmic error between y_true and y_pred.View aliases
tf.keras.metrics.poisson,"tf.keras.metrics.poisson(
    y_true, y_pred
)
",Computes the Poisson loss between y_true and y_pred.View aliases
tf.keras.metrics.serialize,"tf.keras.metrics.serialize(
    metric
)
",Serializes metric function or Metric instance.View aliases
tf.keras.metrics.sparse_categorical_accuracy,"tf.keras.metrics.sparse_categorical_accuracy(
    y_true, y_pred
)
",Calculates how often predictions match integer labels.View aliases
tf.keras.metrics.sparse_categorical_crossentropy,"tf.keras.metrics.sparse_categorical_crossentropy(
    y_true, y_pred, from_logits=False, axis=-1, ignore_class=None
)
",Computes the sparse categorical crossentropy loss.View aliases
tf.keras.metrics.sparse_top_k_categorical_accuracy,"tf.keras.metrics.sparse_top_k_categorical_accuracy(
    y_true, y_pred, k=5
)
",Computes how often integer targets are in the top K predictions.View aliases
tf.keras.metrics.squared_hinge,"tf.keras.metrics.squared_hinge(
    y_true, y_pred
)
",Computes the squared hinge loss between y_true and y_pred.View aliases
tf.keras.metrics.top_k_categorical_accuracy,"tf.keras.metrics.top_k_categorical_accuracy(
    y_true, y_pred, k=5
)
",Computes how often targets are in the top K predictions.View aliases
tf.keras.experimental.LinearModel,"tf.keras.experimental.LinearModel(
    units=1,
    activation=None,
    use_bias=True,
    kernel_initializer='zeros',
    bias_initializer='zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    **kwargs
)
","Linear Model for regression and classification problems.Inherits From: Model, Layer, ModuleView aliases"
tf.keras.Model,"tf.keras.Model(
    *args, **kwargs
)
","Model groups layers into an object with training and inference features.Inherits From: Layer, ModuleView aliases"
tf.keras.Sequential,"tf.keras.Sequential(
    layers=None, name=None
)
","Sequential groups a linear stack of layers into a tf.keras.Model.Inherits From: Model, Layer, ModuleView aliases"
tf.keras.experimental.WideDeepModel,"tf.keras.experimental.WideDeepModel(
    linear_model, dnn_model, activation=None, **kwargs
)
","Wide & Deep Model for regression and classification problems.Inherits From: Model, Layer, ModuleView aliases"
tf.keras.models.clone_model,"tf.keras.models.clone_model(
    model, input_tensors=None, clone_function=None
)
",Clone a Functional or Sequential Model instance.View aliases
tf.keras.models.load_model,"tf.keras.models.load_model(
    filepath, custom_objects=None, compile=True, options=None
)
",Loads a model saved via model.save().View aliases
tf.keras.models.model_from_config,"tf.keras.models.model_from_config(
    config, custom_objects=None
)
",Instantiates a Keras model from its config.View aliases
tf.keras.models.model_from_json,"tf.keras.models.model_from_json(
    json_string, custom_objects=None
)
",Parses a JSON model configuration string and returns a model instance.View aliases
tf.keras.models.model_from_yaml,"tf.keras.models.model_from_yaml(
    yaml_string, custom_objects=None
)
",Parses a yaml model configuration file and returns a model instance.View aliases
tf.keras.models.save_model,"tf.keras.models.save_model(
    model,
    filepath,
    overwrite=True,
    include_optimizer=True,
    save_format=None,
    signatures=None,
    options=None,
    save_traces=True
)
",Saves a model as a TensorFlow SavedModel or HDF5 file.View aliases
tf.keras.optimizers.Adadelta,"tf.keras.optimizers.Adadelta(
    learning_rate=0.001,
    rho=0.95,
    epsilon=1e-07,
    name='Adadelta',
    **kwargs
)
",Optimizer that implements the Adadelta algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Adagrad,"tf.keras.optimizers.Adagrad(
    learning_rate=0.001,
    initial_accumulator_value=0.1,
    epsilon=1e-07,
    name='Adagrad',
    **kwargs
)
",Optimizer that implements the Adagrad algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Adam,"tf.keras.optimizers.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    name='Adam',
    **kwargs
)
",Optimizer that implements the Adam algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Adamax,"tf.keras.optimizers.Adamax(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    name='Adamax',
    **kwargs
)
",Optimizer that implements the Adamax algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Ftrl,"tf.keras.optimizers.Ftrl(
    learning_rate=0.001,
    learning_rate_power=-0.5,
    initial_accumulator_value=0.1,
    l1_regularization_strength=0.0,
    l2_regularization_strength=0.0,
    name='Ftrl',
    l2_shrinkage_regularization_strength=0.0,
    beta=0.0,
    **kwargs
)
",Optimizer that implements the FTRL algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Nadam,"tf.keras.optimizers.Nadam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    name='Nadam',
    **kwargs
)
",Optimizer that implements the NAdam algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.Optimizer,"tf.keras.optimizers.Optimizer(
    name, gradient_aggregator=None, gradient_transformers=None, **kwargs
)
",Base class for Keras optimizers.View aliases
tf.keras.optimizers.RMSprop,"tf.keras.optimizers.RMSprop(
    learning_rate=0.001,
    rho=0.9,
    momentum=0.0,
    epsilon=1e-07,
    centered=False,
    name='RMSprop',
    **kwargs
)
",Optimizer that implements the RMSprop algorithm.Inherits From: OptimizerView aliases
tf.keras.optimizers.SGD,"tf.keras.optimizers.SGD(
    learning_rate=0.01,
    momentum=0.0,
    nesterov=False,
    name='SGD',
    **kwargs
)
",Gradient descent (with momentum) optimizer.Inherits From: OptimizerView aliases
tf.keras.optimizers.deserialize,"tf.keras.optimizers.deserialize(
    config, custom_objects=None, **kwargs
)
",Inverse of the serialize function.View aliases
tf.keras.optimizers.get,"tf.keras.optimizers.get(
    identifier, **kwargs
)
",Retrieves a Keras Optimizer instance.View aliases
tf.keras.optimizers.legacy.Adadelta,"tf.keras.optimizers.legacy.Adadelta(
    learning_rate=0.001,
    rho=0.95,
    epsilon=1e-07,
    name='Adadelta',
    **kwargs
)
","Optimizer that implements the Adadelta algorithm.Inherits From: Adadelta, OptimizerView aliases"
tf.keras.optimizers.legacy.Adagrad,"tf.keras.optimizers.legacy.Adagrad(
    learning_rate=0.001,
    initial_accumulator_value=0.1,
    epsilon=1e-07,
    name='Adagrad',
    **kwargs
)
","Optimizer that implements the Adagrad algorithm.Inherits From: Adagrad, OptimizerView aliases"
tf.keras.optimizers.legacy.Adam,"tf.keras.optimizers.legacy.Adam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    amsgrad=False,
    name='Adam',
    **kwargs
)
","Optimizer that implements the Adam algorithm.Inherits From: Adam, OptimizerView aliases"
tf.keras.optimizers.legacy.Adamax,"tf.keras.optimizers.legacy.Adamax(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    name='Adamax',
    **kwargs
)
","Optimizer that implements the Adamax algorithm.Inherits From: Adamax, OptimizerView aliases"
tf.keras.optimizers.legacy.Ftrl,"tf.keras.optimizers.legacy.Ftrl(
    learning_rate=0.001,
    learning_rate_power=-0.5,
    initial_accumulator_value=0.1,
    l1_regularization_strength=0.0,
    l2_regularization_strength=0.0,
    name='Ftrl',
    l2_shrinkage_regularization_strength=0.0,
    beta=0.0,
    **kwargs
)
","Optimizer that implements the FTRL algorithm.Inherits From: Ftrl, OptimizerView aliases"
tf.keras.optimizers.legacy.Nadam,"tf.keras.optimizers.legacy.Nadam(
    learning_rate=0.001,
    beta_1=0.9,
    beta_2=0.999,
    epsilon=1e-07,
    name='Nadam',
    **kwargs
)
","Optimizer that implements the NAdam algorithm.Inherits From: Nadam, OptimizerView aliases"
tf.keras.optimizers.legacy.Optimizer,"tf.keras.optimizers.legacy.Optimizer(
    name, gradient_aggregator=None, gradient_transformers=None, **kwargs
)
",Base class for Keras optimizers.Inherits From: OptimizerView aliases
tf.keras.optimizers.legacy.RMSprop,"tf.keras.optimizers.legacy.RMSprop(
    learning_rate=0.001,
    rho=0.9,
    momentum=0.0,
    epsilon=1e-07,
    centered=False,
    name='RMSprop',
    **kwargs
)
","Optimizer that implements the RMSprop algorithm.Inherits From: RMSprop, OptimizerView aliases"
tf.keras.optimizers.legacy.SGD,"tf.keras.optimizers.legacy.SGD(
    learning_rate=0.01,
    momentum=0.0,
    nesterov=False,
    name='SGD',
    **kwargs
)
","Gradient descent (with momentum) optimizer.Inherits From: SGD, OptimizerView aliases"
tf.keras.optimizers.schedules.CosineDecay,"tf.keras.optimizers.schedules.CosineDecay(
    initial_learning_rate, decay_steps, alpha=0.0, name=None
)
",A LearningRateSchedule that uses a cosine decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.CosineDecayRestarts,"tf.keras.optimizers.schedules.CosineDecayRestarts(
    initial_learning_rate,
    first_decay_steps,
    t_mul=2.0,
    m_mul=1.0,
    alpha=0.0,
    name=None
)
",A LearningRateSchedule that uses a cosine decay schedule with restarts.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.ExponentialDecay,"tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate, decay_steps, decay_rate, staircase=False, name=None
)
",A LearningRateSchedule that uses an exponential decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.InverseTimeDecay,"tf.keras.optimizers.schedules.InverseTimeDecay(
    initial_learning_rate, decay_steps, decay_rate, staircase=False, name=None
)
",A LearningRateSchedule that uses an inverse time decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.PiecewiseConstantDecay,"tf.keras.optimizers.schedules.PiecewiseConstantDecay(
    boundaries, values, name=None
)
",A LearningRateSchedule that uses a piecewise constant decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.PolynomialDecay,"tf.keras.optimizers.schedules.PolynomialDecay(
    initial_learning_rate,
    decay_steps,
    end_learning_rate=0.0001,
    power=1.0,
    cycle=False,
    name=None
)
",A LearningRateSchedule that uses a polynomial decay schedule.Inherits From: LearningRateScheduleView aliases
tf.keras.optimizers.schedules.deserialize,"tf.keras.optimizers.schedules.deserialize(
    config, custom_objects=None
)
",Instantiates a LearningRateSchedule object from a serialized form.View aliases
tf.keras.optimizers.schedules.serialize,"tf.keras.optimizers.schedules.serialize(
    learning_rate_schedule
)
",Serializes a LearningRateSchedule into a JSON-compatible representation.View aliases
tf.keras.optimizers.serialize,"tf.keras.optimizers.serialize(
    optimizer
)
",Serialize the optimizer configuration to JSON compatible python dict.View aliases
tf.keras.preprocessing.image.DirectoryIterator,"tf.keras.preprocessing.image.DirectoryIterator(
    directory,
    image_data_generator,
    target_size=(256, 256),
    color_mode='rgb',
    classes=None,
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=None,
    data_format=None,
    save_to_dir=None,
    save_prefix='',
    save_format='png',
    follow_links=False,
    subset=None,
    interpolation='nearest',
    keep_aspect_ratio=False,
    dtype=None
)
","Iterator capable of reading images from a directory on disk.Inherits From: Iterator, SequenceView aliases"
tf.keras.preprocessing.image.ImageDataGenerator,"tf.keras.preprocessing.image.ImageDataGenerator(
    featurewise_center=False,
    samplewise_center=False,
    featurewise_std_normalization=False,
    samplewise_std_normalization=False,
    zca_whitening=False,
    zca_epsilon=1e-06,
    rotation_range=0,
    width_shift_range=0.0,
    height_shift_range=0.0,
    brightness_range=None,
    shear_range=0.0,
    zoom_range=0.0,
    channel_shift_range=0.0,
    fill_mode='nearest',
    cval=0.0,
    horizontal_flip=False,
    vertical_flip=False,
    rescale=None,
    preprocessing_function=None,
    data_format=None,
    validation_split=0.0,
    interpolation_order=1,
    dtype=None
)
",Generate batches of tensor image data with real-time data augmentation.View aliases
tf.keras.preprocessing.image.Iterator,"tf.keras.preprocessing.image.Iterator(
    n, batch_size, shuffle, seed
)
",Base class for image data iterators.Inherits From: SequenceView aliases
tf.keras.preprocessing.image.NumpyArrayIterator,"tf.keras.preprocessing.image.NumpyArrayIterator(
    x,
    y,
    image_data_generator,
    batch_size=32,
    shuffle=False,
    sample_weight=None,
    seed=None,
    data_format=None,
    save_to_dir=None,
    save_prefix='',
    save_format='png',
    subset=None,
    ignore_class_split=False,
    dtype=None
)
","Iterator yielding data from a Numpy array.Inherits From: Iterator, SequenceView aliases"
tf.keras.preprocessing.image.apply_affine_transform,"tf.keras.preprocessing.image.apply_affine_transform(
    x,
    theta=0,
    tx=0,
    ty=0,
    shear=0,
    zx=1,
    zy=1,
    row_axis=1,
    col_axis=2,
    channel_axis=0,
    fill_mode='nearest',
    cval=0.0,
    order=1
)
",Applies an affine transformation specified by the parameters given.View aliases
tf.keras.preprocessing.image.apply_brightness_shift,"tf.keras.preprocessing.image.apply_brightness_shift(
    x, brightness, scale=True
)
",Performs a brightness shift.View aliases
tf.keras.preprocessing.image.apply_channel_shift,"tf.keras.preprocessing.image.apply_channel_shift(
    x, intensity, channel_axis=0
)
",Performs a channel shift.View aliases
tf.keras.utils.array_to_img,"tf.keras.utils.array_to_img(
    x, data_format=None, scale=True, dtype=None
)
",Converts a 3D Numpy array to a PIL Image instance.View aliases
tf.keras.utils.img_to_array,"tf.keras.utils.img_to_array(
    img, data_format=None, dtype=None
)
",Converts a PIL Image instance to a Numpy array.View aliases
tf.keras.utils.load_img,"tf.keras.utils.load_img(
    path,
    grayscale=False,
    color_mode='rgb',
    target_size=None,
    interpolation='nearest',
    keep_aspect_ratio=False
)
",Loads an image into PIL format.View aliases
tf.keras.preprocessing.image.random_brightness,"tf.keras.preprocessing.image.random_brightness(
    x, brightness_range, scale=True
)
",Performs a random brightness shift.View aliases
tf.keras.preprocessing.image.random_channel_shift,"tf.keras.preprocessing.image.random_channel_shift(
    x, intensity_range, channel_axis=0
)
",Performs a random channel shift.View aliases
tf.keras.preprocessing.image.random_rotation,"tf.keras.preprocessing.image.random_rotation(
    x,
    rg,
    row_axis=1,
    col_axis=2,
    channel_axis=0,
    fill_mode='nearest',
    cval=0.0,
    interpolation_order=1
)
",Performs a random rotation of a Numpy image tensor.View aliases
tf.keras.preprocessing.image.random_shear,"tf.keras.preprocessing.image.random_shear(
    x,
    intensity,
    row_axis=1,
    col_axis=2,
    channel_axis=0,
    fill_mode='nearest',
    cval=0.0,
    interpolation_order=1
)
",Performs a random spatial shear of a Numpy image tensor.View aliases
tf.keras.preprocessing.image.random_shift,"tf.keras.preprocessing.image.random_shift(
    x,
    wrg,
    hrg,
    row_axis=1,
    col_axis=2,
    channel_axis=0,
    fill_mode='nearest',
    cval=0.0,
    interpolation_order=1
)
",Performs a random spatial shift of a Numpy image tensor.View aliases
tf.keras.preprocessing.image.random_zoom,"tf.keras.preprocessing.image.random_zoom(
    x,
    zoom_range,
    row_axis=1,
    col_axis=2,
    channel_axis=0,
    fill_mode='nearest',
    cval=0.0,
    interpolation_order=1
)
",Performs a random spatial zoom of a Numpy image tensor.View aliases
tf.keras.utils.save_img,"tf.keras.utils.save_img(
    path, x, data_format=None, file_format=None, scale=True, **kwargs
)
",Saves an image stored as a Numpy array to a path or file object.View aliases
tf.keras.preprocessing.sequence.TimeseriesGenerator,"tf.keras.preprocessing.sequence.TimeseriesGenerator(
    data,
    targets,
    length,
    sampling_rate=1,
    stride=1,
    start_index=0,
    end_index=None,
    shuffle=False,
    reverse=False,
    batch_size=128
)
",Utility class for generating batches of temporal data.Inherits From: SequenceView aliases
tf.keras.preprocessing.sequence.make_sampling_table,"tf.keras.preprocessing.sequence.make_sampling_table(
    size, sampling_factor=1e-05
)
",Generates a word rank-based probabilistic sampling table.View aliases
tf.keras.utils.pad_sequences,"tf.keras.utils.pad_sequences(
    sequences,
    maxlen=None,
    dtype='int32',
    padding='pre',
    truncating='pre',
    value=0.0
)
",Pads sequences to the same length.View aliases
tf.keras.preprocessing.sequence.skipgrams,"tf.keras.preprocessing.sequence.skipgrams(
    sequence,
    vocabulary_size,
    window_size=4,
    negative_samples=1.0,
    shuffle=True,
    categorical=False,
    sampling_table=None,
    seed=None
)
",Generates skipgram word pairs.View aliases
tf.keras.preprocessing.text.Tokenizer,"tf.keras.preprocessing.text.Tokenizer(
    num_words=None,
    filters='!""#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
    lower=True,
    split=' ',
    char_level=False,
    oov_token=None,
    analyzer=None,
    **kwargs
)
",Text tokenization utility class.View aliases
tf.keras.preprocessing.text.hashing_trick,"tf.keras.preprocessing.text.hashing_trick(
    text,
    n,
    hash_function=None,
    filters='!""#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
    lower=True,
    split=' ',
    analyzer=None
)
",Converts a text to a sequence of indexes in a fixed-size hashing space.View aliases
tf.keras.preprocessing.text.one_hot,"tf.keras.preprocessing.text.one_hot(
    input_text,
    n,
    filters='!""#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
    lower=True,
    split=' ',
    analyzer=None
)
",One-hot encodes a text into a list of word indexes of size n.View aliases
tf.keras.preprocessing.text.text_to_word_sequence,"tf.keras.preprocessing.text.text_to_word_sequence(
    input_text,
    filters='!""#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',
    lower=True,
    split=' '
)
",Converts a text to a sequence of words (or tokens).View aliases
tf.keras.preprocessing.text.tokenizer_from_json,"tf.keras.preprocessing.text.tokenizer_from_json(
    json_string
)
",Parses a JSON tokenizer configuration and returns a tokenizer instance.View aliases
tf.keras.regularizers.L1,"tf.keras.regularizers.L1(
    l1=0.01, **kwargs
)
",A regularizer that applies a L1 regularization penalty.Inherits From: RegularizerView aliases
tf.keras.regularizers.L1L2,"tf.keras.regularizers.L1L2(
    l1=0.0, l2=0.0
)
",A regularizer that applies both L1 and L2 regularization penalties.Inherits From: RegularizerView aliases
tf.keras.regularizers.L2,"tf.keras.regularizers.L2(
    l2=0.01, **kwargs
)
",A regularizer that applies a L2 regularization penalty.Inherits From: RegularizerView aliases
tf.keras.regularizers.deserialize,"tf.keras.regularizers.deserialize(
    config, custom_objects=None
)
",View aliases
tf.keras.regularizers.get,"tf.keras.regularizers.get(
    identifier
)
",Retrieve a regularizer instance from a config or identifier.View aliases
tf.keras.regularizers.L1,"tf.keras.regularizers.L1(
    l1=0.01, **kwargs
)
",A regularizer that applies a L1 regularization penalty.Inherits From: RegularizerView aliases
tf.keras.regularizers.l1_l2,"tf.keras.regularizers.l1_l2(
    l1=0.01, l2=0.01
)
",Create a regularizer that applies both L1 and L2 penalties.View aliases
tf.keras.regularizers.L2,"tf.keras.regularizers.L2(
    l2=0.01, **kwargs
)
",A regularizer that applies a L2 regularization penalty.Inherits From: RegularizerView aliases
tf.keras.regularizers.serialize,"tf.keras.regularizers.serialize(
    regularizer
)
",View aliases
tf.keras.utils.custom_object_scope,"tf.keras.utils.custom_object_scope(
    *args
)
",Exposes custom classes/functions to Keras deserialization internals.View aliases
tf.compat.v1.keras.utils.DeterministicRandomTestTool,"tf.compat.v1.keras.utils.DeterministicRandomTestTool(
    seed: int = 42, mode='constant'
)
",DeterministicRandomTestTool is a testing tool.
tf.keras.utils.GeneratorEnqueuer,"tf.keras.utils.GeneratorEnqueuer(
    generator, use_multiprocessing=False, random_seed=None
)
",Builds a queue out of a data generator.Inherits From: SequenceEnqueuerView aliases
tf.keras.utils.OrderedEnqueuer,"tf.keras.utils.OrderedEnqueuer(
    sequence, use_multiprocessing=False, shuffle=False
)
",Builds a Enqueuer from a Sequence.Inherits From: SequenceEnqueuerView aliases
tf.keras.utils.Progbar,"tf.keras.utils.Progbar(
    target,
    width=30,
    verbose=1,
    interval=0.05,
    stateful_metrics=None,
    unit_name='step'
)
",Displays a progress bar.View aliases
tf.keras.utils.SequenceEnqueuer,"tf.keras.utils.SequenceEnqueuer(
    sequence, use_multiprocessing=False
)
",Base class to enqueue inputs.View aliases
tf.keras.utils.array_to_img,"tf.keras.utils.array_to_img(
    x, data_format=None, scale=True, dtype=None
)
",Converts a 3D Numpy array to a PIL Image instance.View aliases
tf.keras.utils.custom_object_scope,"tf.keras.utils.custom_object_scope(
    *args
)
",Exposes custom classes/functions to Keras deserialization internals.View aliases
tf.keras.utils.deserialize_keras_object,"tf.keras.utils.deserialize_keras_object(
    identifier,
    module_objects=None,
    custom_objects=None,
    printable_module_name='object'
)
",Turns the serialized form of a Keras object back into an actual object.View aliases
tf.keras.utils.get_file,"tf.keras.utils.get_file(
    fname=None,
    origin=None,
    untar=False,
    md5_hash=None,
    file_hash=None,
    cache_subdir='datasets',
    hash_algorithm='auto',
    extract=False,
    archive_format='auto',
    cache_dir=None
)
",Downloads a file from a URL if it not already in the cache.View aliases
tf.compat.v1.keras.utils.get_or_create_layer,"tf.compat.v1.keras.utils.get_or_create_layer(
    name, create_layer_method
)
",Use this method to track nested keras models in a shim-decorated method.
tf.keras.utils.get_registered_name,"tf.keras.utils.get_registered_name(
    obj
)
",Returns the name registered to an object within the Keras framework.View aliases
tf.keras.utils.get_registered_object,"tf.keras.utils.get_registered_object(
    name, custom_objects=None, module_objects=None
)
",Returns the class associated with name if it is registered with Keras.View aliases
tf.keras.utils.get_source_inputs,"tf.keras.utils.get_source_inputs(
    tensor, layer=None, node_index=None
)
",Returns the list of input tensors necessary to compute tensor.View aliases
tf.keras.utils.img_to_array,"tf.keras.utils.img_to_array(
    img, data_format=None, dtype=None
)
",Converts a PIL Image instance to a Numpy array.View aliases
tf.keras.utils.load_img,"tf.keras.utils.load_img(
    path,
    grayscale=False,
    color_mode='rgb',
    target_size=None,
    interpolation='nearest',
    keep_aspect_ratio=False
)
",Loads an image into PIL format.View aliases
tf.keras.utils.model_to_dot,"tf.keras.utils.model_to_dot(
    model,
    show_shapes=False,
    show_dtype=False,
    show_layer_names=True,
    rankdir='TB',
    expand_nested=False,
    dpi=96,
    subgraph=False,
    layer_range=None,
    show_layer_activations=False
)
",Convert a Keras model to dot format.View aliases
tf.keras.utils.normalize,"tf.keras.utils.normalize(
    x, axis=-1, order=2
)
",Normalizes a Numpy array.View aliases
tf.keras.utils.pad_sequences,"tf.keras.utils.pad_sequences(
    sequences,
    maxlen=None,
    dtype='int32',
    padding='pre',
    truncating='pre',
    value=0.0
)
",Pads sequences to the same length.View aliases
tf.keras.utils.plot_model,"tf.keras.utils.plot_model(
    model,
    to_file='model.png',
    show_shapes=False,
    show_dtype=False,
    show_layer_names=True,
    rankdir='TB',
    expand_nested=False,
    dpi=96,
    layer_range=None,
    show_layer_activations=False
)
",Converts a Keras model to dot format and save to a file.View aliases
tf.keras.utils.register_keras_serializable,"tf.keras.utils.register_keras_serializable(
    package='Custom', name=None
)
",Registers an object with the Keras serialization framework.View aliases
tf.keras.utils.save_img,"tf.keras.utils.save_img(
    path, x, data_format=None, file_format=None, scale=True, **kwargs
)
",Saves an image stored as a Numpy array to a path or file object.View aliases
tf.keras.utils.serialize_keras_object,"tf.keras.utils.serialize_keras_object(
    instance
)
",Serialize a Keras object into a JSON-compatible representation.View aliases
tf.keras.utils.to_categorical,"tf.keras.utils.to_categorical(
    y, num_classes=None, dtype='float32'
)
",Converts a class vector (integers) to binary class matrix.View aliases
tf.compat.v1.keras.utils.track_tf1_style_variables,"tf.compat.v1.keras.utils.track_tf1_style_variables(
    method
)
",Wrap layer & module methods in this decorator to capture tf1-style
tf.compat.v1.layers.AveragePooling1D,"tf.compat.v1.layers.AveragePooling1D(
    pool_size,
    strides,
    padding='valid',
    data_format='channels_last',
    name=None,
    **kwargs
)
","Average Pooling layer for 1D inputs.Inherits From: AveragePooling1D, Layer, Layer, Module"
tf.compat.v1.layers.AveragePooling2D,"tf.compat.v1.layers.AveragePooling2D(
    pool_size,
    strides,
    padding='valid',
    data_format='channels_last',
    name=None,
    **kwargs
)
","Average pooling layer for 2D inputs (e.g. images).Inherits From: AveragePooling2D, Layer, Layer, Module"
tf.compat.v1.layers.AveragePooling3D,"tf.compat.v1.layers.AveragePooling3D(
    pool_size,
    strides,
    padding='valid',
    data_format='channels_last',
    name=None,
    **kwargs
)
","Average pooling layer for 3D inputs (e.g. volumes).Inherits From: AveragePooling3D, Layer, Layer, Module"
tf.compat.v1.layers.BatchNormalization,"tf.compat.v1.layers.BatchNormalization(
    axis=-1,
    momentum=0.99,
    epsilon=0.001,
    center=True,
    scale=True,
    beta_initializer=tf.compat.v1.zeros_initializer(),
    gamma_initializer=tf.compat.v1.ones_initializer(),
    moving_mean_initializer=tf.compat.v1.zeros_initializer(),
    moving_variance_initializer=tf.compat.v1.ones_initializer(),
    beta_regularizer=None,
    gamma_regularizer=None,
    beta_constraint=None,
    gamma_constraint=None,
    renorm=False,
    renorm_clipping=None,
    renorm_momentum=0.99,
    fused=None,
    trainable=True,
    virtual_batch_size=None,
    adjustment=None,
    name=None,
    **kwargs
)
","Batch Normalization layer from (Ioffe et al., 2015).Inherits From: BatchNormalization, Layer, Layer, Module"
tf.compat.v1.layers.Conv1D,"tf.compat.v1.layers.Conv1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format='channels_last',
    dilation_rate=1,
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    **kwargs
)
","1D convolution layer (e.g. temporal convolution).Inherits From: Conv1D, Layer, Layer, Module"
tf.compat.v1.layers.Conv2D,"tf.compat.v1.layers.Conv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format='channels_last',
    dilation_rate=(1, 1),
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    **kwargs
)
","2D convolution layer (e.g. spatial convolution over images).Inherits From: Conv2D, Layer, Layer, Module"
tf.compat.v1.layers.Conv2DTranspose,"tf.compat.v1.layers.Conv2DTranspose(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format='channels_last',
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    **kwargs
)
","Transposed 2D convolution layer (sometimes called 2D Deconvolution).Inherits From: Conv2DTranspose, Conv2D, Layer, Layer, Module"
tf.compat.v1.layers.Conv3D,"tf.compat.v1.layers.Conv3D(
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    data_format='channels_last',
    dilation_rate=(1, 1, 1),
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    **kwargs
)
","3D convolution layer (e.g. spatial convolution over volumes).Inherits From: Conv3D, Layer, Layer, Module"
tf.compat.v1.layers.Conv3DTranspose,"tf.compat.v1.layers.Conv3DTranspose(
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    data_format='channels_last',
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    **kwargs
)
","Transposed 3D convolution layer (sometimes called 3D Deconvolution).Inherits From: Conv3DTranspose, Conv3D, Layer, Layer, Module"
tf.compat.v1.layers.Dense,"tf.compat.v1.layers.Dense(
    units,
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    **kwargs
)
","Densely-connected layer class.Inherits From: Dense, Layer, Layer, Module"
tf.compat.v1.layers.Dropout,"tf.compat.v1.layers.Dropout(
    rate=0.5, noise_shape=None, seed=None, name=None, **kwargs
)
","Applies Dropout to the input.Inherits From: Dropout, Layer, Layer, Module"
tf.compat.v1.layers.Flatten,"tf.compat.v1.layers.Flatten(
    data_format=None, **kwargs
)
","Flattens an input tensor while preserving the batch axis (axis 0).Inherits From: Flatten, Layer, Layer, Module"
tf.keras.layers.InputSpec,"tf.keras.layers.InputSpec(
    dtype=None,
    shape=None,
    ndim=None,
    max_ndim=None,
    min_ndim=None,
    axes=None,
    allow_last_axis_squeeze=False,
    name=None
)
","Specifies the rank, dtype and shape of every input to a layer.View aliases"
tf.compat.v1.layers.Layer,"tf.compat.v1.layers.Layer(
    trainable=True, name=None, dtype=None, **kwargs
)
","Base layer class.Inherits From: Layer, Module"
tf.compat.v1.layers.MaxPooling1D,"tf.compat.v1.layers.MaxPooling1D(
    pool_size,
    strides,
    padding='valid',
    data_format='channels_last',
    name=None,
    **kwargs
)
","Max Pooling layer for 1D inputs.Inherits From: MaxPool1D, Layer, Layer, Module"
tf.compat.v1.layers.MaxPooling2D,"tf.compat.v1.layers.MaxPooling2D(
    pool_size,
    strides,
    padding='valid',
    data_format='channels_last',
    name=None,
    **kwargs
)
","Max pooling layer for 2D inputs (e.g. images).Inherits From: MaxPool2D, Layer, Layer, Module"
tf.compat.v1.layers.MaxPooling3D,"tf.compat.v1.layers.MaxPooling3D(
    pool_size,
    strides,
    padding='valid',
    data_format='channels_last',
    name=None,
    **kwargs
)
","Max pooling layer for 3D inputs (e.g. volumes).Inherits From: MaxPool3D, Layer, Layer, Module"
tf.compat.v1.layers.SeparableConv1D,"tf.compat.v1.layers.SeparableConv1D(
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format='channels_last',
    dilation_rate=1,
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    depthwise_initializer=None,
    pointwise_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    depthwise_regularizer=None,
    pointwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    pointwise_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    **kwargs
)
","Depthwise separable 1D convolution.Inherits From: SeparableConv1D, Layer, Layer, Module"
tf.compat.v1.layers.SeparableConv2D,"tf.compat.v1.layers.SeparableConv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format='channels_last',
    dilation_rate=(1, 1),
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    depthwise_initializer=None,
    pointwise_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    depthwise_regularizer=None,
    pointwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    pointwise_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    **kwargs
)
","Depthwise separable 2D convolution.Inherits From: SeparableConv2D, Layer, Layer, Module"
tf.compat.v1.layers.average_pooling1d,"tf.compat.v1.layers.average_pooling1d(
    inputs,
    pool_size,
    strides,
    padding='valid',
    data_format='channels_last',
    name=None
)
",Average Pooling layer for 1D inputs.
tf.compat.v1.layers.average_pooling2d,"tf.compat.v1.layers.average_pooling2d(
    inputs,
    pool_size,
    strides,
    padding='valid',
    data_format='channels_last',
    name=None
)
",Average pooling layer for 2D inputs (e.g. images).
tf.compat.v1.layers.average_pooling3d,"tf.compat.v1.layers.average_pooling3d(
    inputs,
    pool_size,
    strides,
    padding='valid',
    data_format='channels_last',
    name=None
)
",Average pooling layer for 3D inputs (e.g. volumes).
tf.compat.v1.layers.batch_normalization,"tf.compat.v1.layers.batch_normalization(
    inputs,
    axis=-1,
    momentum=0.99,
    epsilon=0.001,
    center=True,
    scale=True,
    beta_initializer=tf.compat.v1.zeros_initializer(),
    gamma_initializer=tf.compat.v1.ones_initializer(),
    moving_mean_initializer=tf.compat.v1.zeros_initializer(),
    moving_variance_initializer=tf.compat.v1.ones_initializer(),
    beta_regularizer=None,
    gamma_regularizer=None,
    beta_constraint=None,
    gamma_constraint=None,
    training=False,
    trainable=True,
    name=None,
    reuse=None,
    renorm=False,
    renorm_clipping=None,
    renorm_momentum=0.99,
    fused=None,
    virtual_batch_size=None,
    adjustment=None
)
",Functional interface for the batch normalization layer from_config(Ioffe
tf.compat.v1.layers.conv1d,"tf.compat.v1.layers.conv1d(
    inputs,
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format='channels_last',
    dilation_rate=1,
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    reuse=None
)
",Functional interface for 1D convolution layer (e.g. temporal convolution).
tf.compat.v1.layers.conv2d,"tf.compat.v1.layers.conv2d(
    inputs,
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format='channels_last',
    dilation_rate=(1, 1),
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    reuse=None
)
",Functional interface for the 2D convolution layer.
tf.compat.v1.layers.conv2d_transpose,"tf.compat.v1.layers.conv2d_transpose(
    inputs,
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format='channels_last',
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    reuse=None
)
",Functional interface for transposed 2D convolution layer.
tf.compat.v1.layers.conv3d,"tf.compat.v1.layers.conv3d(
    inputs,
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    data_format='channels_last',
    dilation_rate=(1, 1, 1),
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    reuse=None
)
",Functional interface for the 3D convolution layer.
tf.compat.v1.layers.conv3d_transpose,"tf.compat.v1.layers.conv3d_transpose(
    inputs,
    filters,
    kernel_size,
    strides=(1, 1, 1),
    padding='valid',
    data_format='channels_last',
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    reuse=None
)
",Functional interface for transposed 3D convolution layer.
tf.compat.v1.layers.dense,"tf.compat.v1.layers.dense(
    inputs,
    units,
    activation=None,
    use_bias=True,
    kernel_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    reuse=None
)
",Functional interface for the densely-connected layer.
tf.compat.v1.layers.dropout,"tf.compat.v1.layers.dropout(
    inputs, rate=0.5, noise_shape=None, seed=None, training=False, name=None
)
",Applies Dropout to the input.
tf.compat.v1.layers.flatten,"tf.compat.v1.layers.flatten(
    inputs, name=None, data_format='channels_last'
)
",Flattens an input tensor while preserving the batch axis (axis 0).
tf.compat.v1.layers.max_pooling1d,"tf.compat.v1.layers.max_pooling1d(
    inputs,
    pool_size,
    strides,
    padding='valid',
    data_format='channels_last',
    name=None
)
",Max Pooling layer for 1D inputs.
tf.compat.v1.layers.max_pooling2d,"tf.compat.v1.layers.max_pooling2d(
    inputs,
    pool_size,
    strides,
    padding='valid',
    data_format='channels_last',
    name=None
)
",Max pooling layer for 2D inputs (e.g. images).
tf.compat.v1.layers.max_pooling3d,"tf.compat.v1.layers.max_pooling3d(
    inputs,
    pool_size,
    strides,
    padding='valid',
    data_format='channels_last',
    name=None
)
",Max pooling layer for 3D inputs (e.g.
tf.compat.v1.layers.separable_conv1d,"tf.compat.v1.layers.separable_conv1d(
    inputs,
    filters,
    kernel_size,
    strides=1,
    padding='valid',
    data_format='channels_last',
    dilation_rate=1,
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    depthwise_initializer=None,
    pointwise_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    depthwise_regularizer=None,
    pointwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    pointwise_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    reuse=None
)
",Functional interface for the depthwise separable 1D convolution layer.
tf.compat.v1.layers.separable_conv2d,"tf.compat.v1.layers.separable_conv2d(
    inputs,
    filters,
    kernel_size,
    strides=(1, 1),
    padding='valid',
    data_format='channels_last',
    dilation_rate=(1, 1),
    depth_multiplier=1,
    activation=None,
    use_bias=True,
    depthwise_initializer=None,
    pointwise_initializer=None,
    bias_initializer=tf.compat.v1.zeros_initializer(),
    depthwise_regularizer=None,
    pointwise_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    depthwise_constraint=None,
    pointwise_constraint=None,
    bias_constraint=None,
    trainable=True,
    name=None,
    reuse=None
)
",Functional interface for the depthwise separable 2D convolution layer.
tf.math.lbeta,"tf.math.lbeta(
    x, name=None
)
","Computes \(ln(|Beta(x)|)\), reducing along the last dimension.View aliases"
tf.math.less,"tf.math.less(
    x, y, name=None
)
",Returns the truth value of (x < y) element-wise.View aliases
tf.math.less_equal,"tf.math.less_equal(
    x, y, name=None
)
",Returns the truth value of (x <= y) element-wise.View aliases
tf.math.lgamma,"tf.math.lgamma(
    x, name=None
)
",Computes the log of the absolute value of Gamma(x) element-wise.View aliases
tf.linspace,"tf.linspace(
    start, stop, num, name=None, axis=0
)
",Generates evenly-spaced values in an interval along a given axis.View aliases
tf.linalg.LinearOperator,"tf.linalg.LinearOperator(
    dtype,
    graph_parents=None,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name=None,
    parameters=None
)
",Base class defining a [batch of] linear operator[s].Inherits From: ModuleView aliases
tf.linalg.LinearOperatorAdjoint,"tf.linalg.LinearOperatorAdjoint(
    operator,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name=None
)
","LinearOperator representing the adjoint of another operator.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorBlockDiag,"tf.linalg.LinearOperatorBlockDiag(
    operators,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=True,
    name=None
)
","Combines one or more LinearOperators in to a Block Diagonal matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorBlockLowerTriangular,"tf.linalg.LinearOperatorBlockLowerTriangular(
    operators,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorBlockLowerTriangular'
)
","Combines LinearOperators into a blockwise lower-triangular matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorCirculant,"tf.linalg.LinearOperatorCirculant(
    spectrum,
    input_output_dtype=tf.dtypes.complex64,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=True,
    name='LinearOperatorCirculant'
)
","LinearOperator acting like a circulant matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorCirculant2D,"tf.linalg.LinearOperatorCirculant2D(
    spectrum,
    input_output_dtype=tf.dtypes.complex64,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=True,
    name='LinearOperatorCirculant2D'
)
","LinearOperator acting like a block circulant matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorCirculant3D,"tf.linalg.LinearOperatorCirculant3D(
    spectrum,
    input_output_dtype=tf.dtypes.complex64,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=True,
    name='LinearOperatorCirculant3D'
)
","LinearOperator acting like a nested block circulant matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorComposition,"tf.linalg.LinearOperatorComposition(
    operators,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name=None
)
","Composes one or more LinearOperators.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorDiag,"tf.linalg.LinearOperatorDiag(
    diag,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorDiag'
)
","LinearOperator acting like a [batch] square diagonal matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorFullMatrix,"tf.linalg.LinearOperatorFullMatrix(
    matrix,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorFullMatrix'
)
","LinearOperator that wraps a [batch] matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorHouseholder,"tf.linalg.LinearOperatorHouseholder(
    reflection_axis,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorHouseholder'
)
","LinearOperator acting like a [batch] of Householder transformations.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorIdentity,"tf.linalg.LinearOperatorIdentity(
    num_rows,
    batch_shape=None,
    dtype=None,
    is_non_singular=True,
    is_self_adjoint=True,
    is_positive_definite=True,
    is_square=True,
    assert_proper_shapes=False,
    name='LinearOperatorIdentity'
)
","LinearOperator acting like a [batch] square identity matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorInversion,"tf.linalg.LinearOperatorInversion(
    operator,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name=None
)
","LinearOperator representing the inverse of another operator.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorKronecker,"tf.linalg.LinearOperatorKronecker(
    operators,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name=None
)
","Kronecker product between two LinearOperators.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorLowRankUpdate,"tf.linalg.LinearOperatorLowRankUpdate(
    base_operator,
    u,
    diag_update=None,
    v=None,
    is_diag_update_positive=None,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorLowRankUpdate'
)
","Perturb a LinearOperator with a rank K update.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorLowerTriangular,"tf.linalg.LinearOperatorLowerTriangular(
    tril,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorLowerTriangular'
)
","LinearOperator acting like a [batch] square lower triangular matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorPermutation,"tf.linalg.LinearOperatorPermutation(
    perm,
    dtype=tf.dtypes.float32,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorPermutation'
)
","LinearOperator acting like a [batch] of permutation matrices.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorScaledIdentity,"tf.linalg.LinearOperatorScaledIdentity(
    num_rows,
    multiplier,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=True,
    assert_proper_shapes=False,
    name='LinearOperatorScaledIdentity'
)
","LinearOperator acting like a scaled [batch] identity matrix A = c I.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorToeplitz,"tf.linalg.LinearOperatorToeplitz(
    col,
    row,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorToeplitz'
)
","LinearOperator acting like a [batch] of toeplitz matrices.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorTridiag,"tf.linalg.LinearOperatorTridiag(
    diagonals,
    diagonals_format=_COMPACT,
    is_non_singular=None,
    is_self_adjoint=None,
    is_positive_definite=None,
    is_square=None,
    name='LinearOperatorTridiag'
)
","LinearOperator acting like a [batch] square tridiagonal matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.LinearOperatorZeros,"tf.linalg.LinearOperatorZeros(
    num_rows,
    num_columns=None,
    batch_shape=None,
    dtype=None,
    is_non_singular=False,
    is_self_adjoint=True,
    is_positive_definite=False,
    is_square=True,
    assert_proper_shapes=False,
    name='LinearOperatorZeros'
)
","LinearOperator acting like a [batch] zero matrix.Inherits From: LinearOperator, ModuleView aliases"
tf.linalg.adjoint,"tf.linalg.adjoint(
    matrix, name=None
)
",Transposes the last two dimensions of and conjugates tensor matrix.View aliases
tf.linalg.band_part,"tf.linalg.band_part(
    input, num_lower, num_upper, name=None
)
",Copy a tensor setting everything outside a central band in each innermost matrix to zero.View aliases
tf.linalg.cholesky,"tf.linalg.cholesky(
    input, name=None
)
",Computes the Cholesky decomposition of one or more square matrices.View aliases
tf.linalg.cholesky_solve,"tf.linalg.cholesky_solve(
    chol, rhs, name=None
)
","Solves systems of linear eqns A X = RHS, given Cholesky factorizations.View aliases"
tf.linalg.cross,"tf.linalg.cross(
    a, b, name=None
)
",Compute the pairwise cross product.View aliases
tf.linalg.det,"tf.linalg.det(
    input, name=None
)
",Computes the determinant of one or more square matrices.View aliases
tf.linalg.diag,"tf.linalg.diag(
    diagonal,
    name='diag',
    k=0,
    num_rows=-1,
    num_cols=-1,
    padding_value=0,
    align='RIGHT_LEFT'
)
",Returns a batched diagonal tensor with given batched diagonal values.View aliases
tf.linalg.diag_part,"tf.linalg.diag_part(
    input,
    name='diag_part',
    k=0,
    padding_value=0,
    align='RIGHT_LEFT'
)
",Returns the batched diagonal part of a batched tensor.View aliases
tf.linalg.eigh,"tf.linalg.eigh(
    tensor, name=None
)
",Computes the eigen decomposition of a batch of self-adjoint matrices.View aliases
tf.linalg.eigh_tridiagonal,"tf.linalg.eigh_tridiagonal(
    alpha,
    beta,
    eigvals_only=True,
    select='a',
    select_range=None,
    tol=None,
    name=None
)
",Computes the eigenvalues of a Hermitian tridiagonal matrix.View aliases
tf.linalg.eigvalsh,"tf.linalg.eigvalsh(
    tensor, name=None
)
",Computes the eigenvalues of one or more self-adjoint matrices.View aliases
tf.einsum,"tf.einsum(
    equation, *inputs, **kwargs
)
",Tensor contraction over specified indices and outer product.View aliases
tf.linalg.experimental.conjugate_gradient,"tf.linalg.experimental.conjugate_gradient(
    operator,
    rhs,
    preconditioner=None,
    x=None,
    tol=1e-05,
    max_iter=20,
    name='conjugate_gradient'
)
",Conjugate gradient solver.View aliases
tf.linalg.expm,"tf.linalg.expm(
    input, name=None
)
",Computes the matrix exponential of one or more square matrices.View aliases
tf.eye,"tf.eye(
    num_rows,
    num_columns=None,
    batch_shape=None,
    dtype=tf.dtypes.float32,
    name=None
)
","Construct an identity matrix, or a batch of matrices.View aliases"
tf.linalg.global_norm,"tf.linalg.global_norm(
    t_list, name=None
)
",Computes the global norm of multiple tensors.View aliases
tf.linalg.inv,"tf.linalg.inv(
    input, adjoint=False, name=None
)
",Computes the inverse of one or more square invertible matrices or their adjoints (conjugate transposes).View aliases
tf.math.l2_normalize,"tf.math.l2_normalize(
    x, axis=None, epsilon=1e-12, name=None, dim=None
)
",Normalizes along dimension axis using an L2 norm. (deprecated arguments)View aliases
tf.linalg.logdet,"tf.linalg.logdet(
    matrix, name=None
)
",Computes log of the determinant of a hermitian positive definite matrix.View aliases
tf.linalg.logm,"tf.linalg.logm(
    input, name=None
)
",Computes the matrix logarithm of one or more square matrices:View aliases
tf.linalg.lstsq,"tf.linalg.lstsq(
    matrix, rhs, l2_regularizer=0.0, fast=True, name=None
)
",Solves one or more linear least-squares problems.View aliases
tf.linalg.lu,"tf.linalg.lu(
    input,
    output_idx_type=tf.dtypes.int32,
    name=None
)
",Computes the LU decomposition of one or more square matrices.View aliases
tf.linalg.lu_matrix_inverse,"tf.linalg.lu_matrix_inverse(
    lower_upper, perm, validate_args=False, name=None
)
",Computes the inverse given the LU decomposition(s) of one or more matrices.View aliases
tf.linalg.lu_reconstruct,"tf.linalg.lu_reconstruct(
    lower_upper, perm, validate_args=False, name=None
)
",The reconstruct one or more matrices from their LU decomposition(s).View aliases
tf.linalg.lu_solve,"tf.linalg.lu_solve(
    lower_upper, perm, rhs, validate_args=False, name=None
)
","Solves systems of linear eqns A X = RHS, given LU factorizations.View aliases"
tf.linalg.matmul,"tf.linalg.matmul(
    a,
    b,
    transpose_a=False,
    transpose_b=False,
    adjoint_a=False,
    adjoint_b=False,
    a_is_sparse=False,
    b_is_sparse=False,
    output_type=None,
    name=None
)
","Multiplies matrix a by matrix b, producing a * b.View aliases"
tf.linalg.matrix_rank,"tf.linalg.matrix_rank(
    a, tol=None, validate_args=False, name=None
)
",Compute the matrix rank of one or more matrices.View aliases
tf.linalg.matrix_transpose,"tf.linalg.matrix_transpose(
    a, name='matrix_transpose', conjugate=False
)
",Transposes last two dimensions of tensor a.View aliases
tf.linalg.matvec,"tf.linalg.matvec(
    a,
    b,
    transpose_a=False,
    adjoint_a=False,
    a_is_sparse=False,
    b_is_sparse=False,
    name=None
)
","Multiplies matrix a by vector b, producing a * b.View aliases"
tf.compat.v1.norm,"tf.compat.v1.norm(
    tensor,
    ord='euclidean',
    axis=None,
    keepdims=None,
    name=None,
    keep_dims=None
)
","Computes the norm of vectors, matrices, and tensors. (deprecated arguments)View aliases"
tf.linalg.normalize,"tf.linalg.normalize(
    tensor, ord='euclidean', axis=None, name=None
)
",Normalizes tensor along dimension axis using specified norm.View aliases
tf.linalg.pinv,"tf.linalg.pinv(
    a, rcond=None, validate_args=False, name=None
)
",Compute the Moore-Penrose pseudo-inverse of one or more matrices.View aliases
tf.linalg.qr,"tf.linalg.qr(
    input, full_matrices=False, name=None
)
",Computes the QR decompositions of one or more matrices.View aliases
tf.linalg.set_diag,"tf.linalg.set_diag(
    input,
    diagonal,
    name='set_diag',
    k=0,
    align='RIGHT_LEFT'
)
",Returns a batched matrix tensor with new batched diagonal values.View aliases
tf.linalg.slogdet,"tf.linalg.slogdet(
    input, name=None
)
",Computes the sign and the log of the absolute value of the determinant ofView aliases
tf.linalg.solve,"tf.linalg.solve(
    matrix, rhs, adjoint=False, name=None
)
",Solves systems of linear equations.View aliases
tf.linalg.sqrtm,"tf.linalg.sqrtm(
    input, name=None
)
",Computes the matrix square root of one or more square matrices:View aliases
tf.linalg.svd,"tf.linalg.svd(
    tensor, full_matrices=False, compute_uv=True, name=None
)
",Computes the singular value decompositions of one or more matrices.View aliases
tf.linalg.tensor_diag,"tf.linalg.tensor_diag(
    diagonal, name=None
)
",Returns a diagonal tensor with a given diagonal values.View aliases
tf.linalg.tensor_diag_part,"tf.linalg.tensor_diag_part(
    input, name=None
)
",Returns the diagonal part of the tensor.View aliases
tf.tensordot,"tf.tensordot(
    a, b, axes, name=None
)
",Tensor contraction of a and b along specified axes and outer product.View aliases
tf.linalg.trace,"tf.linalg.trace(
    x, name=None
)
",Compute the trace of a tensor x.View aliases
tf.linalg.matrix_transpose,"tf.linalg.matrix_transpose(
    a, name='matrix_transpose', conjugate=False
)
",Transposes last two dimensions of tensor a.View aliases
tf.linalg.triangular_solve,"tf.linalg.triangular_solve(
    matrix, rhs, lower=True, adjoint=False, name=None
)
",Solve systems of linear equations with upper or lower triangular matrices.View aliases
tf.linalg.tridiagonal_matmul,"tf.linalg.tridiagonal_matmul(
    diagonals, rhs, diagonals_format='compact', name=None
)
",Multiplies tridiagonal matrix by matrix.View aliases
tf.linalg.tridiagonal_solve,"tf.linalg.tridiagonal_solve(
    diagonals,
    rhs,
    diagonals_format='compact',
    transpose_rhs=False,
    conjugate_rhs=False,
    name=None,
    partial_pivoting=True,
    perturb_singular=False
)
",Solves tridiagonal systems of equations.View aliases
tf.linspace,"tf.linspace(
    start, stop, num, name=None, axis=0
)
",Generates evenly-spaced values in an interval along a given axis.View aliases
tf.lite.Interpreter,"tf.lite.Interpreter(
    model_path=None,
    model_content=None,
    experimental_delegates=None,
    num_threads=None,
    experimental_op_resolver_type=tf.lite.experimental.OpResolverType.AUTO,
    experimental_preserve_all_tensors=False
)
",Interpreter interface for running TensorFlow Lite models.View aliases
tf.compat.v1.lite.OpHint,"tf.compat.v1.lite.OpHint(
    function_name, level=1, children_inputs_mappings=None, **kwargs
)
",A class that helps build tflite function invocations. (deprecated)
tf.compat.v1.lite.OpHint.OpHintArgumentTracker,"tf.compat.v1.lite.OpHint.OpHintArgumentTracker(
    function_name,
    unique_function_id,
    node_name_prefix,
    attr_name,
    level=1,
    children_inputs_mappings=None
)
","Conceptually tracks indices of arguments of ""OpHint functions""."
tf.lite.RepresentativeDataset,"tf.lite.RepresentativeDataset(
    input_gen
)
",Representative dataset used to optimize the model.View aliases
tf.compat.v1.lite.TFLiteConverter,"tf.compat.v1.lite.TFLiteConverter(
    graph_def,
    input_tensors,
    output_tensors,
    input_arrays_with_shape=None,
    output_arrays=None,
    experimental_debug_info_func=None
)
",Convert a TensorFlow model into output_format.
tf.lite.TargetSpec,"tf.lite.TargetSpec(
    supported_ops=None,
    supported_types=None,
    experimental_select_user_tf_ops=None,
    experimental_supported_backends=None
)
",Specification of target device used to optimize the model.View aliases
tf.lite.experimental.QuantizationDebugOptions,"tf.lite.experimental.QuantizationDebugOptions(
    layer_debug_metrics: Optional[Mapping[str, Callable[[np.ndarray], float]]] = None,
    model_debug_metrics: Optional[Mapping[str, Callable[[Sequence[np.ndarray], Sequence[np.ndarray]],
        float]]] = None,
    layer_direct_compare_metrics: Optional[Mapping[str, Callable[[Sequence[np.ndarray], Sequence[np.ndarray],
        float, int], float]]] = None,
    denylisted_ops: Optional[List[str]] = None,
    denylisted_nodes: Optional[List[str]] = None,
    fully_quantize: bool = False
) -> None
",Debug options to set up a given QuantizationDebugger.View aliases
tf.lite.experimental.QuantizationDebugger,"tf.lite.experimental.QuantizationDebugger(
    quant_debug_model_path: Optional[str] = None,
    quant_debug_model_content: Optional[bytes] = None,
    float_model_path: Optional[str] = None,
    float_model_content: Optional[bytes] = None,
    debug_dataset: Optional[Callable[[], Iterable[Sequence[np.ndarray]]]] = None,
    debug_options: Optional[tf.lite.experimental.QuantizationDebugOptions] = None,
    converter: Optional[TFLiteConverter] = None
) -> None
",Debugger for Quantized TensorFlow Lite debug mode models.View aliases
tf.lite.experimental.authoring.compatible,"tf.lite.experimental.authoring.compatible(
    target=None, converter_target_spec=None, **kwargs
)
",Wraps tf.function into a callable function with TFLite compatibility checking.View aliases
tf.compat.v1.lite.experimental.convert_op_hints_to_stubs,"tf.compat.v1.lite.experimental.convert_op_hints_to_stubs(
    session=None,
    graph_def=None,
    write_callback=(lambda graph_def, comments: None)
)
",Converts a graphdef with LiteOp hints into stub operations. (deprecated)
tf.lite.experimental.load_delegate,"tf.lite.experimental.load_delegate(
    library, options=None
)
",Returns loaded Delegate object.View aliases
tf.compat.v1.lite.toco_convert,"tf.compat.v1.lite.toco_convert(
    input_data, input_tensors, output_tensors, *args, **kwargs
)
",Convert a TensorFlow GraphDef to TFLite. (deprecated)
tf.compat.v1.load_file_system_library,"tf.compat.v1.load_file_system_library(
    library_filename
)
","Loads a TensorFlow plugin, containing file system implementation. (deprecated)"
tf.load_library,"tf.load_library(
    library_location
)
",Loads a TensorFlow plugin.View aliases
tf.load_op_library,"tf.load_op_library(
    library_filename
)
","Loads a TensorFlow plugin, containing custom ops and kernels.View aliases"
tf.compat.v1.local_variables,"tf.compat.v1.local_variables(
    scope=None
)
",Returns local variables.
tf.math.log,"tf.math.log(
    x, name=None
)
",Computes natural logarithm of x element-wise.View aliases
tf.math.log1p,"tf.math.log1p(
    x, name=None
)
",Computes natural logarithm of (1 + x) element-wise.View aliases
tf.math.log_sigmoid,"tf.math.log_sigmoid(
    x, name=None
)
",Computes log sigmoid of x element-wise.View aliases
tf.compat.v1.logging.TaskLevelStatusMessage,"tf.compat.v1.logging.TaskLevelStatusMessage(
    msg
)
",nan
tf.compat.v1.logging.debug,"tf.compat.v1.logging.debug(
    msg, *args, **kwargs
)
",nan
tf.compat.v1.logging.error,"tf.compat.v1.logging.error(
    msg, *args, **kwargs
)
",nan
tf.compat.v1.logging.fatal,"tf.compat.v1.logging.fatal(
    msg, *args, **kwargs
)
",nan
tf.compat.v1.logging.info,"tf.compat.v1.logging.info(
    msg, *args, **kwargs
)
",nan
tf.compat.v1.logging.log,"tf.compat.v1.logging.log(
    level, msg, *args, **kwargs
)
",nan
tf.compat.v1.logging.log_every_n,"tf.compat.v1.logging.log_every_n(
    level, msg, n, *args
)
",Log 'msg % args' at level 'level' once per 'n' times.
tf.compat.v1.logging.log_first_n,"tf.compat.v1.logging.log_first_n(
    level, msg, n, *args
)
",Log 'msg % args' at level 'level' only first 'n' times.
tf.compat.v1.logging.log_if,"tf.compat.v1.logging.log_if(
    level, msg, condition, *args
)
",Log 'msg % args' at level 'level' only if condition is fulfilled.
tf.compat.v1.logging.set_verbosity,"tf.compat.v1.logging.set_verbosity(
    v
)
",Sets the threshold for what messages will be logged.
tf.compat.v1.logging.vlog,"tf.compat.v1.logging.vlog(
    level, msg, *args, **kwargs
)
",nan
tf.compat.v1.logging.warn,"tf.compat.v1.logging.warn(
    msg, *args, **kwargs
)
",nan
tf.compat.v1.logging.warning,"tf.compat.v1.logging.warning(
    msg, *args, **kwargs
)
",nan
tf.math.logical_and,"tf.math.logical_and(
    x, y, name=None
)
",Returns the truth value of x AND y element-wise.View aliases
tf.math.logical_not,"tf.math.logical_not(
    x, name=None
)
",Returns the truth value of NOT x element-wise.View aliases
tf.math.logical_or,"tf.math.logical_or(
    x, y, name=None
)
",Returns the truth value of x OR y element-wise.View aliases
tf.math.logical_xor,"tf.math.logical_xor(
    x, y, name='LogicalXor'
)
",Logical XOR function.View aliases
tf.lookup.KeyValueTensorInitializer,"tf.lookup.KeyValueTensorInitializer(
    keys, values, key_dtype=None, value_dtype=None, name=None
)
",Table initializers given keys and values tensors.View aliases
tf.compat.v1.lookup.StaticHashTable,"tf.compat.v1.lookup.StaticHashTable(
    initializer, default_value, name=None, experimental_is_anonymous=False
)
","A generic hash table that is immutable once initialized.Inherits From: StaticHashTable, TrackableResource"
tf.compat.v1.lookup.StaticVocabularyTable,"tf.compat.v1.lookup.StaticVocabularyTable(
    initializer,
    num_oov_buckets,
    lookup_key_dtype=None,
    name=None,
    experimental_is_anonymous=False
)
","String to Id table that assigns out-of-vocabulary keys to hash buckets.Inherits From: StaticVocabularyTable, TrackableResource"
tf.lookup.TextFileInitializer,"tf.lookup.TextFileInitializer(
    filename,
    key_dtype,
    key_index,
    value_dtype,
    value_index,
    vocab_size=None,
    delimiter='\t',
    name=None,
    value_index_offset=0
)
",Table initializers from a text file.View aliases
tf.lookup.experimental.DenseHashTable,"tf.lookup.experimental.DenseHashTable(
    key_dtype,
    value_dtype,
    default_value,
    empty_key,
    deleted_key,
    initial_num_buckets=None,
    name='MutableDenseHashTable',
    checkpoint=True,
    experimental_is_anonymous=False
)
",A mutable hash table with faster lookups and higher memory usage.Inherits From: TrackableResourceView aliases
tf.lookup.experimental.MutableHashTable,"tf.lookup.experimental.MutableHashTable(
    key_dtype,
    value_dtype,
    default_value,
    name='MutableHashTable',
    checkpoint=True,
    experimental_is_anonymous=False
)
",A generic mutable hash table implementation.Inherits From: TrackableResourceView aliases
tf.compat.v1.losses.absolute_difference,"tf.compat.v1.losses.absolute_difference(
    labels,
    predictions,
    weights=1.0,
    scope=None,
    loss_collection=ops.GraphKeys.LOSSES,
    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS
)
",Adds an Absolute Difference loss to the training procedure.
tf.compat.v1.losses.add_loss,"tf.compat.v1.losses.add_loss(
    loss, loss_collection=ops.GraphKeys.LOSSES
)
",Adds a externally defined loss to the collection of losses.
tf.compat.v1.losses.compute_weighted_loss,"tf.compat.v1.losses.compute_weighted_loss(
    losses,
    weights=1.0,
    scope=None,
    loss_collection=ops.GraphKeys.LOSSES,
    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS
)
",Computes the weighted loss.
tf.compat.v1.losses.cosine_distance,"tf.compat.v1.losses.cosine_distance(
    labels,
    predictions,
    axis=None,
    weights=1.0,
    scope=None,
    loss_collection=ops.GraphKeys.LOSSES,
    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS,
    dim=None
)
",Adds a cosine-distance loss to the training procedure. (deprecated arguments)
tf.compat.v1.losses.get_losses,"tf.compat.v1.losses.get_losses(
    scope=None, loss_collection=ops.GraphKeys.LOSSES
)
",Gets the list of losses from the loss_collection.
tf.compat.v1.losses.get_regularization_loss,"tf.compat.v1.losses.get_regularization_loss(
    scope=None, name='total_regularization_loss'
)
",Gets the total regularization loss.
tf.compat.v1.losses.get_regularization_losses,"tf.compat.v1.losses.get_regularization_losses(
    scope=None
)
",Gets the list of regularization losses.
tf.compat.v1.losses.get_total_loss,"tf.compat.v1.losses.get_total_loss(
    add_regularization_losses=True, name='total_loss', scope=None
)
",Returns a tensor whose value represents the total loss.
tf.compat.v1.losses.hinge_loss,"tf.compat.v1.losses.hinge_loss(
    labels,
    logits,
    weights=1.0,
    scope=None,
    loss_collection=ops.GraphKeys.LOSSES,
    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS
)
",Adds a hinge loss to the training procedure.
tf.compat.v1.losses.huber_loss,"tf.compat.v1.losses.huber_loss(
    labels,
    predictions,
    weights=1.0,
    delta=1.0,
    scope=None,
    loss_collection=ops.GraphKeys.LOSSES,
    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS
)
",Adds a Huber Loss term to the training procedure.
tf.compat.v1.losses.log_loss,"tf.compat.v1.losses.log_loss(
    labels,
    predictions,
    weights=1.0,
    epsilon=1e-07,
    scope=None,
    loss_collection=ops.GraphKeys.LOSSES,
    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS
)
",Adds a Log Loss term to the training procedure.
tf.compat.v1.losses.mean_pairwise_squared_error,"tf.compat.v1.losses.mean_pairwise_squared_error(
    labels,
    predictions,
    weights=1.0,
    scope=None,
    loss_collection=ops.GraphKeys.LOSSES
)
",Adds a pairwise-errors-squared loss to the training procedure.
tf.compat.v1.losses.mean_squared_error,"tf.compat.v1.losses.mean_squared_error(
    labels,
    predictions,
    weights=1.0,
    scope=None,
    loss_collection=ops.GraphKeys.LOSSES,
    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS
)
",Adds a Sum-of-Squares loss to the training procedure.
tf.compat.v1.losses.mean_squared_error,tf.compat.v1.losses.mean_squared_error(,"Adds a Sum-of-Squares loss to the training procedure.tf.compat.v1.losses.mean_squared_error(    labels,    predictions,    weights=1.0,    scope=None,    loss_collection=ops.GraphKeys.LOSSES,    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS)Caution: This API was designed for TensorFlow v1.Continue reading for details on how to migrate from this API to a nativeTensorFlow v2 equivalent. See thetf.compat.v1.losses.mean_squared_error is mostly compatible with eagerexecution and tf.function. But, the loss_collection argument isignored when executing eagerly and no loss will be written to the losscollections. You will need to either hold on to the return value manuallyor rely on tf.keras.Model loss tracking.To switch to native TF2 style, instantiate the tf.keras.losses.MeanSquaredError class and call the object instead.Structural Mapping to Native TF2Before:loss = tf.compat.v1.losses.mean_squared_error(  labels=labels,  predictions=predictions,  weights=weights,  reduction=reduction)After:loss_fn = tf.keras.losses.MeanSquaredError(  reduction=reduction)loss = loss_fn(  y_true=labels,  y_pred=predictions,  sample_weight=weights)How to Map ArgumentsBefore & After Usage ExampleBefore:y_true = [1, 2, 3]y_pred = [1, 3, 5]weights = [0, 1, 0.25]# samples with zero-weight are excluded from calculation when `reduction`# argument is set to default value `Reduction.SUM_BY_NONZERO_WEIGHTS`tf.compat.v1.losses.mean_squared_error(   labels=y_true,   predictions=y_pred,   weights=weights).numpy()1.0"
tf.compat.v1.losses.sigmoid_cross_entropy,"tf.compat.v1.losses.sigmoid_cross_entropy(
    multi_class_labels,
    logits,
    weights=1.0,
    label_smoothing=0,
    scope=None,
    loss_collection=ops.GraphKeys.LOSSES,
    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS
)
",Creates a cross-entropy loss using tf.nn.sigmoid_cross_entropy_with_logits.
tf.compat.v1.losses.softmax_cross_entropy,"tf.compat.v1.losses.softmax_cross_entropy(
    onehot_labels,
    logits,
    weights=1.0,
    label_smoothing=0,
    scope=None,
    loss_collection=ops.GraphKeys.LOSSES,
    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS
)
",Creates a cross-entropy loss using tf.nn.softmax_cross_entropy_with_logits_v2.
tf.compat.v1.losses.sparse_softmax_cross_entropy,"tf.compat.v1.losses.sparse_softmax_cross_entropy(
    labels,
    logits,
    weights=1.0,
    scope=None,
    loss_collection=ops.GraphKeys.LOSSES,
    reduction=Reduction.SUM_BY_NONZERO_WEIGHTS
)
",Cross-entropy loss using tf.nn.sparse_softmax_cross_entropy_with_logits.
tf.make_ndarray,"tf.make_ndarray(
    tensor
)
",Create a numpy ndarray from a tensor.View aliases
tf.compat.v1.make_template,"tf.compat.v1.make_template(
    name_,
    func_,
    create_scope_now_=False,
    unique_name_=None,
    custom_getter_=None,
    **kwargs
)
","Given an arbitrary function, wrap it so that it does variable sharing."
tf.make_tensor_proto,"tf.make_tensor_proto(
    values, dtype=None, shape=None, verify_shape=False, allow_broadcast=False
)
",Create a TensorProto.View aliases
tf.compat.v1.batch_to_space_nd,"tf.compat.v1.batch_to_space_nd(
    input, block_shape, crops, name=None
)
",BatchToSpace for N-D tensors of type T.View aliases
tf.compat.v1.gather_nd,"tf.compat.v1.gather_nd(
    params, indices, name=None, batch_dims=0
)
",Gather slices from params into a Tensor with shape specified by indices.View aliases
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)tf.gather_nd(    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0'],        [b'a1', b'b1']],       [[b'a0', b'b0'],        [b'c1', b'd1']]], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)tf.gather_nd(    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0'],        [b'a1', b'b1']],       [[b'a0', b'b0'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'b0', b'b1'],       [b'd0', b'c1']], dtype=object)Examples with batched 'params' and 'indices':"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)tf.gather_nd(    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0'],        [b'a1', b'b1']],       [[b'a0', b'b0'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'b0', b'b1'],       [b'd0', b'c1']], dtype=object)Examples with batched 'params' and 'indices':tf.gather_nd(    batch_dims = 1,    indices = [[1],               [0]],    params = [[['a0', 'b0'],               ['c0', 'd0']],              [['a1', 'b1'],               ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)"
tf.gather_nd,tf.gather_nd(,"Gather slices from params into a Tensor with shape specified by indices.View aliasestf.compat.v1.gather_nd(    params, indices, name=None, batch_dims=0)indices is a Tensor of indices into params. The index vectors arearranged along the last axis of indices.This is similar to tf.gather, in which indices defines slices into thefirst dimension of params. In tf.gather_nd, indices defines slices into thefirst N dimensions of params, where N = indices.shape[-1].Caution: On CPU, if an out of bound index is found, an error is returned.On GPU, if an out of bound index is found, a 0 is stored in thecorresponding output value.Gathering scalarsIn the simplest case the vectors in indices index the full rank of params:tf.gather_nd(    indices=[[0, 0],             [1, 1]],    params = [['a', 'b'],              ['c', 'd']]).numpy()array([b'a', b'd'], dtype=object)In this case the result has 1-axis fewer than indices, and each index vectoris replaced by the scalar indexed from params.In this case the shape relationship is:index_depth = indices.shape[-1]assert index_depth == params.shape.rankresult_shape = indices.shape[:-1]If indices has a rank of K, it is helpful to think indices as a(K-1)-dimensional tensor of indices into params.Gathering slicesIf the index vectors do not index the full rank of params then each locationin the result contains a slice of params. This example collects rows from amatrix:tf.gather_nd(    indices = [[1],               [0]],    params = [['a', 'b', 'c'],              ['d', 'e', 'f']]).numpy()array([[b'd', b'e', b'f'],       [b'a', b'b', b'c']], dtype=object)Here indices contains [2] index vectors, each with a length of 1.The index vectors each refer to rows of the params matrix. Eachrow has a shape of [3] so the output shape is [2, 3].In this case, the relationship between the shapes is:index_depth = indices.shape[-1]outer_shape = indices.shape[:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[index_depth:]output_shape = outer_shape + inner_shapeIt is helpful to think of the results in this case as tensors-of-tensors.The shape of the outer tensor is set by the leading dimensions of indices.While the shape of the inner tensors is the shape of a single slice.BatchesAdditionally both params and indices can have M leading batchdimensions that exactly match. In this case batch_dims must be set to M.For example, to collect one row from each of a batch of matrices you couldset the leading elements of the index vectors to be their location in thebatch:tf.gather_nd(    indices = [[0, 1],               [1, 0],               [2, 4],               [3, 2],               [4, 1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]The batch_dims argument lets you omit those leading location dimensionsfrom the index:tf.gather_nd(    batch_dims=1,    indices = [[1],               [0],               [4],               [2],               [1]],    params=tf.zeros([5, 7, 3])).shape.as_list()[5, 3]This is equivalent to caling a separate gather_nd for each location in thebatch dimensions.params=tf.zeros([5, 7, 3])indices=tf.zeros([5, 1])batch_dims = 1index_depth = indices.shape[-1]batch_shape = indices.shape[:batch_dims]assert params.shape[:batch_dims] == batch_shapeouter_shape = indices.shape[batch_dims:-1]assert index_depth <= params.shape.rankinner_shape = params.shape[batch_dims + index_depth:]output_shape = batch_shape + outer_shape + inner_shapeoutput_shape.as_list()[5, 3]More examplesIndexing into a 3-tensor:tf.gather_nd(    indices = [[1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'a1', b'b1'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[0, 1], [1, 0]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    indices = [[0, 0, 1], [1, 0, 1]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([b'b0', b'b1'], dtype=object)The examples below are for the case when only indices have leading extradimensions. If both 'params' and 'indices' have leading batch dimensions, usethe 'batch_dims' parameter to run gather_nd in batch mode.Batched indexing into a matrix:tf.gather_nd(    indices = [[[0, 0]], [[0, 1]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[b'a'],       [b'b']], dtype=object)Batched slice indexing into a matrix:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [['a', 'b'], ['c', 'd']]).numpy()array([[[b'c', b'd']],       [[b'a', b'b']]], dtype=object)Batched indexing into a 3-tensor:tf.gather_nd(    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[[b'a1', b'b1'],         [b'c1', b'd1']]],       [[[b'a0', b'b0'],         [b'c0', b'd0']]]], dtype=object)tf.gather_nd(    indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0'],        [b'a1', b'b1']],       [[b'a0', b'b0'],        [b'c1', b'd1']]], dtype=object)tf.gather_nd(    indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[b'b0', b'b1'],       [b'd0', b'c1']], dtype=object)Examples with batched 'params' and 'indices':tf.gather_nd(    batch_dims = 1,    indices = [[1],               [0]],    params = [[['a0', 'b0'],               ['c0', 'd0']],              [['a1', 'b1'],               ['c1', 'd1']]]).numpy()array([[b'c0', b'd0'],       [b'a1', b'b1']], dtype=object)tf.gather_nd(    batch_dims = 1,    indices = [[[1]], [[0]]],    params = [[['a0', 'b0'], ['c0', 'd0']],              [['a1', 'b1'], ['c1', 'd1']]]).numpy()array([[[b'c0', b'd0']],       [[b'a1', b'b1']]], dtype=object)"
tf.reshape,"tf.reshape(
    tensor, shape, name=None
)
",Reshapes a tensor.View aliases
tf.reverse,"tf.reverse(
    tensor, axis, name=None
)
",Reverses specific dimensions of a tensor.View aliases
tf.roll,"tf.roll(
    input, shift, axis, name=None
)
",Rolls the elements of a tensor along an axis.View aliases
tf.scatter_nd,"tf.scatter_nd(
    indices, updates, shape, name=None
)
",Scatters updates into a tensor of shape shape according to indices.View aliases
tf.space_to_batch_nd,"tf.space_to_batch_nd(
    input, block_shape, paddings, name=None
)
",SpaceToBatch for N-D tensors of type T.View aliases
tf.tile,"tf.tile(
    input, multiples, name=None
)
",Constructs a tensor by tiling a given tensor.View aliases
tf.compat.v1.map_fn,"tf.compat.v1.map_fn(
    fn,
    elems,
    dtype=None,
    parallel_iterations=None,
    back_prop=True,
    swap_memory=False,
    infer_shape=True,
    name=None,
    fn_output_signature=None
)
",Transforms elems by applying fn to each element unstacked on axis 0. (deprecated arguments)
tf.map_fn,"tf.map_fn(fn=tf.strings.length,  # input & output have different dtypes","Transforms elems by applying fn to each element unstacked on axis 0. (deprecated arguments)tf.compat.v1.map_fn(    fn,    elems,    dtype=None,    parallel_iterations=None,    back_prop=True,    swap_memory=False,    infer_shape=True,    name=None,    fn_output_signature=None)Used in the notebooksDeprecated: SOME ARGUMENTS ARE DEPRECATED: See also tf.scan.map_fn unstacks elems on axis 0 to obtain a sequence of elements;calls fn to transform each element; and then stacks the transformedvalues back together.Mapping functions with single-Tensor inputs and outputsIf elems is a single tensor and fn's signature is tf.Tensor->tf.Tensor,then map_fn(fn, elems) is equivalent totf.stack([fn(elem) for elem in tf.unstack(elems)]).  E.g.:tf.map_fn(fn=lambda t: tf.range(t, t + 3), elems=tf.constant([3, 5, 2]))<tf.Tensor: shape=(3, 3), dtype=int32, numpy=  array([[3, 4, 5],         [5, 6, 7],         [2, 3, 4]], dtype=int32)>map_fn(fn, elems).shape = [elems.shape[0]] + fn(elems[0]).shape.Mapping functions with multi-arity inputs and outputsmap_fn also supports functions with multi-arity inputs and outputs:If If Specifying fn's output signatureIf fn's input and output signatures are different, then the outputsignature must be specified using fn_output_signature.  (The input andoutput signatures are differ if their structures, dtypes, or tensor types donot match).  E.g.:"
tf.io.matching_files,"tf.io.matching_files(
    pattern, name=None
)
",Returns the set of files matching one or more glob patterns.View aliases
tf.math.abs,"tf.math.abs(
    x, name=None
)
",Computes the absolute value of a tensor.View aliases
tf.math.accumulate_n,"tf.math.accumulate_n(
    inputs, shape=None, tensor_dtype=None, name=None
)
",Returns the element-wise sum of a list of tensors.View aliases
tf.math.acos,"tf.math.acos(
    x, name=None
)
",Computes acos of x element-wise.View aliases
tf.math.acosh,"tf.math.acosh(
    x, name=None
)
",Computes inverse hyperbolic cosine of x element-wise.View aliases
tf.math.add,"tf.math.add(
    x, y, name=None
)
",Returns x + y element-wise.View aliases
tf.math.add_n,"tf.math.add_n(
    inputs, name=None
)
",Adds all input tensors element-wise.View aliases
tf.math.angle,"tf.math.angle(
    input, name=None
)
",Returns the element-wise argument of a complex (or real) tensor.View aliases
tf.math.approx_max_k,"tf.math.approx_max_k(
    operand,
    k,
    reduction_dimension=-1,
    recall_target=0.95,
    reduction_input_size_override=-1,
    aggregate_to_topk=True,
    name=None
)
",Returns max k values and their indices of the input operand in an approximate manner.View aliases
tf.math.approx_min_k,"tf.math.approx_min_k(
    operand,
    k,
    reduction_dimension=-1,
    recall_target=0.95,
    reduction_input_size_override=-1,
    aggregate_to_topk=True,
    name=None
)
",Returns min k values and their indices of the input operand in an approximate manner.View aliases
tf.compat.v1.argmax,"tf.compat.v1.argmax(
    input,
    axis=None,
    name=None,
    dimension=None,
    output_type=tf.dtypes.int64
)
",Returns the index with the largest value across axes of a tensor. (deprecated arguments)View aliases
tf.compat.v1.argmin,"tf.compat.v1.argmin(
    input,
    axis=None,
    name=None,
    dimension=None,
    output_type=tf.dtypes.int64
)
",Returns the index with the smallest value across axes of a tensor. (deprecated arguments)View aliases
tf.math.asin,"tf.math.asin(
    x, name=None
)
",Computes the trignometric inverse sine of x element-wise.View aliases
tf.math.asinh,"tf.math.asinh(
    x, name=None
)
",Computes inverse hyperbolic sine of x element-wise.View aliases
tf.math.atan,"tf.math.atan(
    x, name=None
)
",Computes the trignometric inverse tangent of x element-wise.View aliases
tf.math.atan2,"tf.math.atan2(
    y, x, name=None
)
","Computes arctangent of y/x element-wise, respecting signs of the arguments.View aliases"
tf.math.atanh,"tf.math.atanh(
    x, name=None
)
",Computes inverse hyperbolic tangent of x element-wise.View aliases
tf.math.bessel_i0,"tf.math.bessel_i0(
    x, name=None
)
",Computes the Bessel i0 function of x element-wise.View aliases
tf.math.bessel_i0e,"tf.math.bessel_i0e(
    x, name=None
)
",Computes the Bessel i0e function of x element-wise.View aliases
tf.math.bessel_i1,"tf.math.bessel_i1(
    x, name=None
)
",Computes the Bessel i1 function of x element-wise.View aliases
tf.math.bessel_i1e,"tf.math.bessel_i1e(
    x, name=None
)
",Computes the Bessel i1e function of x element-wise.View aliases
tf.math.betainc,"tf.math.betainc(
    a, b, x, name=None
)
","Compute the regularized incomplete beta integral \(I_x(a, b)\).View aliases"
tf.compat.v1.bincount,"tf.compat.v1.bincount(
    arr,
    weights=None,
    minlength=None,
    maxlength=None,
    dtype=tf.dtypes.int32
)
",Counts the number of occurrences of each value in an integer array.View aliases
tf.math.ceil,"tf.math.ceil(
    x, name=None
)
","Return the ceiling of the input, element-wise.View aliases"
tf.compat.v1.confusion_matrix,"tf.compat.v1.confusion_matrix(
    labels,
    predictions,
    num_classes=None,
    dtype=tf.dtypes.int32,
    name=None,
    weights=None
)
",Computes the confusion matrix from predictions and labels.View aliases
tf.math.conj,"tf.math.conj(
    x, name=None
)
",Returns the complex conjugate of a complex number.View aliases
tf.math.cos,"tf.math.cos(
    x, name=None
)
",Computes cos of x element-wise.View aliases
tf.math.cosh,"tf.math.cosh(
    x, name=None
)
",Computes hyperbolic cosine of x element-wise.View aliases
tf.compat.v1.count_nonzero,"tf.compat.v1.count_nonzero(
    input_tensor=None,
    axis=None,
    keepdims=None,
    dtype=tf.dtypes.int64,
    name=None,
    reduction_indices=None,
    keep_dims=None,
    input=None
)
",Computes number of nonzero elements across dimensions of a tensor. (deprecated arguments) (deprecated arguments)View aliases
tf.math.cumprod,"tf.math.cumprod(
    x, axis=0, exclusive=False, reverse=False, name=None
)
",Compute the cumulative product of the tensor x along axis.View aliases
tf.math.cumsum,"tf.math.cumsum(
    x, axis=0, exclusive=False, reverse=False, name=None
)
",Compute the cumulative sum of the tensor x along axis.View aliases
tf.math.cumulative_logsumexp,"tf.math.cumulative_logsumexp(
    x, axis=0, exclusive=False, reverse=False, name=None
)
",Compute the cumulative log-sum-exp of the tensor x along axis.View aliases
tf.math.digamma,"tf.math.digamma(
    x, name=None
)
","Computes Psi, the derivative of Lgamma (the log of the absolute value ofView aliases"
tf.math.divide,"tf.math.divide(
    x, y, name=None
)
",Computes Python style division of x by y.View aliases
tf.math.divide_no_nan,"tf.math.divide_no_nan(
    x, y, name=None
)
",Computes a safe divide which returns 0 if y (denominator) is zero.View aliases
tf.constant,tf.constant(3.0) / 0.0,"Computes a safe divide which returns 0 if y (denominator) is zero.View aliasestf.math.divide_no_nan(    x, y, name=None)For example:"
tf.math.equal,"tf.math.equal(
    x, y, name=None
)
",Returns the truth value of (x == y) element-wise.View aliases
tf.math.erf,"tf.math.erf(
    x, name=None
)
","Computes the Gauss error function of x element-wise. In statistics, for non-negative values of \(x\), the error function has the following interpretation: for a random variable \(Y\) that is normally distributed with mean 0 and variance \(1/\sqrt{2}\), \(erf(x)\) is the probability that \(Y\) falls in the range \([x, x]\).View aliases"
tf.math.erfc,"tf.math.erfc(
    x, name=None
)
",Computes the complementary error function of x element-wise.View aliases
tf.math.erfcinv,"tf.math.erfcinv(
    x, name=None
)
",Computes the inverse of complementary error function.View aliases
tf.math.erfinv,"tf.math.erfinv(
    x, name=None
)
",Compute inverse error function.View aliases
tf.math.exp,"tf.math.exp(
    x, name=None
)
",Computes exponential of x element-wise.  \(y = e^x\).View aliases
tf.math.expm1,"tf.math.expm1(
    x, name=None
)
",Computes exp(x) - 1 element-wise.View aliases
tf.math.floor,"tf.math.floor(
    x, name=None
)
",Returns element-wise largest integer not greater than x.View aliases
tf.math.floordiv,"tf.math.floordiv(
    x, y, name=None
)
","Divides x / y elementwise, rounding toward the most negative integer.View aliases"
tf.math.floormod,"tf.math.floormod(
    x, y, name=None
)
",Returns element-wise remainder of division. When x < 0 xor y < 0 isView aliases
tf.math.greater,"tf.math.greater(
    x, y, name=None
)
",Returns the truth value of (x > y) element-wise.View aliases
tf.math.greater_equal,"tf.math.greater_equal(
    x, y, name=None
)
",Returns the truth value of (x >= y) element-wise.View aliases
tf.math.igamma,"tf.math.igamma(
    a, x, name=None
)
","Compute the lower regularized incomplete Gamma function P(a, x).View aliases"
tf.math.igammac,"tf.math.igammac(
    a, x, name=None
)
","Compute the upper regularized incomplete Gamma function Q(a, x).View aliases"
tf.math.imag,"tf.math.imag(
    input, name=None
)
",Returns the imaginary part of a complex (or real) tensor.View aliases
tf.compat.v1.math.in_top_k,"tf.compat.v1.math.in_top_k(
    predictions, targets, k, name=None
)
",Says whether the targets are in the top K predictions.View aliases
tf.math.invert_permutation,"tf.math.invert_permutation(
    x, name=None
)
",Computes the inverse permutation of a tensor.View aliases
tf.math.is_finite,"tf.math.is_finite(
    x, name=None
)
",Returns which elements of x are finite.View aliases
tf.math.is_inf,"tf.math.is_inf(
    x, name=None
)
",Returns which elements of x are Inf.View aliases
tf.math.is_nan,"tf.math.is_nan(
    x, name=None
)
",Returns which elements of x are NaN.View aliases
tf.math.is_non_decreasing,"tf.math.is_non_decreasing(
    x, name=None
)
",Returns True if x is non-decreasing.View aliases
tf.math.is_strictly_increasing,"tf.math.is_strictly_increasing(
    x, name=None
)
",Returns True if x is strictly increasing.View aliases
tf.math.l2_normalize,"tf.math.l2_normalize(
    x, axis=None, epsilon=1e-12, name=None, dim=None
)
",Normalizes along dimension axis using an L2 norm. (deprecated arguments)View aliases
tf.math.lbeta,"tf.math.lbeta(
    x, name=None
)
","Computes \(ln(|Beta(x)|)\), reducing along the last dimension.View aliases"
tf.math.less,"tf.math.less(
    x, y, name=None
)
",Returns the truth value of (x < y) element-wise.View aliases
tf.math.less_equal,"tf.math.less_equal(
    x, y, name=None
)
",Returns the truth value of (x <= y) element-wise.View aliases
tf.math.lgamma,"tf.math.lgamma(
    x, name=None
)
",Computes the log of the absolute value of Gamma(x) element-wise.View aliases
tf.math.log,"tf.math.log(
    x, name=None
)
",Computes natural logarithm of x element-wise.View aliases
tf.math.log1p,"tf.math.log1p(
    x, name=None
)
",Computes natural logarithm of (1 + x) element-wise.View aliases
tf.math.log_sigmoid,"tf.math.log_sigmoid(
    x, name=None
)
",Computes log sigmoid of x element-wise.View aliases
tf.compat.v1.math.log_softmax,"tf.compat.v1.math.log_softmax(
    logits, axis=None, name=None, dim=None
)
",Computes log softmax activations. (deprecated arguments)View aliases
tf.math.logical_and,"tf.math.logical_and(
    x, y, name=None
)
",Returns the truth value of x AND y element-wise.View aliases
tf.math.logical_not,"tf.math.logical_not(
    x, name=None
)
",Returns the truth value of NOT x element-wise.View aliases
tf.math.logical_or,"tf.math.logical_or(
    x, y, name=None
)
",Returns the truth value of x OR y element-wise.View aliases
tf.math.logical_xor,"tf.math.logical_xor(
    x, y, name='LogicalXor'
)
",Logical XOR function.View aliases
tf.math.maximum,"tf.math.maximum(
    x, y, name=None
)
",Returns the max of x and y (i.e. x > y ? x : y) element-wise.View aliases
tf.math.minimum,"tf.math.minimum(
    x, y, name=None
)
",Returns the min of x and y (i.e. x < y ? x : y) element-wise.View aliases
tf.math.floormod,"tf.math.floormod(
    x, y, name=None
)
",Returns element-wise remainder of division. When x < 0 xor y < 0 isView aliases
tf.math.multiply,"tf.math.multiply(
    x, y, name=None
)
",Returns an element-wise x * y.View aliases
tf.math.multiply_no_nan,"tf.math.multiply_no_nan(
    x, y, name=None
)
","Computes the product of x and y and returns 0 if the y is zero, even if x is NaN or infinite.View aliases"
tf.math.ndtri,"tf.math.ndtri(
    x, name=None
)
",Compute quantile of Standard Normal.View aliases
tf.math.negative,"tf.math.negative(
    x, name=None
)
",Computes numerical negative value element-wise.View aliases
tf.math.nextafter,"tf.math.nextafter(
    x1, x2, name=None
)
","Returns the next representable value of x1 in the direction of x2, element-wise.View aliases"
tf.math.not_equal,"tf.math.not_equal(
    x, y, name=None
)
",Returns the truth value of (x != y) element-wise.View aliases
tf.math.polygamma,"tf.math.polygamma(
    a, x, name=None
)
",Compute the polygamma function \(\psi^{(n)}(x)\).View aliases
tf.math.polyval,"tf.math.polyval(
    coeffs, x, name=None
)
",Computes the elementwise value of a polynomial.View aliases
tf.math.pow,"tf.math.pow(
    x, y, name=None
)
",Computes the power of one value to another.View aliases
tf.math.real,"tf.math.real(
    input, name=None
)
",Returns the real part of a complex (or real) tensor.View aliases
tf.math.reciprocal,"tf.math.reciprocal(
    x, name=None
)
",Computes the reciprocal of x element-wise.View aliases
tf.math.reciprocal_no_nan,"tf.math.reciprocal_no_nan(
    x, name=None
)
","Performs a safe reciprocal operation, element wise.View aliases"
tf.compat.v1.reduce_all,"tf.compat.v1.reduce_all(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes tf.math.logical_and of elements across dimensions of a tensor. (deprecated arguments)View aliases
tf.compat.v1.reduce_any,"tf.compat.v1.reduce_any(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes tf.math.logical_or of elements across dimensions of a tensor. (deprecated arguments)View aliases
tf.math.reduce_euclidean_norm,"tf.math.reduce_euclidean_norm(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes the Euclidean norm of elements across dimensions of a tensor.View aliases
tf.compat.v1.reduce_logsumexp,"tf.compat.v1.reduce_logsumexp(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes log(sum(exp(elements across dimensions of a tensor))). (deprecated arguments)View aliases
tf.compat.v1.reduce_max,"tf.compat.v1.reduce_max(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes tf.math.maximum of elements across dimensions of a tensor. (deprecated arguments)View aliases
tf.compat.v1.reduce_mean,"tf.compat.v1.reduce_mean(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes the mean of elements across dimensions of a tensor.View aliases
tf.compat.v1.reduce_min,"tf.compat.v1.reduce_min(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes the tf.math.minimum of elements across dimensions of a tensor. (deprecated arguments)View aliases
tf.compat.v1.reduce_prod,"tf.compat.v1.reduce_prod(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes tf.math.multiply of elements across dimensions of a tensor. (deprecated arguments)View aliases
tf.math.reduce_std,"tf.math.reduce_std(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes the standard deviation of elements across dimensions of a tensor.View aliases
tf.compat.v1.reduce_sum,"tf.compat.v1.reduce_sum(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes the sum of elements across dimensions of a tensor. (deprecated arguments)View aliases
tf.math.reduce_variance,"tf.math.reduce_variance(
    input_tensor, axis=None, keepdims=False, name=None
)
",Computes the variance of elements across dimensions of a tensor.View aliases
tf.math.rint,"tf.math.rint(
    x, name=None
)
",Returns element-wise integer closest to x.View aliases
tf.math.round,"tf.math.round(
    x, name=None
)
","Rounds the values of a tensor to the nearest integer, element-wise.View aliases"
tf.math.rsqrt,"tf.math.rsqrt(
    x, name=None
)
",Computes reciprocal of square root of x element-wise.View aliases
tf.compat.v1.scalar_mul,"tf.compat.v1.scalar_mul(
    scalar, x, name=None
)
",Multiplies a scalar times a Tensor or IndexedSlices object.View aliases
tf.math.segment_max,"tf.math.segment_max(
    data, segment_ids, name=None
)
",Computes the maximum along segments of a tensor.View aliases
tf.math.segment_mean,"tf.math.segment_mean(
    data, segment_ids, name=None
)
",Computes the mean along segments of a tensor.View aliases
tf.math.segment_min,"tf.math.segment_min(
    data, segment_ids, name=None
)
",Computes the minimum along segments of a tensor.View aliases
tf.math.segment_prod,"tf.math.segment_prod(
    data, segment_ids, name=None
)
",Computes the product along segments of a tensor.View aliases
tf.math.segment_sum,"tf.math.segment_sum(
    data, segment_ids, name=None
)
",Computes the sum along segments of a tensor.View aliases
tf.math.sigmoid,"tf.math.sigmoid(
    x, name=None
)
",Computes sigmoid of x element-wise.View aliases
tf.math.sign,"tf.math.sign(
    x, name=None
)
",Returns an element-wise indication of the sign of a number.View aliases
tf.math.sin,"tf.math.sin(
    x, name=None
)
",Computes sine of x element-wise.View aliases
tf.math.sinh,"tf.math.sinh(
    x, name=None
)
",Computes hyperbolic sine of x element-wise.View aliases
tf.math.sobol_sample,"tf.math.sobol_sample(
    dim,
    num_results,
    skip=0,
    dtype=tf.dtypes.float32,
    name=None
)
",Generates points from the Sobol sequence.View aliases
tf.compat.v1.math.softmax,"tf.compat.v1.math.softmax(
    logits, axis=None, name=None, dim=None
)
",Computes softmax activations.View aliases
tf.math.softplus,"tf.math.softplus(
    features, name=None
)
",Computes elementwise softplus: softplus(x) = log(exp(x) + 1).View aliases
tf.nn.softsign,"tf.nn.softsign(
    features, name=None
)
",Computes softsign: features / (abs(features) + 1).View aliases
tf.math.bessel_i0,"tf.math.bessel_i0(
    x, name=None
)
",Computes the Bessel i0 function of x element-wise.View aliases
tf.math.bessel_i0e,"tf.math.bessel_i0e(
    x, name=None
)
",Computes the Bessel i0e function of x element-wise.View aliases
tf.math.bessel_i1,"tf.math.bessel_i1(
    x, name=None
)
",Computes the Bessel i1 function of x element-wise.View aliases
tf.math.bessel_i1e,"tf.math.bessel_i1e(
    x, name=None
)
",Computes the Bessel i1e function of x element-wise.View aliases
tf.math.special.bessel_j0,"tf.math.special.bessel_j0(
    x, name=None
)
",Computes the Bessel j0 function of x element-wise.View aliases
tf.math.special.bessel_j1,"tf.math.special.bessel_j1(
    x, name=None
)
",Computes the Bessel j1 function of x element-wise.View aliases
tf.math.special.bessel_k0,"tf.math.special.bessel_k0(
    x, name=None
)
",Computes the Bessel k0 function of x element-wise.View aliases
tf.math.special.bessel_k0e,"tf.math.special.bessel_k0e(
    x, name=None
)
",Computes the Bessel k0e function of x element-wise.View aliases
tf.math.special.bessel_k1,"tf.math.special.bessel_k1(
    x, name=None
)
",Computes the Bessel k1 function of x element-wise.View aliases
tf.math.special.bessel_k1e,"tf.math.special.bessel_k1e(
    x, name=None
)
",Computes the Bessel k1e function of x element-wise.View aliases
tf.math.special.bessel_y0,"tf.math.special.bessel_y0(
    x, name=None
)
",Computes the Bessel y0 function of x element-wise.View aliases
tf.math.special.bessel_y1,"tf.math.special.bessel_y1(
    x, name=None
)
",Computes the Bessel y1 function of x element-wise.View aliases
tf.math.special.dawsn,"tf.math.special.dawsn(
    x, name=None
)
",Computes Dawson's integral of x element-wise.View aliases
tf.math.special.expint,"tf.math.special.expint(
    x, name=None
)
",Computes the Exponential integral of x element-wise.View aliases
tf.math.special.fresnel_cos,"tf.math.special.fresnel_cos(
    x, name=None
)
",Computes Fresnel's cosine integral of x element-wise.View aliases
tf.math.special.fresnel_sin,"tf.math.special.fresnel_sin(
    x, name=None
)
",Computes Fresnel's sine integral of x element-wise.View aliases
tf.math.special.spence,"tf.math.special.spence(
    x, name=None
)
",Computes Spence's integral of x element-wise.View aliases
tf.math.sqrt,"tf.math.sqrt(
    x, name=None
)
",Computes element-wise square root of the input tensor.View aliases
tf.math.square,"tf.math.square(
    x, name=None
)
",Computes square of x element-wise.View aliases
tf.math.squared_difference,"tf.math.squared_difference(
    x, y, name=None
)
",Returns conj(x - y)(x - y) element-wise.View aliases
tf.math.subtract,"tf.math.subtract(
    x, y, name=None
)
",Returns x - y element-wise.View aliases
tf.math.tan,"tf.math.tan(
    x, name=None
)
",Computes tan of x element-wise.View aliases
tf.math.tanh,"tf.math.tanh(
    x, name=None
)
",Computes hyperbolic tangent of x element-wise.View aliases
tf.math.top_k,"tf.math.top_k(
    input, k=1, sorted=True, name=None
)
",Finds values and indices of the k largest entries for the last dimension.View aliases
tf.math.truediv,"tf.math.truediv(
    x, y, name=None
)
",Divides x / y elementwise (using Python 3 division operator semantics).View aliases
tf.math.unsorted_segment_max,"tf.math.unsorted_segment_max(
    data, segment_ids, num_segments, name=None
)
",Computes the maximum along segments of a tensor.View aliases
tf.math.unsorted_segment_mean,"tf.math.unsorted_segment_mean(
    data, segment_ids, num_segments, name=None
)
",Computes the mean along segments of a tensor.View aliases
tf.math.unsorted_segment_min,"tf.math.unsorted_segment_min(
    data, segment_ids, num_segments, name=None
)
",Computes the minimum along segments of a tensor.View aliases
tf.math.unsorted_segment_prod,"tf.math.unsorted_segment_prod(
    data, segment_ids, num_segments, name=None
)
",Computes the product along segments of a tensor.View aliases
tf.math.unsorted_segment_sqrt_n,"tf.math.unsorted_segment_sqrt_n(
    data, segment_ids, num_segments, name=None
)
",Computes the sum along segments of a tensor divided by the sqrt(N).View aliases
tf.math.unsorted_segment_sum,"tf.math.unsorted_segment_sum(
    data, segment_ids, num_segments, name=None
)
",Computes the sum along segments of a tensor.View aliases
tf.math.xdivy,"tf.math.xdivy(
    x, y, name=None
)
","Returns 0 if x == 0, and x / y otherwise, elementwise.View aliases"
tf.math.xlog1py,"tf.math.xlog1py(
    x, y, name=None
)
",Compute x * log1p(y).View aliases
tf.math.xlogy,"tf.math.xlogy(
    x, y, name=None
)
","Returns 0 if x == 0, and x * log(y) otherwise, elementwise.View aliases"
tf.math.zero_fraction,"tf.math.zero_fraction(
    value, name=None
)
",Returns the fraction of zeros in value.View aliases
tf.math.zeta,"tf.math.zeta(
    x, q, name=None
)
","Compute the Hurwitz zeta function \(\zeta(x, q)\).View aliases"
tf.linalg.matmul,"tf.linalg.matmul(
    a,
    b,
    transpose_a=False,
    transpose_b=False,
    adjoint_a=False,
    adjoint_b=False,
    a_is_sparse=False,
    b_is_sparse=False,
    output_type=None,
    name=None
)
","Multiplies matrix a by matrix b, producing a * b.View aliases"
tf.linalg.band_part,"tf.linalg.band_part(
    input, num_lower, num_upper, name=None
)
",Copy a tensor setting everything outside a central band in each innermost matrix to zero.View aliases
tf.linalg.det,"tf.linalg.det(
    input, name=None
)
",Computes the determinant of one or more square matrices.View aliases
tf.linalg.diag,"tf.linalg.diag(
    diagonal,
    name='diag',
    k=0,
    num_rows=-1,
    num_cols=-1,
    padding_value=0,
    align='RIGHT_LEFT'
)
",Returns a batched diagonal tensor with given batched diagonal values.View aliases
tf.linalg.diag_part,"tf.linalg.diag_part(
    input,
    name='diag_part',
    k=0,
    padding_value=0,
    align='RIGHT_LEFT'
)
",Returns the batched diagonal part of a batched tensor.View aliases
tf.linalg.inv,"tf.linalg.inv(
    input, adjoint=False, name=None
)
",Computes the inverse of one or more square invertible matrices or their adjoints (conjugate transposes).View aliases
tf.linalg.set_diag,"tf.linalg.set_diag(
    input,
    diagonal,
    name='set_diag',
    k=0,
    align='RIGHT_LEFT'
)
",Returns a batched matrix tensor with new batched diagonal values.View aliases
tf.linalg.solve,"tf.linalg.solve(
    matrix, rhs, adjoint=False, name=None
)
",Solves systems of linear equations.View aliases
tf.linalg.lstsq,"tf.linalg.lstsq(
    matrix, rhs, l2_regularizer=0.0, fast=True, name=None
)
",Solves one or more linear least-squares problems.View aliases
tf.linalg.sqrtm,"tf.linalg.sqrtm(
    input, name=None
)
",Computes the matrix square root of one or more square matrices:View aliases
tf.linalg.matrix_transpose,"tf.linalg.matrix_transpose(
    a, name='matrix_transpose', conjugate=False
)
",Transposes last two dimensions of tensor a.View aliases
tf.linalg.triangular_solve,"tf.linalg.triangular_solve(
    matrix, rhs, lower=True, adjoint=False, name=None
)
",Solve systems of linear equations with upper or lower triangular matrices.View aliases
tf.math.maximum,"tf.math.maximum(
    x, y, name=None
)
",Returns the max of x and y (i.e. x > y ? x : y) element-wise.View aliases
tf.meshgrid,"tf.meshgrid(
    *args, **kwargs
)
",Broadcasts parameters for evaluation on an N-D grid.View aliases
tf.compat.v1.metrics.accuracy,"tf.compat.v1.metrics.accuracy(
    labels,
    predictions,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Calculates how often predictions matches labels.
tf.compat.v1.metrics.auc,"tf.compat.v1.metrics.auc(
    labels,
    predictions,
    weights=None,
    num_thresholds=200,
    metrics_collections=None,
    updates_collections=None,
    curve='ROC',
    name=None,
    summation_method='trapezoidal',
    thresholds=None
)
",Computes the approximate AUC via a Riemann sum. (deprecated)
tf.compat.v1.metrics.average_precision_at_k,"tf.compat.v1.metrics.average_precision_at_k(
    labels,
    predictions,
    k,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes average precision@k of predictions with respect to sparse labels.
tf.compat.v1.metrics.false_negatives,"tf.compat.v1.metrics.false_negatives(
    labels,
    predictions,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes the total number of false negatives.
tf.compat.v1.metrics.false_negatives_at_thresholds,"tf.compat.v1.metrics.false_negatives_at_thresholds(
    labels,
    predictions,
    thresholds,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes false negatives at provided threshold values.
tf.compat.v1.metrics.false_positives,"tf.compat.v1.metrics.false_positives(
    labels,
    predictions,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Sum the weights of false positives.
tf.compat.v1.metrics.false_positives_at_thresholds,"tf.compat.v1.metrics.false_positives_at_thresholds(
    labels,
    predictions,
    thresholds,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes false positives at provided threshold values.
tf.compat.v1.metrics.mean,"tf.compat.v1.metrics.mean(
    values,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes the (weighted) mean of the given values.
tf.compat.v1.metrics.mean_absolute_error,"tf.compat.v1.metrics.mean_absolute_error(
    labels,
    predictions,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes the mean absolute error between the labels and predictions.
tf.compat.v1.metrics.mean_cosine_distance,"tf.compat.v1.metrics.mean_cosine_distance(
    labels,
    predictions,
    dim,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes the cosine distance between the labels and predictions.
tf.compat.v1.metrics.mean_iou,"tf.compat.v1.metrics.mean_iou(
    labels,
    predictions,
    num_classes,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Calculate per-step mean Intersection-Over-Union (mIOU).
tf.compat.v1.metrics.mean_per_class_accuracy,"tf.compat.v1.metrics.mean_per_class_accuracy(
    labels,
    predictions,
    num_classes,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Calculates the mean of the per-class accuracies.
tf.compat.v1.metrics.mean_relative_error,"tf.compat.v1.metrics.mean_relative_error(
    labels,
    predictions,
    normalizer,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes the mean relative error by normalizing with the given values.
tf.compat.v1.metrics.mean_squared_error,"tf.compat.v1.metrics.mean_squared_error(
    labels,
    predictions,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes the mean squared error between the labels and predictions.
tf.compat.v1.metrics.mean_tensor,"tf.compat.v1.metrics.mean_tensor(
    values,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes the element-wise (weighted) mean of the given tensors.
tf.compat.v1.metrics.percentage_below,"tf.compat.v1.metrics.percentage_below(
    values,
    threshold,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes the percentage of values less than the given threshold.
tf.compat.v1.metrics.precision,"tf.compat.v1.metrics.precision(
    labels,
    predictions,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes the precision of the predictions with respect to the labels.
tf.compat.v1.metrics.precision_at_k,"tf.compat.v1.metrics.precision_at_k(
    labels,
    predictions,
    k,
    class_id=None,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes precision@k of the predictions with respect to sparse labels.
tf.compat.v1.metrics.precision_at_thresholds,"tf.compat.v1.metrics.precision_at_thresholds(
    labels,
    predictions,
    thresholds,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes precision values for different thresholds on predictions.
tf.compat.v1.metrics.precision_at_top_k,"tf.compat.v1.metrics.precision_at_top_k(
    labels,
    predictions_idx,
    k=None,
    class_id=None,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes precision@k of the predictions with respect to sparse labels.
tf.compat.v1.metrics.recall,"tf.compat.v1.metrics.recall(
    labels,
    predictions,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes the recall of the predictions with respect to the labels.
tf.compat.v1.metrics.recall_at_k,"tf.compat.v1.metrics.recall_at_k(
    labels,
    predictions,
    k,
    class_id=None,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes recall@k of the predictions with respect to sparse labels.
tf.compat.v1.metrics.recall_at_thresholds,"tf.compat.v1.metrics.recall_at_thresholds(
    labels,
    predictions,
    thresholds,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes various recall values for different thresholds on predictions.
tf.compat.v1.metrics.recall_at_top_k,"tf.compat.v1.metrics.recall_at_top_k(
    labels,
    predictions_idx,
    k=None,
    class_id=None,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes recall@k of top-k predictions with respect to sparse labels.
tf.compat.v1.metrics.root_mean_squared_error,"tf.compat.v1.metrics.root_mean_squared_error(
    labels,
    predictions,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes the root mean squared error between the labels and predictions.
tf.compat.v1.metrics.sensitivity_at_specificity,"tf.compat.v1.metrics.sensitivity_at_specificity(
    labels,
    predictions,
    specificity,
    weights=None,
    num_thresholds=200,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes the specificity at a given sensitivity.
tf.compat.v1.metrics.sparse_average_precision_at_k,"tf.compat.v1.metrics.sparse_average_precision_at_k(
    labels,
    predictions,
    k,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
","Renamed to average_precision_at_k, please use that method instead. (deprecated)"
tf.compat.v1.metrics.sparse_precision_at_k,"tf.compat.v1.metrics.sparse_precision_at_k(
    labels,
    predictions,
    k,
    class_id=None,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
","Renamed to precision_at_k, please use that method instead. (deprecated)"
tf.compat.v1.metrics.specificity_at_sensitivity,"tf.compat.v1.metrics.specificity_at_sensitivity(
    labels,
    predictions,
    sensitivity,
    weights=None,
    num_thresholds=200,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes the specificity at a given sensitivity.
tf.compat.v1.metrics.true_negatives,"tf.compat.v1.metrics.true_negatives(
    labels,
    predictions,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Sum the weights of true_negatives.
tf.compat.v1.metrics.true_negatives_at_thresholds,"tf.compat.v1.metrics.true_negatives_at_thresholds(
    labels,
    predictions,
    thresholds,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes true negatives at provided threshold values.
tf.compat.v1.metrics.true_positives,"tf.compat.v1.metrics.true_positives(
    labels,
    predictions,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Sum the weights of true_positives.
tf.compat.v1.metrics.true_positives_at_thresholds,"tf.compat.v1.metrics.true_positives_at_thresholds(
    labels,
    predictions,
    thresholds,
    weights=None,
    metrics_collections=None,
    updates_collections=None,
    name=None
)
",Computes true positives at provided threshold values.
tf.compat.v1.min_max_variable_partitioner,"tf.compat.v1.min_max_variable_partitioner(
    max_partitions=1,
    axis=0,
    min_slice_size=(256 << 10),
    bytes_per_string_element=16
)
",Partitioner to allocate minimum size per slice.
tf.math.minimum,"tf.math.minimum(
    x, y, name=None
)
",Returns the min of x and y (i.e. x < y ? x : y) element-wise.View aliases
tf.compat.v1.mixed_precision.DynamicLossScale,"tf.compat.v1.mixed_precision.DynamicLossScale(
    initial_loss_scale=(2 ** 15), increment_period=2000, multiplier=2.0
)
",Loss scale that dynamically adjusts itself.Inherits From: LossScaleView aliases
tf.compat.v1.mixed_precision.FixedLossScale,"tf.compat.v1.mixed_precision.FixedLossScale(
    loss_scale_value
)
",Loss scale with a fixed value.Inherits From: LossScaleView aliases
tf.compat.v1.mixed_precision.MixedPrecisionLossScaleOptimizer,"tf.compat.v1.mixed_precision.MixedPrecisionLossScaleOptimizer(
    opt, loss_scale
)
",An optimizer that applies loss scaling.Inherits From: OptimizerView aliases
tf.compat.v1.mixed_precision.enable_mixed_precision_graph_rewrite,"tf.compat.v1.mixed_precision.enable_mixed_precision_graph_rewrite(
    opt, loss_scale='dynamic'
)
",Enable mixed precision via a graph rewrite.View aliases
tf.compat.v1.mixed_precision.DynamicLossScale,"tf.compat.v1.mixed_precision.DynamicLossScale(
    initial_loss_scale=(2 ** 15), increment_period=2000, multiplier=2.0
)
",Loss scale that dynamically adjusts itself.Inherits From: LossScaleView aliases
tf.compat.v1.mixed_precision.FixedLossScale,"tf.compat.v1.mixed_precision.FixedLossScale(
    loss_scale_value
)
",Loss scale with a fixed value.Inherits From: LossScaleView aliases
tf.mlir.experimental.convert_function,"tf.mlir.experimental.convert_function(
    concrete_function,
    pass_pipeline='tf-standard-pipeline',
    show_debug_info=False
)
",Import a ConcreteFunction and convert it to a textual MLIR module.View aliases
tf.mlir.experimental.convert_graph_def,"tf.mlir.experimental.convert_graph_def(
    graph_def,
    pass_pipeline='tf-standard-pipeline',
    show_debug_info=False
)
",Import a GraphDef and convert it to a textual MLIR module.View aliases
tf.math.floormod,"tf.math.floormod(
    x, y, name=None
)
",Returns element-wise remainder of division. When x < 0 xor y < 0 isView aliases
tf.compat.v1.model_variables,"tf.compat.v1.model_variables(
    scope=None
)
",Returns all variables in the MODEL_VARIABLES collection.
tf.compat.v1.moving_average_variables,"tf.compat.v1.moving_average_variables(
    scope=None
)
",Returns all variables that maintain their moving averages.
tf.compat.v1.multinomial,"tf.compat.v1.multinomial(
    logits, num_samples, seed=None, name=None, output_dtype=None
)
",Draws samples from a multinomial distribution. (deprecated)View aliases
tf.math.multiply,"tf.math.multiply(
    x, y, name=None
)
",Returns an element-wise x * y.View aliases
tf.compat.v1.keras.backend.name_scope,"tf.compat.v1.keras.backend.name_scope(
    name, default_name=None, values=None
)
",A context manager for use when defining a Python op.View aliases
tf.math.negative,"tf.math.negative(
    x, name=None
)
",Computes numerical negative value element-wise.View aliases
tf.nest.assert_same_structure,"tf.nest.assert_same_structure(
    nest1, nest2, check_types=True, expand_composites=False
)
",Asserts that two structures are nested in the same way.View aliases
tf.nest.flatten,"tf.nest.flatten(
    structure, expand_composites=False
)
",Returns a flat list from a given structure.View aliases
tf.nest.is_nested,"tf.nest.is_nested(
    seq
)
",Returns true if its input is a nested structure.View aliases
tf.nest.map_structure,"tf.nest.map_structure(
    func, *structure, **kwargs
)
",Creates a new structure by applying func to each atom in structure.View aliases
tf.nest.pack_sequence_as,"tf.nest.pack_sequence_as(
    structure, flat_sequence, expand_composites=False
)
",Returns a given flattened sequence packed into a given structure.View aliases
tf.random.all_candidate_sampler,"tf.random.all_candidate_sampler(
    true_classes, num_true, num_sampled, unique, seed=None, name=None
)
",Generate the set of all classes.View aliases
tf.math.approx_max_k,"tf.math.approx_max_k(
    operand,
    k,
    reduction_dimension=-1,
    recall_target=0.95,
    reduction_input_size_override=-1,
    aggregate_to_topk=True,
    name=None
)
",Returns max k values and their indices of the input operand in an approximate manner.View aliases
tf.math.approx_min_k,"tf.math.approx_min_k(
    operand,
    k,
    reduction_dimension=-1,
    recall_target=0.95,
    reduction_input_size_override=-1,
    aggregate_to_topk=True,
    name=None
)
",Returns min k values and their indices of the input operand in an approximate manner.View aliases
tf.nn.atrous_conv2d,"tf.nn.atrous_conv2d(
    value, filters, rate, padding, name=None
)
",Atrous convolution (a.k.a. convolution with holes or dilated convolution).View aliases
tf.nn.atrous_conv2d_transpose,"tf.nn.atrous_conv2d_transpose(
    value, filters, output_shape, rate, padding, name=None
)
",The transpose of atrous_conv2d.View aliases
tf.compat.v1.nn.avg_pool,"tf.compat.v1.nn.avg_pool(
    value,
    ksize,
    strides,
    padding,
    data_format='NHWC',
    name=None,
    input=None
)
",Performs the average pooling on the input.View aliases
tf.nn.avg_pool1d,"tf.nn.avg_pool1d(
    input, ksize, strides, padding, data_format='NWC', name=None
)
",Performs the average pooling on the input.View aliases
tf.compat.v1.nn.avg_pool,"tf.compat.v1.nn.avg_pool(
    value,
    ksize,
    strides,
    padding,
    data_format='NHWC',
    name=None,
    input=None
)
",Performs the average pooling on the input.View aliases
tf.nn.avg_pool3d,"tf.nn.avg_pool3d(
    input, ksize, strides, padding, data_format='NDHWC', name=None
)
",Performs the average pooling on the input.View aliases
tf.nn.avg_pool,"tf.nn.avg_pool(
    input, ksize, strides, padding, data_format=None, name=None
)
",Performs the avg pooling on the input.View aliases
tf.compat.v1.nn.batch_norm_with_global_normalization,"tf.compat.v1.nn.batch_norm_with_global_normalization(
    t=None,
    m=None,
    v=None,
    beta=None,
    gamma=None,
    variance_epsilon=None,
    scale_after_normalization=None,
    name=None,
    input=None,
    mean=None,
    variance=None
)
",Batch normalization.
tf.nn.batch_normalization,"tf.nn.batch_normalization(
    x, mean, variance, offset, scale, variance_epsilon, name=None
)
",Batch normalization.View aliases
tf.nn.bias_add,"tf.nn.bias_add(
    value, bias, data_format=None, name=None
)
",Adds bias to value.View aliases
tf.compat.v1.nn.bidirectional_dynamic_rnn,"tf.compat.v1.nn.bidirectional_dynamic_rnn(
    cell_fw,
    cell_bw,
    inputs,
    sequence_length=None,
    initial_state_fw=None,
    initial_state_bw=None,
    dtype=None,
    parallel_iterations=None,
    swap_memory=False,
    time_major=False,
    scope=None
)
",Creates a dynamic version of bidirectional recurrent neural network. (deprecated)
tf.nn.collapse_repeated,"tf.nn.collapse_repeated(
    labels, seq_length, name=None
)
",Merge repeated labels into single labels.View aliases
tf.nn.compute_accidental_hits,"tf.nn.compute_accidental_hits(
    true_classes, sampled_candidates, num_true, seed=None, name=None
)
",Compute the position ids in sampled_candidates matching true_classes.View aliases
tf.nn.compute_average_loss,"tf.nn.compute_average_loss(
    per_example_loss, sample_weight=None, global_batch_size=None
)
",Scales per-example losses with sample_weights and computes their average.View aliases
tf.compat.v1.nn.conv1d,"tf.compat.v1.nn.conv1d(
    value=None,
    filters=None,
    stride=None,
    padding=None,
    use_cudnn_on_gpu=None,
    data_format=None,
    name=None,
    input=None,
    dilations=None
)
",Computes a 1-D convolution of input with rank >=3 and a 3-D filter. (deprecated argument values) (deprecated argument values)
tf.nn.conv1d_transpose,"tf.nn.conv1d_transpose(
    input,
    filters,
    output_shape,
    strides,
    padding='SAME',
    data_format='NWC',
    dilations=None,
    name=None
)
",The transpose of conv1d.View aliases
tf.compat.v1.nn.conv2d,"tf.compat.v1.nn.conv2d(
    input,
    filter=None,
    strides=None,
    padding=None,
    use_cudnn_on_gpu=True,
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None,
    filters=None
)
",Computes a 2-D convolution given 4-D input and filter tensors.
tf.compat.v1.nn.conv2d_backprop_filter,"tf.compat.v1.nn.conv2d_backprop_filter(
    input,
    filter_sizes,
    out_backprop,
    strides,
    padding,
    use_cudnn_on_gpu=True,
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes the gradients of convolution with respect to the filter.
tf.compat.v1.nn.conv2d_backprop_input,"tf.compat.v1.nn.conv2d_backprop_input(
    input_sizes,
    filter=None,
    out_backprop=None,
    strides=None,
    padding=None,
    use_cudnn_on_gpu=True,
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None,
    filters=None
)
",Computes the gradients of convolution with respect to the input.
tf.compat.v1.nn.conv2d_transpose,"tf.compat.v1.nn.conv2d_transpose(
    value=None,
    filter=None,
    output_shape=None,
    strides=None,
    padding='SAME',
    data_format='NHWC',
    name=None,
    input=None,
    filters=None,
    dilations=None
)
",The transpose of conv2d.
tf.compat.v1.nn.conv3d,"tf.compat.v1.nn.conv3d(
    input,
    filter=None,
    strides=None,
    padding=None,
    data_format='NDHWC',
    dilations=[1, 1, 1, 1, 1],
    name=None,
    filters=None
)
",Computes a 3-D convolution given 5-D input and filter tensors.
tf.compat.v1.nn.conv3d_backprop_filter,"tf.compat.v1.nn.conv3d_backprop_filter(
    input,
    filter_sizes,
    out_backprop,
    strides,
    padding,
    data_format='NDHWC',
    dilations=[1, 1, 1, 1, 1],
    name=None
)
",Computes the gradients of 3-D convolution with respect to the filter.View aliases
tf.compat.v1.nn.conv3d_backprop_filter,"tf.compat.v1.nn.conv3d_backprop_filter(
    input,
    filter_sizes,
    out_backprop,
    strides,
    padding,
    data_format='NDHWC',
    dilations=[1, 1, 1, 1, 1],
    name=None
)
",Computes the gradients of 3-D convolution with respect to the filter.View aliases
tf.compat.v1.nn.conv3d_transpose,"tf.compat.v1.nn.conv3d_transpose(
    value,
    filter=None,
    output_shape=None,
    strides=None,
    padding='SAME',
    data_format='NDHWC',
    name=None,
    input=None,
    filters=None,
    dilations=None
)
",The transpose of conv3d.
tf.nn.conv_transpose,"tf.nn.conv_transpose(
    input,
    filters,
    output_shape,
    strides,
    padding='SAME',
    data_format=None,
    dilations=None,
    name=None
)
",The transpose of convolution.View aliases
tf.compat.v1.nn.convolution,"tf.compat.v1.nn.convolution(
    input,
    filter,
    padding,
    strides=None,
    dilation_rate=None,
    name=None,
    data_format=None,
    filters=None,
    dilations=None
)
",Computes sums of N-D convolutions (actually cross-correlation).
tf.compat.v1.nn.crelu,"tf.compat.v1.nn.crelu(
    features, name=None, axis=-1
)
",Computes Concatenated ReLU.
tf.compat.v1.nn.ctc_beam_search_decoder,"tf.compat.v1.nn.ctc_beam_search_decoder(
    inputs, sequence_length, beam_width=100, top_paths=1, merge_repeated=True
)
",Performs beam search decoding on the logits given in input.
tf.nn.ctc_beam_search_decoder,"tf.nn.ctc_beam_search_decoder(
    inputs, sequence_length, beam_width=100, top_paths=1
)
",Performs beam search decoding on the logits given in input.View aliases
tf.nn.ctc_greedy_decoder,"tf.nn.ctc_greedy_decoder(
    inputs, sequence_length, merge_repeated=True, blank_index=None
)
",Performs greedy decoding on the logits given in input (best path).View aliases
tf.compat.v1.nn.ctc_loss,"tf.compat.v1.nn.ctc_loss(
    labels,
    inputs=None,
    sequence_length=None,
    preprocess_collapse_repeated=False,
    ctc_merge_repeated=True,
    ignore_longer_outputs_than_inputs=False,
    time_major=True,
    logits=None
)
",Computes the CTC (Connectionist Temporal Classification) Loss.
tf.compat.v1.nn.ctc_loss_v2,"tf.compat.v1.nn.ctc_loss_v2(
    labels,
    logits,
    label_length,
    logit_length,
    logits_time_major=True,
    unique=None,
    blank_index=None,
    name=None
)
",Computes CTC (Connectionist Temporal Classification) loss.
tf.nn.ctc_unique_labels,"tf.nn.ctc_unique_labels(
    labels, name=None
)
",Get unique labels and indices for batched labels for tf.nn.ctc_loss.View aliases
tf.compat.v1.depth_to_space,"tf.compat.v1.depth_to_space(
    input, block_size, name=None, data_format='NHWC'
)
",DepthToSpace for tensors of type T.View aliases
tf.compat.v1.nn.depthwise_conv2d,"tf.compat.v1.nn.depthwise_conv2d(
    input,
    filter,
    strides,
    padding,
    rate=None,
    name=None,
    data_format=None,
    dilations=None
)
",Depthwise 2-D convolution.
tf.compat.v1.nn.depthwise_conv2d,"tf.compat.v1.nn.depthwise_conv2d(x, kernel, strides=[1, 1, 1, 1],","Depthwise 2-D convolution.tf.compat.v1.nn.depthwise_conv2d(    input,    filter,    strides,    padding,    rate=None,    name=None,    data_format=None,    dilations=None)Given a 4D input tensor ('NHWC' or 'NCHW' data formats)and a filter tensor of shape[filter_height, filter_width, in_channels, channel_multiplier]containing in_channels convolutional filters of depth 1, depthwise_conv2dapplies a different filter to each input channel (expanding from 1 channelto channel_multiplier channels for each), then concatenates the resultstogether.  The output has in_channels * channel_multiplier channels.In detail, with the default NHWC format,output[b, i, j, k * channel_multiplier + q] = sum_{di, dj}     filter[di, dj, k, q] * input[b, strides[1] * i + rate[0] * di,                                     strides[2] * j + rate[1] * dj, k]Must have strides[0] = strides[3] = 1.  For the most common case of thesame horizontal and vertical strides, strides = [1, stride, stride, 1].If any value in rate is greater than 1, we perform atrous depthwiseconvolution, in which case all values in the strides tensor must be equalto 1.Usage Example:x = np.array([    [1., 2.],    [3., 4.],    [5., 6.]], dtype=np.float32).reshape((1, 3, 2, 1))kernel = np.array([    [1., 2.],    [3., 4]], dtype=np.float32).reshape((2, 1, 1, 2))tf.compat.v1.nn.depthwise_conv2d(x, kernel, strides=[1, 1, 1, 1],                                 padding='VALID').numpy()  array([[[[10., 14.],           [14., 20.]],          [[18., 26.],           [22., 32.]]]], dtype=float32)"
tf.nn.depthwise_conv2d_backprop_filter,"tf.nn.depthwise_conv2d_backprop_filter(
    input,
    filter_sizes,
    out_backprop,
    strides,
    padding,
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes the gradients of depthwise convolution with respect to the filter.View aliases
tf.nn.depthwise_conv2d_backprop_input,"tf.nn.depthwise_conv2d_backprop_input(
    input_sizes,
    filter,
    out_backprop,
    strides,
    padding,
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes the gradients of depthwise convolution with respect to the input.View aliases
tf.compat.v1.nn.depthwise_conv2d_native,"tf.compat.v1.nn.depthwise_conv2d_native(
    input,
    filter,
    strides,
    padding,
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes a 2-D depthwise convolution.
tf.nn.depthwise_conv2d_backprop_filter,"tf.nn.depthwise_conv2d_backprop_filter(
    input,
    filter_sizes,
    out_backprop,
    strides,
    padding,
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes the gradients of depthwise convolution with respect to the filter.View aliases
tf.nn.depthwise_conv2d_backprop_input,"tf.nn.depthwise_conv2d_backprop_input(
    input_sizes,
    filter,
    out_backprop,
    strides,
    padding,
    data_format='NHWC',
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes the gradients of depthwise convolution with respect to the input.View aliases
tf.compat.v1.nn.dilation2d,"tf.compat.v1.nn.dilation2d(
    input,
    filter=None,
    strides=None,
    rates=None,
    padding=None,
    name=None,
    filters=None,
    dilations=None
)
",Computes the grayscale dilation of 4-D input and 3-D filter tensors.
tf.compat.v1.nn.dropout,"tf.compat.v1.nn.dropout(
    x, keep_prob=None, noise_shape=None, seed=None, name=None, rate=None
)
",Computes dropout. (deprecated arguments)
tf.compat.v1.nn.dynamic_rnn,"tf.compat.v1.nn.dynamic_rnn(
    cell,
    inputs,
    sequence_length=None,
    initial_state=None,
    dtype=None,
    parallel_iterations=None,
    swap_memory=False,
    time_major=False,
    scope=None
)
",Creates a recurrent neural network specified by RNNCell cell. (deprecated)
tf.nn.elu,"tf.nn.elu(
    features, name=None
)
",Computes the exponential linear function.View aliases
tf.compat.v1.nn.embedding_lookup,"tf.compat.v1.nn.embedding_lookup(
    params,
    ids,
    partition_strategy='mod',
    name=None,
    validate_indices=True,
    max_norm=None
)
",Looks up embeddings for the given ids from a list of tensors.
tf.compat.v1.nn.embedding_lookup_sparse,"tf.compat.v1.nn.embedding_lookup_sparse(
    params,
    sp_ids,
    sp_weights,
    partition_strategy='mod',
    name=None,
    combiner=None,
    max_norm=None
)
",Looks up embeddings for the given ids and weights from a list of tensors.
tf.compat.v1.nn.erosion2d,"tf.compat.v1.nn.erosion2d(
    value, kernel, strides, rates, padding, name=None
)
",Computes the grayscale erosion of 4-D value and 3-D kernel tensors.
tf.nn.experimental.stateless_dropout,"tf.nn.experimental.stateless_dropout(
    x, rate, seed, rng_alg=None, noise_shape=None, name=None
)
",Computes dropout: randomly sets elements to zero to prevent overfitting.View aliases
tf.nn.experimental.stateless_dropout,"tf.nn.experimental.stateless_dropout(x, rate=0.0, seed=[1, 0]) == x","Computes dropout: randomly sets elements to zero to prevent overfitting.View aliasestf.nn.experimental.stateless_dropout(    x, rate, seed, rng_alg=None, noise_shape=None, name=None)Dropout is useful for regularizing DNNmodels. Inputs elements are randomly set to zero (and the other elements arerescaled). This encourages each node to be independently useful, as it cannotrely on the output of other nodes.More precisely: With probability rate elements of x are set to 0.The remaining elements are scaled up by 1.0 / (1 - rate), so that theexpected value is preserved.x = tf.ones([3,5])tf.nn.experimental.stateless_dropout(x, rate=0.5, seed=[1, 0])<tf.Tensor: shape=(3, 5), dtype=float32, numpy=array([[2., 0., 2., 0., 0.],       [0., 0., 2., 0., 2.],       [0., 0., 0., 0., 2.]], dtype=float32)>x = tf.ones([3,5])tf.nn.experimental.stateless_dropout(x, rate=0.8, seed=[1, 0])<tf.Tensor: shape=(3, 5), dtype=float32, numpy=array([[5., 0., 0., 0., 0.],       [0., 0., 0., 0., 5.],       [0., 0., 0., 0., 5.]], dtype=float32)>"
tf.random.fixed_unigram_candidate_sampler,"tf.random.fixed_unigram_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    vocab_file='',
    distortion=1.0,
    num_reserved_ids=0,
    num_shards=1,
    shard=0,
    unigrams=(),
    seed=None,
    name=None
)
",Samples a set of classes using the provided (fixed) base distribution.View aliases
tf.compat.v1.nn.fractional_avg_pool,"tf.compat.v1.nn.fractional_avg_pool(
    value,
    pooling_ratio,
    pseudo_random=False,
    overlapping=False,
    deterministic=False,
    seed=0,
    seed2=0,
    name=None
)
",Performs fractional average pooling on the input. (deprecated)
tf.compat.v1.nn.fractional_max_pool,"tf.compat.v1.nn.fractional_max_pool(
    value,
    pooling_ratio,
    pseudo_random=False,
    overlapping=False,
    deterministic=False,
    seed=0,
    seed2=0,
    name=None
)
",Performs fractional max pooling on the input. (deprecated)
tf.compat.v1.nn.fused_batch_norm,"tf.compat.v1.nn.fused_batch_norm(
    x,
    scale,
    offset,
    mean=None,
    variance=None,
    epsilon=0.001,
    data_format='NHWC',
    is_training=True,
    name=None,
    exponential_avg_factor=1.0
)
",Batch normalization.
tf.compat.v1.math.in_top_k,"tf.compat.v1.math.in_top_k(
    predictions, targets, k, name=None
)
",Says whether the targets are in the top K predictions.View aliases
tf.nn.l2_loss,"tf.nn.l2_loss(
    t, name=None
)
",L2 Loss.View aliases
tf.math.l2_normalize,"tf.math.l2_normalize(
    x, axis=None, epsilon=1e-12, name=None, dim=None
)
",Normalizes along dimension axis using an L2 norm. (deprecated arguments)View aliases
tf.nn.leaky_relu,"tf.nn.leaky_relu(
    features, alpha=0.2, name=None
)
",Compute the Leaky ReLU activation function.View aliases
tf.random.learned_unigram_candidate_sampler,"tf.random.learned_unigram_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=None,
    name=None
)
",Samples a set of classes from a distribution learned during training.View aliases
tf.nn.local_response_normalization,"tf.nn.local_response_normalization(
    input, depth_radius=5, bias=1, alpha=1, beta=0.5, name=None
)
",Local Response Normalization.View aliases
tf.nn.log_poisson_loss,"tf.nn.log_poisson_loss(
    targets, log_input, compute_full_loss=False, name=None
)
",Computes log Poisson loss given log_input.View aliases
tf.compat.v1.math.log_softmax,"tf.compat.v1.math.log_softmax(
    logits, axis=None, name=None, dim=None
)
",Computes log softmax activations. (deprecated arguments)View aliases
tf.random.log_uniform_candidate_sampler,"tf.random.log_uniform_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=None,
    name=None
)
",Samples a set of classes using a log-uniform (Zipfian) base distribution.View aliases
tf.nn.local_response_normalization,"tf.nn.local_response_normalization(
    input, depth_radius=5, bias=1, alpha=1, beta=0.5, name=None
)
",Local Response Normalization.View aliases
tf.compat.v1.nn.max_pool,"tf.compat.v1.nn.max_pool(
    value,
    ksize,
    strides,
    padding,
    data_format='NHWC',
    name=None,
    input=None
)
",Performs the max pooling on the input.
tf.nn.max_pool1d,"tf.nn.max_pool1d(
    input, ksize, strides, padding, data_format='NWC', name=None
)
",Performs the max pooling on the input.View aliases
tf.nn.max_pool2d,"tf.nn.max_pool2d(
    input, ksize, strides, padding, data_format='NHWC', name=None
)
",Performs max pooling on 2D spatial data such as images.View aliases
tf.nn.max_pool3d,"tf.nn.max_pool3d(
    input, ksize, strides, padding, data_format='NDHWC', name=None
)
",Performs the max pooling on the input.View aliases
tf.nn.max_pool,"tf.nn.max_pool(
    input, ksize, strides, padding, data_format=None, name=None
)
",Performs max pooling on the input.View aliases
tf.compat.v1.nn.max_pool_with_argmax,"tf.compat.v1.nn.max_pool_with_argmax(
    input,
    ksize,
    strides,
    padding,
    data_format='NHWC',
    Targmax=None,
    name=None,
    output_dtype=None,
    include_batch_in_index=False
)
",Performs max pooling on the input and outputs both max values and indices.
tf.compat.v1.nn.moments,"tf.compat.v1.nn.moments(
    x, axes, shift=None, name=None, keep_dims=None, keepdims=None
)
",Calculate the mean and variance of x.
tf.compat.v1.nn.nce_loss,"tf.compat.v1.nn.nce_loss(
    weights,
    biases,
    labels,
    inputs,
    num_sampled,
    num_classes,
    num_true=1,
    sampled_values=None,
    remove_accidental_hits=False,
    partition_strategy='mod',
    name='nce_loss'
)
",Computes and returns the noise-contrastive estimation training loss.
tf.nn.normalize_moments,"tf.nn.normalize_moments(
    counts, mean_ss, variance_ss, shift, name=None
)
",Calculate the mean and variance of based on the sufficient statistics.View aliases
tf.compat.v1.nn.pool,"tf.compat.v1.nn.pool(
    input,
    window_shape,
    pooling_type,
    padding,
    dilation_rate=None,
    strides=None,
    name=None,
    data_format=None,
    dilations=None
)
",Performs an N-D pooling operation.
tf.compat.v1.nn.quantized_avg_pool,"tf.compat.v1.nn.quantized_avg_pool(
    input, min_input, max_input, ksize, strides, padding, name=None
)
",Produces the average pool of the input tensor for quantized types.
tf.compat.v1.nn.quantized_conv2d,"tf.compat.v1.nn.quantized_conv2d(
    input,
    filter,
    min_input,
    max_input,
    min_filter,
    max_filter,
    strides,
    padding,
    out_type=tf.dtypes.qint32,
    dilations=[1, 1, 1, 1],
    name=None
)
",Computes a 2D convolution given quantized 4D input and filter tensors.
tf.compat.v1.nn.quantized_max_pool,"tf.compat.v1.nn.quantized_max_pool(
    input, min_input, max_input, ksize, strides, padding, name=None
)
",Produces the max pool of the input tensor for quantized types.
tf.compat.v1.nn.quantized_relu_x,"tf.compat.v1.nn.quantized_relu_x(
    features,
    max_value,
    min_features,
    max_features,
    out_type=tf.dtypes.quint8,
    name=None
)
","Computes Quantized Rectified Linear X: min(max(features, 0), max_value)"
tf.compat.v1.nn.raw_rnn,"tf.compat.v1.nn.raw_rnn(
    cell, loop_fn, parallel_iterations=None, swap_memory=False, scope=None
)
",Creates an RNN specified by RNNCell cell and loop function loop_fn.
tf.nn.relu,"tf.nn.relu(
    features, name=None
)
","Computes rectified linear: max(features, 0).View aliases"
tf.nn.relu6,"tf.nn.relu6(
    features, name=None
)
","Computes Rectified Linear 6: min(max(features, 0), 6).View aliases"
tf.compat.v1.nn.relu_layer,"tf.compat.v1.nn.relu_layer(
    x, weights, biases, name=None
)
",Computes Relu(x * weight + biases).
tf.compat.v1.nn.rnn_cell.BasicLSTMCell,"tf.compat.v1.nn.rnn_cell.BasicLSTMCell(
    num_units,
    forget_bias=1.0,
    state_is_tuple=True,
    activation=None,
    reuse=None,
    name=None,
    dtype=None,
    **kwargs
)
","Deprecated: Please use Inherits From: RNNCell, Layer, Layer, Module"
tf.compat.v1.nn.rnn_cell.BasicRNNCell,"tf.compat.v1.nn.rnn_cell.BasicRNNCell(
    num_units, activation=None, reuse=None, name=None, dtype=None, **kwargs
)
","The most basic RNN cell.Inherits From: RNNCell, Layer, Layer, Module"
tf.compat.v1.nn.rnn_cell.DeviceWrapper,"tf.compat.v1.nn.rnn_cell.DeviceWrapper(
    cell, device, **kwargs
)
","Operator that ensures an RNNCell runs on a particular device.Inherits From: RNNCell, Layer, Layer, Module"
tf.compat.v1.nn.rnn_cell.DropoutWrapper,"tf.compat.v1.nn.rnn_cell.DropoutWrapper(
    cell,
    input_keep_prob=1.0,
    output_keep_prob=1.0,
    state_keep_prob=1.0,
    variational_recurrent=False,
    input_size=None,
    dtype=None,
    seed=None,
    dropout_state_filter_visitor=None,
    **kwargs
)
","Operator adding dropout to inputs and outputs of the given cell.Inherits From: RNNCell, Layer, Layer, Module"
tf.compat.v1.nn.rnn_cell.GRUCell,"tf.compat.v1.nn.rnn_cell.GRUCell(
    num_units,
    activation=None,
    reuse=None,
    kernel_initializer=None,
    bias_initializer=None,
    name=None,
    dtype=None,
    **kwargs
)
","Gated Recurrent Unit cell.Inherits From: RNNCell, Layer, Layer, Module"
tf.compat.v1.nn.rnn_cell.LSTMCell,"tf.compat.v1.nn.rnn_cell.LSTMCell(
    num_units,
    use_peepholes=False,
    cell_clip=None,
    initializer=None,
    num_proj=None,
    proj_clip=None,
    num_unit_shards=None,
    num_proj_shards=None,
    forget_bias=1.0,
    state_is_tuple=True,
    activation=None,
    reuse=None,
    name=None,
    dtype=None,
    **kwargs
)
","Long short-term memory unit (LSTM) recurrent network cell.Inherits From: RNNCell, Layer, Layer, Module"
tf.compat.v1.nn.rnn_cell.LSTMStateTuple,"tf.compat.v1.nn.rnn_cell.LSTMStateTuple(
    c, h
)
","Tuple used by LSTM Cells for state_size, zero_state, and output state."
tf.compat.v1.nn.rnn_cell.MultiRNNCell,"tf.compat.v1.nn.rnn_cell.MultiRNNCell(
    cells, state_is_tuple=True
)
","RNN cell composed sequentially of multiple simple cells.Inherits From: RNNCell, Layer, Layer, Module"
tf.compat.v1.nn.rnn_cell.RNNCell,"tf.compat.v1.nn.rnn_cell.RNNCell(
    trainable=True, name=None, dtype=None, **kwargs
)
","Abstract object representing an RNN cell.Inherits From: Layer, Layer, Module"
tf.compat.v1.nn.rnn_cell.ResidualWrapper,"tf.compat.v1.nn.rnn_cell.ResidualWrapper(
    cell, residual_fn=None, **kwargs
)
","RNNCell wrapper that ensures cell inputs are added to the outputs.Inherits From: RNNCell, Layer, Layer, Module"
tf.compat.v1.nn.safe_embedding_lookup_sparse,"tf.compat.v1.nn.safe_embedding_lookup_sparse(
    embedding_weights,
    sparse_ids,
    sparse_weights=None,
    combiner='mean',
    default_id=None,
    name=None,
    partition_strategy='div',
    max_norm=None
)
","Lookup embedding results, accounting for invalid IDs and empty features."
tf.compat.v1.nn.sampled_softmax_loss,"tf.compat.v1.nn.sampled_softmax_loss(
    weights,
    biases,
    labels,
    inputs,
    num_sampled,
    num_classes,
    num_true=1,
    sampled_values=None,
    remove_accidental_hits=True,
    partition_strategy='mod',
    name='sampled_softmax_loss',
    seed=None
)
",Computes and returns the sampled softmax training loss.
tf.nn.scale_regularization_loss,"tf.nn.scale_regularization_loss(
    regularization_loss
)
",Scales the sum of the given regularization losses by number of replicas.View aliases
tf.nn.selu,"tf.nn.selu(
    features, name=None
)
",Computes scaled exponential linear: scale * alpha * (exp(features) - 1)View aliases
tf.compat.v1.nn.separable_conv2d,"tf.compat.v1.nn.separable_conv2d(
    input,
    depthwise_filter,
    pointwise_filter,
    strides,
    padding,
    rate=None,
    name=None,
    data_format=None,
    dilations=None
)
",2-D convolution with separable filters.
tf.math.sigmoid,"tf.math.sigmoid(
    x, name=None
)
",Computes sigmoid of x element-wise.View aliases
tf.compat.v1.nn.sigmoid_cross_entropy_with_logits,"tf.compat.v1.nn.sigmoid_cross_entropy_with_logits(
    _sentinel=None, labels=None, logits=None, name=None
)
",Computes sigmoid cross entropy given logits.
tf.nn.silu,"tf.nn.silu(
    features, beta=1.0
)
",Computes the SiLU or Swish activation function: x * sigmoid(beta * x).View aliases
tf.compat.v1.math.softmax,"tf.compat.v1.math.softmax(
    logits, axis=None, name=None, dim=None
)
",Computes softmax activations.View aliases
tf.compat.v1.nn.softmax_cross_entropy_with_logits,"tf.compat.v1.nn.softmax_cross_entropy_with_logits(
    _sentinel=None, labels=None, logits=None, dim=-1, name=None, axis=None
)
",Computes softmax cross entropy between logits and labels. (deprecated)
tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2,"tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(
    labels, logits, axis=None, name=None, dim=None
)
",Computes softmax cross entropy between logits and labels. (deprecated arguments)
tf.math.softplus,"tf.math.softplus(
    features, name=None
)
",Computes elementwise softplus: softplus(x) = log(exp(x) + 1).View aliases
tf.nn.softsign,"tf.nn.softsign(
    features, name=None
)
",Computes softsign: features / (abs(features) + 1).View aliases
tf.compat.v1.space_to_batch,"tf.compat.v1.space_to_batch(
    input, paddings, block_size=None, name=None, block_shape=None
)
",SpaceToBatch for 4-D tensors of type T.View aliases
tf.compat.v1.space_to_depth,"tf.compat.v1.space_to_depth(
    input, block_size, name=None, data_format='NHWC'
)
",SpaceToDepth for tensors of type T.View aliases
tf.compat.v1.nn.sparse_softmax_cross_entropy_with_logits,"tf.compat.v1.nn.sparse_softmax_cross_entropy_with_logits(
    _sentinel=None, labels=None, logits=None, name=None
)
",Computes sparse softmax cross entropy between logits and labels.
tf.compat.v1.nn.static_bidirectional_rnn,"tf.compat.v1.nn.static_bidirectional_rnn(
    cell_fw,
    cell_bw,
    inputs,
    initial_state_fw=None,
    initial_state_bw=None,
    dtype=None,
    sequence_length=None,
    scope=None
)
",Creates a bidirectional recurrent neural network. (deprecated)
tf.compat.v1.nn.static_rnn,"tf.compat.v1.nn.static_rnn(
    cell,
    inputs,
    initial_state=None,
    dtype=None,
    sequence_length=None,
    scope=None
)
",Creates a recurrent neural network specified by RNNCell cell. (deprecated)
tf.compat.v1.nn.static_state_saving_rnn,"tf.compat.v1.nn.static_state_saving_rnn(
    cell, inputs, state_saver, state_name, sequence_length=None, scope=None
)
",RNN that accepts a state saver for time-truncated RNN calculation. (deprecated)
tf.compat.v1.nn.sufficient_statistics,"tf.compat.v1.nn.sufficient_statistics(
    x, axes, shift=None, keep_dims=None, name=None, keepdims=None
)
",Calculate the sufficient statistics for the mean and variance of x.
tf.nn.silu,"tf.nn.silu(
    features, beta=1.0
)
",Computes the SiLU or Swish activation function: x * sigmoid(beta * x).View aliases
tf.math.tanh,"tf.math.tanh(
    x, name=None
)
",Computes hyperbolic tangent of x element-wise.View aliases
tf.math.top_k,"tf.math.top_k(
    input, k=1, sorted=True, name=None
)
",Finds values and indices of the k largest entries for the last dimension.View aliases
tf.random.uniform_candidate_sampler,"tf.random.uniform_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=None,
    name=None
)
",Samples a set of classes using a uniform base distribution.View aliases
tf.compat.v1.nn.weighted_cross_entropy_with_logits,"tf.compat.v1.nn.weighted_cross_entropy_with_logits(
    labels=None, logits=None, pos_weight=None, name=None, targets=None
)
",Computes a weighted cross entropy. (deprecated arguments)
tf.compat.v1.nn.weighted_moments,"tf.compat.v1.nn.weighted_moments(
    x, axes, frequency_weights, name=None, keep_dims=None, keepdims=None
)
",Returns the frequency-weighted mean and variance of x.
tf.nn.with_space_to_batch,"tf.nn.with_space_to_batch(
    input,
    dilation_rate,
    padding,
    op,
    filter_shape=None,
    spatial_dims=None,
    data_format=None
)
",Performs op on the space-to-batch representation of input.View aliases
tf.compat.v1.nn.xw_plus_b,"tf.compat.v1.nn.xw_plus_b(
    x, weights, biases, name=None
)
","Computes matmul(x, weights) + biases."
tf.math.zero_fraction,"tf.math.zero_fraction(
    value, name=None
)
",Returns the fraction of zeros in value.View aliases
tf.no_gradient,"tf.no_gradient(
    op_type
)
",Specifies that ops of type op_type is not differentiable.View aliases
tf.no_op,"tf.no_op(
    name=None
)
",Does nothing. Only useful as a placeholder for control edges.View aliases
tf.compat.v1.no_regularizer,"tf.compat.v1.no_regularizer(
    _
)
",Use this function to prevent regularization of variables.
tf.nondifferentiable_batch_function,"tf.nondifferentiable_batch_function(
    num_batch_threads,
    max_batch_size,
    batch_timeout_micros,
    allowed_batch_sizes=None,
    max_enqueued_batches=10,
    autograph=True,
    enable_large_batch_splitting=True
)
",Batches the computation done by the decorated function.View aliases
tf.compat.v1.norm,"tf.compat.v1.norm(
    tensor,
    ord='euclidean',
    axis=None,
    keepdims=None,
    name=None,
    keep_dims=None
)
","Computes the norm of vectors, matrices, and tensors. (deprecated arguments)View aliases"
tf.math.not_equal,"tf.math.not_equal(
    x, y, name=None
)
",Returns the truth value of (x != y) element-wise.View aliases
tf.numpy_function,"tf.numpy_function(
    func, inp, Tout, stateful=True, name=None
)
",Wraps a python function and uses it as a TensorFlow op.View aliases
tf.one_hot,"tf.one_hot(
    indices,
    depth,
    on_value=None,
    off_value=None,
    axis=None,
    dtype=None,
    name=None
)
",Returns a one-hot tensor.View aliases
tf.ones,"tf.ones(
    shape,
    dtype=tf.dtypes.float32,
    name=None
)
",Creates a tensor with all elements set to one (1).View aliases
tf.compat.v1.keras.initializers.Ones,"tf.compat.v1.keras.initializers.Ones(
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors initialized to 1.View aliases
tf.compat.v1.ones_like,"tf.compat.v1.ones_like(
    tensor, dtype=None, name=None, optimize=True
)
",Creates a tensor with all elements set to 1.
tf.compat.v1.keras.initializers.Orthogonal,"tf.compat.v1.keras.initializers.Orthogonal(
    gain=1.0,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates an orthogonal matrix.View aliases
tf.compat.v1.pad,"tf.compat.v1.pad(
    tensor, paddings, mode='CONSTANT', name=None, constant_values=0
)
",Pads a tensor.
tf.parallel_stack,"tf.parallel_stack(
    values, name='parallel_stack'
)
",Stacks a list of rank-R tensors into one rank-(R+1) tensor in parallel.View aliases
tf.compat.v1.parse_example,"tf.compat.v1.parse_example(
    serialized, features, name=None, example_names=None
)
",Parses Example protos into a dict of tensors.View aliases
tf.compat.v1.parse_single_example,"tf.compat.v1.parse_single_example(
    serialized, features, name=None, example_names=None
)
",Parses a single Example proto.View aliases
tf.io.parse_single_sequence_example,"tf.io.parse_single_sequence_example(
    serialized,
    context_features=None,
    sequence_features=None,
    example_name=None,
    name=None
)
",Parses a single SequenceExample proto.View aliases
tf.io.parse_tensor,"tf.io.parse_tensor(
    serialized, out_type, name=None
)
",Transforms a serialized tensorflow.TensorProto proto into a Tensor.View aliases
tf.compat.v1.placeholder,"tf.compat.v1.placeholder(
    dtype, shape=None, name=None
)
",Inserts a placeholder for a tensor that will be always fed.
tf.compat.v1.placeholder_with_default,"tf.compat.v1.placeholder_with_default(
    input, shape, name=None
)
",A placeholder op that passes through input when its output is not fed.
tf.math.polygamma,"tf.math.polygamma(
    a, x, name=None
)
",Compute the polygamma function \(\psi^{(n)}(x)\).View aliases
tf.math.pow,"tf.math.pow(
    x, y, name=None
)
",Computes the power of one value to another.View aliases
tf.print,"tf.print(
    *inputs, **kwargs
)
",Print the specified inputs.View aliases
tf.compat.v1.profiler.ProfileOptionBuilder,"tf.compat.v1.profiler.ProfileOptionBuilder(
    options=None
)
",Option Builder for Profiling API.
tf.compat.v1.profiler.Profiler,"tf.compat.v1.profiler.Profiler(
    graph=None, op_log=None
)
",TensorFlow multi-step profiler.
tf.compat.v1.profiler.advise,"tf.compat.v1.profiler.advise(
    graph=None, run_meta=None, options=_DEFAULT_ADVISE_OPTIONS
)
",Auto profile and advise.
tf.compat.v1.profiler.profile,"tf.compat.v1.profiler.profile(
    graph=None,
    run_meta=None,
    op_log=None,
    cmd='scope',
    options=_DEFAULT_PROFILE_OPTIONS
)
",Profile model.
tf.compat.v1.profiler.write_op_log,"tf.compat.v1.profiler.write_op_log(
    graph, log_dir, op_log=None, run_meta=None, add_trace=True
)
","Log provided 'op_log', and add additional model information below."
tf.compat.v1.py_func,"tf.compat.v1.py_func(
    func, inp, Tout, stateful=True, name=None
)
",Wraps a python function and uses it as a TensorFlow op.
tf.numpy_function,"tf.numpy_function(fn_using_numpy, inp=[tf.constant([1., 2.])],","Wraps a python function and uses it as a TensorFlow op.tf.compat.v1.py_func(    func, inp, Tout, stateful=True, name=None)Caution: This API was designed for TensorFlow v1.Continue reading for details on how to migrate from this API to a nativeTensorFlow v2 equivalent. See theThis name was deprecated and removed in TF2, but tf.numpy_function is anear-exact replacement, just drop the stateful argument (alltf.numpy_function calls are considered stateful). It is compatible witheager execution and tf.function.tf.py_function is a close but not an exact replacement, passing TensorFlowtensors to the wrapped function instead of NumPy arrays, which providesgradients and can take advantage of accelerators.Before:def fn_using_numpy(x):  x[0] = 0.  return xtf.compat.v1.py_func(fn_using_numpy, inp=[tf.constant([1., 2.])],    Tout=tf.float32, stateful=False)<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 2.], dtype=float32)>After:"
tf.py_function,"tf.py_function(
    func, inp, Tout, name=None
)
",Wraps a python function into a TensorFlow op that executes it eagerly.View aliases
tf.io.TFRecordOptions,"tf.io.TFRecordOptions(
    compression_type=None,
    flush_mode=None,
    input_buffer_size=None,
    output_buffer_size=None,
    window_bits=None,
    compression_level=None,
    compression_method=None,
    mem_level=None,
    compression_strategy=None
)
",Options used for manipulating TFRecord files.View aliases
tf.io.TFRecordWriter,"tf.io.TFRecordWriter(
    path, options=None
)
",A class to write records to a TFRecords file.View aliases
tf.compat.v1.io.tf_record_iterator,"tf.compat.v1.io.tf_record_iterator(
    path, options=None
)
",An iterator that read the records from a TFRecords file. (deprecated)View aliases
tf.linalg.qr,"tf.linalg.qr(
    input, full_matrices=False, name=None
)
",Computes the QR decompositions of one or more matrices.View aliases
tf.quantization.dequantize,"tf.quantization.dequantize(
    input,
    min_range,
    max_range,
    mode='MIN_COMBINED',
    name=None,
    axis=None,
    narrow_range=False,
    dtype=tf.dtypes.float32
)
",Dequantize the 'input' tensor into a float or bfloat16 Tensor.View aliases
tf.quantization.fake_quant_with_min_max_args,"tf.quantization.fake_quant_with_min_max_args(
    inputs, min=-6, max=6, num_bits=8, narrow_range=False, name=None
)
","Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.View aliases"
tf.quantization.fake_quant_with_min_max_args_gradient,"tf.quantization.fake_quant_with_min_max_args_gradient(
    gradients, inputs, min=-6, max=6, num_bits=8, narrow_range=False, name=None
)
",Compute gradients for a FakeQuantWithMinMaxArgs operation.View aliases
tf.quantization.fake_quant_with_min_max_vars,"tf.quantization.fake_quant_with_min_max_vars(
    inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Fake-quantize the 'inputs' tensor of type float via global float scalarsView aliases
tf.quantization.fake_quant_with_min_max_vars_gradient,"tf.quantization.fake_quant_with_min_max_vars_gradient(
    gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Compute gradients for a FakeQuantWithMinMaxVars operation.View aliases
tf.quantization.fake_quant_with_min_max_vars_per_channel,"tf.quantization.fake_quant_with_min_max_vars_per_channel(
    inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Fake-quantize the 'inputs' tensor of type float via per-channel floatsView aliases
tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient,"tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient(
    gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None
)
",Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.View aliases
tf.quantization.quantize,"tf.quantization.quantize(
    input,
    min_range,
    max_range,
    T,
    mode='MIN_COMBINED',
    round_mode='HALF_AWAY_FROM_ZERO',
    name=None,
    narrow_range=False,
    axis=None,
    ensure_minimum_range=0.01
)
",Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.View aliases
tf.quantization.quantize_and_dequantize,"tf.quantization.quantize_and_dequantize(
    input,
    input_min,
    input_max,
    signed_input=True,
    num_bits=8,
    range_given=False,
    round_mode='HALF_TO_EVEN',
    name=None,
    narrow_range=False,
    axis=None
)
",Quantizes then dequantizes a tensor. (deprecated)View aliases
tf.quantization.quantize_and_dequantize_v2,"tf.quantization.quantize_and_dequantize_v2(
    input,
    input_min,
    input_max,
    signed_input=True,
    num_bits=8,
    range_given=False,
    round_mode='HALF_TO_EVEN',
    name=None,
    narrow_range=False,
    axis=None
)
",Quantizes then dequantizes a tensor.View aliases
tf.quantization.quantized_concat,"tf.quantization.quantized_concat(
    concat_dim, values, input_mins, input_maxes, name=None
)
",Concatenates quantized tensors along one dimension.View aliases
tf.quantization.quantize,"tf.quantization.quantize(
    input,
    min_range,
    max_range,
    T,
    mode='MIN_COMBINED',
    round_mode='HALF_AWAY_FROM_ZERO',
    name=None,
    narrow_range=False,
    axis=None,
    ensure_minimum_range=0.01
)
",Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.View aliases
tf.compat.v1.quantize_v2,"tf.compat.v1.quantize_v2(
    input,
    min_range,
    max_range,
    T,
    mode='MIN_COMBINED',
    name=None,
    round_mode='HALF_AWAY_FROM_ZERO',
    narrow_range=False,
    axis=None,
    ensure_minimum_range=0.01
)
",Please use tf.quantization.quantize instead.
tf.quantization.quantized_concat,"tf.quantization.quantized_concat(
    concat_dim, values, input_mins, input_maxes, name=None
)
",Concatenates quantized tensors along one dimension.View aliases
tf.queue.FIFOQueue,"tf.queue.FIFOQueue(
    capacity,
    dtypes,
    shapes=None,
    names=None,
    shared_name=None,
    name='fifo_queue'
)
",A queue implementation that dequeues elements in first-in first-out order.Inherits From: QueueBaseView aliases
tf.queue.PaddingFIFOQueue,"tf.queue.PaddingFIFOQueue(
    capacity,
    dtypes,
    shapes,
    names=None,
    shared_name=None,
    name='padding_fifo_queue'
)
",A FIFOQueue that supports batching variable-sized tensors by padding.Inherits From: QueueBaseView aliases
tf.queue.PriorityQueue,"tf.queue.PriorityQueue(
    capacity,
    types,
    shapes=None,
    names=None,
    shared_name=None,
    name='priority_queue'
)
",A queue implementation that dequeues elements in prioritized order.Inherits From: QueueBaseView aliases
tf.queue.QueueBase,"tf.queue.QueueBase(
    dtypes, shapes, names, queue_ref
)
",Base class for queue implementations.View aliases
tf.queue.RandomShuffleQueue,"tf.queue.RandomShuffleQueue(
    capacity,
    min_after_dequeue,
    dtypes,
    shapes=None,
    names=None,
    seed=None,
    shared_name=None,
    name='random_shuffle_queue'
)
",A queue implementation that dequeues elements in a random order.Inherits From: QueueBaseView aliases
tf.compat.v1.ragged.RaggedTensorValue,"tf.compat.v1.ragged.RaggedTensorValue(
    values, row_splits
)
",Represents the value of a RaggedTensor.
tf.ragged.boolean_mask,"tf.ragged.boolean_mask(
    data, mask, name=None
)
",Applies a boolean mask to data without flattening the mask dimensions.View aliases
tf.ragged.boolean_mask,tf.ragged.boolean_mask(  # Mask a 2D Tensor.,"Applies a boolean mask to data without flattening the mask dimensions.View aliasestf.ragged.boolean_mask(    data, mask, name=None)Used in the notebooksReturns a potentially ragged tensor that is formed by retaining the elementsin data where the corresponding value in mask is True.output[a1...aA, i, b1...bB] = data[a1...aA, j, b1...bB]Note that output preserves the mask dimensions a1...aA; this differsfrom tf.boolean_mask, which flattens those dimensions.rank(output) = rank(data)output.ragged_rank = max(data.ragged_rank, rank(mask) - 1)Examples:# Aliases for True & False so data and mask line up.T, F = (True, False)"
tf.ragged.boolean_mask,tf.ragged.boolean_mask(  # Mask a 2D RaggedTensor.,"Applies a boolean mask to data without flattening the mask dimensions.View aliasestf.ragged.boolean_mask(    data, mask, name=None)Used in the notebooksReturns a potentially ragged tensor that is formed by retaining the elementsin data where the corresponding value in mask is True.output[a1...aA, i, b1...bB] = data[a1...aA, j, b1...bB]Note that output preserves the mask dimensions a1...aA; this differsfrom tf.boolean_mask, which flattens those dimensions.rank(output) = rank(data)output.ragged_rank = max(data.ragged_rank, rank(mask) - 1)Examples:# Aliases for True & False so data and mask line up.T, F = (True, False)tf.ragged.boolean_mask(  # Mask a 2D Tensor.    data=[[1, 2, 3], [4, 5, 6], [7, 8, 9]],    mask=[[T, F, T], [F, F, F], [T, F, F]]).to_list()[[1, 3], [], [7]]"
tf.ragged.boolean_mask,tf.ragged.boolean_mask(  # Mask rows of a 2D RaggedTensor.,"Applies a boolean mask to data without flattening the mask dimensions.View aliasestf.ragged.boolean_mask(    data, mask, name=None)Used in the notebooksReturns a potentially ragged tensor that is formed by retaining the elementsin data where the corresponding value in mask is True.output[a1...aA, i, b1...bB] = data[a1...aA, j, b1...bB]Note that output preserves the mask dimensions a1...aA; this differsfrom tf.boolean_mask, which flattens those dimensions.rank(output) = rank(data)output.ragged_rank = max(data.ragged_rank, rank(mask) - 1)Examples:# Aliases for True & False so data and mask line up.T, F = (True, False)tf.ragged.boolean_mask(  # Mask a 2D Tensor.    data=[[1, 2, 3], [4, 5, 6], [7, 8, 9]],    mask=[[T, F, T], [F, F, F], [T, F, F]]).to_list()[[1, 3], [], [7]]tf.ragged.boolean_mask(  # Mask a 2D RaggedTensor.    tf.ragged.constant([[1, 2, 3], [4], [5, 6]]),    tf.ragged.constant([[F, F, T], [F], [T, T]])).to_list()[[3], [], [5, 6]]"
tf.ragged.constant,"tf.ragged.constant(
    pylist,
    dtype=None,
    ragged_rank=None,
    inner_shape=None,
    name=None,
    row_splits_dtype=tf.dtypes.int64
)
",Constructs a constant RaggedTensor from a nested Python list.View aliases
tf.compat.v1.ragged.constant_value,"tf.compat.v1.ragged.constant_value(
    pylist,
    dtype=None,
    ragged_rank=None,
    inner_shape=None,
    row_splits_dtype='int64'
)
",Constructs a RaggedTensorValue from a nested Python list.
tf.ragged.cross,"tf.ragged.cross(
    inputs, name=None
)
",Generates feature cross from a list of tensors.View aliases
tf.ragged.cross,"tf.ragged.cross([tf.ragged.constant([['a'], ['b', 'c']]),","Generates feature cross from a list of tensors.View aliasestf.ragged.cross(    inputs, name=None)The input tensors must have rank=2, and must all have the same number ofrows.  The result is a RaggedTensor with the same number of rows as theinputs, where result[row] contains a list of all combinations of valuesformed by taking a single value from each input's corresponding row(inputs[i][row]).  Values are combined by joining their strings with 'X'.E.g.:"
tf.ragged.cross_hashed,"tf.ragged.cross_hashed(
    inputs, num_buckets=0, hash_key=None, name=None
)
",Generates hashed feature cross from a list of tensors.View aliases
tf.ragged.cross_hashed,"tf.ragged.cross_hashed([tf.ragged.constant([['a'], ['b', 'c']]),","Generates hashed feature cross from a list of tensors.View aliasestf.ragged.cross_hashed(    inputs, num_buckets=0, hash_key=None, name=None)The input tensors must have rank=2, and must all have the same number ofrows.  The result is a RaggedTensor with the same number of rows as theinputs, where result[row] contains a list of all combinations of valuesformed by taking a single value from each input's corresponding row(inputs[i][row]).  Values are combined by hashing together theirfingerprints. E.g.:"
tf.ragged.map_flat_values,"tf.ragged.map_flat_values(
    op, *args, **kwargs
)
",Applies op to the flat_values of one or more RaggedTensors.View aliases
tf.compat.v1.ragged.placeholder,"tf.compat.v1.ragged.placeholder(
    dtype, ragged_rank, value_shape=None, name=None
)
",Creates a placeholder for a tf.RaggedTensor that will always be fed.
tf.ragged.range,"tf.ragged.range(
    starts,
    limits=None,
    deltas=1,
    dtype=None,
    name=None,
    row_splits_dtype=tf.dtypes.int64
)
",Returns a RaggedTensor containing the specified sequences of numbers.View aliases
tf.ragged.row_splits_to_segment_ids,"tf.ragged.row_splits_to_segment_ids(
    splits, name=None, out_type=None
)
",Generates the segmentation corresponding to a RaggedTensor row_splits.View aliases
tf.ragged.segment_ids_to_row_splits,"tf.ragged.segment_ids_to_row_splits(
    segment_ids, num_segments=None, out_type=None, name=None
)
",Generates the RaggedTensor row_splits corresponding to a segmentation.View aliases
tf.ragged.stack,"tf.ragged.stack(
    values: typing.List[ragged_tensor.RaggedOrDense], axis=0, name=None
)
",Stacks a list of rank-R tensors into one rank-(R+1) RaggedTensor.View aliases
tf.ragged.stack_dynamic_partitions,"tf.ragged.stack_dynamic_partitions(
    data, partitions, num_partitions, name=None
)
",Stacks dynamic partitions of a Tensor or RaggedTensor.View aliases
tf.random.Generator,"tf.random.Generator(
    copy_from=None, state=None, alg=None
)
",Random-number generator.View aliases
tf.random.all_candidate_sampler,"tf.random.all_candidate_sampler(
    true_classes, num_true, num_sampled, unique, seed=None, name=None
)
",Generate the set of all classes.View aliases
tf.random.categorical,"tf.random.categorical(
    logits, num_samples, dtype=None, seed=None, name=None
)
",Draws samples from a categorical distribution.View aliases
tf.random.create_rng_state,"tf.random.create_rng_state(
    seed, alg
)
",Creates a RNG state from an integer or a vector.View aliases
tf.random.create_rng_state,tf.random.create_rng_state(,"Creates a RNG state from an integer or a vector.View aliasestf.random.create_rng_state(    seed, alg)Example:"
tf.random.Generator,"tf.random.Generator(
    copy_from=None, state=None, alg=None
)
",Random-number generator.View aliases
tf.random.create_rng_state,"tf.random.create_rng_state(
    seed, alg
)
",Creates a RNG state from an integer or a vector.View aliases
tf.random.create_rng_state,tf.random.create_rng_state(,"Creates a RNG state from an integer or a vector.View aliasestf.random.create_rng_state(    seed, alg)Example:"
tf.random.experimental.index_shuffle,"tf.random.experimental.index_shuffle(
    index, seed, max_index
)
","Outputs the position of index in a permutation of [0, ..., max_index].View aliases"
tf.random.set_global_generator,"tf.random.set_global_generator(
    generator
)
",Replaces the global generator with another Generator object.View aliases
tf.random.experimental.stateless_fold_in,"tf.random.experimental.stateless_fold_in(
    seed, data, alg='auto_select'
)
",Folds in data to an RNG seed to form a new RNG seed.View aliases
tf.random.experimental.stateless_shuffle,"tf.random.experimental.stateless_shuffle(
    value, seed, alg='auto_select', name=None
)
",Randomly and deterministically shuffles a tensor along its first dimension.View aliases
tf.random.experimental.stateless_split,"tf.random.experimental.stateless_split(
    seed, num=2, alg='auto_select'
)
",Splits an RNG seed into num new seeds by adding a leading axis.View aliases
tf.random.fixed_unigram_candidate_sampler,"tf.random.fixed_unigram_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    vocab_file='',
    distortion=1.0,
    num_reserved_ids=0,
    num_shards=1,
    shard=0,
    unigrams=(),
    seed=None,
    name=None
)
",Samples a set of classes using the provided (fixed) base distribution.View aliases
tf.random.gamma,"tf.random.gamma(
    shape,
    alpha,
    beta=None,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Draws shape samples from each of the given Gamma distribution(s).View aliases
tf.compat.v1.get_seed,"tf.compat.v1.get_seed(
    op_seed
)
",Returns the local seeds an operation should use given an op-specific seed.View aliases
tf.random.learned_unigram_candidate_sampler,"tf.random.learned_unigram_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=None,
    name=None
)
",Samples a set of classes from a distribution learned during training.View aliases
tf.random.log_uniform_candidate_sampler,"tf.random.log_uniform_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=None,
    name=None
)
",Samples a set of classes using a log-uniform (Zipfian) base distribution.View aliases
tf.compat.v1.multinomial,"tf.compat.v1.multinomial(
    logits, num_samples, seed=None, name=None, output_dtype=None
)
",Draws samples from a multinomial distribution. (deprecated)View aliases
tf.random.normal,"tf.random.normal(
    shape,
    mean=0.0,
    stddev=1.0,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Outputs random values from a normal distribution.View aliases
tf.random.set_seed,tf.random.set_seed(5);,"Outputs random values from a normal distribution.View aliasestf.random.normal(    shape,    mean=0.0,    stddev=1.0,    dtype=Used in the notebooksExample that generates a new set of random values every time:"
tf.random.set_seed,tf.random.set_seed(5);,"Outputs random values from a normal distribution.View aliasestf.random.normal(    shape,    mean=0.0,    stddev=1.0,    dtype=Used in the notebooksExample that generates a new set of random values every time:tf.random.set_seed(5);tf.random.normal([4], 0, 1, tf.float32)<tf.Tensor: shape=(4,), dtype=float32, numpy=..., dtype=float32)>Example that outputs a reproducible result:"
tf.compat.v1.random_poisson,"tf.compat.v1.random_poisson(
    lam,
    shape,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Draws shape samples from each of the given Poisson distribution(s).View aliases
tf.random.set_global_generator,"tf.random.set_global_generator(
    generator
)
",Replaces the global generator with another Generator object.View aliases
tf.compat.v1.set_random_seed,"tf.compat.v1.set_random_seed(
    seed
)
",Sets the graph-level random seed for the default graph.View aliases
tf.random.shuffle,"tf.random.shuffle(
    value, seed=None, name=None
)
",Randomly shuffles a tensor along its first dimension.View aliases
tf.random.stateless_binomial,"tf.random.stateless_binomial(
    shape,
    seed,
    counts,
    probs,
    output_dtype=tf.dtypes.int32,
    name=None
)
",Outputs deterministic pseudorandom values from a binomial distribution.View aliases
tf.random.stateless_categorical,"tf.random.stateless_categorical(
    logits,
    num_samples,
    seed,
    dtype=tf.dtypes.int64,
    name=None
)
",Draws deterministic pseudorandom samples from a categorical distribution.View aliases
tf.random.stateless_gamma,"tf.random.stateless_gamma(
    shape,
    seed,
    alpha,
    beta=None,
    dtype=tf.dtypes.float32,
    name=None
)
",Outputs deterministic pseudorandom values from a gamma distribution.View aliases
tf.compat.v1.random.stateless_multinomial,"tf.compat.v1.random.stateless_multinomial(
    logits,
    num_samples,
    seed,
    output_dtype=tf.dtypes.int64,
    name=None
)
",Draws deterministic pseudorandom samples from a multinomial distribution. (deprecated)
tf.random.stateless_normal,"tf.random.stateless_normal(
    shape,
    seed,
    mean=0.0,
    stddev=1.0,
    dtype=tf.dtypes.float32,
    name=None,
    alg='auto_select'
)
",Outputs deterministic pseudorandom values from a normal distribution.View aliases
tf.random.stateless_parameterized_truncated_normal,"tf.random.stateless_parameterized_truncated_normal(
    shape, seed, means=0.0, stddevs=1.0, minvals=-2.0, maxvals=2.0, name=None
)
",Outputs random values from a truncated normal distribution.View aliases
tf.random.stateless_poisson,"tf.random.stateless_poisson(
    shape,
    seed,
    lam,
    dtype=tf.dtypes.int32,
    name=None
)
",Outputs deterministic pseudorandom values from a Poisson distribution.View aliases
tf.random.stateless_truncated_normal,"tf.random.stateless_truncated_normal(
    shape,
    seed,
    mean=0.0,
    stddev=1.0,
    dtype=tf.dtypes.float32,
    name=None,
    alg='auto_select'
)
","Outputs deterministic pseudorandom values, truncated normally distributed.View aliases"
tf.random.stateless_uniform,"tf.random.stateless_uniform(
    shape,
    seed,
    minval=0,
    maxval=None,
    dtype=tf.dtypes.float32,
    name=None,
    alg='auto_select'
)
",Outputs deterministic pseudorandom values from a uniform distribution.View aliases
tf.random.truncated_normal,"tf.random.truncated_normal(
    shape,
    mean=0.0,
    stddev=1.0,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Outputs random values from a truncated normal distribution.View aliases
tf.random.uniform,"tf.random.uniform(
    shape,
    minval=0,
    maxval=None,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Outputs random values from a uniform distribution.View aliases
tf.random.uniform_candidate_sampler,"tf.random.uniform_candidate_sampler(
    true_classes,
    num_true,
    num_sampled,
    unique,
    range_max,
    seed=None,
    name=None
)
",Samples a set of classes using a uniform base distribution.View aliases
tf.image.random_crop,"tf.image.random_crop(
    value, size, seed=None, name=None
)
",Randomly crops a tensor to a given size.View aliases
tf.random.gamma,"tf.random.gamma(
    shape,
    alpha,
    beta=None,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Draws shape samples from each of the given Gamma distribution(s).View aliases
tf.random_index_shuffle,"tf.random_index_shuffle(
    index, seed, max_index, name=None
)
","Outputs the position of value in a permutation of [0, ..., max_index].View aliases"
tf.random.normal,"tf.random.normal(
    shape,
    mean=0.0,
    stddev=1.0,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Outputs random values from a normal distribution.View aliases
tf.random.set_seed,tf.random.set_seed(5);,"Outputs random values from a normal distribution.View aliasestf.random.normal(    shape,    mean=0.0,    stddev=1.0,    dtype=Used in the notebooksExample that generates a new set of random values every time:"
tf.random.set_seed,tf.random.set_seed(5);,"Outputs random values from a normal distribution.View aliasestf.random.normal(    shape,    mean=0.0,    stddev=1.0,    dtype=Used in the notebooksExample that generates a new set of random values every time:tf.random.set_seed(5);tf.random.normal([4], 0, 1, tf.float32)<tf.Tensor: shape=(4,), dtype=float32, numpy=..., dtype=float32)>Example that outputs a reproducible result:"
tf.compat.v1.random_normal_initializer,"tf.compat.v1.random_normal_initializer(
    mean=0.0,
    stddev=1.0,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors with a normal distribution.View aliases
tf.compat.v1.random_poisson,"tf.compat.v1.random_poisson(
    lam,
    shape,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Draws shape samples from each of the given Poisson distribution(s).View aliases
tf.random.shuffle,"tf.random.shuffle(
    value, seed=None, name=None
)
",Randomly shuffles a tensor along its first dimension.View aliases
tf.random.uniform,"tf.random.uniform(
    shape,
    minval=0,
    maxval=None,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Outputs random values from a uniform distribution.View aliases
tf.compat.v1.random_uniform_initializer,"tf.compat.v1.random_uniform_initializer(
    minval=0.0,
    maxval=None,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors with a uniform distribution.View aliases
tf.rank,"tf.rank(
    input, name=None
)
",Returns the rank of a tensor.View aliases
tf.io.read_file,"tf.io.read_file(
    filename, name=None
)
",Reads the contents of file.View aliases
tf.math.real,"tf.math.real(
    input, name=None
)
",Returns the real part of a complex (or real) tensor.View aliases
tf.realdiv,"tf.realdiv(
    x, y, name=None
)
",Returns x / y element-wise for real types.View aliases
tf.math.reciprocal,"tf.math.reciprocal(
    x, name=None
)
",Computes the reciprocal of x element-wise.View aliases
tf.recompute_grad,"tf.recompute_grad(
    f
)
",Defines a function as a recompute-checkpoint for the tape auto-diff.View aliases
tf.compat.v1.reduce_all,"tf.compat.v1.reduce_all(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes tf.math.logical_and of elements across dimensions of a tensor. (deprecated arguments)View aliases
tf.compat.v1.reduce_any,"tf.compat.v1.reduce_any(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes tf.math.logical_or of elements across dimensions of a tensor. (deprecated arguments)View aliases
tf.compat.v1.reduce_join,"tf.compat.v1.reduce_join(
    inputs,
    axis=None,
    keep_dims=None,
    separator='',
    name=None,
    reduction_indices=None,
    keepdims=None
)
","Joins all strings into a single string, or joins along an axis.View aliases"
tf.strings.reduce_join,"tf.strings.reduce_join([['abc','123'],","Joins all strings into a single string, or joins along an axis.View aliasestf.compat.v1.reduce_join(    inputs,    axis=None,    keep_dims=None,    separator='',    name=None,    reduction_indices=None,    keepdims=None)This is the reduction operation for the elementwise tf.strings.join op."
tf.compat.v1.reduce_logsumexp,"tf.compat.v1.reduce_logsumexp(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes log(sum(exp(elements across dimensions of a tensor))). (deprecated arguments)View aliases
tf.compat.v1.reduce_max,"tf.compat.v1.reduce_max(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes tf.math.maximum of elements across dimensions of a tensor. (deprecated arguments)View aliases
tf.compat.v1.reduce_mean,"tf.compat.v1.reduce_mean(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes the mean of elements across dimensions of a tensor.View aliases
tf.compat.v1.reduce_min,"tf.compat.v1.reduce_min(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes the tf.math.minimum of elements across dimensions of a tensor. (deprecated arguments)View aliases
tf.compat.v1.reduce_prod,"tf.compat.v1.reduce_prod(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes tf.math.multiply of elements across dimensions of a tensor. (deprecated arguments)View aliases
tf.compat.v1.reduce_sum,"tf.compat.v1.reduce_sum(
    input_tensor,
    axis=None,
    keepdims=None,
    name=None,
    reduction_indices=None,
    keep_dims=None
)
",Computes the sum of elements across dimensions of a tensor. (deprecated arguments)View aliases
tf.strings.regex_replace,"tf.strings.regex_replace(
    input, pattern, rewrite, replace_global=True, name=None
)
",Replace elements of input matching regex pattern with rewrite.View aliases
tf.strings.regex_replace,"tf.strings.regex_replace(""Text with tags.<br /><b>contains html</b>"",","Replace elements of input matching regex pattern with rewrite.View aliasestf.strings.regex_replace(    input, pattern, rewrite, replace_global=True, name=None)Used in the notebooks"
tf.register_tensor_conversion_function,"tf.register_tensor_conversion_function(
    base_type, conversion_func, priority=100
)
",Registers a function for converting objects of base_type to Tensor.View aliases
tf.repeat,"tf.repeat(
    input, repeats, axis=None, name=None
)
",Repeat elements of input.View aliases
tf.compat.v1.report_uninitialized_variables,"tf.compat.v1.report_uninitialized_variables(
    var_list=None, name='report_uninitialized_variables'
)
",Adds ops to list the names of uninitialized variables.
tf.required_space_to_batch_paddings,"tf.required_space_to_batch_paddings(
    input_shape, block_shape, base_paddings=None, name=None
)
",Calculate padding required to make block_shape divide input_shape.View aliases
tf.reshape,"tf.reshape(
    tensor, shape, name=None
)
",Reshapes a tensor.View aliases
tf.compat.v1.resource_loader.get_path_to_datafile,"tf.compat.v1.resource_loader.get_path_to_datafile(
    path
)
",Get the path to the specified file in the data dependencies.
tf.compat.v1.resource_loader.load_resource,"tf.compat.v1.resource_loader.load_resource(
    path
)
","Load the resource at given path, where path is relative to tensorflow/."
tf.compat.v1.resource_loader.readahead_file_path,"tf.compat.v1.resource_loader.readahead_file_path(
    path, readahead='128M'
)
",Readahead files not implemented; simply returns given path.
tf.reverse,"tf.reverse(
    tensor, axis, name=None
)
",Reverses specific dimensions of a tensor.View aliases
tf.compat.v1.reverse_sequence,"tf.compat.v1.reverse_sequence(
    input,
    seq_lengths,
    seq_axis=None,
    batch_axis=None,
    name=None,
    seq_dim=None,
    batch_dim=None
)
",Reverses variable length slices. (deprecated arguments) (deprecated arguments)
tf.reverse,"tf.reverse(
    tensor, axis, name=None
)
",Reverses specific dimensions of a tensor.View aliases
tf.math.rint,"tf.math.rint(
    x, name=None
)
",Returns element-wise integer closest to x.View aliases
tf.roll,"tf.roll(
    input, shift, axis, name=None
)
",Rolls the elements of a tensor along an axis.View aliases
tf.math.round,"tf.math.round(
    x, name=None
)
","Rounds the values of a tensor to the nearest integer, element-wise.View aliases"
tf.math.rsqrt,"tf.math.rsqrt(
    x, name=None
)
",Computes reciprocal of square root of x element-wise.View aliases
tf.dtypes.saturate_cast,"tf.dtypes.saturate_cast(
    value, dtype, name=None
)
",Performs a safe saturating cast of value to dtype.View aliases
tf.saved_model.Asset,"tf.saved_model.Asset(
    path
)
",Represents a file asset to hermetically include in a SavedModel.View aliases
tf.compat.v1.saved_model.Builder,"tf.compat.v1.saved_model.Builder(
    export_dir
)
",Builds the SavedModel protocol buffer and saves variables and assets.View aliases
tf.saved_model.SaveOptions,"tf.saved_model.SaveOptions(
    namespace_whitelist=None,
    save_debug_info=False,
    function_aliases=None,
    experimental_io_device=None,
    experimental_variable_policy=None,
    experimental_custom_gradients=True
)
",Options for saving to SavedModel.View aliases
tf.compat.v1.saved_model.build_signature_def,"tf.compat.v1.saved_model.build_signature_def(
    inputs=None, outputs=None, method_name=None
)
",Utility function to build a SignatureDef protocol buffer.View aliases
tf.compat.v1.saved_model.build_tensor_info,"tf.compat.v1.saved_model.build_tensor_info(
    tensor
)
",Utility function to build TensorInfo proto from a Tensor. (deprecated)View aliases
tf.compat.v1.saved_model.Builder,"tf.compat.v1.saved_model.Builder(
    export_dir
)
",Builds the SavedModel protocol buffer and saves variables and assets.View aliases
tf.compat.v1.saved_model.classification_signature_def,"tf.compat.v1.saved_model.classification_signature_def(
    examples, classes, scores
)
",Creates classification signature from given examples and predictions.View aliases
tf.compat.v1.saved_model.contains_saved_model,"tf.compat.v1.saved_model.contains_saved_model(
    export_dir
)
",Checks whether the provided export directory could contain a SavedModel.View aliases
tf.saved_model.experimental.TrackableResource,"tf.saved_model.experimental.TrackableResource(
    device=''
)
",Holds a Tensor which a tf.function can capture.View aliases
tf.saved_model.save,"tf.saved_model.save(
    obj, export_dir, signatures=None, options=None
)
",Exports a tf.Module (and subclasses) obj to SavedModel format.View aliases
tf.compat.v1.saved_model.get_tensor_from_tensor_info,"tf.compat.v1.saved_model.get_tensor_from_tensor_info(
    tensor_info, graph=None, import_scope=None
)
",Returns the Tensor or CompositeTensor described by a TensorInfo proto. (deprecated)View aliases
tf.compat.v1.saved_model.is_valid_signature,"tf.compat.v1.saved_model.is_valid_signature(
    signature_def
)
",Determine whether a SignatureDef can be served by TensorFlow Serving.View aliases
tf.compat.v1.saved_model.load,"tf.compat.v1.saved_model.load(
    sess, tags, export_dir, import_scope=None, **saver_kwargs
)
",Loads the model from a SavedModel as specified by tags. (deprecated)View aliases
tf.saved_model.load,"tf.saved_model.load(
    export_dir, tags=None, options=None
)
",Load a SavedModel from export_dir.View aliases
tf.compat.v1.saved_model.load,"tf.compat.v1.saved_model.load(
    sess, tags, export_dir, import_scope=None, **saver_kwargs
)
",Loads the model from a SavedModel as specified by tags. (deprecated)View aliases
tf.compat.v1.saved_model.contains_saved_model,"tf.compat.v1.saved_model.contains_saved_model(
    export_dir
)
",Checks whether the provided export directory could contain a SavedModel.View aliases
tf.compat.v1.saved_model.main_op_with_restore,"tf.compat.v1.saved_model.main_op_with_restore(
    restore_op_name
)
","Returns a main op to init variables, tables and restore the graph. (deprecated)View aliases"
tf.compat.v1.saved_model.main_op_with_restore,"tf.compat.v1.saved_model.main_op_with_restore(
    restore_op_name
)
","Returns a main op to init variables, tables and restore the graph. (deprecated)View aliases"
tf.compat.v1.saved_model.contains_saved_model,"tf.compat.v1.saved_model.contains_saved_model(
    export_dir
)
",Checks whether the provided export directory could contain a SavedModel.View aliases
tf.compat.v1.saved_model.predict_signature_def,"tf.compat.v1.saved_model.predict_signature_def(
    inputs, outputs
)
",Creates prediction signature from given inputs and outputs.View aliases
tf.compat.v1.saved_model.regression_signature_def,"tf.compat.v1.saved_model.regression_signature_def(
    examples, predictions
)
",Creates regression signature from given examples and predictions.View aliases
tf.saved_model.save,"tf.saved_model.save(
    obj, export_dir, signatures=None, options=None
)
",Exports a tf.Module (and subclasses) obj to SavedModel format.View aliases
tf.compat.v1.saved_model.signature_def_utils.MethodNameUpdater,"tf.compat.v1.saved_model.signature_def_utils.MethodNameUpdater(
    export_dir
)
",Updates the method name(s) of the SavedModel stored in the given path.
tf.compat.v1.saved_model.build_signature_def,"tf.compat.v1.saved_model.build_signature_def(
    inputs=None, outputs=None, method_name=None
)
",Utility function to build a SignatureDef protocol buffer.View aliases
tf.compat.v1.saved_model.classification_signature_def,"tf.compat.v1.saved_model.classification_signature_def(
    examples, classes, scores
)
",Creates classification signature from given examples and predictions.View aliases
tf.compat.v1.saved_model.is_valid_signature,"tf.compat.v1.saved_model.is_valid_signature(
    signature_def
)
",Determine whether a SignatureDef can be served by TensorFlow Serving.View aliases
tf.compat.v1.saved_model.predict_signature_def,"tf.compat.v1.saved_model.predict_signature_def(
    inputs, outputs
)
",Creates prediction signature from given inputs and outputs.View aliases
tf.compat.v1.saved_model.regression_signature_def,"tf.compat.v1.saved_model.regression_signature_def(
    examples, predictions
)
",Creates regression signature from given examples and predictions.View aliases
tf.compat.v1.saved_model.simple_save,"tf.compat.v1.saved_model.simple_save(
    session, export_dir, inputs, outputs, legacy_init_op=None
)
",Convenience function to build a SavedModel suitable for serving. (deprecated)
tf.compat.v1.saved_model.build_tensor_info,"tf.compat.v1.saved_model.build_tensor_info(
    tensor
)
",Utility function to build TensorInfo proto from a Tensor. (deprecated)View aliases
tf.compat.v1.saved_model.get_tensor_from_tensor_info,"tf.compat.v1.saved_model.get_tensor_from_tensor_info(
    tensor_info, graph=None, import_scope=None
)
",Returns the Tensor or CompositeTensor described by a TensorInfo proto. (deprecated)View aliases
tf.compat.v1.scalar_mul,"tf.compat.v1.scalar_mul(
    scalar, x, name=None
)
",Multiplies a scalar times a Tensor or IndexedSlices object.View aliases
tf.compat.v1.scan,"tf.compat.v1.scan(
    fn,
    elems,
    initializer=None,
    parallel_iterations=10,
    back_prop=True,
    swap_memory=False,
    infer_shape=True,
    reverse=False,
    name=None
)
",scan on the list of tensors unpacked from elems on dimension 0.
tf.compat.v1.scatter_add,"tf.compat.v1.scatter_add(
    ref, indices, updates, use_locking=False, name=None
)
",Adds sparse updates to the variable referenced by resource.
tf.compat.v1.scatter_div,"tf.compat.v1.scatter_div(
    ref, indices, updates, use_locking=False, name=None
)
",Divides a variable reference by sparse updates.
tf.compat.v1.scatter_max,"tf.compat.v1.scatter_max(
    ref, indices, updates, use_locking=False, name=None
)
",Reduces sparse updates into a variable reference using the max operation.
tf.compat.v1.scatter_min,"tf.compat.v1.scatter_min(
    ref, indices, updates, use_locking=False, name=None
)
",Reduces sparse updates into a variable reference using the min operation.
tf.compat.v1.scatter_mul,"tf.compat.v1.scatter_mul(
    ref, indices, updates, use_locking=False, name=None
)
",Multiplies sparse updates into a variable reference.
tf.scatter_nd,"tf.scatter_nd(
    indices, updates, shape, name=None
)
",Scatters updates into a tensor of shape shape according to indices.View aliases
tf.compat.v1.scatter_nd_add,"tf.compat.v1.scatter_nd_add(
    ref, indices, updates, use_locking=False, name=None
)
",Applies sparse addition to individual values or slices in a Variable.
tf.compat.v1.scatter_nd_sub,"tf.compat.v1.scatter_nd_sub(
    ref, indices, updates, use_locking=False, name=None
)
",Applies sparse subtraction to individual values or slices in a Variable.
tf.compat.v1.scatter_nd_update,"tf.compat.v1.scatter_nd_update(
    ref, indices, updates, use_locking=True, name=None
)
",Applies sparse updates to individual values or slices in a Variable.
tf.compat.v1.scatter_sub,"tf.compat.v1.scatter_sub(
    ref, indices, updates, use_locking=False, name=None
)
",Subtracts sparse updates to a variable reference.
tf.compat.v1.scatter_update,"tf.compat.v1.scatter_update(
    ref, indices, updates, use_locking=True, name=None
)
",Applies sparse updates to a variable reference.
tf.searchsorted,"tf.searchsorted(
    sorted_sequence,
    values,
    side='left',
    out_type=tf.dtypes.int32,
    name=None
)
",Searches for where a value would go in a sorted sequence.View aliases
tf.math.segment_max,"tf.math.segment_max(
    data, segment_ids, name=None
)
",Computes the maximum along segments of a tensor.View aliases
tf.math.segment_mean,"tf.math.segment_mean(
    data, segment_ids, name=None
)
",Computes the mean along segments of a tensor.View aliases
tf.math.segment_min,"tf.math.segment_min(
    data, segment_ids, name=None
)
",Computes the minimum along segments of a tensor.View aliases
tf.math.segment_prod,"tf.math.segment_prod(
    data, segment_ids, name=None
)
",Computes the product along segments of a tensor.View aliases
tf.math.segment_sum,"tf.math.segment_sum(
    data, segment_ids, name=None
)
",Computes the sum along segments of a tensor.View aliases
tf.linalg.eigh,"tf.linalg.eigh(
    tensor, name=None
)
",Computes the eigen decomposition of a batch of self-adjoint matrices.View aliases
tf.linalg.eigvalsh,"tf.linalg.eigvalsh(
    tensor, name=None
)
",Computes the eigenvalues of one or more self-adjoint matrices.View aliases
tf.sequence_mask,"tf.sequence_mask(
    lengths,
    maxlen=None,
    dtype=tf.dtypes.bool,
    name=None
)
",Returns a mask tensor representing the first N positions of each cell.View aliases
tf.compat.v1.serialize_many_sparse,"tf.compat.v1.serialize_many_sparse(
    sp_input,
    name=None,
    out_type=tf.dtypes.string
)
","Serialize N-minibatch SparseTensor into an [N, 3] Tensor.View aliases"
tf.compat.v1.serialize_sparse,"tf.compat.v1.serialize_sparse(
    sp_input,
    name=None,
    out_type=tf.dtypes.string
)
",Serialize a SparseTensor into a 3-vector (1-D Tensor) object.View aliases
tf.io.serialize_tensor,"tf.io.serialize_tensor(
    tensor, name=None
)
",Transforms a Tensor into a serialized TensorProto proto.View aliases
tf.compat.v1.set_random_seed,"tf.compat.v1.set_random_seed(
    seed
)
",Sets the graph-level random seed for the default graph.View aliases
tf.compat.v1.setdiff1d,"tf.compat.v1.setdiff1d(
    x,
    y,
    index_dtype=tf.dtypes.int32,
    name=None
)
",Computes the difference between two lists of numbers or strings.
tf.sets.difference,"tf.sets.difference(
    a, b, aminusb=True, validate_indices=True
)
",Compute set difference of elements in last dimension of a and b.View aliases
tf.sets.intersection,"tf.sets.intersection(
    a, b, validate_indices=True
)
",Compute set intersection of elements in last dimension of a and b.View aliases
tf.sets.difference,"tf.sets.difference(
    a, b, aminusb=True, validate_indices=True
)
",Compute set difference of elements in last dimension of a and b.View aliases
tf.sets.intersection,"tf.sets.intersection(
    a, b, validate_indices=True
)
",Compute set intersection of elements in last dimension of a and b.View aliases
tf.sets.size,"tf.sets.size(
    a, validate_indices=True
)
",Compute number of unique elements along last dimension of a.View aliases
tf.sets.union,"tf.sets.union(
    a, b, validate_indices=True
)
",Compute set union of elements in last dimension of a and b.View aliases
tf.sets.size,"tf.sets.size(
    a, validate_indices=True
)
",Compute number of unique elements along last dimension of a.View aliases
tf.sets.union,"tf.sets.union(
    a, b, validate_indices=True
)
",Compute set union of elements in last dimension of a and b.View aliases
tf.compat.v1.shape,"tf.compat.v1.shape(
    input,
    name=None,
    out_type=tf.dtypes.int32
)
",Returns the shape of a tensor.
tf.shape_n,"tf.shape_n(
    input,
    out_type=tf.dtypes.int32,
    name=None
)
",Returns shape of tensors.View aliases
tf.math.sigmoid,"tf.math.sigmoid(
    x, name=None
)
",Computes sigmoid of x element-wise.View aliases
tf.math.sign,"tf.math.sign(
    x, name=None
)
",Returns an element-wise indication of the sign of a number.View aliases
tf.signal.dct,"tf.signal.dct(
    input, type=2, n=None, axis=-1, norm=None, name=None
)
",Computes the 1D Discrete Cosine Transform (DCT) of input.View aliases
tf.signal.fft,"tf.signal.fft(
    input, name=None
)
",Fast Fourier transform.View aliases
tf.signal.fft2d,"tf.signal.fft2d(
    input, name=None
)
",2D fast Fourier transform.View aliases
tf.signal.fft3d,"tf.signal.fft3d(
    input, name=None
)
",3D fast Fourier transform.View aliases
tf.signal.fftshift,"tf.signal.fftshift(
    x, axes=None, name=None
)
",Shift the zero-frequency component to the center of the spectrum.View aliases
tf.signal.frame,"tf.signal.frame(
    signal,
    frame_length,
    frame_step,
    pad_end=False,
    pad_value=0,
    axis=-1,
    name=None
)
",Expands signal's axis dimension into frames of frame_length.View aliases
tf.signal.hamming_window,"tf.signal.hamming_window(
    window_length,
    periodic=True,
    dtype=tf.dtypes.float32,
    name=None
)
",Generate a Hamming window.View aliases
tf.signal.hann_window,"tf.signal.hann_window(
    window_length,
    periodic=True,
    dtype=tf.dtypes.float32,
    name=None
)
",Generate a Hann window.View aliases
tf.signal.idct,"tf.signal.idct(
    input, type=2, n=None, axis=-1, norm=None, name=None
)
",Computes the 1D Inverse Discrete Cosine Transform (DCT) of input.View aliases
tf.signal.ifft,"tf.signal.ifft(
    input, name=None
)
",Inverse fast Fourier transform.View aliases
tf.signal.ifft2d,"tf.signal.ifft2d(
    input, name=None
)
",Inverse 2D fast Fourier transform.View aliases
tf.signal.ifft3d,"tf.signal.ifft3d(
    input, name=None
)
",Inverse 3D fast Fourier transform.View aliases
tf.signal.ifftshift,"tf.signal.ifftshift(
    x, axes=None, name=None
)
",The inverse of fftshift.View aliases
tf.signal.inverse_mdct,"tf.signal.inverse_mdct(
    mdcts,
    window_fn=tf.signal.vorbis_window,
    norm=None,
    name=None
)
",Computes the inverse modified DCT of mdcts.View aliases
tf.signal.inverse_stft,"tf.signal.inverse_stft(
    stfts,
    frame_length,
    frame_step,
    fft_length=None,
    window_fn=tf.signal.hann_window,
    name=None
)
",Computes the inverse Short-time Fourier Transform of stfts.View aliases
tf.signal.inverse_stft_window_fn,"tf.signal.inverse_stft_window_fn(
    frame_step,
    forward_window_fn=tf.signal.hann_window,
    name=None
)
",Generates a window function that can be used in inverse_stft.View aliases
tf.signal.irfft,"tf.signal.irfft(
    input_tensor, fft_length=None, name=None
)
",Inverse real-valued fast Fourier transform.View aliases
tf.signal.irfft2d,"tf.signal.irfft2d(
    input_tensor, fft_length=None, name=None
)
",Inverse 2D real-valued fast Fourier transform.View aliases
tf.signal.irfft3d,"tf.signal.irfft3d(
    input_tensor, fft_length=None, name=None
)
",Inverse 3D real-valued fast Fourier transform.View aliases
tf.signal.kaiser_bessel_derived_window,"tf.signal.kaiser_bessel_derived_window(
    window_length,
    beta=12.0,
    dtype=tf.dtypes.float32,
    name=None
)
",Generate a Kaiser Bessel derived window.View aliases
tf.signal.kaiser_window,"tf.signal.kaiser_window(
    window_length,
    beta=12.0,
    dtype=tf.dtypes.float32,
    name=None
)
",Generate a Kaiser window.View aliases
tf.signal.linear_to_mel_weight_matrix,"tf.signal.linear_to_mel_weight_matrix(
    num_mel_bins=20,
    num_spectrogram_bins=129,
    sample_rate=8000,
    lower_edge_hertz=125.0,
    upper_edge_hertz=3800.0,
    dtype=tf.dtypes.float32,
    name=None
)
",Returns a matrix to warp linear scale spectrograms to the mel scale.View aliases
tf.signal.mdct,"tf.signal.mdct(
    signals,
    frame_length,
    window_fn=tf.signal.vorbis_window,
    pad_end=False,
    norm=None,
    name=None
)
",Computes the Modified Discrete Cosine Transform of signals.View aliases
tf.signal.mfccs_from_log_mel_spectrograms,"tf.signal.mfccs_from_log_mel_spectrograms(
    log_mel_spectrograms, name=None
)
",Computes MFCCs of log_mel_spectrograms.View aliases
tf.signal.overlap_and_add,"tf.signal.overlap_and_add(
    signal, frame_step, name=None
)
",Reconstructs a signal from a framed representation.View aliases
tf.signal.rfft,"tf.signal.rfft(
    input_tensor, fft_length=None, name=None
)
",Real-valued fast Fourier transform.View aliases
tf.signal.rfft2d,"tf.signal.rfft2d(
    input_tensor, fft_length=None, name=None
)
",2D real-valued fast Fourier transform.View aliases
tf.signal.rfft3d,"tf.signal.rfft3d(
    input_tensor, fft_length=None, name=None
)
",3D real-valued fast Fourier transform.View aliases
tf.signal.stft,"tf.signal.stft(
    signals,
    frame_length,
    frame_step,
    fft_length=None,
    window_fn=tf.signal.hann_window,
    pad_end=False,
    name=None
)
",Computes the Short-time Fourier Transform of signals.View aliases
tf.signal.vorbis_window,"tf.signal.vorbis_window(
    window_length,
    dtype=tf.dtypes.float32,
    name=None
)
",Generate a Vorbis power complementary window.View aliases
tf.math.sin,"tf.math.sin(
    x, name=None
)
",Computes sine of x element-wise.View aliases
tf.math.sinh,"tf.math.sinh(
    x, name=None
)
",Computes hyperbolic sine of x element-wise.View aliases
tf.compat.v1.size,"tf.compat.v1.size(
    input,
    name=None,
    out_type=tf.dtypes.int32
)
",Returns the size of a tensor.
tf.slice,"tf.slice(
    input_, begin, size, name=None
)
",Extracts a slice from a tensor.View aliases
tf.sort,"tf.sort(
    values, axis=-1, direction='ASCENDING', name=None
)
",Sorts a tensor.View aliases
tf.compat.v1.space_to_batch,"tf.compat.v1.space_to_batch(
    input, paddings, block_size=None, name=None, block_shape=None
)
",SpaceToBatch for 4-D tensors of type T.View aliases
tf.space_to_batch_nd,"tf.space_to_batch_nd(
    input, block_shape, paddings, name=None
)
",SpaceToBatch for N-D tensors of type T.View aliases
tf.compat.v1.space_to_depth,"tf.compat.v1.space_to_depth(
    input, block_size, name=None, data_format='NHWC'
)
",SpaceToDepth for tensors of type T.View aliases
tf.compat.v1.SparseConditionalAccumulator,"tf.compat.v1.SparseConditionalAccumulator(
    dtype,
    shape=None,
    shared_name=None,
    name='sparse_conditional_accumulator',
    reduction_type='MEAN'
)
",A conditional accumulator for aggregating sparse gradients.Inherits From: ConditionalAccumulatorBaseView aliases
tf.sparse.SparseTensor,"tf.sparse.SparseTensor(
    indices, values, dense_shape
)
",Represents a sparse tensor.View aliases
tf.compat.v1.sparse_add,"tf.compat.v1.sparse_add(
    a, b, threshold=None, thresh=None
)
","Adds two tensors, at least one of each is a SparseTensor. (deprecated arguments)View aliases"
tf.sparse.bincount,"tf.sparse.bincount(
    values,
    weights=None,
    axis=0,
    minlength=None,
    maxlength=None,
    binary_output=False,
    name=None
)
",Count the number of times an integer value appears in a tensor.View aliases
tf.compat.v1.sparse_concat,"tf.compat.v1.sparse_concat(
    axis,
    sp_inputs,
    name=None,
    expand_nonconcat_dim=False,
    concat_dim=None,
    expand_nonconcat_dims=None
)
",Concatenates a list of SparseTensor along the specified dimension. (deprecated arguments)View aliases
tf.sparse.cross,"tf.sparse.cross(
    inputs, name=None, separator=None
)
",Generates sparse cross from a list of sparse and dense tensors.View aliases
tf.sparse.cross_hashed,"tf.sparse.cross_hashed(
    inputs, num_buckets=0, hash_key=None, name=None
)
",Generates hashed sparse cross from a list of sparse and dense tensors.View aliases
tf.sparse.expand_dims,"tf.sparse.expand_dims(
    sp_input, axis=None, name=None
)
",Returns a tensor with an length 1 axis inserted at index axis.View aliases
tf.sparse.eye,"tf.sparse.eye(
    num_rows,
    num_columns=None,
    dtype=tf.dtypes.float32,
    name=None
)
",Creates a two-dimensional sparse tensor with ones along the diagonal.View aliases
tf.sparse.fill_empty_rows,"tf.sparse.fill_empty_rows(
    sp_input, default_value, name=None
)
",Fills empty rows in the input 2-D SparseTensor with a default value.View aliases
tf.sparse.from_dense,"tf.sparse.from_dense(
    tensor, name=None
)
",Converts a dense tensor into a sparse tensor.View aliases
tf.sparse.mask,"tf.sparse.mask(
    a, mask_indices, name=None
)
",Masks elements of IndexedSlices.View aliases
tf.sparse.sparse_dense_matmul,"tf.sparse.sparse_dense_matmul(
    sp_a, b, adjoint_a=False, adjoint_b=False, name=None
)
","Multiply SparseTensor (or dense Matrix) (of rank 2) ""A"" by dense matrixView aliases"
tf.sparse.maximum,"tf.sparse.maximum(
    sp_a, sp_b, name=None
)
",Returns the element-wise max of two SparseTensors.View aliases
tf.compat.v1.sparse_merge,"tf.compat.v1.sparse_merge(
    sp_ids, sp_values, vocab_size, name=None, already_sorted=False
)
",Combines a batch of feature ids and values into a single SparseTensor. (deprecated)View aliases
tf.sparse.minimum,"tf.sparse.minimum(
    sp_a, sp_b, name=None
)
",Returns the element-wise min of two SparseTensors.View aliases
tf.compat.v1.sparse_placeholder,"tf.compat.v1.sparse_placeholder(
    dtype, shape=None, name=None
)
",Inserts a placeholder for a sparse tensor that will be always fed.View aliases
tf.compat.v1.sparse_reduce_max,"tf.compat.v1.sparse_reduce_max(
    sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None
)
",Computes tf.sparse.maximum of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)View aliases
tf.compat.v1.sparse_reduce_max_sparse,"tf.compat.v1.sparse_reduce_max_sparse(
    sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None
)
",Computes the max of elements across dimensions of a SparseTensor. (deprecated arguments)View aliases
tf.compat.v1.sparse_reduce_sum,"tf.compat.v1.sparse_reduce_sum(
    sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None
)
",Computes tf.sparse.add of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)View aliases
tf.compat.v1.sparse_reduce_sum_sparse,"tf.compat.v1.sparse_reduce_sum_sparse(
    sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None
)
",Computes the sum of elements across dimensions of a SparseTensor. (deprecated arguments)View aliases
tf.sparse.reorder,"tf.sparse.reorder(
    sp_input, name=None
)
","Reorders a SparseTensor into the canonical, row-major ordering.View aliases"
tf.sparse.reset_shape,"tf.sparse.reset_shape(
    sp_input, new_shape=None
)
",Resets the shape of a SparseTensor with indices and values unchanged.View aliases
tf.sparse.reshape,"tf.sparse.reshape(
    sp_input, shape, name=None
)
",Reshapes a SparseTensor to represent values in a new dense shape.View aliases
tf.sparse.retain,"tf.sparse.retain(
    sp_input, to_retain
)
",Retains specified non-empty values within a SparseTensor.View aliases
tf.compat.v1.sparse_segment_mean,"tf.compat.v1.sparse_segment_mean(
    data, indices, segment_ids, name=None, num_segments=None
)
",Computes the mean along sparse segments of a tensor.View aliases
tf.compat.v1.sparse_segment_sqrt_n,"tf.compat.v1.sparse_segment_sqrt_n(
    data, indices, segment_ids, name=None, num_segments=None
)
",Computes the sum along sparse segments of a tensor divided by the sqrt(N).View aliases
tf.compat.v1.sparse_segment_sum,"tf.compat.v1.sparse_segment_sum(
    data, indices, segment_ids, name=None, num_segments=None
)
",Computes the sum along sparse segments of a tensor.View aliases
tf.sparse.slice,"tf.sparse.slice(
    sp_input, start, size, name=None
)
",Slice a SparseTensor based on the start and size.View aliases
tf.sparse.softmax,"tf.sparse.softmax(
    sp_input, name=None
)
",Applies softmax to a batched N-D SparseTensor.View aliases
tf.sparse.sparse_dense_matmul,"tf.sparse.sparse_dense_matmul(
    sp_a, b, adjoint_a=False, adjoint_b=False, name=None
)
","Multiply SparseTensor (or dense Matrix) (of rank 2) ""A"" by dense matrixView aliases"
tf.compat.v1.sparse_split,"tf.compat.v1.sparse_split(
    keyword_required=KeywordRequired(),
    sp_input=None,
    num_split=None,
    axis=None,
    name=None,
    split_dim=None
)
",Split a SparseTensor into num_split tensors along axis. (deprecated arguments)View aliases
tf.sparse.to_dense,"tf.sparse.to_dense(
    sp_input, default_value=None, validate_indices=True, name=None
)
",Converts a SparseTensor into a dense tensor.View aliases
tf.sparse.to_indicator,"tf.sparse.to_indicator(
    sp_input, vocab_size, name=None
)
",Converts a SparseTensor of ids into a dense bool indicator tensor.View aliases
tf.sparse.transpose,"tf.sparse.transpose(
    sp_input, perm=None, name=None
)
",Transposes a SparseTensorView aliases
tf.compat.v1.sparse_add,"tf.compat.v1.sparse_add(
    a, b, threshold=None, thresh=None
)
","Adds two tensors, at least one of each is a SparseTensor. (deprecated arguments)View aliases"
tf.compat.v1.sparse_concat,"tf.compat.v1.sparse_concat(
    axis,
    sp_inputs,
    name=None,
    expand_nonconcat_dim=False,
    concat_dim=None,
    expand_nonconcat_dims=None
)
",Concatenates a list of SparseTensor along the specified dimension. (deprecated arguments)View aliases
tf.sparse.fill_empty_rows,"tf.sparse.fill_empty_rows(
    sp_input, default_value, name=None
)
",Fills empty rows in the input 2-D SparseTensor with a default value.View aliases
tf.sparse.mask,"tf.sparse.mask(
    a, mask_indices, name=None
)
",Masks elements of IndexedSlices.View aliases
tf.compat.v1.sparse_matmul,"tf.compat.v1.sparse_matmul(
    a,
    b,
    transpose_a=False,
    transpose_b=False,
    a_is_sparse=False,
    b_is_sparse=False,
    name=None
)
","Multiply matrix ""a"" by matrix ""b""."
tf.sparse.maximum,"tf.sparse.maximum(
    sp_a, sp_b, name=None
)
",Returns the element-wise max of two SparseTensors.View aliases
tf.compat.v1.sparse_merge,"tf.compat.v1.sparse_merge(
    sp_ids, sp_values, vocab_size, name=None, already_sorted=False
)
",Combines a batch of feature ids and values into a single SparseTensor. (deprecated)View aliases
tf.sparse.minimum,"tf.sparse.minimum(
    sp_a, sp_b, name=None
)
",Returns the element-wise min of two SparseTensors.View aliases
tf.compat.v1.sparse_placeholder,"tf.compat.v1.sparse_placeholder(
    dtype, shape=None, name=None
)
",Inserts a placeholder for a sparse tensor that will be always fed.View aliases
tf.compat.v1.sparse_reduce_max,"tf.compat.v1.sparse_reduce_max(
    sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None
)
",Computes tf.sparse.maximum of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)View aliases
tf.compat.v1.sparse_reduce_max_sparse,"tf.compat.v1.sparse_reduce_max_sparse(
    sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None
)
",Computes the max of elements across dimensions of a SparseTensor. (deprecated arguments)View aliases
tf.compat.v1.sparse_reduce_sum,"tf.compat.v1.sparse_reduce_sum(
    sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None
)
",Computes tf.sparse.add of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)View aliases
tf.compat.v1.sparse_reduce_sum_sparse,"tf.compat.v1.sparse_reduce_sum_sparse(
    sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None
)
",Computes the sum of elements across dimensions of a SparseTensor. (deprecated arguments)View aliases
tf.sparse.reorder,"tf.sparse.reorder(
    sp_input, name=None
)
","Reorders a SparseTensor into the canonical, row-major ordering.View aliases"
tf.sparse.reset_shape,"tf.sparse.reset_shape(
    sp_input, new_shape=None
)
",Resets the shape of a SparseTensor with indices and values unchanged.View aliases
tf.sparse.reshape,"tf.sparse.reshape(
    sp_input, shape, name=None
)
",Reshapes a SparseTensor to represent values in a new dense shape.View aliases
tf.sparse.retain,"tf.sparse.retain(
    sp_input, to_retain
)
",Retains specified non-empty values within a SparseTensor.View aliases
tf.compat.v1.sparse_segment_mean,"tf.compat.v1.sparse_segment_mean(
    data, indices, segment_ids, name=None, num_segments=None
)
",Computes the mean along sparse segments of a tensor.View aliases
tf.compat.v1.sparse_segment_sqrt_n,"tf.compat.v1.sparse_segment_sqrt_n(
    data, indices, segment_ids, name=None, num_segments=None
)
",Computes the sum along sparse segments of a tensor divided by the sqrt(N).View aliases
tf.compat.v1.sparse_segment_sum,"tf.compat.v1.sparse_segment_sum(
    data, indices, segment_ids, name=None, num_segments=None
)
",Computes the sum along sparse segments of a tensor.View aliases
tf.sparse.slice,"tf.sparse.slice(
    sp_input, start, size, name=None
)
",Slice a SparseTensor based on the start and size.View aliases
tf.sparse.softmax,"tf.sparse.softmax(
    sp_input, name=None
)
",Applies softmax to a batched N-D SparseTensor.View aliases
tf.compat.v1.sparse_split,"tf.compat.v1.sparse_split(
    keyword_required=KeywordRequired(),
    sp_input=None,
    num_split=None,
    axis=None,
    name=None,
    split_dim=None
)
",Split a SparseTensor into num_split tensors along axis. (deprecated arguments)View aliases
tf.sparse.sparse_dense_matmul,"tf.sparse.sparse_dense_matmul(
    sp_a, b, adjoint_a=False, adjoint_b=False, name=None
)
","Multiply SparseTensor (or dense Matrix) (of rank 2) ""A"" by dense matrixView aliases"
tf.sparse.to_dense,"tf.sparse.to_dense(
    sp_input, default_value=None, validate_indices=True, name=None
)
",Converts a SparseTensor into a dense tensor.View aliases
tf.compat.v1.sparse_to_dense,"tf.compat.v1.sparse_to_dense(
    sparse_indices,
    output_shape,
    sparse_values,
    default_value=0,
    validate_indices=True,
    name=None
)
",Converts a sparse representation into a dense tensor. (deprecated)
tf.sparse.to_indicator,"tf.sparse.to_indicator(
    sp_input, vocab_size, name=None
)
",Converts a SparseTensor of ids into a dense bool indicator tensor.View aliases
tf.sparse.transpose,"tf.sparse.transpose(
    sp_input, perm=None, name=None
)
",Transposes a SparseTensorView aliases
tf.signal.dct,"tf.signal.dct(
    input, type=2, n=None, axis=-1, norm=None, name=None
)
",Computes the 1D Discrete Cosine Transform (DCT) of input.View aliases
tf.signal.fft,"tf.signal.fft(
    input, name=None
)
",Fast Fourier transform.View aliases
tf.signal.fft2d,"tf.signal.fft2d(
    input, name=None
)
",2D fast Fourier transform.View aliases
tf.signal.fft3d,"tf.signal.fft3d(
    input, name=None
)
",3D fast Fourier transform.View aliases
tf.signal.idct,"tf.signal.idct(
    input, type=2, n=None, axis=-1, norm=None, name=None
)
",Computes the 1D Inverse Discrete Cosine Transform (DCT) of input.View aliases
tf.signal.ifft,"tf.signal.ifft(
    input, name=None
)
",Inverse fast Fourier transform.View aliases
tf.signal.ifft2d,"tf.signal.ifft2d(
    input, name=None
)
",Inverse 2D fast Fourier transform.View aliases
tf.signal.ifft3d,"tf.signal.ifft3d(
    input, name=None
)
",Inverse 3D fast Fourier transform.View aliases
tf.signal.irfft,"tf.signal.irfft(
    input_tensor, fft_length=None, name=None
)
",Inverse real-valued fast Fourier transform.View aliases
tf.signal.irfft2d,"tf.signal.irfft2d(
    input_tensor, fft_length=None, name=None
)
",Inverse 2D real-valued fast Fourier transform.View aliases
tf.signal.irfft3d,"tf.signal.irfft3d(
    input_tensor, fft_length=None, name=None
)
",Inverse 3D real-valued fast Fourier transform.View aliases
tf.signal.rfft,"tf.signal.rfft(
    input_tensor, fft_length=None, name=None
)
",Real-valued fast Fourier transform.View aliases
tf.signal.rfft2d,"tf.signal.rfft2d(
    input_tensor, fft_length=None, name=None
)
",2D real-valued fast Fourier transform.View aliases
tf.signal.rfft3d,"tf.signal.rfft3d(
    input_tensor, fft_length=None, name=None
)
",3D real-valued fast Fourier transform.View aliases
tf.split,"tf.split(
    value, num_or_size_splits, axis=0, num=None, name='split'
)
",Splits a tensor value into a list of sub tensors.View aliases
tf.math.sqrt,"tf.math.sqrt(
    x, name=None
)
",Computes element-wise square root of the input tensor.View aliases
tf.math.square,"tf.math.square(
    x, name=None
)
",Computes square of x element-wise.View aliases
tf.math.squared_difference,"tf.math.squared_difference(
    x, y, name=None
)
",Returns conj(x - y)(x - y) element-wise.View aliases
tf.compat.v1.squeeze,"tf.compat.v1.squeeze(
    input, axis=None, name=None, squeeze_dims=None
)
",Removes dimensions of size 1 from the shape of a tensor. (deprecated arguments)
tf.stack,"tf.stack(
    values, axis=0, name='stack'
)
",Stacks a list of rank-R tensors into one rank-(R+1) tensor.View aliases
tf.stop_gradient,"tf.stop_gradient(
    input, name=None
)
",Stops gradient computation.View aliases
tf.strided_slice,"tf.strided_slice(
    input_,
    begin,
    end,
    strides=None,
    begin_mask=0,
    end_mask=0,
    ellipsis_mask=0,
    new_axis_mask=0,
    shrink_axis_mask=0,
    var=None,
    name=None
)
",Extracts a strided slice of a tensor (generalized Python array indexing).View aliases
tf.strings.join,"tf.strings.join(
    inputs, separator='', name=None
)
",Perform element-wise concatenation of a list of string tensors.View aliases
tf.compat.v1.string_split,"tf.compat.v1.string_split(
    source,
    sep=None,
    skip_empty=True,
    delimiter=None,
    result_type='SparseTensor',
    name=None
)
",Split elements of source based on delimiter. (deprecated arguments)
tf.strings.strip,"tf.strings.strip(
    input, name=None
)
",Strip leading and trailing whitespaces from the Tensor.View aliases
tf.compat.v1.string_to_hash_bucket,"tf.compat.v1.string_to_hash_bucket(
    string_tensor=None, num_buckets=None, name=None, input=None
)
",Converts each string in the input Tensor to its hash mod by a number of buckets.View aliases
tf.strings.to_hash_bucket_fast,"tf.strings.to_hash_bucket_fast(
    input, num_buckets, name=None
)
",Converts each string in the input Tensor to its hash mod by a number of buckets.View aliases
tf.strings.to_hash_bucket_strong,"tf.strings.to_hash_bucket_strong(
    input, num_buckets, key, name=None
)
",Converts each string in the input Tensor to its hash mod by a number of buckets.View aliases
tf.compat.v1.string_to_number,"tf.compat.v1.string_to_number(
    string_tensor=None,
    out_type=tf.dtypes.float32,
    name=None,
    input=None
)
",Converts each string in the input Tensor to the specified numeric type.View aliases
tf.strings.as_string,"tf.strings.as_string(
    input,
    precision=-1,
    scientific=False,
    shortest=False,
    width=-1,
    fill='',
    name=None
)
",Converts each entry in the given tensor to strings.View aliases
tf.strings.bytes_split,"tf.strings.bytes_split(
    input, name=None
)
",Split string elements of input into bytes.View aliases
tf.strings.format,"tf.strings.format(
    template, inputs, placeholder='{}', summarize=3, name=None
)
",Formats a string template using a list of tensors.View aliases
tf.strings.join,"tf.strings.join(
    inputs, separator='', name=None
)
",Perform element-wise concatenation of a list of string tensors.View aliases
tf.compat.v1.strings.length,"tf.compat.v1.strings.length(
    input, name=None, unit='BYTE'
)
",Computes the length of each string given in the input tensor.
tf.strings.lower,"tf.strings.lower(
    input, encoding='', name=None
)
",Converts all uppercase characters into their respective lowercase replacements.View aliases
tf.strings.ngrams,"tf.strings.ngrams(
    data,
    ngram_width,
    separator=' ',
    pad_values=None,
    padding_width=None,
    preserve_short_sequences=False,
    name=None
)
",Create a tensor of n-grams based on data.View aliases
tf.compat.v1.reduce_join,"tf.compat.v1.reduce_join(
    inputs,
    axis=None,
    keep_dims=None,
    separator='',
    name=None,
    reduction_indices=None,
    keepdims=None
)
","Joins all strings into a single string, or joins along an axis.View aliases"
tf.strings.reduce_join,"tf.strings.reduce_join([['abc','123'],","Joins all strings into a single string, or joins along an axis.View aliasestf.compat.v1.reduce_join(    inputs,    axis=None,    keep_dims=None,    separator='',    name=None,    reduction_indices=None,    keepdims=None)This is the reduction operation for the elementwise tf.strings.join op."
tf.strings.regex_full_match,"tf.strings.regex_full_match(
    input, pattern, name=None
)
",Check if the input matches the regex pattern.View aliases
tf.strings.regex_replace,"tf.strings.regex_replace(
    input, pattern, rewrite, replace_global=True, name=None
)
",Replace elements of input matching regex pattern with rewrite.View aliases
tf.strings.regex_replace,"tf.strings.regex_replace(""Text with tags.<br /><b>contains html</b>"",","Replace elements of input matching regex pattern with rewrite.View aliasestf.strings.regex_replace(    input, pattern, rewrite, replace_global=True, name=None)Used in the notebooks"
tf.compat.v1.strings.split,"tf.compat.v1.strings.split(
    input=None,
    sep=None,
    maxsplit=-1,
    result_type='SparseTensor',
    source=None,
    name=None
)
",Split elements of input based on sep.
tf.strings.strip,"tf.strings.strip(
    input, name=None
)
",Strip leading and trailing whitespaces from the Tensor.View aliases
tf.compat.v1.strings.substr,"tf.compat.v1.strings.substr(
    input, pos, len, name=None, unit='BYTE'
)
",Return substrings from Tensor of strings.
tf.compat.v1.string_to_hash_bucket,"tf.compat.v1.string_to_hash_bucket(
    string_tensor=None, num_buckets=None, name=None, input=None
)
",Converts each string in the input Tensor to its hash mod by a number of buckets.View aliases
tf.strings.to_hash_bucket_fast,"tf.strings.to_hash_bucket_fast(
    input, num_buckets, name=None
)
",Converts each string in the input Tensor to its hash mod by a number of buckets.View aliases
tf.strings.to_hash_bucket_strong,"tf.strings.to_hash_bucket_strong(
    input, num_buckets, key, name=None
)
",Converts each string in the input Tensor to its hash mod by a number of buckets.View aliases
tf.compat.v1.string_to_number,"tf.compat.v1.string_to_number(
    string_tensor=None,
    out_type=tf.dtypes.float32,
    name=None,
    input=None
)
",Converts each string in the input Tensor to the specified numeric type.View aliases
tf.strings.unicode_decode,"tf.strings.unicode_decode(
    input,
    input_encoding,
    errors='replace',
    replacement_char=65533,
    replace_control_characters=False,
    name=None
)
",Decodes each string in input into a sequence of Unicode code points.View aliases
tf.strings.unicode_decode_with_offsets,"tf.strings.unicode_decode_with_offsets(
    input,
    input_encoding,
    errors='replace',
    replacement_char=65533,
    replace_control_characters=False,
    name=None
)
",Decodes each string into a sequence of code points with start offsets.View aliases
tf.strings.unicode_encode,"tf.strings.unicode_encode(
    input,
    output_encoding,
    errors='replace',
    replacement_char=65533,
    name=None
)
",Encodes each sequence of Unicode code points in input into a string.View aliases
tf.strings.unicode_script,"tf.strings.unicode_script(
    input, name=None
)
",Determine the script codes of a given tensor of Unicode integer code points.View aliases
tf.strings.unicode_split,"tf.strings.unicode_split(
    input,
    input_encoding,
    errors='replace',
    replacement_char=65533,
    name=None
)
",Splits each string in input into a sequence of Unicode code points.View aliases
tf.strings.unicode_split_with_offsets,"tf.strings.unicode_split_with_offsets(
    input,
    input_encoding,
    errors='replace',
    replacement_char=65533,
    name=None
)
",Splits each string into a sequence of code points with start offsets.View aliases
tf.strings.unicode_transcode,"tf.strings.unicode_transcode(
    input,
    input_encoding,
    output_encoding,
    errors='replace',
    replacement_char=65533,
    replace_control_characters=False,
    name=None
)
",Transcode the input text from a source encoding to a destination encoding.View aliases
tf.strings.unsorted_segment_join,"tf.strings.unsorted_segment_join(
    inputs, segment_ids, num_segments, separator='', name=None
)
",Joins the elements of inputs based on segment_ids.View aliases
tf.strings.upper,"tf.strings.upper(
    input, encoding='', name=None
)
",Converts all lowercase characters into their respective uppercase replacements.View aliases
tf.compat.v1.substr,"tf.compat.v1.substr(
    input, pos, len, name=None, unit='BYTE'
)
",Return substrings from Tensor of strings.
tf.math.subtract,"tf.math.subtract(
    x, y, name=None
)
",Returns x - y element-wise.View aliases
tf.compat.v1.summary.FileWriter,"tf.compat.v1.summary.FileWriter(
    logdir,
    graph=None,
    max_queue=10,
    flush_secs=120,
    graph_def=None,
    filename_suffix=None,
    session=None
)
",Writes Summary protocol buffers to event files.
tf.compat.v1.summary.audio,"tf.compat.v1.summary.audio(
    name, tensor, sample_rate, max_outputs=3, collections=None, family=None
)
",Outputs a Summary protocol buffer with audio.
tf.compat.v1.summary.get_summary_description,"tf.compat.v1.summary.get_summary_description(
    node_def
)
","Given a TensorSummary node_def, retrieve its SummaryDescription."
tf.compat.v1.summary.histogram,"tf.compat.v1.summary.histogram(
    name, values, collections=None, family=None
)
",Outputs a Summary protocol buffer with a histogram.
tf.compat.v1.summary.image,"tf.compat.v1.summary.image(
    name, tensor, max_outputs=3, collections=None, family=None
)
",Outputs a Summary protocol buffer with images.
tf.compat.v1.summary.initialize,"tf.compat.v1.summary.initialize(
    graph=None, session=None
)
",Initializes summary writing for graph execution mode.
tf.compat.v1.summary.merge,"tf.compat.v1.summary.merge(
    inputs, collections=None, name=None
)
",Merges summaries.
tf.compat.v1.summary.merge_all,"tf.compat.v1.summary.merge_all(
    key=_ops.GraphKeys.SUMMARIES, scope=None, name=None
)
",Merges all summaries collected in the default graph.
tf.compat.v1.summary.scalar,"tf.compat.v1.summary.scalar(
    name, tensor, collections=None, family=None
)
",Outputs a Summary protocol buffer containing a single scalar value.
tf.compat.v1.summary.tensor_summary,"tf.compat.v1.summary.tensor_summary(
    name,
    tensor,
    summary_description=None,
    collections=None,
    summary_metadata=None,
    family=None,
    display_name=None
)
",Outputs a Summary protocol buffer with a serialized tensor.proto.
tf.compat.v1.summary.text,"tf.compat.v1.summary.text(
    name, tensor, collections=None
)
",Summarizes textual data.
tf.linalg.svd,"tf.linalg.svd(
    tensor, full_matrices=False, compute_uv=True, name=None
)
",Computes the singular value decompositions of one or more matrices.View aliases
tf.switch_case,"tf.switch_case(
    branch_index, branch_fns, default=None, name='switch_case'
)
","Create a switch/case operation, i.e. an integer-indexed conditional.View aliases"
tf.compat.v1.tables_initializer,"tf.compat.v1.tables_initializer(
    name='init_all_tables'
)
",Returns an Op that initializes all tables of the default graph.View aliases
tf.math.tan,"tf.math.tan(
    x, name=None
)
",Computes tan of x element-wise.View aliases
tf.math.tanh,"tf.math.tanh(
    x, name=None
)
",Computes hyperbolic tangent of x element-wise.View aliases
tf.tensor_scatter_nd_add,"tf.tensor_scatter_nd_add(
    tensor, indices, updates, name=None
)
",Adds sparse updates to an existing tensor according to indices.View aliases
tf.tensor_scatter_nd_add,"tf.tensor_scatter_nd_add(
    tensor, indices, updates, name=None
)
",Adds sparse updates to an existing tensor according to indices.View aliases
tf.tensor_scatter_nd_max,"tf.tensor_scatter_nd_max(
    tensor, indices, updates, name=None
)
",Apply a sparse update to a tensor taking the element-wise maximum.View aliases
tf.tensor_scatter_nd_min,"tf.tensor_scatter_nd_min(
    tensor, indices, updates, name=None
)
",View aliases
tf.tensor_scatter_nd_sub,"tf.tensor_scatter_nd_sub(
    tensor, indices, updates, name=None
)
",Subtracts sparse updates from an existing tensor according to indices.View aliases
tf.tensor_scatter_nd_update,"tf.tensor_scatter_nd_update(
    tensor, indices, updates, name=None
)
",Scatter updates into an existing tensor according to indices.View aliases
tf.tensor_scatter_nd_sub,"tf.tensor_scatter_nd_sub(
    tensor, indices, updates, name=None
)
",Subtracts sparse updates from an existing tensor according to indices.View aliases
tf.tensor_scatter_nd_update,"tf.tensor_scatter_nd_update(
    tensor, indices, updates, name=None
)
",Scatter updates into an existing tensor according to indices.View aliases
tf.tensordot,"tf.tensordot(
    a, b, axes, name=None
)
",Tensor contraction of a and b along specified axes and outer product.View aliases
tf.test.TestCase,"tf.test.TestCase(
    methodName='runTest'
)
",Base class for tests that need to test TensorFlow.View aliases
tf.test.TestCase.failureException,"tf.test.TestCase.failureException(
    *args, **kwargs
)
",Assertion failed.View aliases
tf.compat.v1.test.assert_equal_graph_def,"tf.compat.v1.test.assert_equal_graph_def(
    actual, expected, checkpoint_v2=False, hash_table_shared_name=False
)
",Asserts that two GraphDefs are (mostly) the same.
tf.compat.v1.test.compute_gradient,"tf.compat.v1.test.compute_gradient(
    x,
    x_shape,
    y,
    y_shape,
    x_init_value=None,
    delta=0.001,
    init_targets=None,
    extra_feed_dict=None
)
",Computes and returns the theoretical and numerical Jacobian. (deprecated)
tf.compat.v1.test.compute_gradient_error,"tf.compat.v1.test.compute_gradient_error(
    x,
    x_shape,
    y,
    y_shape,
    x_init_value=None,
    delta=0.001,
    init_targets=None,
    extra_feed_dict=None
)
",Computes the gradient error. (deprecated)
tf.test.create_local_cluster,"tf.test.create_local_cluster(
    num_workers,
    num_ps,
    protocol='grpc',
    worker_config=None,
    ps_config=None
)
",Create and start local servers and return the associated Server objects.View aliases
tf.test.disable_with_predicate,"tf.test.disable_with_predicate(
    pred, skip_message
)
",Disables the test if pred is true.View aliases
tf.test.is_gpu_available,"tf.test.is_gpu_available(
    cuda_only=False, min_cuda_compute_capability=None
)
",Returns whether TensorFlow can access a GPU. (deprecated)View aliases
tf.test.main,"tf.test.main(
    argv=None
)
",Runs all unit tests.View aliases
tf.compat.v1.test.test_src_dir_path,"tf.compat.v1.test.test_src_dir_path(
    relative_path
)
",Creates an absolute test srcdir path given a relative path.
tf.test.with_eager_op_as_function,"tf.test.with_eager_op_as_function(
    cls=None, only_as_function=False
)
",Adds methods that call original methods with eager_op_as_function enabled.View aliases
tf.tile,"tf.tile(
    input, multiples, name=None
)
",Constructs a tensor by tiling a given tensor.View aliases
tf.timestamp,"tf.timestamp(
    name=None
)
",Provides the time since epoch in seconds.View aliases
tf.compat.v1.to_bfloat16,"tf.compat.v1.to_bfloat16(
    x, name='ToBFloat16'
)
",Casts a tensor to type bfloat16. (deprecated)
tf.compat.v1.to_complex128,"tf.compat.v1.to_complex128(
    x, name='ToComplex128'
)
",Casts a tensor to type complex128. (deprecated)
tf.compat.v1.to_complex64,"tf.compat.v1.to_complex64(
    x, name='ToComplex64'
)
",Casts a tensor to type complex64. (deprecated)
tf.compat.v1.to_double,"tf.compat.v1.to_double(
    x, name='ToDouble'
)
",Casts a tensor to type float64. (deprecated)
tf.compat.v1.to_float,"tf.compat.v1.to_float(
    x, name='ToFloat'
)
",Casts a tensor to type float32. (deprecated)
tf.compat.v1.to_int32,"tf.compat.v1.to_int32(
    x, name='ToInt32'
)
",Casts a tensor to type int32. (deprecated)
tf.compat.v1.to_int64,"tf.compat.v1.to_int64(
    x, name='ToInt64'
)
",Casts a tensor to type int64. (deprecated)
tf.compat.v1.tpu.CrossShardOptimizer,"tf.compat.v1.tpu.CrossShardOptimizer(
    opt,
    reduction=losses.Reduction.MEAN,
    name='CrossShardOptimizer',
    group_assignment=None
)
",An optimizer that averages gradients across TPU shards.Inherits From: Optimizer
tf.tpu.XLAOptions,"tf.tpu.XLAOptions(
    use_spmd_for_xla_partitioning=True, enable_xla_dynamic_padder=True
)
",XLA compilation options.View aliases
tf.compat.v1.tpu.batch_parallel,"tf.compat.v1.tpu.batch_parallel(
    computation: Callable[..., Any],
    inputs: Optional[List[List[Optional[core_types.Tensor]]]] = None,
    num_shards: int = 1,
    infeed_queue: Optional[tpu_feed.InfeedQueue] = None,
    device_assignment: Optional[tf.tpu.experimental.DeviceAssignment] = None,
    name: Optional[Text] = None,
    xla_options: Optional[tf.tpu.XLAOptions] = None
)
",Shards computation along the batch dimension for parallel execution.
tf.compat.v1.tpu.core,"tf.compat.v1.tpu.core(
    num: int
) -> Text
",Returns the device name for a core in a replicated TPU computation.
tf.compat.v1.tpu.cross_replica_sum,"tf.compat.v1.tpu.cross_replica_sum(
    x, group_assignment=None, name=None
)
",Sum the input tensor across replicas according to group_assignment.
tf.compat.v1.tpu.experimental.AdagradParameters,"tf.compat.v1.tpu.experimental.AdagradParameters(
    learning_rate: float,
    initial_accumulator: float = 0.1,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: Optional[bool] = None,
    clip_gradient_min: Optional[float] = None,
    clip_gradient_max: Optional[float] = None
)
",Optimization parameters for Adagrad with TPU embeddings.
tf.compat.v1.tpu.experimental.AdamParameters,"tf.compat.v1.tpu.experimental.AdamParameters(
    learning_rate: float,
    beta1: float = 0.9,
    beta2: float = 0.999,
    epsilon: float = 1e-08,
    lazy_adam: bool = True,
    sum_inside_sqrt: bool = True,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: Optional[bool] = None,
    clip_gradient_min: Optional[float] = None,
    clip_gradient_max: Optional[float] = None
)
",Optimization parameters for Adam with TPU embeddings.
tf.tpu.experimental.DeviceAssignment,"tf.tpu.experimental.DeviceAssignment(
    topology: tf.tpu.experimental.Topology,
    core_assignment: np.ndarray
)
",Mapping from logical cores in a computation to the physical TPU topology.View aliases
tf.compat.v1.tpu.experimental.FtrlParameters,"tf.compat.v1.tpu.experimental.FtrlParameters(
    learning_rate: float,
    learning_rate_power: float = -0.5,
    initial_accumulator_value: float = 0.1,
    l1_regularization_strength: float = 0.0,
    l2_regularization_strength: float = 0.0,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: Optional[bool] = None,
    multiply_linear_by_learning_rate: bool = False,
    beta: float = 0,
    allow_zero_accumulator: bool = False,
    clip_gradient_min: Optional[float] = None,
    clip_gradient_max: Optional[float] = None
)
",Optimization parameters for Ftrl with TPU embeddings.
tf.tpu.experimental.HardwareFeature,"tf.tpu.experimental.HardwareFeature(
    tpu_hardware_feature_proto
)
",class holds all the feature info about the TPU.View aliases
tf.compat.v1.tpu.experimental.StochasticGradientDescentParameters,"tf.compat.v1.tpu.experimental.StochasticGradientDescentParameters(
    learning_rate: float,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: Optional[bool] = None,
    clip_gradient_min: Optional[float] = None,
    clip_gradient_max: Optional[float] = None
)
",Optimization parameters for stochastic gradient descent for TPU embeddings.
tf.tpu.experimental.TPUSystemMetadata,"tf.tpu.experimental.TPUSystemMetadata(
    num_cores, num_hosts, num_of_cores_per_host, topology, devices
)
",Describes some metadata about the TPU system.View aliases
tf.tpu.experimental.Topology,"tf.tpu.experimental.Topology(
    serialized=None, mesh_shape=None, device_coordinates=None
)
",Describes a set of TPU devices.View aliases
tf.tpu.experimental.embedding.Adagrad,"tf.tpu.experimental.embedding.Adagrad(
    learning_rate: Union[float, Callable[[], float]] = 0.001,
    initial_accumulator_value: float = 0.1,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: bool = None,
    slot_variable_creation_fn: Optional[SlotVarCreationFnType] = None,
    clipvalue: Optional[ClipValueType] = None
)
",Optimization parameters for Adagrad with TPU embeddings.View aliases
tf.tpu.experimental.embedding.AdagradMomentum,"tf.tpu.experimental.embedding.AdagradMomentum(
    learning_rate: Union[float, Callable[[], float]] = 0.001,
    momentum: float = 0.0,
    use_nesterov: bool = False,
    exponent: float = 2,
    beta2: float = 1,
    epsilon: float = 1e-10,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: bool = None,
    slot_variable_creation_fn: Optional[SlotVarCreationFnType] = None,
    clipvalue: Optional[ClipValueType] = None
)
",Optimization parameters for Adagrad + Momentum with TPU embeddings.View aliases
tf.tpu.experimental.embedding.Adam,"tf.tpu.experimental.embedding.Adam(
    learning_rate: Union[float, Callable[[], float]] = 0.001,
    beta_1: float = 0.9,
    beta_2: float = 0.999,
    epsilon: float = 1e-07,
    lazy_adam: bool = True,
    sum_inside_sqrt: bool = True,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: bool = None,
    slot_variable_creation_fn: Optional[SlotVarCreationFnType] = None,
    clipvalue: Optional[ClipValueType] = None
)
",Optimization parameters for Adam with TPU embeddings.View aliases
tf.tpu.experimental.embedding.FTRL,"tf.tpu.experimental.embedding.FTRL(
    learning_rate: Union[float, Callable[[], float]] = 0.001,
    learning_rate_power: float = -0.5,
    l1_regularization_strength: float = 0.0,
    l2_regularization_strength: float = 0.0,
    beta: float = 0.0,
    initial_accumulator_value: float = 0.1,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: bool = None,
    slot_variable_creation_fn: Optional[SlotVarCreationFnType] = None,
    clipvalue: Optional[ClipValueType] = None,
    multiply_linear_by_learning_rate: bool = False,
    allow_zero_accumulator: bool = False
)
",Optimization parameters for FTRL with TPU embeddings.View aliases
tf.tpu.experimental.embedding.FeatureConfig,"tf.tpu.experimental.embedding.FeatureConfig(
    table: tf.tpu.experimental.embedding.TableConfig,
    max_sequence_length: int = 0,
    validate_weights_and_indices: bool = True,
    output_shape: Optional[Union[List[int], tf.TensorShape]] = None,
    name: Optional[Text] = None
)
",Configuration data for one embedding feature.View aliases
tf.tpu.experimental.embedding.SGD,"tf.tpu.experimental.embedding.SGD(
    learning_rate: Union[float, Callable[[], float]] = 0.01,
    use_gradient_accumulation: bool = True,
    clip_weight_min: Optional[float] = None,
    clip_weight_max: Optional[float] = None,
    weight_decay_factor: Optional[float] = None,
    multiply_weight_decay_factor_by_learning_rate: bool = None,
    clipvalue: Optional[ClipValueType] = None
)
",Optimization parameters for stochastic gradient descent for TPU embeddings.View aliases
tf.tpu.experimental.embedding.TPUEmbedding,"tf.tpu.experimental.embedding.TPUEmbedding(
    feature_config: Union[tf.tpu.experimental.embedding.FeatureConfig, Iterable],
    optimizer: Optional[tpu_embedding_v2_utils._Optimizer],
    pipeline_execution_with_tensor_core: bool = False
)
",The TPUEmbedding mid level API.View aliases
tf.tpu.experimental.embedding.TPUEmbeddingForServing,"tf.tpu.experimental.embedding.TPUEmbeddingForServing(
    feature_config: Union[tf.tpu.experimental.embedding.FeatureConfig, Iterable],
    optimizer: Optional[tpu_embedding_v2_utils._Optimizer]
)
",The TPUEmbedding mid level API running on CPU for serving.View aliases
tf.tpu.experimental.embedding.TPUEmbeddingV0,"tf.tpu.experimental.embedding.TPUEmbeddingV0(
    feature_config: Union[tf.tpu.experimental.embedding.FeatureConfig, Iterable],
    optimizer: Optional[tpu_embedding_v2_utils._Optimizer]
)
",The TPUEmbedding mid level API running on TPU without Embedding accelerator.View aliases
tf.tpu.experimental.embedding.TableConfig,"tf.tpu.experimental.embedding.TableConfig(
    vocabulary_size: int,
    dim: int,
    initializer: Optional[Callable[[Any], None]] = None,
    optimizer: Optional[_Optimizer] = None,
    combiner: Text = 'mean',
    name: Optional[Text] = None
)
",Configuration data for one embedding table.View aliases
tf.tpu.experimental.embedding.serving_embedding_lookup,"tf.tpu.experimental.embedding.serving_embedding_lookup(
    inputs: Any,
    weights: Optional[Any],
    tables: Dict[tf.tpu.experimental.embedding.TableConfig, tf.Variable],
    feature_config: Union[tf.tpu.experimental.embedding.FeatureConfig, Iterable]
) -> Any
",Apply standard lookup ops with tf.tpu.experimental.embedding configs.View aliases
tf.compat.v1.tpu.experimental.embedding_column,"tf.compat.v1.tpu.experimental.embedding_column(
    categorical_column,
    dimension,
    combiner='mean',
    initializer=None,
    max_sequence_length=0,
    learning_rate_fn=None,
    embedding_lookup_device=None,
    tensor_core_shape=None,
    use_safe_embedding_lookup=True
)
",TPU version of tf.compat.v1.feature_column.embedding_column.
tf.tpu.experimental.initialize_tpu_system,"tf.tpu.experimental.initialize_tpu_system(
    cluster_resolver=None
)
",Initialize the TPU devices.View aliases
tf.compat.v1.tpu.experimental.shared_embedding_columns,"tf.compat.v1.tpu.experimental.shared_embedding_columns(
    categorical_columns,
    dimension,
    combiner='mean',
    initializer=None,
    shared_embedding_collection_name=None,
    max_sequence_lengths=None,
    learning_rate_fn=None,
    embedding_lookup_device=None,
    tensor_core_shape=None,
    use_safe_embedding_lookup=True
)
",TPU version of tf.compat.v1.feature_column.shared_embedding_columns.
tf.tpu.experimental.shutdown_tpu_system,"tf.tpu.experimental.shutdown_tpu_system(
    cluster_resolver=None
)
",Shuts down the TPU devices.View aliases
tf.compat.v1.tpu.initialize_system,"tf.compat.v1.tpu.initialize_system(
    embedding_config: Optional[embedding_pb2.TPUEmbeddingConfiguration] = None,
    job: Optional[Text] = None,
    compilation_failure_closes_chips: bool = True,
    tpu_cancellation_closes_chips: Optional[bool] = None
) -> core_types.Tensor
",Initializes a distributed TPU system for use with TensorFlow.
tf.compat.v1.tpu.outside_compilation,"tf.compat.v1.tpu.outside_compilation(
    computation: Callable[..., Any], *args, **kwargs
) -> Any
",Builds part of a computation outside any current TPU replicate scope.
tf.compat.v1.tpu.replicate,"tf.compat.v1.tpu.replicate(
    computation: Callable[..., Any],
    inputs: Optional[List[List[core_types.Tensor]]] = None,
    infeed_queue: Optional[tpu_feed.InfeedQueue] = None,
    device_assignment: Optional[tf.tpu.experimental.DeviceAssignment] = None,
    name: Optional[Text] = None,
    maximum_shapes: Optional[Any] = None,
    padding_spec: Optional[tf.compat.v1.tpu.PaddingSpec] = None,
    xla_options: Optional[tf.tpu.XLAOptions] = None
) -> List[Any]
",Builds a graph operator that runs a replicated TPU computation.
tf.compat.v1.tpu.rewrite,"tf.compat.v1.tpu.rewrite(
    computation: Callable[..., Any],
    inputs: Optional[List[List[Optional[core_types.Tensor]]]] = None,
    infeed_queue: Optional[tpu_feed.InfeedQueue] = None,
    device_assignment: Optional[tf.tpu.experimental.DeviceAssignment] = None,
    name: Optional[Text] = None,
    xla_options: Optional[tf.tpu.XLAOptions] = None
) -> Any
",Rewrites computation for execution on a TPU system.
tf.compat.v1.tpu.shard,"tf.compat.v1.tpu.shard(
    computation: Callable[..., Any],
    inputs: Optional[List[core_types.Tensor]] = None,
    num_shards: int = 1,
    input_shard_axes: Optional[List[int]] = None,
    outputs_from_all_shards: Union[bool, List[bool]] = True,
    output_shard_axes: Optional[List[int]] = None,
    infeed_queue: Optional[tpu_feed.InfeedQueue] = None,
    device_assignment: Optional[tf.tpu.experimental.DeviceAssignment] = None,
    name: Optional[Text] = None,
    xla_options: Optional[tf.tpu.XLAOptions] = None
) -> List[core_types.Tensor]
",Shards computation for parallel execution.
tf.compat.v1.tpu.shutdown_system,"tf.compat.v1.tpu.shutdown_system(
    job: Optional[Text] = None
) -> tf.Operation
",Shuts down a running a distributed TPU system.
tf.linalg.trace,"tf.linalg.trace(
    x, name=None
)
",Compute the trace of a tensor x.View aliases
tf.compat.v1.train.AdadeltaOptimizer,"tf.compat.v1.train.AdadeltaOptimizer(
    learning_rate=0.001,
    rho=0.95,
    epsilon=1e-08,
    use_locking=False,
    name='Adadelta'
)
",Optimizer that implements the Adadelta algorithm.Inherits From: Optimizer
tf.compat.v1.train.AdagradDAOptimizer,"tf.compat.v1.train.AdagradDAOptimizer(
    learning_rate,
    global_step,
    initial_gradient_squared_accumulator_value=0.1,
    l1_regularization_strength=0.0,
    l2_regularization_strength=0.0,
    use_locking=False,
    name='AdagradDA'
)
",Adagrad Dual Averaging algorithm for sparse linear models.Inherits From: Optimizer
tf.compat.v1.train.AdagradOptimizer,"tf.compat.v1.train.AdagradOptimizer(
    learning_rate,
    initial_accumulator_value=0.1,
    use_locking=False,
    name='Adagrad'
)
",Optimizer that implements the Adagrad algorithm.Inherits From: Optimizer
tf.compat.v1.train.AdamOptimizer,"tf.compat.v1.train.AdamOptimizer(
    learning_rate=0.001,
    beta1=0.9,
    beta2=0.999,
    epsilon=1e-08,
    use_locking=False,
    name='Adam'
)
",Optimizer that implements the Adam algorithm.Inherits From: Optimizer
tf.io.parse_example,tf.io.parse_example(,"Used in tf.train.Example protos. Holds a list of byte-strings.View aliasesUsed in the notebooksAn Example proto is a representation of the following python type:Dict[str,     Union[List[bytes],           List[int64],           List[float]]]This proto implements the List[bytes] portion.from google.protobuf import text_formatexample = text_format.Parse('''  features {    feature {key: ""my_feature""             value {bytes_list {value: ['abc', '12345' ]} } }  }''',  tf.train.Example())example.features.feature['my_feature'].bytes_list.value[""abc"", ""12345""]Use tf.io.parse_example to extract tensors from a serialized Example proto:"
tf.compat.v1.train.Checkpoint,"tf.compat.v1.train.Checkpoint(
    **kwargs
)
","Groups trackable objects, saving and restoring them."
tf.train.CheckpointManager,"tf.train.CheckpointManager(
    checkpoint,
    directory,
    max_to_keep,
    keep_checkpoint_every_n_hours=None,
    checkpoint_name='ckpt',
    step_counter=None,
    checkpoint_interval=None,
    init_fn=None
)
",Manages multiple checkpoints by keeping some and deleting unneeded ones.View aliases
tf.train.CheckpointOptions,"tf.train.CheckpointOptions(
    experimental_io_device=None, experimental_enable_async_checkpoint=False
)
",Options for constructing a Checkpoint.View aliases
tf.estimator.CheckpointSaverHook,"tf.estimator.CheckpointSaverHook(
    checkpoint_dir,
    save_secs=None,
    save_steps=None,
    saver=None,
    checkpoint_basename='model.ckpt',
    scaffold=None,
    listeners=None,
    save_graph_def=True
)
",Saves checkpoints every N steps or seconds.Inherits From: SessionRunHookView aliases
tf.compat.v1.train.ChiefSessionCreator,"tf.compat.v1.train.ChiefSessionCreator(
    scaffold=None,
    master='',
    config=None,
    checkpoint_dir=None,
    checkpoint_filename_with_path=None
)
",Creates a tf.compat.v1.Session for a chief.Inherits From: SessionCreator
tf.train.ClusterSpec,"tf.train.ClusterSpec(
    cluster
)
","Represents a cluster as a set of ""tasks"", organized into ""jobs"".View aliases"
tf.train.Coordinator,"tf.train.Coordinator(
    clean_stop_exception_types=None
)
",A coordinator for threads.View aliases
tf.io.parse_example,tf.io.parse_example(,"An Example is a standard proto storing data for training and inference.View aliasesUsed in the notebooksAn Example proto is a representation of the following python type:Dict[str,     Union[List[bytes],           List[int64],           List[float]]]It contains a key-value store Example.features where each key (string) mapsto a tf.train.Feature message which contains a fixed-type list. This flexibleand compact format allows the storage of large amounts of typed data, butrequires that the data shape and use be determined by the configuration filesand parsers that are used to read and write this format (refer totf.io.parse_example for details).from google.protobuf import text_formatexample = text_format.Parse('''  features {    feature {key: ""my_feature""             value {int64_list {value: [1, 2, 3, 4]} } }  }''',  tf.train.Example())Use tf.io.parse_example to extract tensors from a serialized Example proto:"
tf.train.ExponentialMovingAverage,"tf.train.ExponentialMovingAverage(
    decay,
    num_updates=None,
    zero_debias=False,
    name='ExponentialMovingAverage'
)
",Maintains moving averages of variables by employing an exponential decay.View aliases
tf.io.parse_example,tf.io.parse_example(,"Used in tf.train.Example protos. Contains a list of values.View aliasesUsed in the notebooksAn Example proto is a representation of the following python type:Dict[str,     Union[List[bytes],           List[int64],           List[float]]]This proto implements the Union.The contained list can be one of three types:tf.train.BytesListtf.train.FloatListtf.train.Int64Listint_feature = tf.train.Feature(    int64_list=tf.train.Int64List(value=[1, 2, 3, 4]))float_feature = tf.train.Feature(    float_list=tf.train.FloatList(value=[1., 2., 3., 4.]))bytes_feature = tf.train.Feature(    bytes_list=tf.train.BytesList(value=[b""abc"", b""1234""]))example = tf.train.Example(    features=tf.train.Features(feature={        'my_ints': int_feature,        'my_floats': float_feature,        'my_bytes': bytes_feature,    }))Use tf.io.parse_example to extract tensors from a serialized Example proto:"
tf.io.parse_example,tf.io.parse_example(,"Used in tf.train.Example protos. Contains the mapping from keys to Feature.View aliasesUsed in the notebooksAn Example proto is a representation of the following python type:Dict[str,     Union[List[bytes],           List[int64],           List[float]]]This proto implements the Dict.int_feature = tf.train.Feature(    int64_list=tf.train.Int64List(value=[1, 2, 3, 4]))float_feature = tf.train.Feature(    float_list=tf.train.FloatList(value=[1., 2., 3., 4.]))bytes_feature = tf.train.Feature(    bytes_list=tf.train.BytesList(value=[b""abc"", b""1234""]))example = tf.train.Example(    features=tf.train.Features(feature={        'my_ints': int_feature,        'my_floats': float_feature,        'my_bytes': bytes_feature,    }))Use tf.io.parse_example to extract tensors from a serialized Example proto:"
tf.estimator.FeedFnHook,"tf.estimator.FeedFnHook(
    feed_fn
)
",Runs feed_fn and sets the feed_dict accordingly.Inherits From: SessionRunHookView aliases
tf.estimator.FinalOpsHook,"tf.estimator.FinalOpsHook(
    final_ops, final_ops_feed_dict=None
)
",A hook which evaluates Tensors at the end of a session.Inherits From: SessionRunHookView aliases
tf.io.parse_example,tf.io.parse_example(,"Used in tf.train.Example protos. Holds a list of floats.View aliasesUsed in the notebooksAn Example proto is a representation of the following python type:Dict[str,     Union[List[bytes],           List[int64],           List[float]]]This proto implements the List[float] portion.from google.protobuf import text_formatexample = text_format.Parse('''  features {    feature {key: ""my_feature""             value {float_list {value: [1., 2., 3., 4. ]} } }  }''',  tf.train.Example())example.features.feature['my_feature'].float_list.value[1.0, 2.0, 3.0, 4.0]Use tf.io.parse_example to extract tensors from a serialized Example proto:"
tf.compat.v1.train.FtrlOptimizer,"tf.compat.v1.train.FtrlOptimizer(
    learning_rate,
    learning_rate_power=-0.5,
    initial_accumulator_value=0.1,
    l1_regularization_strength=0.0,
    l2_regularization_strength=0.0,
    use_locking=False,
    name='Ftrl',
    accum_name=None,
    linear_name=None,
    l2_shrinkage_regularization_strength=0.0,
    beta=None
)
",Optimizer that implements the FTRL algorithm.Inherits From: Optimizer
tf.estimator.GlobalStepWaiterHook,"tf.estimator.GlobalStepWaiterHook(
    wait_until_step
)
",Delays execution until global step reaches wait_until_step.Inherits From: SessionRunHookView aliases
tf.compat.v1.train.GradientDescentOptimizer,"tf.compat.v1.train.GradientDescentOptimizer(
    learning_rate, use_locking=False, name='GradientDescent'
)
",Optimizer that implements the gradient descent algorithm.Inherits From: Optimizer
tf.io.parse_example,tf.io.parse_example(,"Used in tf.train.Example protos. Holds a list of Int64s.View aliasesUsed in the notebooksAn Example proto is a representation of the following python type:Dict[str,     Union[List[bytes],           List[int64],           List[float]]]This proto implements the List[int64] portion.from google.protobuf import text_formatexample = text_format.Parse('''  features {    feature {key: ""my_feature""             value {int64_list {value: [1, 2, 3, 4]} } }  }''',  tf.train.Example())example.features.feature['my_feature'].int64_list.value[1, 2, 3, 4]Use tf.io.parse_example to extract tensors from a serialized Example proto:"
tf.estimator.LoggingTensorHook,"tf.estimator.LoggingTensorHook(
    tensors, every_n_iter=None, every_n_secs=None, at_end=False, formatter=None
)
","Prints the given tensors every N local steps, every N seconds, or at end.Inherits From: SessionRunHookView aliases"
tf.compat.v1.train.LooperThread,"tf.compat.v1.train.LooperThread(
    coord, timer_interval_secs, target=None, args=None, kwargs=None
)
","A thread that runs code repeatedly, optionally on a timer."
tf.compat.v1.train.MomentumOptimizer,"tf.compat.v1.train.MomentumOptimizer(
    learning_rate,
    momentum,
    use_locking=False,
    name='Momentum',
    use_nesterov=False
)
",Optimizer that implements the Momentum algorithm.Inherits From: Optimizer
tf.compat.v1.train.MonitoredSession,"tf.compat.v1.train.MonitoredSession(
    session_creator=None, hooks=None, stop_grace_period_secs=120
)
","Session-like object that handles initialization, recovery and hooks."
tf.compat.v1.train.MonitoredSession.StepContext,"tf.compat.v1.train.MonitoredSession.StepContext(
    session, run_with_hooks_fn
)
",Control flow instrument for the step_fn from run_step_fn().View aliases
tf.compat.v1.train.MonitoredTrainingSession,"tf.compat.v1.train.MonitoredTrainingSession(
    master='',
    is_chief=True,
    checkpoint_dir=None,
    scaffold=None,
    hooks=None,
    chief_only_hooks=None,
    save_checkpoint_secs=USE_DEFAULT,
    save_summaries_steps=USE_DEFAULT,
    save_summaries_secs=USE_DEFAULT,
    config=None,
    stop_grace_period_secs=120,
    log_step_count_steps=100,
    max_wait_secs=7200,
    save_checkpoint_steps=USE_DEFAULT,
    summary_dir=None,
    save_graph_def=True
)
",Creates a MonitoredSession for training.
tf.estimator.NanLossDuringTrainingError,"tf.estimator.NanLossDuringTrainingError(
    *args, **kwargs
)
",Unspecified run-time error.View aliases
tf.estimator.NanTensorHook,"tf.estimator.NanTensorHook(
    loss_tensor, fail_on_nan_loss=True
)
",Monitors the loss tensor and stops training if loss is NaN.Inherits From: SessionRunHookView aliases
tf.compat.v1.train.NewCheckpointReader,"tf.compat.v1.train.NewCheckpointReader(
    filepattern
)
",A function that returns a CheckPointReader.
tf.compat.v1.train.Optimizer,"tf.compat.v1.train.Optimizer(
    use_locking, name
)
",Base class for optimizers.
tf.estimator.ProfilerHook,"tf.estimator.ProfilerHook(
    save_steps=None,
    save_secs=None,
    output_dir='',
    show_dataflow=True,
    show_memory=False
)
",Captures CPU/GPU profiling information every N steps or seconds.Inherits From: SessionRunHookView aliases
tf.compat.v1.train.ProximalAdagradOptimizer,"tf.compat.v1.train.ProximalAdagradOptimizer(
    learning_rate,
    initial_accumulator_value=0.1,
    l1_regularization_strength=0.0,
    l2_regularization_strength=0.0,
    use_locking=False,
    name='ProximalAdagrad'
)
",Optimizer that implements the Proximal Adagrad algorithm.Inherits From: Optimizer
tf.compat.v1.train.ProximalGradientDescentOptimizer,"tf.compat.v1.train.ProximalGradientDescentOptimizer(
    learning_rate,
    l1_regularization_strength=0.0,
    l2_regularization_strength=0.0,
    use_locking=False,
    name='ProximalGradientDescent'
)
",Optimizer that implements the proximal gradient descent algorithm.Inherits From: Optimizer
tf.compat.v1.train.QueueRunner,"tf.compat.v1.train.QueueRunner(
    queue=None,
    enqueue_ops=None,
    close_op=None,
    cancel_op=None,
    queue_closed_exception_types=None,
    queue_runner_def=None,
    import_scope=None
)
","Holds a list of enqueue operations for a queue, each to be run in a thread.View aliases"
tf.compat.v1.train.RMSPropOptimizer,"tf.compat.v1.train.RMSPropOptimizer(
    learning_rate,
    decay=0.9,
    momentum=0.0,
    epsilon=1e-10,
    use_locking=False,
    centered=False,
    name='RMSProp'
)
",Optimizer that implements the RMSProp algorithm (Tielemans et al.Inherits From: Optimizer
tf.compat.v1.train.Saver,"tf.compat.v1.train.Saver(
    var_list=None,
    reshape=False,
    sharded=False,
    max_to_keep=5,
    keep_checkpoint_every_n_hours=10000.0,
    name=None,
    restore_sequentially=False,
    saver_def=None,
    builder=None,
    defer_build=False,
    allow_empty=False,
    write_version=saver_pb2.SaverDef.V2,
    pad_step_number=False,
    save_relative_paths=False,
    filename=None
)
",Saves and restores variables.
tf.compat.v1.train.Scaffold,"tf.compat.v1.train.Scaffold(
    init_op=None,
    init_feed_dict=None,
    init_fn=None,
    ready_op=None,
    ready_for_local_init_op=None,
    local_init_op=None,
    summary_op=None,
    saver=None,
    copy_from_scaffold=None,
    local_init_feed_dict=None
)
",Structure to create or gather pieces commonly needed to train a model.
tf.estimator.SecondOrStepTimer,"tf.estimator.SecondOrStepTimer(
    every_secs=None, every_steps=None
)
",Timer that triggers at most once every N seconds or once every N steps.View aliases
tf.distribute.Server,"tf.distribute.Server(
    server_or_cluster_def,
    job_name=None,
    task_index=None,
    protocol=None,
    config=None,
    start=True
)
","An in-process TensorFlow server, for use in distributed training.View aliases"
tf.compat.v1.train.SessionManager,"tf.compat.v1.train.SessionManager(
    local_init_op=None,
    ready_op=None,
    ready_for_local_init_op=None,
    graph=None,
    recovery_wait_secs=30,
    local_init_run_options=None,
    local_init_feed_dict=None
)
",Training helper that restores from checkpoint and creates session.
tf.estimator.SessionRunArgs,"tf.estimator.SessionRunArgs(
    fetches, feed_dict=None, options=None
)
",Represents arguments to be added to a Session.run() call.View aliases
tf.estimator.SessionRunContext,"tf.estimator.SessionRunContext(
    original_args, session
)
",Provides information about the session.run() call being made.View aliases
tf.estimator.SessionRunValues,"tf.estimator.SessionRunValues(
    results, options, run_metadata
)
",Contains the results of Session.run().View aliases
tf.compat.v1.train.SingularMonitoredSession,"tf.compat.v1.train.SingularMonitoredSession(
    hooks=None,
    scaffold=None,
    master='',
    config=None,
    checkpoint_dir=None,
    stop_grace_period_secs=120,
    checkpoint_filename_with_path=None
)
","Session-like object that handles initialization, restoring, and hooks."
tf.compat.v1.train.MonitoredSession.StepContext,"tf.compat.v1.train.MonitoredSession.StepContext(
    session, run_with_hooks_fn
)
",Control flow instrument for the step_fn from run_step_fn().View aliases
tf.estimator.StepCounterHook,"tf.estimator.StepCounterHook(
    every_n_steps=100, every_n_secs=None, output_dir=None, summary_writer=None
)
",Hook that counts steps per second.Inherits From: SessionRunHookView aliases
tf.estimator.StopAtStepHook,"tf.estimator.StopAtStepHook(
    num_steps=None, last_step=None
)
",Hook that requests stop at a specified step.Inherits From: SessionRunHookView aliases
tf.estimator.SummarySaverHook,"tf.estimator.SummarySaverHook(
    save_steps=None,
    save_secs=None,
    output_dir=None,
    summary_writer=None,
    scaffold=None,
    summary_op=None
)
",Saves summaries every N steps.Inherits From: SessionRunHookView aliases
tf.compat.v1.train.Supervisor,"tf.compat.v1.train.Supervisor(
    graph=None,
    ready_op=USE_DEFAULT,
    ready_for_local_init_op=USE_DEFAULT,
    is_chief=True,
    init_op=USE_DEFAULT,
    init_feed_dict=None,
    local_init_op=USE_DEFAULT,
    logdir=None,
    summary_op=USE_DEFAULT,
    saver=USE_DEFAULT,
    global_step=USE_DEFAULT,
    save_summaries_secs=120,
    save_model_secs=600,
    recovery_wait_secs=30,
    stop_grace_secs=120,
    checkpoint_basename='model.ckpt',
    session_manager=None,
    summary_writer=USE_DEFAULT,
    init_fn=None,
    local_init_run_options=None
)
",A training helper that checkpoints models and computes summaries.
tf.compat.v1.train.SyncReplicasOptimizer,"tf.compat.v1.train.SyncReplicasOptimizer(
    opt,
    replicas_to_aggregate,
    total_num_replicas=None,
    variable_averages=None,
    variables_to_average=None,
    use_locking=False,
    name='sync_replicas'
)
","Class to synchronize, aggregate gradients and pass them to the optimizer.Inherits From: Optimizer"
tf.estimator.VocabInfo,"tf.estimator.VocabInfo(
    new_vocab,
    new_vocab_size,
    num_oov_buckets,
    old_vocab,
    old_vocab_size=-1,
    backup_initializer=None,
    axis=0
)
",Vocabulary information for warm-starting.View aliases
tf.compat.v1.train.WorkerSessionCreator,"tf.compat.v1.train.WorkerSessionCreator(
    scaffold=None, master='', config=None, max_wait_secs=(30 * 60)
)
",Creates a tf.compat.v1.Session for a worker.Inherits From: SessionCreator
tf.compat.v1.train.add_queue_runner,"tf.compat.v1.train.add_queue_runner(
    qr, collection=ops.GraphKeys.QUEUE_RUNNERS
)
",Adds a QueueRunner to a collection in the graph. (deprecated)View aliases
tf.compat.v1.train.assert_global_step,"tf.compat.v1.train.assert_global_step(
    global_step_tensor
)
",Asserts global_step_tensor is a scalar int Variable or Tensor.
tf.compat.v1.train.basic_train_loop,"tf.compat.v1.train.basic_train_loop(
    supervisor, train_step_fn, args=None, kwargs=None, master=''
)
",Basic loop to train a model.
tf.compat.v1.train.batch,"tf.compat.v1.train.batch(
    tensors,
    batch_size,
    num_threads=1,
    capacity=32,
    enqueue_many=False,
    shapes=None,
    dynamic_pad=False,
    allow_smaller_final_batch=False,
    shared_name=None,
    name=None
)
",Creates batches of tensors in tensors. (deprecated)
tf.compat.v1.train.batch_join,"tf.compat.v1.train.batch_join(
    tensors_list,
    batch_size,
    capacity=32,
    enqueue_many=False,
    shapes=None,
    dynamic_pad=False,
    allow_smaller_final_batch=False,
    shared_name=None,
    name=None
)
",Runs a list of tensors to fill a queue to create batches of examples. (deprecated)
tf.compat.v1.train.checkpoint_exists,"tf.compat.v1.train.checkpoint_exists(
    checkpoint_prefix
)
",Checks whether a V1 or V2 checkpoint exists with the specified prefix. (deprecated)
tf.train.checkpoints_iterator,"tf.train.checkpoints_iterator(
    checkpoint_dir, min_interval_secs=0, timeout=None, timeout_fn=None
)
",Continuously yield new checkpoint files as they appear.View aliases
tf.compat.v1.train.cosine_decay,"tf.compat.v1.train.cosine_decay(
    learning_rate, global_step, decay_steps, alpha=0.0, name=None
)
",Applies cosine decay to the learning rate.
tf.compat.v1.train.cosine_decay_restarts,"tf.compat.v1.train.cosine_decay_restarts(
    learning_rate,
    global_step,
    first_decay_steps,
    t_mul=2.0,
    m_mul=1.0,
    alpha=0.0,
    name=None
)
",Applies cosine decay with restarts to the learning rate.
tf.compat.v1.train.create_global_step,"tf.compat.v1.train.create_global_step(
    graph=None
)
",Create global step tensor in graph.
tf.compat.v1.train.do_quantize_training_on_graphdef,"tf.compat.v1.train.do_quantize_training_on_graphdef(
    input_graph, num_bits
)
",A general quantization scheme is being developed in tf.contrib.quantize. (deprecated)
tf.compat.v1.mixed_precision.DynamicLossScale,"tf.compat.v1.mixed_precision.DynamicLossScale(
    initial_loss_scale=(2 ** 15), increment_period=2000, multiplier=2.0
)
",Loss scale that dynamically adjusts itself.Inherits From: LossScaleView aliases
tf.compat.v1.mixed_precision.FixedLossScale,"tf.compat.v1.mixed_precision.FixedLossScale(
    loss_scale_value
)
",Loss scale with a fixed value.Inherits From: LossScaleView aliases
tf.compat.v1.mixed_precision.MixedPrecisionLossScaleOptimizer,"tf.compat.v1.mixed_precision.MixedPrecisionLossScaleOptimizer(
    opt, loss_scale
)
",An optimizer that applies loss scaling.Inherits From: OptimizerView aliases
tf.compat.v1.mixed_precision.enable_mixed_precision_graph_rewrite,"tf.compat.v1.mixed_precision.enable_mixed_precision_graph_rewrite(
    opt, loss_scale='dynamic'
)
",Enable mixed precision via a graph rewrite.View aliases
tf.compat.v1.train.exponential_decay,"tf.compat.v1.train.exponential_decay(
    learning_rate,
    global_step,
    decay_steps,
    decay_rate,
    staircase=False,
    name=None
)
",Applies exponential decay to the learning rate.
tf.compat.v1.train.export_meta_graph,"tf.compat.v1.train.export_meta_graph(
    filename=None,
    meta_info_def=None,
    graph_def=None,
    saver_def=None,
    collection_list=None,
    as_text=False,
    graph=None,
    export_scope=None,
    clear_devices=False,
    clear_extraneous_savers=False,
    strip_default_attrs=False,
    save_debug_info=False,
    **kwargs
)
",Returns MetaGraphDef proto.
tf.compat.v1.train.generate_checkpoint_state_proto,"tf.compat.v1.train.generate_checkpoint_state_proto(
    save_dir,
    model_checkpoint_path,
    all_model_checkpoint_paths=None,
    all_model_checkpoint_timestamps=None,
    last_preserved_timestamp=None
)
",Generates a checkpoint state proto.
tf.compat.v1.train.get_checkpoint_mtimes,"tf.compat.v1.train.get_checkpoint_mtimes(
    checkpoint_prefixes
)
",Returns the mtimes (modification timestamps) of the checkpoints. (deprecated)
tf.train.get_checkpoint_state,"tf.train.get_checkpoint_state(
    checkpoint_dir, latest_filename=None
)
","Returns CheckpointState proto from the ""checkpoint"" file.View aliases"
tf.compat.v1.train.get_global_step,"tf.compat.v1.train.get_global_step(
    graph=None
)
",Get the global step tensor.
tf.compat.v1.train.get_or_create_global_step,"tf.compat.v1.train.get_or_create_global_step(
    graph=None
)
",Returns and create (if necessary) the global step tensor.
tf.compat.v1.train.global_step,"tf.compat.v1.train.global_step(
    sess, global_step_tensor
)
",Small helper to get the global step.
tf.compat.v1.train.import_meta_graph,"tf.compat.v1.train.import_meta_graph(
    meta_graph_or_file, clear_devices=False, import_scope=None, **kwargs
)
",Recreates a Graph saved in a MetaGraphDef proto.
tf.compat.v1.train.init_from_checkpoint,"tf.compat.v1.train.init_from_checkpoint(
    ckpt_dir_or_file, assignment_map
)
",Replaces tf.Variable initializers so they load from a checkpoint file.
tf.compat.v1.train.input_producer,"tf.compat.v1.train.input_producer(
    input_tensor,
    element_shape=None,
    num_epochs=None,
    shuffle=True,
    seed=None,
    capacity=32,
    shared_name=None,
    summary_name=None,
    name=None,
    cancel_op=None
)
",Output the rows of input_tensor to a queue for an input pipeline. (deprecated)
tf.compat.v1.train.inverse_time_decay,"tf.compat.v1.train.inverse_time_decay(
    learning_rate,
    global_step,
    decay_steps,
    decay_rate,
    staircase=False,
    name=None
)
",Applies inverse time decay to the initial learning rate.
tf.train.latest_checkpoint,"tf.train.latest_checkpoint(
    checkpoint_dir, latest_filename=None
)
",Finds the filename of latest saved checkpoint file.View aliases
tf.compat.v1.train.limit_epochs,"tf.compat.v1.train.limit_epochs(
    tensor, num_epochs=None, name=None
)
",Returns tensor num_epochs times and then raises an OutOfRange error. (deprecated)
tf.compat.v1.train.linear_cosine_decay,"tf.compat.v1.train.linear_cosine_decay(
    learning_rate,
    global_step,
    decay_steps,
    num_periods=0.5,
    alpha=0.0,
    beta=0.001,
    name=None
)
",Applies linear cosine decay to the learning rate.
tf.train.list_variables,"tf.train.list_variables(
    ckpt_dir_or_file
)
",Lists the checkpoint keys and shapes of variables in a checkpoint.View aliases
tf.train.load_checkpoint,"tf.train.load_checkpoint(
    ckpt_dir_or_file
)
",Returns CheckpointReader for checkpoint found in ckpt_dir_or_file.View aliases
tf.train.load_variable,"tf.train.load_variable(
    ckpt_dir_or_file, name
)
",Returns the tensor value of the given variable in the checkpoint.View aliases
tf.io.match_filenames_once,"tf.io.match_filenames_once(
    pattern, name=None
)
","Save the list of files matching pattern, so it is only computed once.View aliases"
tf.compat.v1.train.maybe_batch,"tf.compat.v1.train.maybe_batch(
    tensors,
    keep_input,
    batch_size,
    num_threads=1,
    capacity=32,
    enqueue_many=False,
    shapes=None,
    dynamic_pad=False,
    allow_smaller_final_batch=False,
    shared_name=None,
    name=None
)
",Conditionally creates batches of tensors based on keep_input. (deprecated)
tf.compat.v1.train.maybe_batch_join,"tf.compat.v1.train.maybe_batch_join(
    tensors_list,
    keep_input,
    batch_size,
    capacity=32,
    enqueue_many=False,
    shapes=None,
    dynamic_pad=False,
    allow_smaller_final_batch=False,
    shared_name=None,
    name=None
)
",Runs a list of tensors to conditionally fill a queue to create batches. (deprecated)
tf.compat.v1.train.maybe_shuffle_batch,"tf.compat.v1.train.maybe_shuffle_batch(
    tensors,
    batch_size,
    capacity,
    min_after_dequeue,
    keep_input,
    num_threads=1,
    seed=None,
    enqueue_many=False,
    shapes=None,
    allow_smaller_final_batch=False,
    shared_name=None,
    name=None
)
",Creates batches by randomly shuffling conditionally-enqueued tensors. (deprecated)
tf.compat.v1.train.maybe_shuffle_batch_join,"tf.compat.v1.train.maybe_shuffle_batch_join(
    tensors_list,
    batch_size,
    capacity,
    min_after_dequeue,
    keep_input,
    seed=None,
    enqueue_many=False,
    shapes=None,
    allow_smaller_final_batch=False,
    shared_name=None,
    name=None
)
",Create batches by randomly shuffling conditionally-enqueued tensors. (deprecated)
tf.compat.v1.train.natural_exp_decay,"tf.compat.v1.train.natural_exp_decay(
    learning_rate,
    global_step,
    decay_steps,
    decay_rate,
    staircase=False,
    name=None
)
",Applies natural exponential decay to the initial learning rate.
tf.compat.v1.train.noisy_linear_cosine_decay,"tf.compat.v1.train.noisy_linear_cosine_decay(
    learning_rate,
    global_step,
    decay_steps,
    initial_variance=1.0,
    variance_decay=0.55,
    num_periods=0.5,
    alpha=0.0,
    beta=0.001,
    name=None
)
",Applies noisy linear cosine decay to the learning rate.
tf.compat.v1.train.piecewise_constant,"tf.compat.v1.train.piecewise_constant(
    x, boundaries, values, name=None
)
",Piecewise constant from boundaries and interval values.View aliases
tf.compat.v1.train.piecewise_constant,"tf.compat.v1.train.piecewise_constant(
    x, boundaries, values, name=None
)
",Piecewise constant from boundaries and interval values.View aliases
tf.compat.v1.train.polynomial_decay,"tf.compat.v1.train.polynomial_decay(
    learning_rate,
    global_step,
    decay_steps,
    end_learning_rate=0.0001,
    power=1.0,
    cycle=False,
    name=None
)
",Applies a polynomial decay to the learning rate.
tf.compat.v1.train.QueueRunner,"tf.compat.v1.train.QueueRunner(
    queue=None,
    enqueue_ops=None,
    close_op=None,
    cancel_op=None,
    queue_closed_exception_types=None,
    queue_runner_def=None,
    import_scope=None
)
","Holds a list of enqueue operations for a queue, each to be run in a thread.View aliases"
tf.compat.v1.train.add_queue_runner,"tf.compat.v1.train.add_queue_runner(
    qr, collection=ops.GraphKeys.QUEUE_RUNNERS
)
",Adds a QueueRunner to a collection in the graph. (deprecated)View aliases
tf.compat.v1.train.start_queue_runners,"tf.compat.v1.train.start_queue_runners(
    sess=None,
    coord=None,
    daemon=True,
    start=True,
    collection=ops.GraphKeys.QUEUE_RUNNERS
)
",Starts all queue runners collected in the graph. (deprecated)View aliases
tf.compat.v1.train.range_input_producer,"tf.compat.v1.train.range_input_producer(
    limit,
    num_epochs=None,
    shuffle=True,
    seed=None,
    capacity=32,
    shared_name=None,
    name=None
)
",Produces the integers from 0 to limit-1 in a queue. (deprecated)
tf.compat.v1.train.remove_checkpoint,"tf.compat.v1.train.remove_checkpoint(
    checkpoint_prefix,
    checkpoint_format_version=saver_pb2.SaverDef.V2,
    meta_graph_suffix='meta'
)
",Removes a checkpoint given by checkpoint_prefix. (deprecated)
tf.compat.v1.train.replica_device_setter,"tf.compat.v1.train.replica_device_setter(
    ps_tasks=0,
    ps_device='/job:ps',
    worker_device='/job:worker',
    merge_devices=True,
    cluster=None,
    ps_ops=None,
    ps_strategy=None
)
",Return a device function to use when building a Graph for replicas.
tf.compat.v1.train.sdca_fprint,"tf.compat.v1.train.sdca_fprint(
    input, name=None
)
",Computes fingerprints of the input strings.
tf.compat.v1.train.sdca_optimizer,"tf.compat.v1.train.sdca_optimizer(
    sparse_example_indices,
    sparse_feature_indices,
    sparse_feature_values,
    dense_features,
    example_weights,
    example_labels,
    sparse_indices,
    sparse_weights,
    dense_weights,
    example_state_data,
    loss_type,
    l1,
    l2,
    num_loss_partitions,
    num_inner_iterations,
    adaptative=True,
    name=None
)
",Distributed version of Stochastic Dual Coordinate Ascent (SDCA) optimizer for
tf.compat.v1.train.sdca_shrink_l1,"tf.compat.v1.train.sdca_shrink_l1(
    weights, l1, l2, name=None
)
",Applies L1 regularization shrink step on the parameters.
tf.compat.v1.train.shuffle_batch,"tf.compat.v1.train.shuffle_batch(
    tensors,
    batch_size,
    capacity,
    min_after_dequeue,
    num_threads=1,
    seed=None,
    enqueue_many=False,
    shapes=None,
    allow_smaller_final_batch=False,
    shared_name=None,
    name=None
)
",Creates batches by randomly shuffling tensors. (deprecated)
tf.compat.v1.train.shuffle_batch_join,"tf.compat.v1.train.shuffle_batch_join(
    tensors_list,
    batch_size,
    capacity,
    min_after_dequeue,
    seed=None,
    enqueue_many=False,
    shapes=None,
    allow_smaller_final_batch=False,
    shared_name=None,
    name=None
)
",Create batches by randomly shuffling tensors. (deprecated)
tf.compat.v1.train.slice_input_producer,"tf.compat.v1.train.slice_input_producer(
    tensor_list,
    num_epochs=None,
    shuffle=True,
    seed=None,
    capacity=32,
    shared_name=None,
    name=None
)
",Produces a slice of each Tensor in tensor_list. (deprecated)
tf.compat.v1.train.start_queue_runners,"tf.compat.v1.train.start_queue_runners(
    sess=None,
    coord=None,
    daemon=True,
    start=True,
    collection=ops.GraphKeys.QUEUE_RUNNERS
)
",Starts all queue runners collected in the graph. (deprecated)View aliases
tf.compat.v1.train.string_input_producer,"tf.compat.v1.train.string_input_producer(
    string_tensor,
    num_epochs=None,
    shuffle=True,
    seed=None,
    capacity=32,
    shared_name=None,
    name=None,
    cancel_op=None
)
",Output strings (e.g. filenames) to a queue for an input pipeline. (deprecated)
tf.compat.v1.train.summary_iterator,"tf.compat.v1.train.summary_iterator(
    path
)
",Returns a iterator for reading Event protocol buffers from an event file.
tf.compat.v1.train.update_checkpoint_state,"tf.compat.v1.train.update_checkpoint_state(
    save_dir,
    model_checkpoint_path,
    all_model_checkpoint_paths=None,
    latest_filename=None,
    all_model_checkpoint_timestamps=None,
    last_preserved_timestamp=None
)
",Updates the content of the 'checkpoint' file. (deprecated)
tf.compat.v1.train.warm_start,"tf.compat.v1.train.warm_start(
    ckpt_to_initialize_from,
    vars_to_warm_start='.*',
    var_name_to_vocab_info=None,
    var_name_to_prev_var_name=None
)
",Warm-starts a model using the given settings.
tf.io.write_graph,"tf.io.write_graph(
    graph_or_graph_def, logdir, name, as_text=True
)
",Writes a graph proto to a file.View aliases
tf.compat.v1.trainable_variables,"tf.compat.v1.trainable_variables(
    scope=None
)
",Returns all variables created with trainable=True.
tf.compat.v1.transpose,"tf.compat.v1.transpose(
    a, perm=None, name='transpose', conjugate=False
)
",Transposes a.
tf.math.truediv,"tf.math.truediv(
    x, y, name=None
)
",Divides x / y elementwise (using Python 3 division operator semantics).View aliases
tf.random.truncated_normal,"tf.random.truncated_normal(
    shape,
    mean=0.0,
    stddev=1.0,
    dtype=tf.dtypes.float32,
    seed=None,
    name=None
)
",Outputs random values from a truncated normal distribution.View aliases
tf.compat.v1.truncated_normal_initializer,"tf.compat.v1.truncated_normal_initializer(
    mean=0.0,
    stddev=1.0,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates a truncated normal distribution.View aliases
tf.truncatediv,"tf.truncatediv(
    x, y, name=None
)
",Returns x / y element-wise for integer types.View aliases
tf.truncatemod,"tf.truncatemod(
    x, y, name=None
)
",Returns element-wise remainder of division. This emulates C semantics in thatView aliases
tf.compat.v1.tuple,"tf.compat.v1.tuple(
    tensors, name=None, control_inputs=None
)
",Group tensors together.
tf.type_spec_from_value,"tf.type_spec_from_value(
    value
) -> tf.TypeSpec
",Returns a tf.TypeSpec that represents the given value.View aliases
tf.compat.v1.uniform_unit_scaling_initializer,"tf.compat.v1.uniform_unit_scaling_initializer(
    factor=1.0,
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors without scaling variance.View aliases
tf.unique,"tf.unique(
    x,
    out_idx=tf.dtypes.int32,
    name=None
)
",Finds unique elements in a 1-D tensor.View aliases
tf.unique_with_counts,"tf.unique_with_counts(
    x,
    out_idx=tf.dtypes.int32,
    name=None
)
",Finds unique elements in a 1-D tensor.View aliases
tf.unravel_index,"tf.unravel_index(
    indices, dims, name=None
)
",Converts an array of flat indices into a tuple of coordinate arrays.View aliases
tf.math.unsorted_segment_max,"tf.math.unsorted_segment_max(
    data, segment_ids, num_segments, name=None
)
",Computes the maximum along segments of a tensor.View aliases
tf.math.unsorted_segment_mean,"tf.math.unsorted_segment_mean(
    data, segment_ids, num_segments, name=None
)
",Computes the mean along segments of a tensor.View aliases
tf.math.unsorted_segment_min,"tf.math.unsorted_segment_min(
    data, segment_ids, num_segments, name=None
)
",Computes the minimum along segments of a tensor.View aliases
tf.math.unsorted_segment_prod,"tf.math.unsorted_segment_prod(
    data, segment_ids, num_segments, name=None
)
",Computes the product along segments of a tensor.View aliases
tf.math.unsorted_segment_sqrt_n,"tf.math.unsorted_segment_sqrt_n(
    data, segment_ids, num_segments, name=None
)
",Computes the sum along segments of a tensor divided by the sqrt(N).View aliases
tf.math.unsorted_segment_sum,"tf.math.unsorted_segment_sum(
    data, segment_ids, num_segments, name=None
)
",Computes the sum along segments of a tensor.View aliases
tf.unstack,"tf.unstack(
    value, num=None, axis=0, name='unstack'
)
",Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.View aliases
tf.compat.v1.variable_axis_size_partitioner,"tf.compat.v1.variable_axis_size_partitioner(
    max_shard_bytes, axis=0, bytes_per_string_element=16, max_shards=None
)
",Get a partitioner for VariableScope to keep shards below max_shard_bytes.
tf.compat.v1.variable_scope,"tf.compat.v1.variable_scope(
    name_or_scope,
    default_name=None,
    values=None,
    initializer=None,
    regularizer=None,
    caching_device=None,
    partitioner=None,
    custom_getter=None,
    reuse=None,
    dtype=None,
    use_resource=None,
    constraint=None,
    auxiliary_name_scope=True
)
",A context manager for defining ops that creates variables (layers).
tf.compat.v1.variables_initializer,"tf.compat.v1.variables_initializer(
    var_list, name='init'
)
",Returns an Op that initializes a list of variables.View aliases
tf.compat.v1.keras.initializers.VarianceScaling,"tf.compat.v1.keras.initializers.VarianceScaling(
    scale=1.0,
    mode='fan_in',
    distribution='truncated_normal',
    seed=None,
    dtype=tf.dtypes.float32
)
",Initializer capable of adapting its scale to the shape of weights tensors.View aliases
tf.vectorized_map,"tf.vectorized_map(
    fn, elems, fallback_to_while_loop=True, warn=True
)
",Parallel map on the list of tensors unpacked from elems on dimension 0.View aliases
tf.compat.v1.verify_tensor_all_finite,"tf.compat.v1.verify_tensor_all_finite(
    t=None, msg=None, name=None, x=None, message=None
)
",Assert that the tensor does not contain any NaN's or Inf's.View aliases
tf.compat.v1.where,"tf.compat.v1.where(
    condition, x=None, y=None, name=None
)
","Return the elements, either from x or y, depending on the condition."
tf.where,"tf.where(
    condition, x=None, y=None, name=None
)
","Returns the indices of non-zero elements, or multiplexes x and y.View aliases"
tf.where,"tf.where([True, False, False, True],","Returns the indices of non-zero elements, or multiplexes x and y.View aliasestf.where(    condition, x=None, y=None, name=None)Used in the notebooksThis operation has two modes:Return the indices of non-zero elementsMultiplex 1. Return the indices of non-zero elementsNote: In this mode If x and y are not provided (both are None):tf.where will return the indices of condition that are non-zero,in the form of a 2-D tensor with shape [n, d], where n is the number ofnon-zero elements in condition (tf.count_nonzero(condition)), and d isthe number of axes of condition (tf.rank(condition)).Indices are output in row-major order. The condition can have a dtype oftf.bool, or any numeric dtype.Here condition is a 1-axis bool tensor with 2 True values. The resulthas a shape of [2,1]tf.where([True, False, False, True]).numpy()array([[0],       [3]])Here condition is a 2-axis integer tensor, with 3 non-zero values. Theresult has a shape of [3, 2].tf.where([[1, 0, 0], [1, 0, 1]]).numpy()array([[0, 0],       [1, 0],       [1, 2]])Here condition is a 3-axis float tensor, with 5 non-zero values. The outputshape is [5, 3].float_tensor = [[[0.1, 0], [0, 2.2], [3.5, 1e6]],                [[0,   0], [0,   0], [99,    0]]]tf.where(float_tensor).numpy()array([[0, 0, 0],       [0, 1, 1],       [0, 2, 0],       [0, 2, 1],       [1, 2, 0]])These indices are the same that tf.sparse.SparseTensor would use torepresent the condition tensor:sparse = tf.sparse.from_dense(float_tensor)sparse.indices.numpy()array([[0, 0, 0],       [0, 1, 1],       [0, 2, 0],       [0, 2, 1],       [1, 2, 0]])A complex number is considered non-zero if either the real or imaginarycomponent is non-zero:tf.where([complex(0.), complex(1.), 0+1j, 1+1j]).numpy()array([[1],       [2],       [3]])2. Multiplex x and yNote: In this mode If x and y are also provided (both have non-None values) the conditiontensor acts as a mask that chooses whether the correspondingelement / row in the output should be taken from x (if the element incondition is True) or y (if it is False).The shape of the result is formed bybroadcastingtogether the shapes of condition, x, and y.When all three inputs have the same size, each is handled element-wise."
tf.where,"tf.where([True, False, True],","Returns the indices of non-zero elements, or multiplexes x and y.View aliasestf.where(    condition, x=None, y=None, name=None)Used in the notebooksThis operation has two modes:Return the indices of non-zero elementsMultiplex 1. Return the indices of non-zero elementsNote: In this mode If x and y are not provided (both are None):tf.where will return the indices of condition that are non-zero,in the form of a 2-D tensor with shape [n, d], where n is the number ofnon-zero elements in condition (tf.count_nonzero(condition)), and d isthe number of axes of condition (tf.rank(condition)).Indices are output in row-major order. The condition can have a dtype oftf.bool, or any numeric dtype.Here condition is a 1-axis bool tensor with 2 True values. The resulthas a shape of [2,1]tf.where([True, False, False, True]).numpy()array([[0],       [3]])Here condition is a 2-axis integer tensor, with 3 non-zero values. Theresult has a shape of [3, 2].tf.where([[1, 0, 0], [1, 0, 1]]).numpy()array([[0, 0],       [1, 0],       [1, 2]])Here condition is a 3-axis float tensor, with 5 non-zero values. The outputshape is [5, 3].float_tensor = [[[0.1, 0], [0, 2.2], [3.5, 1e6]],                [[0,   0], [0,   0], [99,    0]]]tf.where(float_tensor).numpy()array([[0, 0, 0],       [0, 1, 1],       [0, 2, 0],       [0, 2, 1],       [1, 2, 0]])These indices are the same that tf.sparse.SparseTensor would use torepresent the condition tensor:sparse = tf.sparse.from_dense(float_tensor)sparse.indices.numpy()array([[0, 0, 0],       [0, 1, 1],       [0, 2, 0],       [0, 2, 1],       [1, 2, 0]])A complex number is considered non-zero if either the real or imaginarycomponent is non-zero:tf.where([complex(0.), complex(1.), 0+1j, 1+1j]).numpy()array([[1],       [2],       [3]])2. Multiplex x and yNote: In this mode If x and y are also provided (both have non-None values) the conditiontensor acts as a mask that chooses whether the correspondingelement / row in the output should be taken from x (if the element incondition is True) or y (if it is False).The shape of the result is formed bybroadcastingtogether the shapes of condition, x, and y.When all three inputs have the same size, each is handled element-wise.tf.where([True, False, False, True],         [1, 2, 3, 4],         [100, 200, 300, 400]).numpy()array([  1, 200, 300,   4], dtype=int32)There are two main rules for broadcasting:If a tensor has fewer axes than the others, length-1 axes are added to theleft of the shape.Axes with length-1 are streched to match the coresponding axes of the othertensors.A length-1 vector is streched to match the other vectors:tf.where([True, False, False, True], [1, 2, 3, 4], [100]).numpy()array([  1, 100, 100,   4], dtype=int32)A scalar is expanded to match the other arguments:tf.where([[True, False], [False, True]], [[1, 2], [3, 4]], 100).numpy()array([[  1, 100], [100,   4]], dtype=int32)tf.where([[True, False], [False, True]], 1, 100).numpy()array([[  1, 100], [100,   1]], dtype=int32)A scalar condition returns the complete x or y tensor, withbroadcasting applied.tf.where(True, [1, 2, 3, 4], 100).numpy()array([1, 2, 3, 4], dtype=int32)tf.where(False, [1, 2, 3, 4], 100).numpy()array([100, 100, 100, 100], dtype=int32)For a non-trivial example of broadcasting, here condition has a shape of[3], x has a shape of [3,3], and y has a shape of [3,1].Broadcasting first expands the shape of condition to [1,3]. The finalbroadcast shape is [3,3]. condition will select columns from x and y.Since y only has one column, all columns from y will be identical."
tf.compat.v1.while_loop,"tf.compat.v1.while_loop(
    cond,
    body,
    loop_vars,
    shape_invariants=None,
    parallel_iterations=10,
    back_prop=True,
    swap_memory=False,
    name=None,
    maximum_iterations=None,
    return_same_structure=False
)
",Repeat body while the condition cond is true.
tf.compat.v1.wrap_function,"tf.compat.v1.wrap_function(
    fn, signature, name=None
)
",Wraps the TF 1.x function fn into a graph function.
tf.io.write_file,"tf.io.write_file(
    filename, contents, name=None
)
",Writes contents to the file at input filename.View aliases
tf.xla.experimental.compile,"tf.xla.experimental.compile(
    computation, inputs=None
)
",Builds an operator that compiles and runs computation with XLA. (deprecated)View aliases
tf.zeros,"tf.zeros(
    shape,
    dtype=tf.dtypes.float32,
    name=None
)
",Creates a tensor with all elements set to zero.View aliases
tf.compat.v1.keras.initializers.Zeros,"tf.compat.v1.keras.initializers.Zeros(
    dtype=tf.dtypes.float32
)
",Initializer that generates tensors initialized to 0.View aliases
tf.compat.v1.zeros_like,"tf.compat.v1.zeros_like(
    tensor, dtype=None, name=None, optimize=True
)
",Creates a tensor with all elements set to zero.
tf.math.zeta,"tf.math.zeta(
    x, q, name=None
)
","Compute the Hurwitz zeta function \(\zeta(x, q)\).View aliases"
